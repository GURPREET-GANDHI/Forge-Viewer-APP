/*!
 * LMV v7.11.0
 * 
 * Copyright 2020 Autodesk, Inc.
 * All rights reserved.
 * 
 * This computer source code and related instructions and comments are the
 * unpublished confidential and proprietary information of Autodesk, Inc.
 * and are protected under Federal copyright and state trade secret law.
 * They may not be disclosed to, copied or used by any third party without
 * the prior written consent of Autodesk, Inc.
 * 
 * Autodesk Forge Viewer Usage Limitations:
 * 
 * The Autodesk Forge viewer can only be used to view files generated by
 * Autodesk Forge services. The Autodesk Forge Viewer JavaScript must be
 * delivered from an Autodesk hosted URL.
 */
Autodesk.Extensions.MemoryLimited =
/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = "./extensions/MemoryLimited/MemoryLimited.js");
/******/ })
/************************************************************************/
/******/ ({

/***/ "./extensions/MemoryLimited/MemoryLimited.css":
/*!****************************************************!*\
  !*** ./extensions/MemoryLimited/MemoryLimited.css ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {


var content = __webpack_require__(/*! !../../node_modules/css-loader!../../node_modules/sass-loader/dist/cjs.js!./MemoryLimited.css */ "./node_modules/css-loader/index.js!./node_modules/sass-loader/dist/cjs.js!./extensions/MemoryLimited/MemoryLimited.css");

if(typeof content === 'string') content = [[module.i, content, '']];

var transform;
var insertInto;



var options = {"hmr":true}

options.transform = transform
options.insertInto = undefined;

var update = __webpack_require__(/*! ../../node_modules/style-loader/lib/addStyles.js */ "./node_modules/style-loader/lib/addStyles.js")(content, options);

if(content.locals) module.exports = content.locals;

if(false) {}

/***/ }),

/***/ "./extensions/MemoryLimited/MemoryLimited.js":
/*!***************************************************!*\
  !*** ./extensions/MemoryLimited/MemoryLimited.js ***!
  \***************************************************/
/*! exports provided: MemoryLimitedExtension, SvfLoaderML, SvfPagingProxy, InputStreamML */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "MemoryLimitedExtension", function() { return MemoryLimitedExtension; });
/* harmony import */ var _file_loaders_main_SvfLoaderML__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./file-loaders/main/SvfLoaderML */ "./extensions/MemoryLimited/file-loaders/main/SvfLoaderML.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SvfLoaderML", function() { return _file_loaders_main_SvfLoaderML__WEBPACK_IMPORTED_MODULE_0__["SvfLoaderML"]; });

/* harmony import */ var _file_loaders_main_SvfPagingProxy__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./file-loaders/main/SvfPagingProxy */ "./extensions/MemoryLimited/file-loaders/main/SvfPagingProxy.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "SvfPagingProxy", function() { return _file_loaders_main_SvfPagingProxy__WEBPACK_IMPORTED_MODULE_1__["SvfPagingProxy"]; });

/* harmony import */ var _file_loaders_lmvtk_common_InputStreamML__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./file-loaders/lmvtk/common/InputStreamML */ "./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js");
/* harmony reexport (safe) */ __webpack_require__.d(__webpack_exports__, "InputStreamML", function() { return _file_loaders_lmvtk_common_InputStreamML__WEBPACK_IMPORTED_MODULE_2__["InputStreamML"]; });

/* harmony import */ var _MemoryLimited_css__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./MemoryLimited.css */ "./extensions/MemoryLimited/MemoryLimited.css");
/* harmony import */ var _MemoryLimited_css__WEBPACK_IMPORTED_MODULE_3___default = /*#__PURE__*/__webpack_require__.n(_MemoryLimited_css__WEBPACK_IMPORTED_MODULE_3__);






 // IMPORTANT!!

var av = Autodesk.Viewing;
var avp = Autodesk.Viewing.Private;

/**
                                     * Adds limited memory support for SVF files
                                     * 
                                     * The extension id is: `Autodesk.MemoryLimited`
                                     * 
                                     * @example
                                     *   viewer.loadExtension('Autodesk.MemoryLimited')
                                     * 
                                     * @memberof Autodesk.Viewing.Extensions
                                     * @alias Autodesk.Viewing.Extensions.MemoryLimited.MemoryLimitedExtension
                                     * @see {@link Autodesk.Viewing.Extension} for common inherited methods.
                                     * @constructor
                                     */
function MemoryLimitedExtension(viewer, options) {
  av.Extension.call(this, viewer, options);
  this.name = 'memory-limited';
  this._registerOriginal = false;
};

MemoryLimitedExtension.prototype = Object.create(av.Extension.prototype);
MemoryLimitedExtension.prototype.constructor = MemoryLimitedExtension;

/**
                                                                        * Registers the hyperlink tool that will intercept pointer events to provide
                                                                        * hyperlinks next to specific nodes in the model.
                                                                        * 
                                                                        * @alias Autodesk.Viewing.Extensions.MemoryLimited.MemoryLimitedExtension.#load
                                                                        */
MemoryLimitedExtension.prototype.load = function () {var _this = this;
  this.updateProgressBarStyle = function (event) {
    if (event.model && event.model.loader && event.model.loader.pagingProxy)
    _this.viewer.progressbar && _this.viewer.progressbar.setStyle("memory-limited-progressbar-loading");
  };
  this._registerOriginal = av.FileLoaderManager.unregisterFileLoader("svf");
  av.FileLoaderManager.registerFileLoader("memsvf", ["svf"], _file_loaders_main_SvfLoaderML__WEBPACK_IMPORTED_MODULE_0__["SvfLoaderML"]);
  if (this._registerOriginal) {
    av.FileLoaderManager.registerFileLoader("svf", ["gltf", "glb"], avp.SvfLoader);
  }
  this.viewer.addEventListener(av.MODEL_ROOT_LOADED_EVENT, this.updateProgressBarStyle);
  return true;
};

/**
    * Unregisters the hyperlink tool.
    * 
    * @alias Autodesk.Viewing.Extensions.MemoryLimited.MemoryLimitedExtension.#unload
    */
MemoryLimitedExtension.prototype.unload = function () {
  av.FileLoaderManager.unregisterFileLoader("memsvf");
  av.FileLoaderManager.unregisterFileLoader("svf");
  if (this._registerOriginal)
  av.FileLoaderManager.registerFileLoader("svf", ["svf", "gltf", "glb"], avp.SvfLoader);
  this._registerOriginal = false;
  this.viewer.removeEventListener(av.MODEL_ROOT_LOADED_EVENT, this.updateProgressBarStyle);
  this.viewer.progressbar && this.viewer.progressbar.removeStyle("memory-limited-progressbar-loading");
  return true;
};

MemoryLimitedExtension.prototype.activate = function () {
  return false;
};

MemoryLimitedExtension.prototype.deactivate = function () {
  return false;
};

MemoryLimitedExtension.prototype.isActive = function () {
  return false;
};

/**
    * @typedef MemoryStatistics
    * @property {Number} limit The memory limit that was requested, in megabytes.
    * @property {Number} effectiveLimit The memory limit that is enforced, in megabytes.
    *  This may be larger than limit when LMV decides that limit is not large enough
    *  to load the model.
    * @property {Number} loaded The amount of memory that is currently in use, in megabytes.
    */

/**
        * Get memory statistics for memory limited mode
        * @return {MemoryStatistics|null} The memory statistics or null when there aren't any
        *  models loaded with memory limits.
        */
MemoryLimitedExtension.prototype.getMemoryInfo = function () {
  var q = this.viewer.impl.modelQueue();

  var lastMem;
  var returnValue = {
    limit: 0,
    effectiveLimit: 0,
    loaded: 0 };


  function addStats(models) {
    for (var i = 0; i < models.length; ++i) {
      var model = models[i];
      if (model.loader && model.loader.pagingProxy) {
        lastMem = model.loader.pagingProxy.getMemoryInfo();
        returnValue.limit += lastMem.limit;
        returnValue.effectiveLimit += lastMem.effectiveLimit;
        returnValue.loaded += lastMem.loaded;
      }
    }
  }

  addStats(q.getModels());
  addStats(q.getHiddenModels());
  return lastMem ? returnValue : null;
};

var ave = AutodeskNamespace("Autodesk.Viewing.Extension.MemoryLimited");
ave.MemoryLimitedExtension = MemoryLimitedExtension;
ave.SvfLoaderML = _file_loaders_main_SvfLoaderML__WEBPACK_IMPORTED_MODULE_0__["SvfLoaderML"];
ave.SvfPagingProxy = _file_loaders_main_SvfPagingProxy__WEBPACK_IMPORTED_MODULE_1__["SvfPagingProxy"];
ave.InputStreamML = _file_loaders_lmvtk_common_InputStreamML__WEBPACK_IMPORTED_MODULE_2__["InputStreamML"];

av.theExtensionManager.registerExtension('Autodesk.MemoryLimited', MemoryLimitedExtension);



/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js":
/*!*****************************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js ***!
  \*****************************************************************************/
/*! exports provided: InputStreamML */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "InputStreamML", function() { return InputStreamML; });
var pako = __webpack_require__(/*! pako */ "./node_modules/pako/index.js");

"use strict";


/** @constructor */
// This class will read value from compressed data,
// decopress only necessary data and throw away unused.
function InputStreamML(buf, usize) {

  // Offset is the offset to decompressed data.
  // byteLength is the total size of decompressed data.
  this.offset = 0;
  this.byteLength = usize;
  this.range = 0;
  // Assume the buffer is compressed.
  this.compressedBuffer = buf;
  this.compressedByteLength = buf.length;
  this.compressedOffset = 0;
  this.decompressEnd = false;
  // This is to record how many times decompress from scratch. for debug purpose.
  this.resetCount = 0;

  //We will use these shared memory arrays to
  //convert from bytes to the desired data type.
  this.convBuf = new ArrayBuffer(8);
  this.convUint8 = new Uint8Array(this.convBuf);
  this.convUint16 = new Uint16Array(this.convBuf);
  this.convInt32 = new Int32Array(this.convBuf);
  this.convUint32 = new Uint32Array(this.convBuf);
  this.convFloat32 = new Float32Array(this.convBuf);
  this.convFloat64 = new Float64Array(this.convBuf);

  // Compressed chunk size is the size for decompressing each time.
  // Decompressed chunk size is the buffer to hold decompressed data.
  this.COMPRESSED_chunk_SIZE = 512 * 1024;
  this.DECOMPRESSED_chunk_SIZE = 256 * 1024;

  // chunks for decompressed data.
  this.chunks = [];
  this.chunksByteLengthMax = 0;
  this.chunksByteLengthMin = 0;

  // Maintain chunk and chunk offset for reading current data.
  this.chunkPointer = null;
  this.chunkOffset = 0;
  // temp chunk is for reading data that stride over multiple chunks.
  this.tempchunk = {
    startIdx: 0,
    endIdx: 0,
    buffer: null };


  // Infalte for decompressing incremantally. The lib we used is pako_inflate.min.js
  this.inflate = this.getInflate();

  // Prepare first 1K data for quick access.
  this.prepare(0, 1024);
}

InputStreamML.prototype.getInflate = function () {
  if (!this.inflate) {
    this.inflate = new pako.Inflate({ level: 3, chunkSize: this.DECOMPRESSED_chunk_SIZE });

    var self = this;
    this.inflate.onData = function (chunk) {

      // Remove unused chunk for current decompressing.
      self.chunksByteLengthMax += chunk.byteLength;
      if (self.chunksByteLengthMax < self.offset) {
        chunk = null;
        self.chunksByteLengthMin = self.chunksByteLengthMax;
      }

      self.chunks.push(chunk);
    };

    this.inflate.onEnd = function () {
      self.decompressEnd = true;
      self.inflate = null;
      // Check decompressed size is expected.
      if (self.chunksByteLengthMax != self.byteLength)
      throw "Decompress error, unexpected size.";
    };
  }

  return this.inflate;
};

InputStreamML.prototype.prepare = function (off, range, donotclear) {
  // If required data hasn't decompressed yet, let's do it.
  if (this.chunksByteLengthMin > off) {
    // In this case, need to reset stream and decompress from scratch again.
    this.reset();
    this.offset = off;
    this.range = range;
  }

  // Remove unused chunks if no longer used for subsequent reading.
  if (!donotclear) {
    var idx = Math.floor(off / this.DECOMPRESSED_chunk_SIZE);
    var startIdx = Math.floor(this.chunksByteLengthMin / this.DECOMPRESSED_chunk_SIZE);
    var endIdx = this.chunks.length < idx ? this.chunks.length : idx;
    for (var i = startIdx; i < endIdx; i++) {
      this.chunks[i] = null;
    }
    this.chunksByteLengthMin = endIdx * this.DECOMPRESSED_chunk_SIZE;
  }

  // Prepare further decompressed data.
  var range = range || 1;
  var expectEnd = off + range;
  expectEnd = expectEnd > this.byteLength ? this.byteLength : expectEnd;
  var reachEnd = false;
  while (expectEnd > this.chunksByteLengthMax)
  {
    var len = this.COMPRESSED_chunk_SIZE;
    if (this.compressedOffset + len >= this.compressedByteLength) {
      len = this.compressedByteLength - this.compressedOffset;
      reachEnd = true;
    }

    // Push another compressed data chunk to decompress.
    var data = new Uint8Array(this.compressedBuffer.buffer, this.compressedOffset, len);
    this.getInflate().push(data, reachEnd);

    // Move offset forward as decompress processing.
    this.compressedOffset += len;

    if (reachEnd) {
      break;
    }
  }

};

InputStreamML.prototype.ensurechunkData = function (len) {
  // ensure the data is ready for immediate reading.
  len = len || 1;
  var chunkLen = this.chunks.length;

  var chunkIdx = Math.floor(this.offset / this.DECOMPRESSED_chunk_SIZE);
  var endIdx = Math.floor((this.offset + len - 1) / this.DECOMPRESSED_chunk_SIZE);
  if (endIdx >= chunkLen) {
    var length = (endIdx - chunkLen + 1) * this.DECOMPRESSED_chunk_SIZE;
    // When do another prepare in the middle of ensuring data,
    // do not clear any chunk yet, as it may be still in use.
    this.prepare(this.DECOMPRESSED_chunk_SIZE * chunkLen, length, true);
  }

  if (chunkIdx < endIdx) {
    if (this.tempchunk.startIdx > chunkIdx || this.tempchunk.endIdx < endIdx) {
      var size = (endIdx - chunkIdx + 1) * this.DECOMPRESSED_chunk_SIZE;
      this.tempchunk.buffer = new Uint8Array(size);
      var pos = 0;
      for (var i = chunkIdx; i <= endIdx; i++) {
        this.tempchunk.buffer.set(this.chunks[i], pos);
        pos += this.DECOMPRESSED_chunk_SIZE;
      }
      this.tempchunk.startIdx = chunkIdx;
      this.tempchunk.endIdx = endIdx;
    }
    this.chunkPointer = this.tempchunk.buffer;
  } else
  {
    this.chunkPointer = this.chunks[chunkIdx];
  }

  this.chunkOffset = this.offset - chunkIdx * this.DECOMPRESSED_chunk_SIZE;
  this.offset += len;
};

InputStreamML.prototype.seek = function (off, range, donotclear) {
  this.offset = off;
  this.range = range;
  this.prepare(off, range, donotclear);
};

InputStreamML.prototype.getBytes = function (len) {
  this.ensurechunkData(len);
  var ret = new Uint8Array(this.chunkPointer.buffer, this.chunkOffset, len);

  return ret;
};

InputStreamML.prototype.getVarints = function () {
  var b;
  var value = 0;
  var shiftBy = 0;
  do {
    this.ensurechunkData();
    b = this.chunkPointer[this.chunkOffset];
    value |= (b & 0x7f) << shiftBy;
    shiftBy += 7;
  } while (b & 0x80);
  return value;
};

InputStreamML.prototype.getUint8 = function () {
  this.ensurechunkData();
  return this.chunkPointer[this.chunkOffset];
};

InputStreamML.prototype.getUint16 = function () {

  this.ensurechunkData();
  this.convUint8[0] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  this.convUint8[1] = this.chunkPointer[this.chunkOffset];
  return this.convUint16[0];
};

InputStreamML.prototype.getInt16 = function () {
  var tmp = this.getUint16();
  //make negative integer if the ushort is negative
  if (tmp > 0x7fff)
  tmp = tmp | 0xffff0000;
  return tmp;
};

InputStreamML.prototype.getInt32 = function () {

  var dst = this.convUint8;

  this.ensurechunkData();
  dst[0] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[1] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[2] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[3] = this.chunkPointer[this.chunkOffset];

  return this.convInt32[0];
};

InputStreamML.prototype.getUint32 = function () {

  var dst = this.convUint8;

  this.ensurechunkData();
  dst[0] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[1] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[2] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[3] = this.chunkPointer[this.chunkOffset];

  return this.convUint32[0];
};

InputStreamML.prototype.getFloat32 = function () {

  var dst = this.convUint8;

  this.ensurechunkData();
  dst[0] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[1] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[2] = this.chunkPointer[this.chunkOffset];
  this.ensurechunkData();
  dst[3] = this.chunkPointer[this.chunkOffset];

  return this.convFloat32[0];
};

InputStreamML.prototype.getFloat64 = function () {

  var dst = this.convUint8;
  for (var i = 0; i < 8; i++) {
    this.ensurechunkData();
    dst[i] = this.chunkPointer[this.chunkOffset];
  }

  return this.convFloat64[0];
};

InputStreamML.prototype.getString = function (len) {
  var dst = "";
  this.ensurechunkData(len);
  var src = this.chunkPointer;

  for (var i = this.chunkOffset, iEnd = this.chunkOffset + len; i < iEnd; i++) {
    dst += String.fromCharCode(src[i]);
  }

  var res;
  try {
    res = decodeURIComponent(escape(dst));
  } catch (e) {
    res = dst;
    debug("Failed to decode string " + res);
  }

  return res;
};

InputStreamML.prototype.reset = function (buf) {
  this.resetCount++;
  debug("InputStream Less Reset: " + this.resetCount);

  if (buf) {
    this.compressedBuffer = buf;
    this.compressedByteLength = buf.length;
  }

  this.offset = 0;
  this.chunks = [];
  this.chunksByteLengthMax = 0;
  this.chunksByteLengthMin = 0;
  this.compressedOffset = 0;
  this.decompressEnd = false;
  this.chunkPointer = null;
  this.chunkOffset = 0;
  this.inflate = null;

  this.tempchunk.startIdx = 0;
  this.tempchunk.endIdx = 0;
  this.tempchunk.buffer = null;
};

/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/main/EventTypes.js":
/*!******************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/main/EventTypes.js ***!
  \******************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


var av = module.exports;

/**
                          * Fired when fragments are loaded on demand
                          * @event Autodesk.Viewing#FRAGMENTS_LOADED_EVENT
                          * @property {Model}    model - The model that loaded the fragment
                          * @property {function} getFragIds - A function used to return the list of fragment ids loaded
                          * @property {Object}   data - Data use to generate the fragment ids
                          */
av.FRAGMENTS_LOADED_EVENT = 'fragmentLoaded';

/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/main/SvfLoaderML.js":
/*!*******************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/main/SvfLoaderML.js ***!
  \*******************************************************************/
/*! exports provided: SvfLoaderML */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SvfLoaderML", function() { return SvfLoaderML; });
/* harmony import */ var _SvfPagingProxy__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./SvfPagingProxy */ "./extensions/MemoryLimited/file-loaders/main/SvfPagingProxy.js");
/* harmony import */ var _WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./WorkerCreatorML */ "./extensions/MemoryLimited/file-loaders/main/WorkerCreatorML.js");
/* harmony import */ var _WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1__);
/* harmony import */ var _envinit_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./envinit.js */ "./extensions/MemoryLimited/file-loaders/main/envinit.js");
/* harmony import */ var _render_ModelML__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../render/ModelML */ "./extensions/MemoryLimited/render/ModelML.js");
/* harmony import */ var _EventTypes__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./EventTypes */ "./extensions/MemoryLimited/file-loaders/main/EventTypes.js");
/* harmony import */ var _EventTypes__WEBPACK_IMPORTED_MODULE_4___default = /*#__PURE__*/__webpack_require__.n(_EventTypes__WEBPACK_IMPORTED_MODULE_4__);
/* harmony import */ var _render_DbidFragmentMap__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../render/DbidFragmentMap */ "./extensions/MemoryLimited/render/DbidFragmentMap.js");







var av = Autodesk.Viewing;
var avp = av.Private;

var NUM_WORKER_THREADS = av.isNodeJS() ? 10 : av.isMobileDevice() ? 2 : 6;
var WORKER_LOAD_GEOMETRY = "LOAD_GEOMETRY";
var WORKER_LOAD_SVF = "LOAD_SVF";
var WORKER_CALCULATE_LOAD_ORDER = "CALCULATE_LOAD_ORDER";
// This limit in MB is how much memory needs to be available
// to load textures. The texture loader tries to squeeze
// all textures into 32MB, so this limit should be larger than that.
var MOBILE_TEXTURE_LIMIT = 50;

var GEOM_PACK_SIZE_FACTOR = 0.7; // Approximate ratio of geometry size to uncompressed pack file size

var MEGA = 1024 * 1024;

// Overhead constants. The total overhead is calculated as
// <#meshes> * MESH_OVERHEAD + <#fragments> * FRAG_OVERHEAD
var MESH_OVERHEAD = 224; // Fixed overhead per mesh
var FRAG_OVERHEAD = 134; // Fixed overhead per fragment

var _fragLoadedEvent = {
  type: _EventTypes__WEBPACK_IMPORTED_MODULE_4__["FRAGMENTS_LOADED_EVENT"],
  model: null,
  data: null,
  getFragIds: function getFragIds() {
    if (this.fragIds)
    return this.fragIds;

    var rm = this.model;
    if (!rm || !this.data || !this.data.meshes)
    return null;

    var fragIds = this.fragIds = [];
    var packId = this.data.packId;
    var meshIndex = 0;

    var svf = rm.getData();
    var fragments = svf.fragments;
    var meshesLength = this.data.meshes.length;

    for (meshIndex = 0; meshIndex < meshesLength; ++meshIndex) {
      //Find all fragments that instance this mesh
      var meshid = packId + ":" + meshIndex++;

      var fragIndexes = fragments.mesh2frag[meshid];
      if (fragIndexes === undefined)
      return;

      if (Array.isArray(fragIndexes)) {
        fragIndexes.forEach(function (fragId) {
          fragIds.push(fragId);
        });
      } else
      fragIds.push(fragIndexes);
    }

    return fragIds;
  } };


var fireFragmentsLoadedEvent = function fireFragmentsLoadedEvent(loader, data) {
  _fragLoadedEvent.model = loader.model;
  _fragLoadedEvent.data = data;
  loader.viewer3DImpl.api.dispatchEvent(_fragLoadedEvent);
};

var SvfLoader = avp.SvfLoader;

function calculateDefaultMemoryLimit() {
  if (av.isAndroidDevice())
  return 195;
  if (av.isIOSDevice())
  return 150;
  // Firefox on MacOs or Windows supports lots of memory
  if (av.isFirefox())
  return 0; // 0 means disable memory limited
  // Chrome on the Mac supports lots of memory
  if (av.isMac() && av.isChrome())
  return 0; // 0 means disable memory limited
  // Safari on Mac support a good bit of memory.
  if (av.isSafari())
  return 2048;

  return 1024;
}

/** @constructor */
var SvfLoaderML = function SvfLoaderML(parent, config) {
  SvfLoader.call(this, parent, config);

  var memoryOpts = Object(_envinit_js__WEBPACK_IMPORTED_MODULE_2__["processMemoryOptions"])(parent, config);
  var options = this.memoryOpts = {
    debug: {} };

  if (!av.isNodeJS()) {
    // Default on demand loading if not node.js
    options.limit = calculateDefaultMemoryLimit();
    options.onDemandLoading = true;

    // Turn on demand loading off if we get a memory configuration without a limit
    // or the limit is 0.
    if (memoryOpts) {
      options.debug = Object.assign({}, memoryOpts.debug);
      var newLimit = memoryOpts.hasOwnProperty("limit") ? memoryOpts.limit : options.limit;
      if ((newLimit | 0) > 0) {
        options.limit = newLimit | 0;
      } else if (newLimit == 0) {
        options.onDemandLoading = false;
        options.debug.force = false;
      } else {
        avp.logger.warn("Memory limit, " + newLimit + ", is invalid - ignored");
      }
    }
  }
};

SvfLoaderML.prototype = Object.create(SvfLoader.prototype);

SvfLoaderML.prototype.dtor = function () {

  // 1. load order worker can be cancelled.
  if (this.svfLoadOrderWorker) {
    this.svfLoadOrderWorker.terminate();
    this.svfLoadOrderWorker = null;
    avp.logger.debug("SVF loader dtor: on load order worker.");
  }

  // 2. Any on demand jobs can be cancelled.
  if (this.pagingProxy) {
    this.pagingProxy.dtor();
    this.pagingProxy = null;
  }

  // Call super class dtor
  SvfLoader.prototype.dtor.call(this);
};

// We don't use the same mechanism for workers that SvfLoader does,
// So we can just continue the load without doing anything else.
SvfLoaderML.prototype.initWorkerScript = _WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1__["initWorkerScriptML"];

// Create a worker.
SvfLoaderML.prototype.createWorkerWithIntercept = function () {var _this = this;
  var wr = Object(_WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1__["createWorkerWithInterceptML"])();
  // We need to handle WORKER_LOAD_SVF messages special to pass additional
  // options to the work thread.
  wr.doOperation = function (msg) {
    if (msg.operation === WORKER_LOAD_SVF) {
      var optLoad = _this.memoryOpts.onDemandLoading || !!_this.memoryOpts.debug.memoryOptimizedSvfLoading;
      if (optLoad) {
        msg.perfOpt = {
          memoryOptimizedSvfLoading: optLoad,
          forceMemoryOptimizedMode: !!_this.memoryOpts.debug.forceMemoryOptimizedModeOnSvfLoading };

      }
    }
    wr.postMessage(msg);
  };
  return wr;
};

// Start loading the packfiles with the workers
SvfLoaderML.prototype.startWorkers = function () {
  if (this.pagingProxy) {
    // On demand loading is enabled, then
    // Defer to launch jobs for loading some geometry packs,
    // until the viewer really need them.
    avp.logger.debug("[On Demand Loading]: Enabled.");
    this.loadedPacksCount = 0;
  } else
  {
    // Start works normally
    SvfLoader.prototype.startWorkers.call(this);
  }
};

// create and initialize the model
SvfLoaderML.prototype.createModel = function (svf) {
  // Create the API Model object and its render proxy
  var model = this.model = this.pagingProxy ? new _render_ModelML__WEBPACK_IMPORTED_MODULE_3__["ModelML"](svf) : new av.Model(svf);
  model.loader = this;

  model.initialize(this.pagingProxy);
  return model;
};

SvfLoaderML.prototype.loadFile = function (path, options, onDone, onWorkerStart) {

  // Need to re-update on-demand loading settings based on options
  // specific for the file being loaded.
  var disable = !av.isNodeJS() && options.forceDisableOnDemandLoading;

  // If we come from a buble and it has an animation, then disable on demand loading
  if (options.bubbleNode) {
    var geomNode = options.bubbleNode.findParentGeom2Dor3D();
    var modelExtensions = geomNode.extensions();
    if (modelExtensions && modelExtensions.indexOf("Autodesk.Fusion360.Animation") >= 0) {
      disable = true;
    }
  }

  if (disable) {
    this.memoryOpts.limit = 0;
    this.memoryOpts.onDemandLoading = false;
    this.memoryOpts.debug.force = false;
    avp.logger.log('Animation file disables on-demand-loading...');
  }

  return SvfLoader.prototype.loadFile.call(this, path, options, onDone, onWorkerStart);
};


SvfLoaderML.prototype.cancelGeometryPackLoading = function () {

  // Cancel any ongoing geometry pack file loading.
  if (!this.pack_workers || !this.isValid()) {
    return;
  }

  for (var i = 0; i < this.pack_workers.length; i++) {
    if (this.svf) {
      var pf = this.geommap[this.pack_workers[i].packId];
      if (pf)
      pf.loading = false;
    }
    this.pack_workers[i].queued = 0;
    this.pack_workers[i].clearAllEventListenerWithIntercept();
    this.pack_workers[i].terminate();
  }

  this.pack_workers = null;
};

SvfLoaderML.prototype.loadGeometryPack = function (packId, inMemory) {

  // If we aren't use on demand loading, then just use the SVF loadGeometryPack
  var pp = this.pagingProxy;
  if (!pp) {
    SvfLoader.prototype.loadGeometryPack.call(this, packId, inMemory);
    return true;
  }

  // If loader is already destructed, do nothing.
  if (!this.svf || !this.isValid()) {
    return true;
  }

  // Do nothing if the geometry pack file is already in loading.
  var pf = this.geommap[packId];
  if (!pf || pf.loading) {
    return true;
  }

  // Record the time on first on demand geometry pack file loading request
  if (!this.t0) {
    this.t0 = new Date().getTime();
  }

  var i;
  var scope = this;

  // Common handling when a worker is done with a pack file
  function packFileWorkerComplete(worker, packId) {
    worker.queued = 0;
    scope.geommap[packId].loading = false;

    pp.doOnDemandLoadFinished();
  }

  var onMeshLoad = function onMeshLoad(ew) {
    if (ew.data && ew.data.meshes) {

      var meshes = ew.data.meshes;

      var mdata = {
        packId: ew.data.packId,
        meshIndex: 0,
        mesh: null };


      var geomSize = 0;
      for (var i = 0; i < meshes.length; i++) {
        var mesh = meshes[i];

        if (!mesh)
        continue;

        mdata.meshIndex = i;
        mdata.mesh = mesh;

        scope.processReceivedMesh(mdata);
        if (mdata.geometry) {
          geomSize += mdata.geometry.byteSize + avp.GEOMETRY_OVERHEAD;
          mdata.geometry = null;
        }
      }

      pp.onPackFileLoaded(ew.data.packId, ew.data, geomSize / MEGA);
      fireFragmentsLoadedEvent(scope, ew.data);

      if (ew.data.progress >= 1.0) {
        scope.loadedPacksCount++;
        scope.viewer3DImpl.signalProgress(100 * scope.loadedPacksCount / scope.svf.geompacks.length, av.ProgressState.LOADING, scope.model);
        packFileWorkerComplete(scope.pack_workers[ew.data.workerId], ew.data.packId);
      }
    } else if (ew.data && ew.data.progress) {
      scope.pack_workers[ew.data.workerId].queued -= 1;
      scope.viewer3DImpl.signalProgress(100 * scope.loadedPacksCount / scope.svf.geompacks.length);
    } else if (ew.data && ew.data.debug) {
      avp.logger.debug(ew.data.message);
    } else if (ew.data && ew.data.error) {
      pp.onPackFileLoaded(ew.target.packId, null, 0);
      packFileWorkerComplete(ew.target, ew.target.packId);
      ++scope.failedToLoadPacksCount;
      scope.failedToLoadSomeGeometryPacks = { code: ew.data.error.code, msg: ew.data.error.msg };
    } else {
      //Download failed.
      pp.onPackFileLoaded(ew.target.packId, null, 0);
      packFileWorkerComplete(ew.target, ew.target.packId);
    }
  };

  // Initialize pack workers if it is not ready yet.
  if (!this.pack_workers) {
    this.pack_workers = [];

    var numWorkers = NUM_WORKER_THREADS;

    for (i = 0; i < numWorkers; i++) {
      var wr = this.createWorkerWithIntercept();
      wr.addEventListenerWithIntercept(onMeshLoad);

      wr.queued = 0;
      this.pack_workers.push(wr);
    }
  }

  //Find the least busy worker
  var which = 0;
  var queued = this.pack_workers[0].queued;
  for (i = 1; i < this.pack_workers.length; i++) {
    if (this.pack_workers[i].queued < queued) {
      which = i;
      queued = this.pack_workers[i].queued;
    }
  }

  // If worker is busy queue this reqest for next try.
  if (queued > 1 || pp.preparedPackFilesSize() >= pp.getMemoryLimit()) {

    // All workers are busy, then queue it for next try.
    if (!this.pagingProxy.addGeomPackMissingLastFrame(packId)) {
      // If failed to add, it means that it is too many queued.
      // then restart render.
      this.viewer3DImpl.invalidate(false, true);
      //avp.logger.debug("[On Demand Loading] Re-render on too many geom pack file requests.");
    }

    return false;
  }

  var w, workerId;
  var path = pf.uri;
  w = this.pack_workers[which];
  w.queued += 2;
  w.packId = packId;
  workerId = which;

  pp.onPackFileLoading(packId);

  pf.loading = true;
  this.svf.partPacksLoadDone = false; // Still loading geometry pack files.

  avp.logger.debug("[On Demand Loading] Loading Geometry Pack file: " + packId);

  //Pass unzip job to the worker
  var reqPath = avp.pathToURL(this.svf.basePath + path);
  var xfer = { "operation": WORKER_LOAD_GEOMETRY,
    "url": reqPath,
    "packId": packId, /* mesh IDs treat the pack file id as integer to save on storage in the per-fragment arrays */
    "workerId": workerId,
    "packNormals": this.options.packNormals,
    "createWireframe": this.options.createWireframe ||
    this.model.getMetadata('renderEnvironmentDisplayEdges', 'value', false),
    "skipAssetCallback": true,
    "queryParams": this.queryParams,
    "inMemory": inMemory };

  w.doOperation(av.initLoadContext(xfer)); // Send data to our worker.
  return true;
};


SvfLoaderML.prototype.processReceivedMesh = function (mdata) {
  // If we are not on demand loading, then just use the super class
  if (!this.pagingProxy) {
    SvfLoader.prototype.processReceivedMesh.call(this, mdata);
    return;
  }
  // Gross and ugly - we need to preserve fragments.mesh2frag
  var meshid = mdata.packId + ":" + mdata.meshIndex;
  var svf = this.svf;
  var fragments = svf.fragments;
  var fragIndexes = fragments.mesh2frag[meshid];

  SvfLoader.prototype.processReceivedMesh.call(this, mdata);

  // preserve the mesh2frag mapping
  fragments.mesh2frag[meshid] = fragIndexes;

  // We need to keep this to use when discarding geometry from memory
  mdata.geometry.meshIndex = mdata.meshIndex;

  // This is to record how many instances this geometry has,
  // and the number of instances have been rendered in one frame.
  this.pagingProxy.onProcessReceivedMesh(mdata.geometry, Array.isArray(fragIndexes) ? fragIndexes.length : 1);
};

SvfLoaderML.prototype.onModelRootLoadDone = function (svf) {

  // Let's set the options through for each model that control how memory saving mode start,
  // which decide how to load geometry pack files, and whether paging out if needed.
  // And assume the performance tuning options passed through viewer's config.
  var memoryOpts = this.memoryOpts;

  var geommap = this.geommap = {}; // Map packids to geompacks objects
  // Calculate the size of pack files and the geometry in them
  var meshCount = Object.keys(svf.fragments.mesh2frag).length;
  var fragCount = svf.fragments.length;
  var overhead = (meshCount * MESH_OVERHEAD + fragCount * FRAG_OVERHEAD) / MEGA;
  var totalGeomSize = 0;
  svf.geompacks.forEach(function (pf) {
    // If the geometry worker doesn't give us a geom size, then supply an estimate
    if (!pf.hasOwnProperty("geomSize"))
    pf.geomSize = pf.usize * GEOM_PACK_SIZE_FACTOR;
    pf.usize /= MEGA;
    pf.geomSize /= MEGA;
    totalGeomSize += pf.geomSize;
    geommap[parseInt(pf.id)] = pf;
  });
  // On mobile devices the memory used by the GPU is take from system memory, so we need
  // to include that memory in our estimate of the size of the model. This is also true
  // for laptops and other systems that have an integrated GPU, but we only include it
  // for mobile devices.
  var gpuSize = av.isMobileDevice() ? Math.min(totalGeomSize, avp.GPU_MEMORY_LIMIT / MEGA) : 0;
  totalGeomSize += overhead;

  // The estimated total geom size is the size of the geometry plus
  // the amount of memory needed to hold the uncompressed pack files in workers
  memoryOpts.totalGeomSize = totalGeomSize;
  memoryOpts.overheadSize = overhead;

  // On demand loading will be controlled by two factors.
  // 1. A global switch that enable/disable this behavior.
  // 2. The size of the model.
  if (memoryOpts.onDemandLoading) {
    if (totalGeomSize + gpuSize < memoryOpts.limit && !memoryOpts.debug.force)
    memoryOpts.onDemandLoading = false;else
    {
      this.pagingProxy = new _SvfPagingProxy__WEBPACK_IMPORTED_MODULE_0__["SvfPagingProxy"](this, memoryOpts);
    }
  }

  //For 3D models, we can start loading the property database as soon
  //as we know the fragment list which contains the fragId->dbId map.
  //We would not load property db when we are on mobile device AND on demand loading is on (which
  //implies the model is not 'normal' in terms of its size.). This is only a temp solution that
  //allow big models loads on mobile without crash. Without property db loading selection could break.
  if (this.options.skipPropertyDb === undefined) {
    this.options.skipPropertyDb = this.pagingProxy && av.isMobileDevice();
  }

  // Call the super class
  SvfLoader.prototype.onModelRootLoadDone.call(this, svf);

  // Create flat instance tree, if we are skipping the property db.
  if (this.options.skipPropertyDb) {
    // Not loading the property database, supply a flat dbid tree for the instance tree
    this.svf.instanceTree = _render_DbidFragmentMap__WEBPACK_IMPORTED_MODULE_5__["DbidFragmentMap"].buildInstanceTree(this.svf.fragments.fragId2dbId,
    this.model.getFragmentList());
  }

  // Start the load order worker
  var scope = this;
  function onLoaded(ew) {
    if (!scope.isValid() || !scope.pagingProxy)
    return;

    scope.pagingProxy.onLoadOrderCalculated(ew.data);
  }

  // If this is an svf file, then start the worker that calculates the load order
  if (this.pagingProxy && svf.fragments.boxes && svf.fragments.packIds) {
    // Create the worker and send the boxes and packids to it.
    this.svfLoadOrderWorker = Object(_WorkerCreatorML__WEBPACK_IMPORTED_MODULE_1__["createWorkerML"])();
    this.svfLoadOrderWorker.addEventListener('message', onLoaded, false);
    this.svfLoadOrderWorker.doOperation(
    { operation: WORKER_CALCULATE_LOAD_ORDER,
      fragments: { boxes: svf.fragments.boxes, packIds: svf.fragments.packIds } });

    this.model.setUUID(svf.urn);
  }
};


SvfLoaderML.prototype.calculateLoadOrder = function (id, camera, pixelCullingThreshold) {
  if (!this.svfLoadOrderWorker)
  return false;

  var cvtcam = {
    projectionMatrix: { elements: camera.projectionMatrix.elements },
    matrixWorldInverse: { elements: camera.matrixWorldInverse.elements },
    aspect: camera.aspect,
    position: { x: camera.position.x, y: camera.position.y, z: camera.position.z },
    clientWidth: camera.clientWidth,
    clientHeight: camera.clientHeight };

  var msg = {
    operation: WORKER_CALCULATE_LOAD_ORDER,
    id: id,
    camera: cvtcam,
    pixelCullingThreshold: pixelCullingThreshold };

  this.svfLoadOrderWorker.doOperation(msg);
  return true;
};

SvfLoaderML.prototype.onGeomLoadDone = function () {
  // If we aren't using on demand loading, then use the super class
  if (!this.pagingProxy) {
    SvfLoader.prototype.onGeomLoadDone.call(this);
    return;
  }

  // Only check to load textures once.
  if (!this.svf.loadDone) {
    if (av.isMobileDevice()) {
      // If we are on a mobile device, then we will check the memory used
      // to see if we think there may be enough to load textures.

      // Get the memory limit from the renderScene, which can hold multiple models. If
      // we don't have a renderScene to use, just use the model to get the memory limit.
      var info = this.pagingProxy.getMemoryInfo();

      // If we can't get the info, then don't load the textures.
      if (info) {
        // If the effectiveLimit is larger than the limit, then the model has
        // so many fragments, that we don't think we can restrict memory to
        // the requested limit. This means memory should be really tight and
        // we won't load the textures. If the loaded memory size if too close
        // to the limit, then don't load the texture.
        if (info.effectiveLimit <= info.limit && info.limit - info.loaded > MOBILE_TEXTURE_LIMIT) {
          // Listen for the textures loaded event
          var callback = function (e) {
            this.viewer3DImpl.api.removeEventListener(av.TEXTURES_LOADED_EVENT, callback);
            // Calculate the size of textures used by this model
            var size = 0;
            this.viewer3DImpl.matman().enumTextures(this.model, function (tex) {
              if (tex) {
                size += avp.TextureLoader.calculateTextureSize(tex);
              }
            });
            // Adjust the limit in the SvfPagingProxy.
            size /= MEGA;
            this.pagingProxy.options.limit -= size;
          }.bind(this);
          // When all of the textures are loaded, adjust the memory limit
          this.viewer3DImpl.api.addEventListener(av.TEXTURES_LOADED_EVENT, callback);
          // Load the textures
          avp.TextureLoader.loadModelTextures(this.model, this.viewer3DImpl);
        }
      }
    } else {
      // If we aren't on a mobile device, then load the textures.
      avp.TextureLoader.loadModelTextures(this.model, this.viewer3DImpl);
    }
  }

  var wasDone = this.svf.loadDone;
  this.svf.loadDone = true;

  // Time for loading part of the on-demanded geometries.
  var t1 = Date.now();
  var msg = "[On Demand Loading] On demand requested geometries load time: " + (t1 - this.t0);

  avp.logger.log(msg);

  // Track the on demand geom load stats.
  var modelStats = {
    category: "on_demand_geom_load_stats",
    is_f2d: false,
    has_prism: this.viewer3DImpl.matman().hasPrism,
    load_time: t1 - this.t0,
    geometry_size: this.model.getGeometryList().geomMemory,
    meshes_count: this.model.getGeometryList().geoms.length,
    fragments_count: this.model.getFragmentList().getCount(),
    load_pack_count: this.loadedPacksCount,
    urn: this.svfUrn };

  avp.logger.track(modelStats);

  // clear the start time, which can be set again if on demand loading geometry again.
  this.t0 = null;

  this.loadedPacksCount = 0;
  this.svf.partPacksLoadDone = true;

  if (wasDone) {
    this.viewer3DImpl.signalProgress(100, av.ProgressState.LOADING, this.model);
  } else {
    this.viewer3DImpl.onLoadComplete(this.model);
  }

  var geomList = this.model.getGeometryList();
  if (geomList) {
    geomList.printStats();
  }
};

/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/main/SvfPagingProxy.js":
/*!**********************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/main/SvfPagingProxy.js ***!
  \**********************************************************************/
/*! exports provided: SvfPagingProxy */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "SvfPagingProxy", function() { return SvfPagingProxy; });
/* harmony import */ var _render_OcclusionCulling__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../render/OcclusionCulling */ "./extensions/MemoryLimited/render/OcclusionCulling.js");
/* harmony import */ var _render_pageoutStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../render/pageoutStatus */ "./extensions/MemoryLimited/render/pageoutStatus.js");
/* harmony import */ var _render_RenderBatchML__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../render/RenderBatchML */ "./extensions/MemoryLimited/render/RenderBatchML.js");




var LOAD_ORDER_TIMEOUT = 100; // 100 msec delay to ask for sorted load order

var PAST_LAST_PACK = 1.0e10; // Large number past last pack id

// occlusion testing state.
var NO_OCCLUSION_TESTING = 0;
var QUEUE_OCCLUSION_TESTING = 1;
var PERFORM_OCCLUSION_TESTING = 2;

var MEGA = 1024 * 1024;

// This three constants are used to asjust the memory limit if
// the overhead is too large to allow any geometry to be loaded.
// We start with MIN_OVERHEAD_FACTOR * total geometry + overhead size
// and clip it to the range [MIN_OVERHEAD_LIMIT, MAX_OVERHEAD_LIMIT]
var MIN_OVERHEAD_FACTOR = 0.1; // Factor of total size
var MIN_OVERHEAD_LIMIT = 10;
var MAX_OVERHEAD_LIMIT = 50;

var av = Autodesk.Viewing;
var avp = av.Private;

var setSettingsDisplay = function setSettingsDisplay(api, display) {
  var panel = api.getSettingsPanel();
  if (panel) {
    var checkbox = panel.getControl(panel.groundShadowChkBoxId).checkElement;
    var row = checkbox.parentElement.parentElement.parentElement;
    row.style.display = display;
    checkbox = panel.getControl(panel.groundReflectionChkBoxId).checkElement;
    row = checkbox.parentElement.parentElement.parentElement;
    row.style.display = display;
  }
};

// Paging proxy object to manage on demand loading and paging logic,
// that is specific to the model loaded by svf loader.
var SvfPagingProxy = function SvfPagingProxy(loader, options) {

  var _extendObject = function _extendObject(target, source) {
    for (var prop in source) {
      if (source.hasOwnProperty(prop)) {
        target[prop] = source[prop];
      }
    }
  };

  var _loader = loader;

  // Options of control memory management.
  this.options = {};
  _extendObject(this.options, options);

  this.options.debug = {
    // Increase the max page out size. On slow (mobile) devices the scene
    // traversal is a bottle neck and making this larger helps load more
    // pack files earlier in the load.
    maxPageOutSize: 195, // Max we will page out in one go
    pixelCullingEnable: this.options.onDemandLoading, // Useful with on demand loading
    pixelCullingThreshold: avp.PIXEL_CULLING_THRESHOLD,

    occlusionThreshold: 1,
    occlusionTestThreshold: 1,
    startOcclusionTestingPackCount: 8,
    testPackfileCount: 4,
    useOcclusionInstancing: true,
    automaticRefresh: true,
    boxProxyMaxCount: 0, // show this many boxes during a render
    boxProxyMinScreen: 0.4 // if entire render batch is >= 1/10 of the screen in area
  };
  _extendObject(this.options.debug, options.debug);


  // If reach limit, then stop loading any further pack files.
  this.reachLimit = false;
  // the geom ids map, is a dictionary that key is the geometry id,
  // and value is an index to an array that record the traversed count
  // for that geometry.
  // ??? The reason that doesn't use the object to record the count but
  // ??? use the indirect arry is due to PERFORMANCE. 
  // ??? Because, if the JS object properties' value are changed frequently,
  // ??? the performance will hurt a whole lot.
  this.geomidsmap = {};
  this.geomTravCount = [];

  // Variables for recording loaded or loading or queued pack files.
  this.loadedPacks = {}; // Staticly bound to functions, replace this object
  this.loadedPackfileCount = 0;
  this.memoryOverhead = 0;
  this.loadingPacks = {};
  this.loadingPacksSize = 0;
  this.queuedPacks = [];
  this.packQueuedMap = {};
  this.queuedPacksSize = 0;
  this.occludedPacks = [];
  this.occlusionCulledCount = 0;
  this.packsPagedOut = 0;

  this.traversedCounter = 0;
  this.transparentCounter = 0;
  this.resetCount = 0;
  this.invalidateCount = -1;
  this.moving = 0;

  // read from options, and passed by the loader.
  this.geompacks = _loader.svf.geompacks;
  this.geommap = _loader.geommap;
  this.totalGeomSize = this.options.totalGeomSize;
  this.overheadSize = this.options.overheadSize;
  // Adjust the limit if the overhead is too large.
  this.minMemoryLimit = Math.min(Math.max(this.totalGeomSize * MIN_OVERHEAD_FACTOR,
  MIN_OVERHEAD_LIMIT), MAX_OVERHEAD_LIMIT) + this.overheadSize;

  this.lastPageOut = -1;
  this.pageOutResetCounter = -1;

  var _resumeNextFrame = false;

  // Variables used to handle the load order from the worker
  var _nextOrderToLoad = 0; // Next list of fragments to load
  var _nextFragToLoad = 0; // Next fragment in load order
  var _loadOrderId = 0; // Last load order request
  var _fragOrder = []; // Fragment order - allow multiple ordered lists
  var _packOrder; // Pack file order
  var _pfVisible = -1; // Number of visible pack files.
  var _packOrderMap = []; // Order of pack files in pack order
  var _firstReset = true; // Track first time we ask for the load order
  var _lastResult = null; // Last load order result
  var _loadOrderTimer = 0; // Timer used to keep down traffic to load order worker
  var _pageOutStillPossible = true; // More possible to page out
  var _loadDoneSent = false; // Load done has been sent

  var _renderCount;
  var _visibleIds;
  var _visibleWidth;
  var _visibleHeight;

  var _occlusionCulling = new _render_OcclusionCulling__WEBPACK_IMPORTED_MODULE_0__["OcclusionCulling"]();
  _occlusionCulling.initialize(_loader.viewer3DImpl.glrenderer(), _loader.viewer3DImpl.renderer());

  var loadMissingGeometryHandler = function (e) {
    // e.unloadPackFiles is for debugging only
    this.resetCanPageOut(!!e.debug.unloadPackFiles, e.delay != false, false);
  }.bind(this);
  _loader.viewer3DImpl && _loader.viewer3DImpl.api.addEventListener(av.LOAD_MISSING_GEOMETRY, loadMissingGeometryHandler);

  this.dtor = function () {
    this.removeHooks();

    _occlusionCulling && _occlusionCulling.dtor();
    _occlusionCulling = undefined;

    _loader.viewer3DImpl && _loader.viewer3DImpl.api.removeEventListener(av.LOAD_MISSING_GEOMETRY, loadMissingGeometryHandler);
  };

  this.pixelCullingEnable = function () {
    return this.options.debug.pixelCullingEnable;
  };

  this.pixelCullingThreshold = function () {
    return this.options.debug.pixelCullingThreshold;
  };

  this.getMemoryLimit = function () {
    return Math.max(this.minMemoryLimit, this.options.limit);
  };

  /**
      * Get the memory stats when using on demand loading.
      * @returns {object|null} Object containing the limit and loaded memory usage for the model.
      *                        Return null if the model isn't being loaded on demand.
      */
  this.getMemoryInfo = function () {
    return {
      limit: this.options.limit,
      effectiveLimit: this.getMemoryLimit(),
      loaded: this.preparedPackFilesSize() };

  };

  this.getLoadedMeshes = function (packId) {
    var pack = this.loadedPacks[packId];
    return pack && pack.inMemory;
  };

  this.loadPackFile = function () /*packId*/{
    return true;
  };

  this.doLoadPackFile = function (packId) {
    if (this.loadingPacks[packId])
    return true;
    // Skip occluded packs
    if (this.occludedPacks[packId] === true)
    return false;

    if (this.queuedPacks.length > 0 || this.occlusionTesting >= QUEUE_OCCLUSION_TESTING) {
      if (!this.addGeomPackMissingLastFrame(packId))
      return false;
      this.loadGeometryMissingLastFrame();
      return true;
    }
    return _loader.loadGeometryPack(packId, this.getLoadedMeshes(packId));
  };

  // Take the geometry we will keep in a pack file and create a new set
  // of buffers for them.
  function removeAndCompactGeometry(packId, frags, unloadAll, traversed, transparent, pack) {
    var bufferSize = 0;
    var unloadedSize = 0,size;
    var retainedGeoms = [];
    var inMemory = pack.inMemory;
    var needCompaction = false;
    var count = 0;
    var geomsList = frags.geoms;

    // If all of the current geometry has been traversed, then there
    // is nothing for us to do.
    if (!unloadAll && pack.travsed >= pack.currentCount)
    return 0;

    function processMesh(meshIdx) {
      // If mesh isn't in memory, return
      if (!(inMemory[meshIdx >> 5] & 1 << (meshIdx & 31)))
      return;

      var fragId = frags.fragments.mesh2frag[packId + ":" + meshIdx];
      if (Array.isArray(fragId))
      fragId = fragId[0];
      var geom = geomsList.geoms[frags.getGeometryId(fragId)];

      if (geom && geom.packId == packId) {
        // We handle meshes that occupy an entire buffer differently from
        // meshes that are sharing a buffer. If we unload a mesh that is
        // part of a shared buffer, we need to compact the buffer. Similarly
        // we only need to include meshes that are part of a shared buffer
        // in the meshes we want to compact.
        var partialBuffer = geom.vb.buffer === geom.ib.buffer ?
        geom.vb.buffer.byteLength > geom.vb.byteLength + geom.ib.byteLength :
        geom.vb.buffer.byteLength > geom.vb.byteLength ||
        geom.ib.buffer.byteLength > geom.ib.byteLength;
        // remove geometry we don't want to keep and keep track of the size
        if ((unloadAll || geom.traversed != traversed && geom.transparent != transparent) &&
        (size = geomsList.removeGeometry(geom.svfid, _loader.viewer3DImpl.glrenderer())) > 0) {
          unloadedSize += size;
          inMemory[geom.meshIndex >> 5] &= ~(1 << (geom.meshIndex & 31));
          needCompaction = needCompaction || partialBuffer;
        } else {
          ++count;
          // Either don't want to remove the geometry, or we can't remove it
          // We only compact geometry that is stored in a shared array buffer
          if (partialBuffer) {
            bufferSize += geom.vb.byteLength;
            bufferSize += geom.ib.byteLength + 3 & ~3;
            retainedGeoms.push(geom);
          }
        }
      } else
      console.error("Mismapped or missing geometry %d:%d", packId, meshIdx);
    }

    // Remove geometry that we can. Make a list of the geometry that
    // we want to keep.
    var i;
    for (i = 0; i < pack.totalCount; ++i) {
      processMesh(i);}
    pack.currentCount = count;
    pack.culled = 0;

    // Nothing more to do, if nothing was unloaded or everything was unloaded
    if (unloadedSize == 0)
    return 0;

    unloadedSize /= MEGA;
    // If we don't need to compact, then don't
    if (retainedGeoms.length == 0 || !needCompaction)
    return unloadedSize;

    var newBuffer = new ArrayBuffer(bufferSize);
    var offset = 0;

    // Copy a single buffer to the destination
    function copy(type, src, size) {
      var b = null;
      if (src) {
        var round = size - 1;
        offset = offset + round & ~round; // size must be a power of 2
        var length = src.length;
        b = new type(newBuffer, offset, length);
        b.set(src);
        offset += length * size;
      }
      return b;
    }

    // Copy data to new buffer
    retainedGeoms.forEach(function (geom) {
      geom.vb = copy(Float32Array, geom.vb, 4);
      geom.ib = copy(Uint16Array, geom.ib, 2);
    });

    return unloadedSize;
  }

  this.unloadPackFile = function (packId, unloadAll, pageOut) {
    var frags = _loader.model.getFragmentList();
    var pack = this.loadedPacks[packId];
    if (!frags || !pack || !frags.geoms) {
      return false;
    }

    // Remove all geometries comming from this pack file
    removeAndCompactGeometry(packId, frags, unloadAll, this.traversedCounter, this.transparentCounter, pack);

    if (pack.currentCount == 0) {
      // Then, remove the record and decrease the count.
      delete this.loadedPacks[packId];
      --this.loadedPackfileCount;
      if (pageOut)
      ++this.packsPagedOut;
    }

    return true;

  };

  var redrawIfIdle = function () {
    // Schedule a redraw if we think we are idle. We detect idle
    // by tracking when the iterator is reset and when the traversal
    // is done.
    if (this.resetCount != this.pageOutResetCounter)
    return false; // Draw is active
    _loader.viewer3DImpl.invalidate(false, true);
  }.bind(this);

  this.onPackFileLoaded = function (packId, data, geomSize) {
    // Record the pack file loaded.
    var pf = this.geommap[packId];

    _loadDoneSent = false; // Once we load a pack file, we need to send load done again

    // This packId is no longer being loaded, reduce the loading packs size        
    if (this.loadingPacks.hasOwnProperty(packId)) {
      delete this.loadingPacks[packId];
      this.loadingPacksSize -= pf.geomSize + pf.usize;
    }

    // If data is null, then there was an error
    if (data) {
      var pack = this.loadedPacks[packId];
      if (!pack) {
        var count = data.meshes.length;

        pack = this.loadedPacks[packId] = {
          totalCount: count,
          travsed: 0,
          culled: 0,
          resetCounter: this.resetCount,
          geomSize: 0, // Memory used by geometry in the loaded pack file
          inMemory: new Array((count + 31) / 32 | 0) };


        ++this.loadedPackfileCount;
        if (this.options.debug.occlusionTestThreshold > 0 &&
        this.occlusionTesting == NO_OCCLUSION_TESTING &&
        this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount) {
          this.occlusionTesting = QUEUE_OCCLUSION_TESTING;
        }

      }
      // Once we load a pack file, everything is in memory again
      pack.geomSize += geomSize;
      pack.currentCount = pack.totalCount;
      pack.inMemory.fill(~0);

      // The geometry loaded now replaces all the geometry loaded before
      this.totalGeomSize += pack.geomSize - pf.geomSize;

      // Adjust queuedPacksSize if this packId has been queued again.
      if (this.packQueuedMap[packId])
      this.queuedPacksSize += pack.geomSize - pf.geomSize;
      pf.geomSize = pack.geomSize;

      // Need to make sure we render something, to continue the loading process
      redrawIfIdle();
    }

    if (this.loadedGeometrySize() > this.getMemoryLimit()) {
      avp.logger.warn("More pack files being loaded than the max count: " + this.loadedGeometrySize());
    }
  };

  this.checkLoadFinished = function () {
    if (_loadDoneSent)
    return;

    // Are all workers done?
    var pack_workers = _loader.pack_workers;
    if (pack_workers) {
      for (var j = 0; j < pack_workers.length; j++) {
        if (pack_workers[j].queued != 0)
        return;
      }
    }

    // All workers are done. Is there anything more to do.
    if (this.geomPacksMissingLastFrame().length != 0 || _nextOrderToLoad < _fragOrder.length) {
      // More items on the list, so there might be more to do
      if (this.loadedGeometrySize() < this.getMemoryLimit() || _pageOutStillPossible) {
        // There may be more memory, so we aren't done yet
        return;
      }
    }

    // Done
    _loadDoneSent = true;
    _loader.onGeomLoadDone();
  };

  this.doOnDemandLoadFinished = function () {
    // Any more to do?
    this.loadGeometryMissingLastFrame();
    this.checkLoadFinished();
  };

  this.onPackFileLoading = function (packId) {
    if (this.loadingPacks.hasOwnProperty(packId))
    return;
    this.loadingPacks[packId] = true;
    var pf = this.geommap[packId];
    this.loadingPacksSize += pf.geomSize + pf.usize;
  };

  this.onProcessReceivedMesh = function (geometry, numInstances) {

    var geomId = geometry.svfid;
    if (numInstances > 1 && this.geomidsmap[geomId] == null) {
      this.geomidsmap[geomId] = this.geomTravCount.length;
      this.geomTravCount.push(0);
    }
  };

  this.loadedGeometrySize = function () {
    return _loader.model.getGeometryList().geomMemory / MEGA + this.overheadSize;
  };

  this.preparedPackFilesSize = function () {
    return this.loadingPacksSize + this.loadedGeometrySize();
  };

  this.cancelPending = function () {
    if (this.loadingPacksSize > 1.0 / MEGA) {

      // Cancel any on going geometry loading, as it is probably no longer
      // immediately used by the following rendering as scene or camera 
      // changed.
      _loader.cancelGeometryPackLoading();
      this.loadingPacks = {};
      this.loadingPacksSize = 0;
    }

    this.queuedPacks.length = 0;
    this.queuedPacksSize = 0;
    this.packQueuedMap = {};
    this.occlusionTesting = this.options.debug.occlusionTestThreshold > 0 &&
    this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount ?
    QUEUE_OCCLUSION_TESTING : NO_OCCLUSION_TESTING;
    this.occludedPacks.length = 0;
  };

  this.resetIterator = function (camera /*, resetType*/) {
    this.lastCamera = camera;
    _occlusionCulling.setCamera(camera);
    ++this.resetCount;
  };

  this.reset = function () {

    // Reset the record of geometry travsed or culled count.
    var loadedPacks = this.loadedPacks;
    for (var p in loadedPacks) {
      loadedPacks[p].travsed = 0;
      loadedPacks[p].culled = 0;
    }
    this.geomTravCount.fill(0);

    // I don't like this but I don't see any way around it. The goal is to keep all
    // visible geometry in memory. So when we reset the geometry in memory we need
    // to clear the display, which calls this method again. invalidateCount is used
    // to keep us from starting over in that case.
    if (this.resetCount > this.invalidateCount) {
      this.cancelPending();
      this.resetCanPageOut(false, true, true);
    }
  };

  this.geomPacksMissingLastFrame = function () {
    return this.queuedPacks;
  };

  this.addGeomPackMissingLastFrame = function (packId) {

    // Not too many loaded + loading + queued.
    if (this.loadedGeometrySize() >= this.getMemoryLimit()) {
      this.reachLimit = true;
    }

    // Otherwise, schedule a futher loading
    if (!this.packQueuedMap[packId]) {
      var pf = this.geommap[packId];
      if (pf) {
        this.queuedPacks.push(packId);
        this.queuedPacksSize += pf.geomSize;
        this.packQueuedMap[packId] = true;
      }
    }

    return true;
  };

  this.loadGeometryMissingLastFrame = function () {
    // This load is done, then can start as many as possible.
    var missingPacks = this.queuedPacks;
    var i;
    for (i = 0; i < missingPacks.length; ++i) {
      var packId = missingPacks[i];
      if (this.occlusionTesting >= QUEUE_OCCLUSION_TESTING && this.occludedPacks[packId] === undefined)
      break;
      if (!this.geommap[packId].loading && !this.occludedPacks[packId]) {
        // Find one that hasn't been loaded.
        if (!_loader.loadGeometryPack(packId, this.getLoadedMeshes(packId)))
        break; // can't load any more - stop
      }
    }

    // If we weren't able to load anything, redraw to start things up again.
    if (i == 0 && !_loadDoneSent)
    redrawIfIdle();

    // Remove pack files that are loading and the one we will load
    var _this = this;
    missingPacks.splice(0, i).forEach(function (packId) {
      _this.queuedPacksSize -= _this.geommap[packId].geomSize;
      delete _this.packQueuedMap[packId];
    });
  };

  this.needResumeNextFrame = function () {
    return _resumeNextFrame;
  };

  var _packSort = function (a, b) {
    var wa = a >= _packOrderMap.length ? PAST_LAST_PACK : _packOrderMap[a];
    var wb = b >= _packOrderMap.length ? PAST_LAST_PACK : _packOrderMap[b];
    return wb - wa;
  }.bind(this.loadedPacks);

  var copyVisibleIds = function copyVisibleIds(renderer, glrenderer, model) {
    var renderCount = model.getFragmentList()._renderCount;
    if (renderCount === _renderCount)
    return _visibleIds;
    _renderCount = renderCount;

    var idTarget = renderer.getIdTarget();
    if (!idTarget) {
      _visibleIds = undefined;
      return null;
    }

    if (!_visibleIds || _visibleWidth != idTarget.width || _visibleHeight != idTarget.height) {
      _visibleIds = new Uint8Array(4 * idTarget.width * idTarget.height);
      _visibleWidth = idTarget.width;
      _visibleHeight = idTarget.height;
    }

    glrenderer.readRenderTargetPixels(idTarget, 0, 0, idTarget.width, idTarget.height, _visibleIds);
    return _visibleIds;
  };

  this.markVisibleGeoms = function () {
    var viewer3DImpl = _loader.viewer3DImpl;
    var model = _loader.model;
    var map = model.getData().instanceTree;
    var ids;
    // Return if we can't get the data to mark visible geometry
    if (!map || !(ids = copyVisibleIds(viewer3DImpl.renderer(), viewer3DImpl.glrenderer(), model)))
    return;

    var visible = ++this.traversedCounter;
    var found = {};
    var end = ids.length;
    var id, key;
    var loadedPacks = this.loadedPacks;

    // Clear traversed count
    for (key in loadedPacks) {
      loadedPacks[key].travsed = 0;
    }

    // Count pixels covered by each id
    for (var i = 0; i < end; i += 4) {
      id = ids[i] | ids[i + 1] << 8 | ids[i + 2] << 16;
      id = id << 8 >> 8; // recover sign
      if (id > 0)
      found[id] = (found[id] | 0) + 1;
    }

    var frags = model.getFragmentList();
    var threshold = this.options.debug.occlusionThreshold | 0;
    for (key in found) {
      id = Number(key);
      if (found[id] >= threshold) {
        map.enumNodeFragments(id, function (fragId) {
          var geom = frags.getGeometry(fragId);
          if (geom) {
            var pack = loadedPacks[geom.packId];
            if (pack && geom.traversed != visible)
            ++pack.travsed;
            geom.traversed = visible;
          }
        });
      }
    }
  };

  this.pageOut = function (iterationDone, forcePageOut) {

    _resumeNextFrame = false;
    var pageStatus = _render_pageoutStatus__WEBPACK_IMPORTED_MODULE_1__["PAGEOUT_SUCCESS"];

    if (!_pageOutStillPossible || !_loader.isValid())
    return pageStatus;

    if (iterationDone && this.options.debug.occlusionTestThreshold > 0 &&
    this.loadedPackfileCount >= this.options.debug.startOcclusionTestingPackCount) {
      this.occlusionTesting = PERFORM_OCCLUSION_TESTING;
    }
    this.occlusionTest();

    // Only try to page out at the end of iteration of scene travseral,
    // which is to guarantee the geometries loaded from pack files get 
    // all used (either traversed or culled.)
    if (!iterationDone) {
      return pageStatus;
    }

    // This page out will page geometries on a pack file basis
    this.pageOutResetCounter = this.resetCount;
    var size = this.loadedGeometrySize();
    _pageOutStillPossible = true;
    if (size && (this.reachLimit || size > this.getMemoryLimit())) {

      this.markVisibleGeoms();

      var loadedPacks = this.loadedPacks;
      var loadedPackIds = Object.keys(loadedPacks);
      var packsSkipped = false;

      // Sorting functions for different paging strategies

      // Sort so pack files that can be paged come first
      // and are sorted in reverse culled count order.
      // Pack files that can't be paged are not sorted further
      loadedPackIds.sort(_packSort);

      // If we aren't paging normally, then the best performance is to
      // page out as much as possible.
      var unloaded = size - Math.min(size, this.options.debug.maxPageOutSize);

      // Then, unload pack files 
      loadedPackIds.every(function (id) {
        if (loadedPacks[id].resetCounter < this.resetCount) {
          this.unloadPackFile(id, false, true);
        } else
        packsSkipped = true;

        return this.loadedGeometrySize() > unloaded;
      }.bind(this));

      if (forcePageOut && this.loadedGeometrySize() == size &&
      loadedPacks[loadedPackIds[0]].resetCounter < this.resetCount) {
        this.unloadPackFile(loadedPackIds[0], false, true);
        avp.logger.log("A force page out occur.");
      }

      if (this.loadedGeometrySize() == size) {
        pageStatus = _render_pageoutStatus__WEBPACK_IMPORTED_MODULE_1__["PAGEOUT_SUCCESS"];
        this.reachLimit = true;
      } else
      {
        this.reachLimit = false;
        this.loadGeometryMissingLastFrame();
        _resumeNextFrame = true;
      }

      this.lastPageOut = size - this.loadedGeometrySize();
      avp.logger.log("[On Demand Loading] Unload pack files size: " + this.lastPageOut);
      if (window && window.gc) {
        window.gc();
      }

      // If we weren't able to pageout anything, see if we are done
      if (this.lastPageOut == 0) {
        // If we didn't skip any pack files and nothing was paged out
        // then we won't be able to page out more later.
        _pageOutStillPossible = packsSkipped;
        this.checkLoadFinished();
      }

      return pageStatus;
    }

    // resume on missing geom for next frame.
    _resumeNextFrame = _resumeNextFrame || this.queuedPacks.length > 0;

    this.loadFragsFromLoadOrder();

    return pageStatus;
  };

  this.occlusionTest = function (pagingProxy) {
    var fragmentList = null;
    var moving = false;
    var promise = null;
    var packIds = null;
    var occlusionTestTimer = 0;
    var waitingCount = 0;
    var delayPerWaiting = 3;

    function findFragsForPackfile(packIds) {
      var packids = fragmentList.fragments.packIds;
      if (!packids)
      return null;

      var packList = [];
      packIds.forEach(function (packId) {
        var fragIds = [];
        var i = packids.lastIndexOf(packId);
        while (i >= 0) {
          if (packids[i] == packId)
          fragIds.push(i--);else
          if (--i > 0)
          i = packids.lastIndexOf(packId, i);
        }
        packList.push(fragIds);
      });
      return packList;
    }

    function nextPackIds(count) {
      var packIds = null;
      waitingCount = 0;
      var queue = pagingProxy.queuedPacks;
      var occluded = pagingProxy.occludedPacks;
      count = Math.min(4, count || 4);
      var length = queue.length;
      for (var i = 0; i < length && count > 0; ++i) {
        var id = queue[i];
        if (occluded[id] === undefined) {
          packIds = packIds || [];
          packIds.push(id);
          --count;
        } else if (!occluded[id])
        ++waitingCount;
      }
      return packIds;
    }

    function handleOcclusion(visible) {
      promise = null;
      for (var i = 0; i < packIds.length; ++i) {
        pagingProxy.occludedPacks[packIds[i]] = !visible[i];
        if (!visible[i]) {
          avp.logger.debug("[On Demand Loading] Occluded Geometry Pack file: " + packIds[i]);
          ++pagingProxy.occlusionCulledCount;
        }
      }
      pagingProxy.doOnDemandLoadFinished(); // Remove packId from queue
      doOcclusionTest();
    }

    function doOcclusionTest() {
      if (occlusionTestTimer || promise || _loadDoneSent)
      return;

      // Clear previous promise
      promise = null;
      // Can we do occlusion testing now?
      if (!moving && (packIds = nextPackIds(pagingProxy.options.debug.testPackfileCount))) {

        occlusionTestTimer = setTimeout(function () {
          occlusionTestTimer = 0;
          // Yes get the fragment ids for the pack files
          var fragIds = findFragsForPackfile(packIds);
          promise = _occlusionCulling.occlusionTest(fragmentList.boxes, pagingProxy.options.debug.occlusionTestThreshold,
          fragIds, pagingProxy.options.debug.useOcclusionInstancing, packIds);
          promise.then(handleOcclusion, function () {
            // Assume visible if there is an error
            handleOcclusion([true, true, true, true]);
          });
        }, waitingCount * delayPerWaiting);
      }
    }

    function occlusionTest() {
      // If we already have a test scheduled, or occlusion testing hasn't started yet.
      if (promise || this.occlusionTesting < PERFORM_OCCLUSION_TESTING)
      return;

      moving = this.moving-- > 0;
      fragmentList = _loader.model.getFragmentList();

      // Kick off the test
      if (fragmentList && !moving)
      doOcclusionTest();
    }
    return occlusionTest;
  }(this);

  this.loadFragsFromLoadOrder = function () {
    var frags = _loader.model.getFragmentList();
    while (_nextOrderToLoad < _fragOrder.length) {
      var fragOrder = _fragOrder[_nextOrderToLoad];
      var len = fragOrder.length;
      while (_nextFragToLoad < len) {
        var fragId = fragOrder[_nextFragToLoad];
        if (!frags.getGeometry(fragId)) {
          var packId = frags.fragments.packIds ? frags.fragments.packIds[fragId] : fragId;
          var queuedLen = this.queuedPacks.length;
          if (!this.doLoadPackFile(packId) && queuedLen == this.queuedPacks.length)
          return;
        }
        ++_nextFragToLoad;
      }
      ++_nextOrderToLoad;
      _nextFragToLoad = 0;
    }
  };

  this.pfOrder = function () {
    return _packOrder;
  };

  this.getNumVisiblePFs = function () {
    return _packOrder ? _pfVisible : -1;
  };

  this.onLoadOrderCalculated = function (loadOrder) {
    if (loadOrder.error) {
      _lastResult = null;
      return;
    }
    if (loadOrder.fragOrder && loadOrder.packOrder)
    _lastResult = loadOrder;
    if (loadOrder.id != _loadOrderId || !_lastResult) {
      return; // Superseded or error or frustum didn't change
    }

    this.lastPageOut = -1;
    _pageOutStillPossible = true;
    _loadDoneSent = false;

    _fragOrder.length = 0;
    _fragOrder.push(_lastResult.fragOrder);

    // create a map that maps a packId to its position in the load order
    // this is used during pageout to prioritize the packs paged out.
    _packOrder = _lastResult.packOrder;
    _pfVisible = _lastResult.pfVisible;
    var i,len = _packOrder.length;
    _packOrderMap.length = this.geompacks.length;
    // Put all packs at the end of the list
    _packOrderMap.fill(PAST_LAST_PACK);
    // Set the load order for pack Ids in the load order list
    for (i = 0; i < len; ++i) {
      _packOrderMap[_packOrder[i]] = i;}

    // Figure out which pack files need to be unloaded
    // We loop through the fragments and add up the pack file sizes
    // until we reach the memory limit. Those pack files are the
    // ones we keep. If the fragment geometry is in memory, we
    // use the size of geometry currently loaded in memory, if it
    // isn't we use the total size of the pack file.
    var frags = _loader.model.getFragmentList();
    var size = this.overheadSize;
    var limit = this.getMemoryLimit();
    var j;
    for (j = 0; j < _fragOrder.length && size < limit; ++j) {
      var fragOrder = _fragOrder[j];
      len = fragOrder.length;
      var keepPacks = [];
      keepPacks.length = _packOrderMap.length;
      keepPacks.fill(0);
      var geompacks = this.geompacks;
      for (i = 0; i < len && size < limit; ++i) {
        var fragId = fragOrder[i];
        var packId = frags.fragments.packIds ? frags.fragments.packIds[fragId] : fragId;
        var pack = geompacks[packId];
        if (pack) {
          var geomSize = frags.getGeometry(fragId) ? pack.geomSize : pack.totalGeomSize;
          if (geomSize > keepPacks[packId]) {
            size += geomSize - keepPacks[packId];
            keepPacks[packId] = geomSize;
          }
        }
      }
    }

    // Clear can page out for all loaded pack files
    var loadedPacks = this.loadedPacks;
    for (var a in loadedPacks) {
      if ( /*a >= this.options.minPackFiles &&*/loadedPacks.hasOwnProperty(a)) {
        if (!keepPacks[a])
        this.unloadPackFile(a, true);
      }
    }

    ++this.traversedCounter;
    ++this.transparentCounter;
    this.reachLimit = this.loadedGeometrySize() >= this.getMemoryLimit();

    this.cancelPending();
    _nextOrderToLoad = 0;
    _nextFragToLoad = 0;
    this.loadFragsFromLoadOrder();

    _loader.viewer3DImpl.invalidate(true);
    this.invalidateCount = this.resetCount + 1;
  };

  this.resetCanPageOut = function (unloadPackFiles, delay, automatic) {
    if (_loadOrderTimer) {
      clearTimeout(_loadOrderTimer);
      _loadOrderTimer = 0;
    }

    var proxy = this;
    function doReset() {
      _loadOrderTimer = 0;
      // The first time we get here, from this.reset() then calculate the load order
      // This is so the scene will display, without manually calculating the load order.
      if (_firstReset || !automatic || proxy.options.debug.automaticRefresh) {
        proxy.occlusionCulledCount = 0;
        proxy.packsPagedOut = 0;

        var camera = proxy.lastCamera;
        var loadedPacks = proxy.loadedPacks;
        var a;
        // Unload all the pack files if needed;
        if (unloadPackFiles) {
          for (a in loadedPacks) {
            if ( /*a >= proxy.options.minPackFiles &&*/loadedPacks.hasOwnProperty(a)) {
              proxy.unloadPackFile(a, true);
            }
          }
        }

        _loader.calculateLoadOrder(++_loadOrderId, camera,
        proxy.options.debug.pixelCullingEnable ? proxy.options.debug.pixelCullingThreshold : -1);
        _firstReset = false;
      }
    }

    if (delay)
    _loadOrderTimer = setTimeout(doReset, LOAD_ORDER_TIMEOUT);else

    doReset();
  };

  this.onGeomTraversed = function (geometry, transparent) {
    var packId = geometry.packId;
    var geomId = geometry.svfid;
    geometry.traversed = this.traversedCounter;
    if (transparent)
    geometry.transparent = this.transparentCounter;

    // Only record it for paging if the pack file is allowed to be paged out.
    //if (packId >= this.options.minPackFiles) {
    var geomTraversed = true;

    var mapIdx = this.geomidsmap[geomId];
    if (mapIdx != null) {
      // increase counter of traversed geometry instances
      this.geomTravCount[mapIdx] += 2;
      this.geomTravCount[mapIdx] |= 1;

      geomTraversed = geometry.instanceCount == this.geomTravCount[mapIdx] >> 1;
    }

    var loaded = this.loadedPacks[packId];
    if (loaded) {
      if (geomTraversed) {
        loaded.travsed++;
      }
    }
    //}

  };

  this.onGeomCulled = function (geometry) {
    if (!geometry) {
      return;
    }

    var packId = geometry.packId;
    var geomId = geometry.svfid;

    // Only record it for paging if the pack file is allowed to be paged out.
    //if (packId >= this.options.minPackFiles) {
    var mapIdx = this.geomidsmap[geomId];
    var geomCulled = !mapIdx;

    if (mapIdx != null) {
      // The low order bit of geomeTravCount indicates whether the
      // geometry has ever been traversed. If it has, then treat this
      // cull as a traverse.
      if (this.geomTravCount[mapIdx] & 1)
      this.onGeomTraversed(geometry);else
      {
        // ??? multiple geometry instance, may have some traversed
        // ??? and some culled. The culled one is also marked as traversed count,
        // ??? so this geometry may be counted as either culled or traversed,
        // ??? that is ok so far.
        this.geomTravCount[mapIdx] += 2;
        geomCulled = geometry.instanceCount == this.geomTravCount[mapIdx] >> 1;
      }
    }

    var loaded = this.loadedPacks[packId];
    if (loaded && geomCulled)
    loaded.culled++;

    //}

  };

  // Add various hooks and settings needed for on demand loading
  this.removeHooks = function () {
    var viewer3DImpl = _loader.viewer3DImpl;

    // disable rollover highglighting
    var rolloverMethod = viewer3DImpl.rolloverObjectViewport;
    viewer3DImpl.rolloverObjectViewport = function () {};

    var renderer = viewer3DImpl.renderer();
    var renderPartMethod = renderer.renderScenePart;
    var _RenderBatchML = _render_RenderBatchML__WEBPACK_IMPORTED_MODULE_2__["RenderBatchML"];
    renderer.renderScenePart = function (scene, want_colorTarget, want_saoTarget, want_idTarget, updateLights) {
      // Need to handle occlusion ids. If we need occlusionids, then don't include transparent objects
      if (want_idTarget && scene instanceof avp.RenderBatch && scene.sortObjects) {
        want_idTarget = false;
      }

      renderPartMethod.call(this, scene, want_colorTarget, want_saoTarget, want_idTarget, updateLights);

      if (scene instanceof _RenderBatchML) {
        var start = scene.start,end = scene.lastItem;
        var vizflags = scene.frags.vizflags;
        var indices = scene.getIndices();
        var idx;
        while (start < end) {
          idx = indices ? indices[start] : start;
          if (vizflags[idx] & avp.MeshFlags.MESH_DRAWN)
          vizflags[idx] = (vizflags[idx] | avp.MeshFlags.MESH_TRAVERSED) & ~avp.MeshFlags.MESH_DRAWN;
          ++start;
        }
      }
    };

    viewer3DImpl.matman().toggleDepthWriteTransparent(false);

    // Turn on ground shadows and ground reflections for on demand loading
    viewer3DImpl.toggleGroundShadow(false);
    viewer3DImpl.toggleGroundReflection(false);
    var showShadows = false;
    var hideShadows = function hideShadows() {
      showShadows = true;
      viewer3DImpl.api.removeEventListener(av.TOOLBAR_CREATED_EVENT, hideShadows);
      setSettingsDisplay(viewer3DImpl.api, "none");
    };
    viewer3DImpl.api.addEventListener(av.TOOLBAR_CREATED_EVENT, hideShadows);
    var resize = function resize(ev) {
      _occlusionCulling.onResize();
    };
    viewer3DImpl.api.addEventListener(av.VIEWER_RESIZE_EVENT, resize);

    // Restore hooked functions and settings needed
    return function () {
      viewer3DImpl.api.removeEventListener(av.TOOLBAR_CREATED_EVENT, hideShadows);
      viewer3DImpl.api.removeEventListener(av.VIEWER_RESIZE_EVENT, hideShadows);

      viewer3DImpl.rolloverObjectViewport = rolloverMethod;

      viewer3DImpl.matman().toggleDepthWriteTransparent(true);

      // Restore ground shadows and ground reflections
      viewer3DImpl.toggleGroundShadow(viewer3DImpl.api.prefs.groundShadow);
      viewer3DImpl.toggleGroundReflection(viewer3DImpl.api.prefs.groundReflection);
      if (showShadows)
      setSettingsDisplay(viewer3DImpl.api, "");
    };
  }();
};

/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/main/WorkerCreatorML.js":
/*!***********************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/main/WorkerCreatorML.js ***!
  \***********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

var SvfWorkerML = __webpack_require__(/*! worker-loader?inline!../workers/MainWorker-webML */ "./node_modules/worker-loader/dist/cjs.js?inline!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js");

function initWorkerScriptML(callback) {
  callback();
  return undefined;
}

function createWorkerML() {
  var w = new SvfWorkerML();
  w.doOperation = w.postMessage;
  return w;
}

function createWorkerWithInterceptML() {
  var worker = createWorkerML();

  worker.checkEvent = function (e) {
    if (e.data && e.data.assetRequest) {
      return true;
    }
    return false;
  };

  var interceptListeners = [];
  function popCallback(listener) {
    if (!interceptListeners) return null;
    for (var i = 0; i < interceptListeners.length; ++i) {
      if (interceptListeners[i].arg === listener) {
        var ret = interceptListeners[i].callback;
        interceptListeners.splice(i, 1);
        if (interceptListeners.length === 0)
        interceptListeners = null;
        return ret;
      }
    }
    return null;
  }

  worker.addEventListenerWithIntercept = function (listener) {

    var callbackFn = function callbackFn(ew) {
      if (worker.checkEvent(ew))
      return;

      listener(ew);
    };

    if (!interceptListeners) interceptListeners = [];
    interceptListeners.push({ arg: listener, callback: callbackFn });
    worker.addEventListener('message', callbackFn, false);
    return callbackFn;
  };

  worker.removeEventListenerWithIntercept = function (listener) {
    var callbackFn = popCallback(listener);
    if (callbackFn) {
      worker.removeEventListener('message', callbackFn, false);
    }
  };

  worker.clearAllEventListenerWithIntercept = function () {
    if (!interceptListeners) return;
    var copy = interceptListeners.concat();
    for (var i = 0; i < copy.length; ++i) {
      worker.removeEventListenerWithIntercept(copy[i].arg);
    }
  };

  return worker;
}

module.exports = {
  createWorkerML: createWorkerML,
  initWorkerScriptML: initWorkerScriptML,
  createWorkerWithInterceptML: createWorkerWithInterceptML };

/***/ }),

/***/ "./extensions/MemoryLimited/file-loaders/main/envinit.js":
/*!***************************************************************!*\
  !*** ./extensions/MemoryLimited/file-loaders/main/envinit.js ***!
  \***************************************************************/
/*! exports provided: processMemoryOptions */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "processMemoryOptions", function() { return processMemoryOptions; });
var av = Autodesk.Viewing;
var avp = av.Private;

/**
                       * Normalizes memory options passed into the viewer instance or stated in the URL
                       * The URL parameter to check is `viewermemory` and has a number value that represents
                       * the MegaByte memory limit.
                       * @example:
                       *      ?viewermemory=500 ----- set memory limit of 500 MB
                       *      ?viewermemory=500f ---- force memory limit of 500 MB, which activates on-demand-loading mechanism (debug).
                       * @private
                       */
function processMemoryOptions(viewer3Dimpl, config3d) {

  var memoryOpts = Object.assign({}, config3d && config3d.memory);
  memoryOpts.debug = Object.assign({}, memoryOpts.debug);

  var memLimit;
  // Verify memory values are valid/consistant
  memLimit = parseInt(memoryOpts.limit) | 0;
  var forced = memoryOpts.debug && memoryOpts.debug.force || false;
  if (forced && memLimit <= 0) {
    memoryOpts.force = false; // disable forced when the limit is not valid.
    avp.logger.warn('config.memory.limit value is invalid: (' + memoryOpts.limit + ')');
  }

  // If URL argument is passed in, override limit specified through code
  var urlValue = av.getParameterByName('viewermemory');
  var memLimit = parseInt(urlValue);
  // If urlValue isn't a number, memLimit will be a NaN and comparison will fail.
  if (memLimit > 0) {
    // Now, truncate memLimit to an integer.
    memLimit = memLimit | 0;
    // Only allow forced when memLimit > 0, memLimit == 0 disables the limit.
    var isForced = memLimit > 0 && urlValue.charAt(urlValue.length - 1).toLowerCase() === 'f'; // Check if there is an F at the end.
    memoryOpts = {
      limit: memLimit,
      debug: { force: isForced } };

    if (isForced) {
      avp.logger.info('Forcing memory limit to URL param: (' + memLimit + ' MegaBytes).');
    } else {
      avp.logger.info('Setting memory limit to URL param: (' + memLimit + ' MegaBytes).');
    }
  } else if (memLimit === 0) {
    memoryOpts = { limit: 0 };
  } else {
    // don't issue warning if viewermemory parameter (e.g., "&viewermemory=500") is not in URL at all
    if (urlValue !== "")
    avp.logger.warn('Invalid viewermemory URL param value: (' + urlValue + ')');
  }

  var isLimited = function isLimited(models) {
    for (var i = 0; i < models.length; ++i) {
      var frags = models[i].getFragmentList();
      if (frags && frags._pagingProxy)
      return true;
    }
  };

  // If there is another on demand loading model, then disable this one.
  if (isLimited(viewer3Dimpl.modelQueue().getModels()) ||
  isLimited(viewer3Dimpl.modelQueue().getHiddenModels())) {
    // Only one model can be memory lmiited
    memoryOpts.limit = 0;
    memoryOpts.debug.force = false;
  }

  return memoryOpts;
};

/***/ }),

/***/ "./extensions/MemoryLimited/render/DbidFragmentMap.js":
/*!************************************************************!*\
  !*** ./extensions/MemoryLimited/render/DbidFragmentMap.js ***!
  \************************************************************/
/*! exports provided: DbidFragmentMap */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "DbidFragmentMap", function() { return DbidFragmentMap; });
function _typeof(obj) {if (typeof Symbol === "function" && typeof Symbol.iterator === "symbol") {_typeof = function _typeof(obj) {return typeof obj;};} else {_typeof = function _typeof(obj) {return obj && typeof Symbol === "function" && obj.constructor === Symbol && obj !== Symbol.prototype ? "symbol" : typeof obj;};}return _typeof(obj);}function _classCallCheck(instance, Constructor) {if (!(instance instanceof Constructor)) {throw new TypeError("Cannot call a class as a function");}}function _defineProperties(target, props) {for (var i = 0; i < props.length; i++) {var descriptor = props[i];descriptor.enumerable = descriptor.enumerable || false;descriptor.configurable = true;if ("value" in descriptor) descriptor.writable = true;Object.defineProperty(target, descriptor.key, descriptor);}}function _createClass(Constructor, protoProps, staticProps) {if (protoProps) _defineProperties(Constructor.prototype, protoProps);if (staticProps) _defineProperties(Constructor, staticProps);return Constructor;}function _possibleConstructorReturn(self, call) {if (call && (_typeof(call) === "object" || typeof call === "function")) {return call;}return _assertThisInitialized(self);}function _assertThisInitialized(self) {if (self === void 0) {throw new ReferenceError("this hasn't been initialised - super() hasn't been called");}return self;}function _getPrototypeOf(o) {_getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) {return o.__proto__ || Object.getPrototypeOf(o);};return _getPrototypeOf(o);}function _inherits(subClass, superClass) {if (typeof superClass !== "function" && superClass !== null) {throw new TypeError("Super expression must either be null or a function");}subClass.prototype = Object.create(superClass && superClass.prototype, { constructor: { value: subClass, writable: true, configurable: true } });if (superClass) _setPrototypeOf(subClass, superClass);}function _setPrototypeOf(o, p) {_setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) {o.__proto__ = p;return o;};return _setPrototypeOf(o, p);} /* global Autodesk */

var avp = Autodesk.Viewing.Private;

var ROOT_NODE_ID = -1 << 30;

function buildDbIdToFragMap(fragToDbId) {
  var ret = {};
  for (var i = 0, iEnd = fragToDbId.length; i < iEnd; i++) {

    var dbIds = fragToDbId[i];

    //In 2D drawings, a single fragment (consolidation mesh)
    //can contain multiple objects with different dbIds.
    if (!Array.isArray(dbIds)) {
      dbIds = [dbIds];
    }

    for (var j = 0; j < dbIds.length; j++) {
      var dbId = dbIds[j];
      var frags = ret[dbId];
      if (frags === undefined) {
        //If it's the first fragments for this dbid,
        //store the index directly -- most common case.
        ret[dbId] = i;
      } else
      if (!Array.isArray(frags)) {
        //otherwise put the fragments that
        //reference the dbid into an array
        ret[dbId] = [frags, i];
      } else
      {
        //already is an array
        frags.push(i);
      }
    }
  }

  return ret;
}

/**
   * Map dbids to fragment dbids
   * 
   * When there isn't an instance tree this object can be used to get the fragment ids for
   * database ids.
   * 
   * @param {ArrayLike} fragToDbId - fragToDbId[i] is the dbid or an array of dbids for fragment with id i 
   */
var DbidFragmentMap = /*#__PURE__*/function (_avp$InstanceTree) {_inherits(DbidFragmentMap, _avp$InstanceTree);function DbidFragmentMap() {_classCallCheck(this, DbidFragmentMap);return _possibleConstructorReturn(this, _getPrototypeOf(DbidFragmentMap).apply(this, arguments));}_createClass(DbidFragmentMap, null, [{ key: "buildInstanceTree", value: function buildInstanceTree(
    fragToDbId, fragmentList) {
      // Invert the frag to dbid map
      var dbIdToFrags = buildDbIdToFragMap(fragToDbId);

      // Get the dbids and an InstanceTreeStorage object
      var dbIds = Object.keys(dbIdToFrags);
      var count = dbIds.length;
      var storage = new avp.InstanceTreeStorage(count + 1, fragToDbId.length);
      var emptyArray = [];
      var oneArray = [0];

      // Add the root node
      storage.setNode(ROOT_NODE_ID, 0, "root", 0 /* NODE_TYPE_ASSEMBLY */, dbIds, emptyArray);

      // Add the leaf nodes
      for (var i = 0; i < count; ++i) {
        var dbId = dbIds[i];
        var frags = dbIdToFrags[dbId];
        if (!Array.isArray(frags)) {
          oneArray[0] = frags;
          frags = oneArray;
        }
        storage.setNode(dbId, ROOT_NODE_ID, "node:" + dbId, 6 /*NODE_TYPE_GEOMETRY */, emptyArray, frags);
      }
      // Free some stuff that we dont need any longer
      dbIds = undefined;
      dbIdToFrags = undefined;

      // Flatten the storage
      storage.flatten();

      // Convert storage to an instance tree access object
      storage = new avp.InstanceTreeAccess(storage, ROOT_NODE_ID);

      // Create the instance tree
      var tree = new DbidFragmentMap(storage, count + 1, 2);
      tree.setFragmentList(fragmentList);

      // Return it
      return tree;
    } }]);return DbidFragmentMap;}(avp.InstanceTree);

/***/ }),

/***/ "./extensions/MemoryLimited/render/ModelML.js":
/*!****************************************************!*\
  !*** ./extensions/MemoryLimited/render/ModelML.js ***!
  \****************************************************/
/*! exports provided: ModelML */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "ModelML", function() { return ModelML; });
/* harmony import */ var _RenderBatchML__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./RenderBatchML */ "./extensions/MemoryLimited/render/RenderBatchML.js");
/* harmony import */ var _pageoutStatus__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./pageoutStatus */ "./extensions/MemoryLimited/render/pageoutStatus.js");



var av = Autodesk.Viewing;
var avp = av.Private;

// Use 16 bits to store the visibility for draw modes (render phases)
// Different phases can share the same bits if the visibility is the same.
// Phases past the end of the array use the visibility for RENDER_NORMAL
var PHASE_VISIBILITY = [
0x0001, // RENDER_NORMAL
0x0001, // RENDER_HIGHLIGHT
0x0002, // RENDER_HIDDEN
0x0004 // RENDER_SHADOWMAP
];

/**
    * subclass of model for on demand loading
    * @param {*} modelData 
    */
function ModelML(modelData) {var _this = this;
  av.Model.call(this, modelData);
  this.RenderBatch = _RenderBatchML__WEBPACK_IMPORTED_MODULE_0__["RenderBatchML"];
  var _initialize = this.initialize;
  var _resetIterator = this.resetIterator;
  var _nextBatch = this.nextBatch;
  var _dtor = this.dtor;
  var _visibilityMode = PHASE_VISIBILITY[avp.RenderFlags.RENDER_NORMAL]; // Allows different passes to have different visibility (e.g. hidden and normal)
  var _rflag = avp.MeshFlags.MESH_RENDERFLAG;
  var _animReq = 0;

  var animCallback = function animCallback() {
    _animReq = requestAnimationFrame(animCallback);
    _this.frameUpdatePaging();
  };


  this.initialize = function (pagingProxy) {
    _initialize.call(this);

    // Set the paging proxy on the fragment list for later
    var frags = this.getFragmentList();
    frags._pagingProxy = this.loader.pagingProxy;
    frags._renderCount = 0;

    // Calculate the batch bounding boxes
    // TODO: is this only needed for pixelCulling
    var scenes = this.getIterator().getGeomScenes();
    for (var i = 0; i < scenes.length; ++i) {
      scenes[i].calculateBounds();
    }

    _animReq = requestAnimationFrame(animCallback);
  };

  /** 
      *  Deletes all GPU resources.
      *
      *  @param {FireflyWebGLRenderer} glRenderer
      */
  this.dtor = function (glrenderer) {
    if (_animReq) {
      cancelAnimationFrame(_animReq);
      _animReq = 0;
    }

    _dtor.call(this, glrenderer);
  };

  /** 
      *  Starts the scene draw traversal, so that nextBatch() will return the first batch to render.
      *   @param: {UnifiedCamera}      camera       - camera.position was needed for the heuristic to choose between linear iterator and BVH.
      *                                               [HB:] The code is currently outcommented, so the param is currently unused.
      *   @param: {FrustumIntersector} frustum      - used by RenderBatches for frustum culling and z-sorting.
      *   @param: {number}             drawMode     - E.g., RENDER_NORMAL. See RenderFlags.js
      *   @param: {number}             [resetType]  - Must be one of RESET_NORMAL, RESET_REDRAW or RESET_RELOAD.
      *                                               Only used when on demand loading is enabled. RESET_RELOAD will reload and redraw
      *                                               geometry. RESET_REDRAW will redraw geometry. RESET_NORMAL will only redraw geometry
      *                                               that hasn't already been drawn. If undefined RESET_NORMAL is used.
      */
  this.resetIterator = function (camera, frustum, drawMode, resetType) {
    resetType = resetType || avp.ResetFlags.RESET_NORMAL;
    var pagingProxy = this.loader.pagingProxy;
    var frags = this.getFragmentList();
    _rflag = _RenderBatchML__WEBPACK_IMPORTED_MODULE_0__["RENDER_FLAGS"][drawMode] || avp.MeshFlags.MESH_RENDERFLAG;
    pagingProxy.resetIterator(camera, resetType);

    var iterator = _resetIterator.call(this, camera, frustum, drawMode);

    // For visibility, Set the bit used to cache visibility for a phase
    _visibilityMode = PHASE_VISIBILITY[drawMode] || PHASE_VISIBILITY[avp.RenderFlags.RENDER_NORMAL];

    // If scene/camera has changed, we have to rebuild some data that we collected for paging, because the set of currently 
    // needed fragments may change.
    // Note that frags will be null when using a custom iterator. In this case, this
    // paging-related code is not used and can be skipped.
    if (resetType != avp.ResetFlags.RESET_NORMAL) {
      ++frags._renderCount;

      if (resetType >= avp.ResetFlags.RESET_REDRAW) {

        // reset MESH_TRAVERSED flag 
        frags.setFlagGlobal(avp.MeshFlags.MESH_TRAVERSED, false);

        this.resetVisStatus();
      }

      if (resetType >= avp.ResetFlags.RESET_RELOAD) {
        frags._pagingProxy.moving = 2;
        // restart tracking of paging status
        this._pageOutStatus = _pageoutStatus__WEBPACK_IMPORTED_MODULE_1__["PAGEOUT_NONE"];

        // reset lists of culled and traversed geometry
        pagingProxy.reset();
      }

    }

    return iterator;
  };

  this.nextBatch = function () {
    var scene = _nextBatch.call(this);
    // Let the scene know which render flag it should use
    scene && (scene._rflag = _rflag);
    return scene;
  };

  this.applyVisibility = function (scene, drawMode, frustum) {
    // If visible stats for _visibilityMode is 0 then apply visibility check
    if (scene.visibleStats & _visibilityMode) {
      return !(scene.visibleStats & _visibilityMode << 16);
    }

    //TODO: move this into the iterator?
    var allHidden = scene.applyVisibility(
    drawMode,
    frustum);

    // Assume clear visibility calculated clears both bits
    scene.visibleStats |= _visibilityMode;
    if (!allHidden)
    scene.visibleStats |= _visibilityMode << 16;

    // For 3D scenes, sort fragments of this batch. 
    // Note that fragments of F2D scenes must be drawn in original order.
    //TODO: Move this to the iterator?
    if (!allHidden && !this.is2d()) {
      //Generally opaque batches are sorted once by material, while
      //transparent batches are sorted back to front each frame
      if (scene.sortObjects && !this.getFragmentList().useThreeMesh)
      scene.sortByDepth(frustum);else
      if (!scene.sortDone)
      scene.sortByMaterial();
    }

    return allHidden;
  };
}

ModelML.prototype = Object.create(av.Model.prototype);
ModelML.prototype.constructor = ModelML;

ModelML.prototype.resetVisStatus = function () {
  var scenes = this.getIterator().getGeomScenes();
  for (var i = 0; i < scenes.length; ++i) {
    var scene = scenes[i];
    scene && scene.resetVisStatus();
  }
};

/** 
    *  Triggers paging out of geometry if necessary.
    * 
    *  In each frame update, some more batches of the overall scene are rendered until time runs out. 
    *  This function is called at the end of each such frame update to page out stuff if needed.
    *  (see RenderScene.renderSome)
    *
    *   &param [bool] isBeginFrame - Indicates if the current frame update was the first one.
    *                                TODO: isbeginFrame can be removed.
    */
ModelML.prototype.frameUpdatePaging = function () {

  var pagingProxy = this.loader.pagingProxy;
  var done = this.getIterator().done();

  this._pageOutStatus = pagingProxy.pageOut(done, false);

  // When scene rendering traversal is finished and we did not page out enough
  // in the previous frame updates yet, do some final paging-out and make sure that it succeeds.
  if (done && this._pageOutStatus == _pageoutStatus__WEBPACK_IMPORTED_MODULE_1__["PAGEOUT_FAIL"]) {
    // We will give a last try of paging out,
    // if still fail and traversed geometry is not empty, then will need another render.
    // otherwise, need a hard page out no matter geometry get traversed or not.
    this._pageOutStatus = pagingProxy.pageOut(true, true);
  }

  return this._pageOutStatus;
};

/***/ }),

/***/ "./extensions/MemoryLimited/render/OcclusionCulling.js":
/*!*************************************************************!*\
  !*** ./extensions/MemoryLimited/render/OcclusionCulling.js ***!
  \*************************************************************/
/*! exports provided: OcclusionCulling */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OcclusionCulling", function() { return OcclusionCulling; });
/* harmony import */ var _OcclusionShader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./OcclusionShader */ "./extensions/MemoryLimited/render/OcclusionShader.js");




/* global THREE, Autodesk */

var avp = Autodesk.Viewing.Private;
var _white = new THREE.Color().setRGB(1, 1, 1);

function OcclusionCulling() {

  var _renderer;
  var _context; // RenderContext for the viewer
  var _camera;

  // Occlusion test variables
  var _occlusionMaterials = [[], []];
  var _occlusionTarget = null;
  var _occlusionTest = null;
  var _unitCubeVerts = null;
  var _unitCubeIndices = null;
  var _occlusionScene = null;

  //Rendering options - from the render context
  var _settings;

  //TODO: hide this once there is a way
  //to obtain the current pipeline configuration
  this.settings = _settings;

  this.initialize = function (glrenderer, context) {

    if (!glrenderer) {
      avp.logger.error("You need a gl context use occlusion culling. Things will go downhill from here.", av.errorCodeString(av.ErrorCodes.BROWSER_WEBGL_NOT_SUPPORTED));
      return;
    }

    _renderer = glrenderer;
    _context = context;
    _settings = context.settings;

  };

  function destroyOcclusionTarget() {
    if (_occlusionTarget) {
      _occlusionTarget.dispose();
      _occlusionTarget = null;
    }

    _occlusionTest = null;
  }

  this.onResize = function () {
    destroyOcclusionTarget();
  };

  function createOcclusionTarget() {
    _occlusionTarget = new THREE.WebGLRenderTarget(
    _settings.deviceWidth, _settings.deviceHeight,
    { minFilter: THREE.NearestFilter,
      magFilter: THREE.NearestFilter,
      format: THREE.RGBAFormat,
      stencilBuffer: false });

    _occlusionTarget.generateMipmaps = false;
    _occlusionTarget.shareDepthFrom = _context.getColorTarget();
  }

  function addVerts(bboxVerts, toVerts, boxes, from) {
    // Eight corners of the box
    bboxVerts[toVerts++] = boxes[from];
    bboxVerts[toVerts++] = boxes[from + 1];
    bboxVerts[toVerts++] = boxes[from + 2];

    bboxVerts[toVerts++] = boxes[from + 3];
    bboxVerts[toVerts++] = boxes[from + 1];
    bboxVerts[toVerts++] = boxes[from + 2];

    bboxVerts[toVerts++] = boxes[from];
    bboxVerts[toVerts++] = boxes[from + 4];
    bboxVerts[toVerts++] = boxes[from + 2];

    bboxVerts[toVerts++] = boxes[from + 3];
    bboxVerts[toVerts++] = boxes[from + 4];
    bboxVerts[toVerts++] = boxes[from + 2];

    bboxVerts[toVerts++] = boxes[from];
    bboxVerts[toVerts++] = boxes[from + 1];
    bboxVerts[toVerts++] = boxes[from + 5];

    bboxVerts[toVerts++] = boxes[from + 3];
    bboxVerts[toVerts++] = boxes[from + 1];
    bboxVerts[toVerts++] = boxes[from + 5];

    bboxVerts[toVerts++] = boxes[from];
    bboxVerts[toVerts++] = boxes[from + 4];
    bboxVerts[toVerts++] = boxes[from + 5];

    bboxVerts[toVerts++] = boxes[from + 3];
    bboxVerts[toVerts++] = boxes[from + 4];
    bboxVerts[toVerts++] = boxes[from + 5];
    return toVerts;
  }

  function addIndices(bboxIndices, toIndices, indexBase) {
    // -y
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 1;
    bboxIndices[toIndices++] = indexBase + 5;
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 5;
    bboxIndices[toIndices++] = indexBase + 4;

    // -z
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 2;
    bboxIndices[toIndices++] = indexBase + 3;
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 3;
    bboxIndices[toIndices++] = indexBase + 1;

    // -x
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 4;
    bboxIndices[toIndices++] = indexBase + 6;
    bboxIndices[toIndices++] = indexBase;
    bboxIndices[toIndices++] = indexBase + 6;
    bboxIndices[toIndices++] = indexBase + 2;

    // +z
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 6;
    bboxIndices[toIndices++] = indexBase + 4;
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 4;
    bboxIndices[toIndices++] = indexBase + 5;

    // +x
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 5;
    bboxIndices[toIndices++] = indexBase + 1;
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 1;
    bboxIndices[toIndices++] = indexBase + 3;

    // +y
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 3;
    bboxIndices[toIndices++] = indexBase + 2;
    bboxIndices[toIndices++] = indexBase + 7;
    bboxIndices[toIndices++] = indexBase + 2;
    bboxIndices[toIndices++] = indexBase + 6;

    return toIndices;
  }

  function createBBoxGeometry(boxes, fragIds, start, length) {
    var bboxVerts = new Float32Array(length * 24);
    var bboxIndices = new Uint16Array(length * 36);
    var toVerts = 0,toIndices = 0,indexBase = 0;
    length += start;
    for (; start < length; ++start, indexBase += 8) {
      // Copy indices and vertices for the box
      toIndices = addIndices(bboxIndices, toIndices, indexBase);
      toVerts = addVerts(bboxVerts, toVerts, boxes, fragIds[start] * 6);
    }

    var geometry = new THREE.BufferGeometry();
    geometry.addAttribute('position', new THREE.BufferAttribute(bboxVerts, 3));
    geometry.addAttribute('index', new THREE.BufferAttribute(bboxIndices, 1));
    geometry.streamingDraw = true;
    geometry.streamingIndex = true;
    return geometry;
  }

  function createInstancedBBoxGeometry(boxes, fragIds, start, length) {
    // Don't interleave the min and max vertices.
    var minVerts = new Float32Array(length * 3);
    var scaleVerts = new Float32Array(length * 3);
    var toVerts = 0;
    var end = length + start;
    for (; start < end; ++start) {
      var from = fragIds[start] * 6;
      scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
      minVerts[toVerts++] = boxes[from++];
      scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
      minVerts[toVerts++] = boxes[from++];
      scaleVerts[toVerts] = boxes[from + 3] - boxes[from];
      minVerts[toVerts++] = boxes[from++];
    }

    var geometry = new THREE.BufferGeometry();
    geometry.addAttribute('position', new THREE.BufferAttribute(_unitCubeVerts, 3));
    geometry.addAttribute('index', new THREE.BufferAttribute(_unitCubeIndices, 1));
    var minAttr = new THREE.BufferAttribute(minVerts, 3);
    minAttr.divisor = 1;
    var scaleAttr = new THREE.BufferAttribute(scaleVerts, 3);
    scaleAttr.divisor = 1;
    geometry.addAttribute('instOffset', minAttr);
    geometry.addAttribute('instScaling', scaleAttr);
    geometry.numInstances = length;
    geometry.streamingDraw = true;
    geometry.streamingIndex = true;
    return geometry;
  }

  function createUnitCube() {
    // Create unit cube vertex and index buffers
    _unitCubeVerts = new Float32Array(24);
    _unitCubeIndices = new Uint16Array(36);
    addIndices(_unitCubeIndices, 0, 0);
    addVerts(_unitCubeVerts, 0, [0, 0, 0, 1, 1, 1], 0);
  }

  // Create the occlusion materials for testing. The materials can test one pack file
  // in each color component, R, G, B, or A. The colors are setup so we can blend
  // each component separately using D = D * S. The target is initialized to opaque
  // white and a 0 in a component means a pixel was drawn. Doing it this way
  // makes it easier to see the results if we need to look at the bitmap.
  // The colors and alphas are ordered to match the byte ordering in the pixel.
  var colors = [
  [0, 1, 1],
  [1, 0, 1],
  [1, 1, 0],
  [1, 1, 1]];

  var alphas = [1, 1, 1, 0];
  function createOcclusionMaterials(length, instanced) {
    var useInstancing = !!instanced;
    for (var i = _occlusionMaterials[instanced].length; i < length; ++i) {
      var occlusionMaterial = avp.createShaderMaterial(_OcclusionShader__WEBPACK_IMPORTED_MODULE_0__["OcclusionShader"]);
      occlusionMaterial.useInstancing = useInstancing;
      occlusionMaterial.depthWrite = false;
      occlusionMaterial.uniforms.color.value.set(colors[i][0], colors[i][1], colors[i][2]);
      occlusionMaterial.uniforms.opacity.value = alphas[i];
      occlusionMaterial.defaultAttributeValues.instRotate = [1, 0, 0, 0];
      occlusionMaterial.blending = THREE.CustomBlending;
      occlusionMaterial.blendDst = THREE.SrcColorFactor;
      occlusionMaterial.blendSrc = THREE.ZeroFactor;
      occlusionMaterial.blendEquation = THREE.AddEquation;
      occlusionMaterial.transparent = true;
      _occlusionMaterials[instanced][i] = occlusionMaterial;
    }
  }

  // Return whether the fragment ids are occluded
  this.occlusionTest = function (boxes, threshold, fragIds, useInstancing, packIds) {
    if (!fragIds || fragIds.length <= 0 || fragIds.length > 4)
    return Promise.reject({ error: "fragIds invalid. Must be a nonempty array of fragment id arrays with length <= 4" });

    var counts = [0, 0, 0, 0];
    var visibleCount = 0;
    useInstancing = useInstancing && _renderer.supportsInstancedArrays() ? 1 : 0;
    if (!_occlusionMaterials[useInstancing] || _occlusionMaterials[useInstancing].length < fragIds.length)
    createOcclusionMaterials(fragIds.length, useInstancing);

    if (useInstancing && !_unitCubeVerts)
    createUnitCube();

    // Create a scene for the boxes
    if (!_occlusionScene)
    _occlusionScene = new THREE.Scene();
    _occlusionScene.frustumCulled = false;

    // Be careful and don't create buffers to large for short indices
    // 8 vertices per fragment box out of 64K vertices max means we
    // can't do more than 8K fragments per buffer. Cut this in half,
    // and only allow 4096 fragments per buffer. If we are instancing
    // then the buffers only hold a single point per instance, so
    // allow 32K fragments.
    var maxSize = useInstancing ? 32768 : 4096;
    var i;
    for (i = 0; i < fragIds.length; ++i) {
      var fragIdList = fragIds[i];
      if (fragIdList && fragIdList.length > 0) {
        counts[i] = threshold;
        ++visibleCount;
        var occlusionMaterial = _occlusionMaterials[useInstancing][i];
        var length = fragIdList.length;
        var start = 0,end;
        for (; start < length; start += end) {
          end = Math.min(maxSize, length - start);

          // Build buffer for the fragment boxes
          var geometry = useInstancing ? createInstancedBBoxGeometry(boxes, fragIdList, start, end) :
          createBBoxGeometry(boxes, fragIdList, start, end);
          var mesh = new THREE.Mesh(geometry, occlusionMaterial);
          mesh.frustumCulled = false;
          _occlusionScene.add(mesh);
        }
      }
    }

    // Clear render target
    if (!_occlusionTarget)
    createOcclusionTarget();
    _renderer.setClearColor(_white, 1);

    // Render the scene
    _renderer.setRenderTarget(_occlusionTarget);
    _renderer.clear(true, false, false);
    _renderer.render(_occlusionScene, _camera, _occlusionTarget, false, null);

    // Some cleanup
    _renderer.clearBlend();
    _occlusionScene.children.forEach(function (mesh) {
      mesh.geometry.dispose();
    });
    _occlusionScene.remove.apply(_occlusionScene, _occlusionScene.children); // Remove all children from scene

    // Get the result.
    if (!_occlusionTest)
    _occlusionTest = new Uint8Array(_settings.deviceWidth * 4 * _settings.deviceHeight);
    _renderer.readRenderTargetPixels(_occlusionTarget, 0, 0, _settings.deviceWidth, _settings.deviceHeight, _occlusionTest);

    // Look for pixels.
    switch (fragIds.length) {
      case 1:
        for (i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
          if (!_occlusionTest[i]) {
            counts[0] -= 1;
            visibleCount -= !counts[0];
          }
        }
        return Promise.resolve([counts[0] <= 0]);
      case 2:
        for (i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
          if (!_occlusionTest[i]) {
            counts[0] -= 1;
            visibleCount -= !counts[0];
          }
          if (!_occlusionTest[i + 1]) {
            counts[1] -= 1;
            visibleCount -= !counts[1];
          }
        }
        return Promise.resolve([counts[0] <= 0, counts[1] <= 0]);
      case 3:
        for (i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
          if (!_occlusionTest[i]) {
            counts[0] -= 1;
            visibleCount -= !counts[0];
          }
          if (!_occlusionTest[i + 1]) {
            counts[1] -= 1;
            visibleCount -= !counts[1];
          }
          if (!_occlusionTest[i + 2]) {
            counts[2] -= 1;
            visibleCount -= !counts[2];
          }
        }
        return Promise.resolve([counts[0] <= 0, counts[1] <= 0, counts[2] <= 0]);
      case 4:
        for (i = _occlusionTest.length; visibleCount > 0 && (i -= 4) >= 0;) {
          if (!_occlusionTest[i]) {
            counts[0] -= 1;
            visibleCount -= !counts[0];
          }
          if (!_occlusionTest[i + 1]) {
            counts[1] -= 1;
            visibleCount -= !counts[1];
          }
          if (!_occlusionTest[i + 2]) {
            counts[2] -= 1;
            visibleCount -= !counts[2];
          }
          if (!_occlusionTest[i + 3]) {
            counts[3] -= 1;
            visibleCount -= !counts[3];
          }
        }
        return Promise.resolve([counts[0] <= 0, counts[1] <= 0, counts[2] <= 0, counts[3] <= 0]);}

  };

  this.dtor = function () {

    if (_renderer) {
      _renderer.setRenderTarget(null);
    }

    destroyOcclusionTarget();
  };

  //Required for switching camera for stereo rendering
  this.setCamera = function (camera) {
    _camera = camera;
  };
}

/***/ }),

/***/ "./extensions/MemoryLimited/render/OcclusionShader.js":
/*!************************************************************!*\
  !*** ./extensions/MemoryLimited/render/OcclusionShader.js ***!
  \************************************************************/
/*! exports provided: OcclusionShader */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "OcclusionShader", function() { return OcclusionShader; });
/* harmony import */ var _shaders_occlusion_vert_glsl__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./shaders/occlusion_vert.glsl */ "./extensions/MemoryLimited/render/shaders/occlusion_vert.glsl");
/* harmony import */ var _shaders_occlusion_vert_glsl__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(_shaders_occlusion_vert_glsl__WEBPACK_IMPORTED_MODULE_0__);
/* harmony import */ var _shaders_occlusion_frag_glsl__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./shaders/occlusion_frag.glsl */ "./extensions/MemoryLimited/render/shaders/occlusion_frag.glsl");
/* harmony import */ var _shaders_occlusion_frag_glsl__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(_shaders_occlusion_frag_glsl__WEBPACK_IMPORTED_MODULE_1__);
//Simple shader for occlusion testing




/* global THREE */

var OcclusionShader = {

  uniforms: {
    "color": { type: "v3", value: new THREE.Vector3(0, 0, 0) },
    "opacity": { type: "f", value: 1.0 } },


  rawShader: true,

  vertexShader: _shaders_occlusion_vert_glsl__WEBPACK_IMPORTED_MODULE_0___default.a,
  fragmentShader: _shaders_occlusion_frag_glsl__WEBPACK_IMPORTED_MODULE_1___default.a };

/***/ }),

/***/ "./extensions/MemoryLimited/render/RenderBatchML.js":
/*!**********************************************************!*\
  !*** ./extensions/MemoryLimited/render/RenderBatchML.js ***!
  \**********************************************************/
/*! exports provided: RENDER_FLAGS, RenderBatchML */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RENDER_FLAGS", function() { return RENDER_FLAGS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "RenderBatchML", function() { return RenderBatchML; });
/* global THREE, Autodesk */

var _tmpBox = new THREE.Box3();
var avp = Autodesk.Viewing.Private;
var MESH_RENDERFLAG = avp.MeshFlags.MESH_RENDERFLAG;

var RENDER_FLAGS = [
MESH_RENDERFLAG, // RENDER_NORMAL
0x8000, // RENDER_HIDDEN
0x4000, // RENDER_HIGHLIGHTED
0x2000 // RENDER_SHADOWMAP
];

function RenderBatchML(frags, fragOrder, start, count) {
  avp.RenderBatch.call(this, frags, fragOrder, start, count);

  // visibility flag for scene batch. -1: not check yet, 0: not visible, 1: visible
  // this is useful when travserse the same batch again in a re-render without reset the iterator, 
  // that won't apply visibility again.
  this.visibleStats = 0;
}

RenderBatchML.prototype = Object.create(avp.RenderBatch.prototype);
RenderBatchML.prototype.constructor = RenderBatchML;

RenderBatchML.prototype.resetVisStatus = function () {
  this.visibleStats = 0;
};

RenderBatchML.prototype.forEach = function (callback, drawMode, includeEmpty) {

  var indices = this.getIndices();

  var frags = this.frags;
  var sortByShaderPossible = !this.sortByShaderDone;
  var rflag = drawMode;
  if (drawMode === MESH_RENDERFLAG) {
    rflag = this._rflag; // Set by ModelML.nextBatch()
    ++frags._renderCount;
  }

  //var showPF = (frags.showPF === undefined ) ? -1 : frags.showPF;

  for (var i = this.start, iEnd = this.lastItem; i < iEnd; i++) {
    var idx = indices ? indices[i] : i;
    var m = frags.getVizmesh(idx, this.renderImportance, true);
    if (sortByShaderPossible && (!m || !m.material || !m.material.program || m.geometry_proxy))
    sortByShaderPossible = false;

    // If already traversed for rendering, ignore this fragment.
    if (frags.isFlagSet(idx, avp.MeshFlags.MESH_TRAVERSED) && drawMode == MESH_RENDERFLAG) {
      continue;
    }

    // for debug only, if the PF is to be displayed, then check if this fragment is in the designated PF
    //if ((showPF !== -1) && (showPF !== frags.fragments.packIds[idx])) {
    //    continue;
    //}

    // If geometry of this fragment is required...
    if (!includeEmpty && rflag && frags.isFlagSet(idx, rflag)) {

      if (!m.geometry) {
        // Require geometry only when we truly need it, so that it is available on later runs.
        // Note that m.geometry will usually be null here.
        m.geometry = this._requireGeometry(idx);
        if (idx < this.drawOrderRender)
        this.drawOrderRender = idx;

        if (!m.geometry && m.geometry_proxy)
        m.geometry = m.geometry_proxy;
      }
      // geometry may now be set, if retrieved or a proxy box is to be displayed.
      if (m.geometry) {
        // Set traversed flag for this fragment. Don't set it if we are drawing
        // fragments out of order. Then they will be drawn again over anything
        // that might have been drawn.
        var drawn = drawMode == MESH_RENDERFLAG && frags.isFlagSet(idx, avp.MeshFlags.MESH_DRAWN);
        if (drawMode == MESH_RENDERFLAG) {
          if (this.drawOrderRender == undefined || idx < this.drawOrderRender)
          frags.setFlagFragment(idx, avp.MeshFlags.MESH_DRAWN, true);else
          {
            continue; // Don't draw out of order
          }
        }

        // For fragments that may be paged out, check if this fragment was the
        // last one 
        // Only record candidates for paging if it is enabled. 
        if (!drawn) {

          var mtl = frags.getMaterial(idx);
          // no material means the object is not actually loaded yet, it's a box proxy, so should be ignored.
          if (mtl) {
            frags._pagingProxy.onGeomTraversed(m.geometry, mtl.transparent);
          }

        }

      }
    }

    // if drawMode is given, iterate vizflags that match
    if ((includeEmpty || m && m.geometry) && (
    !rflag || frags.isFlagSet(idx, rflag))) {

      callback(m, idx);
    }
  }

  //If all materials shaders are already available, we can sort by shader
  //to minimize shader switches during rendering. This sort will only
  //execute once and changing materials later will break the sorted order again.
  if (sortByShaderPossible)
  this.sortByShader();
};

/**
    * Sets the MESH_RENDERFLAG for a single fragment, depeneding on the drawMode and the other flags of the fragment.
    * @param {number} drawMode - One of the modes defined in Viewer3DImpl.js, e.g. RENDER_NORMAL
    * @param {number} vizflags - vizflags bitmask.
    * @param {number} idx - index into vizflags, for which we want to determine the MESH_RENDERFLAG.
    * @param {bool} hideLines
    * @param {bool} hidePoints
    * @returns {bool} Final, evaluated visibility.
    */
function evalVisibility(drawMode, vizflags, idx, hideLines, hidePoints, rflag) {

  var v;
  var vfin = vizflags[idx] & ~rflag;
  switch (drawMode) {

    case avp.RenderFlags.RENDER_HIDDEN:
      v = !(vfin & avp.MeshFlags.MESH_VISIBLE); //visible (bit 0 on)
      break;
    case avp.RenderFlags.RENDER_HIGHLIGHTED:
      v = vfin & avp.MeshFlags.MESH_HIGHLIGHTED; //highlighted (bit 1 on)
      break;
    default:
      v = (vfin & (avp.MeshFlags.MESH_VISIBLE | avp.MeshFlags.MESH_HIGHLIGHTED | avp.MeshFlags.MESH_HIDE)) == 1; //visible but not highlighted, and not a hidden line (bit 0 on, bit 1 off, bit 2 off)
      break;}


  if (hideLines) {
    var isLine = vfin & (avp.MeshFlags.MESH_ISLINE | avp.MeshFlags.MESH_ISWIDELINE);
    v = v && !isLine;
  }

  if (hidePoints) {
    var isPoint = vfin & avp.MeshFlags.MESH_ISPOINT;
    v = v && !isPoint;
  }

  //Store evaluated visibility into bit 7 of the vizflags
  //to use for immediate rendering
  vizflags[idx] = vfin | (v ? rflag : 0);

  return v;
}


/**
   * Checks if fragment is outside the frustum.
   * @param {bool} checkCull - indicates if culling is enabled. If false, return value is always false.
   * @param {Autodesk.Viewing.Private.FrustumIntersector} frustum
   * @param {FragmentList} frags
   * @param {number} idx - index into frags.
   * @returns {bool} True if the given fragment is outside the frustum and culling is enabled.
   */
function evalCulling(checkCull, frustum, frags, idx) {

  var culled = false;

  frags.getWorldBounds(idx, _tmpBox);
  var intersects = frustum.intersectsBox(_tmpBox);
  if (checkCull && intersects === avp.FrustumIntersector.OUTSIDE) {
    culled = true;
  } else
  if (frags._pagingProxy.pixelCullingEnable()) {
    // Check whether the projected area is smaller than a threshold,
    // if yes, do not render it.
    // ??? This may impact rendering that need to profile further.
    var area = frustum.projectedBoxArea(_tmpBox, intersects === avp.FrustumIntersector.CONTAINS);
    area *= frustum.areaConv;
    if (area < frags._pagingProxy.pixelCullingThreshold()) {
      culled = true;
    }
  }


  return culled;
}


RenderBatchML.prototype.applyVisibility = function () {

  var frags, vizflags, frustum, drawMode, rflag, fragIdCb, checkCull, allHidden, done;

  function applyVisCB(m, idx) {
    if (!m && frags.useThreeMesh) {
      if (fragIdCb)
      fragIdCb(idx);
      return;
    }

    var culled = done || evalCulling(checkCull, frustum, frags, idx);

    if (culled) {
      if (m) {
        m.visible = false;
      } else {
        THREE.warn("Unexpected null mesh");
      }
      vizflags[idx] = vizflags[idx] & ~rflag;

      // Record culled geometries for paging out.
      // This fragment is culled, then move its geometry to culled geometry list.
      var geomId = frags.geomids[idx];
      var geometry = frags.geoms.getGeometry(geomId);

      frags._pagingProxy.onGeomCulled(geometry);

      return;
    }

    var v = evalVisibility(drawMode, vizflags, idx, frags.linesHidden,
    frags.pointsHidden, rflag);

    if (m)
    m.visible = !!v;

    allHidden = allHidden && !v;
  }

  function fragIdCallback(fragId) {
    var packId = frags.fragments.packIds[fragId];
    frags._pagingProxy.addGeomPackMissingLastFrame(packId);
  }

  return function (drawModeIn, frustumIn) {

    //Used when parts of the same scene
    //have to draw in separate passes (e.g. during isolate).
    //Consider maintaining two render queues instead if the
    //use cases get too complex, because this approach
    //is not very scalable as currently done (it traverses
    //the entire scene twice, plus the flag flipping for each item).

    allHidden = true;
    done = false;
    frustum = frustumIn;
    drawMode = drawModeIn;
    rflag = RENDER_FLAGS[drawMode] || RENDER_FLAGS[0];

    frags = this.frags;

    //Check if the entire render batch is contained inside
    //the frustum. This will save per-object checks.
    var bbox = drawMode === avp.RenderFlags.RENDER_HIDDEN ? this.getBoundingBoxHidden() : this.getBoundingBox();
    var containment = frustum.intersectsBox(bbox);
    if (containment === avp.FrustumIntersector.OUTSIDE)
    done = true; //nothing to draw

    checkCull = containment !== avp.FrustumIntersector.CONTAINS;

    if (frags._pagingProxy.pixelCullingEnable()) {

      // if this scene get culled by projected area pixel, 
      // can bail out earlier. 
      var area = this.renderImportance;
      if (area == 0) {
        area = frustum.projectedBoxArea(bbox, !checkCull);
      }
      area *= frustum.areaConv;
      if (area < frags._pagingProxy.pixelCullingThreshold()) {
        done = true;
      }
    }

    vizflags = this.frags.vizflags;

    // There is another version of forEach: forEachNoMesh which won't be used in this case.
    // Also, it seems even in RenderBatch's implementation, forEachNoMesh logic never get called (on 3d or 2d).
    this.forEach(applyVisCB, null, fragIdCallback);

    return allHidden;
  };
}();

// Requests the geometry of a fragment for loading, unless it is already in memory or the request limit is reached.
// If already in memory, it just returns the geometry directly.
RenderBatchML.prototype._requireGeometry = function (fragId) {
  var frags = this.frags;
  var geom = null;
  var geomId = frags.geomids[fragId];
  if (geomId >= 0) {
    // A valid geometry id, then get corresponding geometry
    geom = frags.geoms.getGeometry(geomId);
  }

  if (geom == null) {

    // Request to load this geometry.
    var packId = frags.fragments.packIds ? frags.fragments.packIds[fragId] : fragId;

    frags._pagingProxy.loadPackFile(packId);
  }

  return geom;
};

/***/ }),

/***/ "./extensions/MemoryLimited/render/pageoutStatus.js":
/*!**********************************************************!*\
  !*** ./extensions/MemoryLimited/render/pageoutStatus.js ***!
  \**********************************************************/
/*! exports provided: PAGEOUT_SUCCESS, PAGEOUT_FAIL, PAGEOUT_NONE */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PAGEOUT_SUCCESS", function() { return PAGEOUT_SUCCESS; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PAGEOUT_FAIL", function() { return PAGEOUT_FAIL; });
/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, "PAGEOUT_NONE", function() { return PAGEOUT_NONE; });
var PAGEOUT_SUCCESS = 0;
var PAGEOUT_FAIL = 1;
var PAGEOUT_NONE = 2;

/***/ }),

/***/ "./extensions/MemoryLimited/render/shaders/occlusion_frag.glsl":
/*!*********************************************************************!*\
  !*** ./extensions/MemoryLimited/render/shaders/occlusion_frag.glsl ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = "precision lowp float;\nvarying vec4 finalColor;\nvoid main() {\n    gl_FragColor = finalColor;\n}\n";

/***/ }),

/***/ "./extensions/MemoryLimited/render/shaders/occlusion_vert.glsl":
/*!*********************************************************************!*\
  !*** ./extensions/MemoryLimited/render/shaders/occlusion_vert.glsl ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

module.exports = "\n#include<instancing_decl_vert>\nvarying vec4 finalColor;\nuniform vec3 color;\nuniform float opacity;\nvoid main() {\n    gl_Position = projectionMatrix * (viewMatrix * vec4(getInstancePos(position), 1.0));\n    finalColor = vec4(color, opacity);\n}\n";

/***/ }),

/***/ "./node_modules/css-loader/index.js!./node_modules/sass-loader/dist/cjs.js!./extensions/MemoryLimited/MemoryLimited.css":
/*!*********************************************************************************************************************!*\
  !*** ./node_modules/css-loader!./node_modules/sass-loader/dist/cjs.js!./extensions/MemoryLimited/MemoryLimited.css ***!
  \*********************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

exports = module.exports = __webpack_require__(/*! ../../node_modules/css-loader/lib/css-base.js */ "./node_modules/css-loader/lib/css-base.js")(false);
// imports


// module
exports.push([module.i, ".memory-limited-progressbar-loading {\n  height: 4px;\n  background: linear-gradient(to right, #337ab7, #83aff7) !important;\n  width: 240px;\n  border-radius: 2px; }\n", ""]);

// exports


/***/ }),

/***/ "./node_modules/css-loader/lib/css-base.js":
/*!*************************************************!*\
  !*** ./node_modules/css-loader/lib/css-base.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

/*
	MIT License http://www.opensource.org/licenses/mit-license.php
	Author Tobias Koppers @sokra
*/
// css base code, injected by the css-loader
module.exports = function(useSourceMap) {
	var list = [];

	// return the list of modules as css string
	list.toString = function toString() {
		return this.map(function (item) {
			var content = cssWithMappingToString(item, useSourceMap);
			if(item[2]) {
				return "@media " + item[2] + "{" + content + "}";
			} else {
				return content;
			}
		}).join("");
	};

	// import a list of modules into the list
	list.i = function(modules, mediaQuery) {
		if(typeof modules === "string")
			modules = [[null, modules, ""]];
		var alreadyImportedModules = {};
		for(var i = 0; i < this.length; i++) {
			var id = this[i][0];
			if(typeof id === "number")
				alreadyImportedModules[id] = true;
		}
		for(i = 0; i < modules.length; i++) {
			var item = modules[i];
			// skip already imported module
			// this implementation is not 100% perfect for weird media query combinations
			//  when a module is imported multiple times with different media queries.
			//  I hope this will never occur (Hey this way we have smaller bundles)
			if(typeof item[0] !== "number" || !alreadyImportedModules[item[0]]) {
				if(mediaQuery && !item[2]) {
					item[2] = mediaQuery;
				} else if(mediaQuery) {
					item[2] = "(" + item[2] + ") and (" + mediaQuery + ")";
				}
				list.push(item);
			}
		}
	};
	return list;
};

function cssWithMappingToString(item, useSourceMap) {
	var content = item[1] || '';
	var cssMapping = item[3];
	if (!cssMapping) {
		return content;
	}

	if (useSourceMap && typeof btoa === 'function') {
		var sourceMapping = toComment(cssMapping);
		var sourceURLs = cssMapping.sources.map(function (source) {
			return '/*# sourceURL=' + cssMapping.sourceRoot + source + ' */'
		});

		return [content].concat(sourceURLs).concat([sourceMapping]).join('\n');
	}

	return [content].join('\n');
}

// Adapted from convert-source-map (MIT)
function toComment(sourceMap) {
	// eslint-disable-next-line no-undef
	var base64 = btoa(unescape(encodeURIComponent(JSON.stringify(sourceMap))));
	var data = 'sourceMappingURL=data:application/json;charset=utf-8;base64,' + base64;

	return '/*# ' + data + ' */';
}


/***/ }),

/***/ "./node_modules/pako/index.js":
/*!************************************!*\
  !*** ./node_modules/pako/index.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// Top level file is just a mixin of submodules & constants


var assign    = __webpack_require__(/*! ./lib/utils/common */ "./node_modules/pako/lib/utils/common.js").assign;

var deflate   = __webpack_require__(/*! ./lib/deflate */ "./node_modules/pako/lib/deflate.js");
var inflate   = __webpack_require__(/*! ./lib/inflate */ "./node_modules/pako/lib/inflate.js");
var constants = __webpack_require__(/*! ./lib/zlib/constants */ "./node_modules/pako/lib/zlib/constants.js");

var pako = {};

assign(pako, deflate, inflate, constants);

module.exports = pako;


/***/ }),

/***/ "./node_modules/pako/lib/deflate.js":
/*!******************************************!*\
  !*** ./node_modules/pako/lib/deflate.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";



var zlib_deflate = __webpack_require__(/*! ./zlib/deflate */ "./node_modules/pako/lib/zlib/deflate.js");
var utils        = __webpack_require__(/*! ./utils/common */ "./node_modules/pako/lib/utils/common.js");
var strings      = __webpack_require__(/*! ./utils/strings */ "./node_modules/pako/lib/utils/strings.js");
var msg          = __webpack_require__(/*! ./zlib/messages */ "./node_modules/pako/lib/zlib/messages.js");
var ZStream      = __webpack_require__(/*! ./zlib/zstream */ "./node_modules/pako/lib/zlib/zstream.js");

var toString = Object.prototype.toString;

/* Public constants ==========================================================*/
/* ===========================================================================*/

var Z_NO_FLUSH      = 0;
var Z_FINISH        = 4;

var Z_OK            = 0;
var Z_STREAM_END    = 1;
var Z_SYNC_FLUSH    = 2;

var Z_DEFAULT_COMPRESSION = -1;

var Z_DEFAULT_STRATEGY    = 0;

var Z_DEFLATED  = 8;

/* ===========================================================================*/


/**
 * class Deflate
 *
 * Generic JS-style wrapper for zlib calls. If you don't need
 * streaming behaviour - use more simple functions: [[deflate]],
 * [[deflateRaw]] and [[gzip]].
 **/

/* internal
 * Deflate.chunks -> Array
 *
 * Chunks of output data, if [[Deflate#onData]] not overridden.
 **/

/**
 * Deflate.result -> Uint8Array|Array
 *
 * Compressed result, generated by default [[Deflate#onData]]
 * and [[Deflate#onEnd]] handlers. Filled after you push last chunk
 * (call [[Deflate#push]] with `Z_FINISH` / `true` param)  or if you
 * push a chunk with explicit flush (call [[Deflate#push]] with
 * `Z_SYNC_FLUSH` param).
 **/

/**
 * Deflate.err -> Number
 *
 * Error code after deflate finished. 0 (Z_OK) on success.
 * You will not need it in real life, because deflate errors
 * are possible only on wrong options or bad `onData` / `onEnd`
 * custom handlers.
 **/

/**
 * Deflate.msg -> String
 *
 * Error message, if [[Deflate.err]] != 0
 **/


/**
 * new Deflate(options)
 * - options (Object): zlib deflate options.
 *
 * Creates new deflator instance with specified params. Throws exception
 * on bad params. Supported options:
 *
 * - `level`
 * - `windowBits`
 * - `memLevel`
 * - `strategy`
 * - `dictionary`
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Additional options, for internal needs:
 *
 * - `chunkSize` - size of generated data chunks (16K by default)
 * - `raw` (Boolean) - do raw deflate
 * - `gzip` (Boolean) - create gzip wrapper
 * - `to` (String) - if equal to 'string', then result will be "binary string"
 *    (each char code [0..255])
 * - `header` (Object) - custom header for gzip
 *   - `text` (Boolean) - true if compressed data believed to be text
 *   - `time` (Number) - modification time, unix timestamp
 *   - `os` (Number) - operation system code
 *   - `extra` (Array) - array of bytes with extra data (max 65536)
 *   - `name` (String) - file name (binary string)
 *   - `comment` (String) - comment (binary string)
 *   - `hcrc` (Boolean) - true if header crc should be added
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
 *
 * var deflate = new pako.Deflate({ level: 3});
 *
 * deflate.push(chunk1, false);
 * deflate.push(chunk2, true);  // true -> last chunk
 *
 * if (deflate.err) { throw new Error(deflate.err); }
 *
 * console.log(deflate.result);
 * ```
 **/
function Deflate(options) {
  if (!(this instanceof Deflate)) return new Deflate(options);

  this.options = utils.assign({
    level: Z_DEFAULT_COMPRESSION,
    method: Z_DEFLATED,
    chunkSize: 16384,
    windowBits: 15,
    memLevel: 8,
    strategy: Z_DEFAULT_STRATEGY,
    to: ''
  }, options || {});

  var opt = this.options;

  if (opt.raw && (opt.windowBits > 0)) {
    opt.windowBits = -opt.windowBits;
  }

  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {
    opt.windowBits += 16;
  }

  this.err    = 0;      // error code, if happens (0 = Z_OK)
  this.msg    = '';     // error message
  this.ended  = false;  // used to avoid multiple onEnd() calls
  this.chunks = [];     // chunks of compressed data

  this.strm = new ZStream();
  this.strm.avail_out = 0;

  var status = zlib_deflate.deflateInit2(
    this.strm,
    opt.level,
    opt.method,
    opt.windowBits,
    opt.memLevel,
    opt.strategy
  );

  if (status !== Z_OK) {
    throw new Error(msg[status]);
  }

  if (opt.header) {
    zlib_deflate.deflateSetHeader(this.strm, opt.header);
  }

  if (opt.dictionary) {
    var dict;
    // Convert data if needed
    if (typeof opt.dictionary === 'string') {
      // If we need to compress text, change encoding to utf8.
      dict = strings.string2buf(opt.dictionary);
    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {
      dict = new Uint8Array(opt.dictionary);
    } else {
      dict = opt.dictionary;
    }

    status = zlib_deflate.deflateSetDictionary(this.strm, dict);

    if (status !== Z_OK) {
      throw new Error(msg[status]);
    }

    this._dict_set = true;
  }
}

/**
 * Deflate#push(data[, mode]) -> Boolean
 * - data (Uint8Array|Array|ArrayBuffer|String): input data. Strings will be
 *   converted to utf8 byte sequence.
 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.
 *
 * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with
 * new compressed chunks. Returns `true` on success. The last data block must have
 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
 * [[Deflate#onEnd]]. For interim explicit flushes (without ending the stream) you
 * can use mode Z_SYNC_FLUSH, keeping the compression context.
 *
 * On fail call [[Deflate#onEnd]] with error code and return false.
 *
 * We strongly recommend to use `Uint8Array` on input for best speed (output
 * array format is detected automatically). Also, don't skip last param and always
 * use the same type in your code (boolean or number). That will improve JS speed.
 *
 * For regular `Array`-s make sure all elements are [0..255].
 *
 * ##### Example
 *
 * ```javascript
 * push(chunk, false); // push one of data chunks
 * ...
 * push(chunk, true);  // push last chunk
 * ```
 **/
Deflate.prototype.push = function (data, mode) {
  var strm = this.strm;
  var chunkSize = this.options.chunkSize;
  var status, _mode;

  if (this.ended) { return false; }

  _mode = (mode === ~~mode) ? mode : ((mode === true) ? Z_FINISH : Z_NO_FLUSH);

  // Convert data if needed
  if (typeof data === 'string') {
    // If we need to compress text, change encoding to utf8.
    strm.input = strings.string2buf(data);
  } else if (toString.call(data) === '[object ArrayBuffer]') {
    strm.input = new Uint8Array(data);
  } else {
    strm.input = data;
  }

  strm.next_in = 0;
  strm.avail_in = strm.input.length;

  do {
    if (strm.avail_out === 0) {
      strm.output = new utils.Buf8(chunkSize);
      strm.next_out = 0;
      strm.avail_out = chunkSize;
    }
    status = zlib_deflate.deflate(strm, _mode);    /* no bad return value */

    if (status !== Z_STREAM_END && status !== Z_OK) {
      this.onEnd(status);
      this.ended = true;
      return false;
    }
    if (strm.avail_out === 0 || (strm.avail_in === 0 && (_mode === Z_FINISH || _mode === Z_SYNC_FLUSH))) {
      if (this.options.to === 'string') {
        this.onData(strings.buf2binstring(utils.shrinkBuf(strm.output, strm.next_out)));
      } else {
        this.onData(utils.shrinkBuf(strm.output, strm.next_out));
      }
    }
  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== Z_STREAM_END);

  // Finalize on the last chunk.
  if (_mode === Z_FINISH) {
    status = zlib_deflate.deflateEnd(this.strm);
    this.onEnd(status);
    this.ended = true;
    return status === Z_OK;
  }

  // callback interim results if Z_SYNC_FLUSH.
  if (_mode === Z_SYNC_FLUSH) {
    this.onEnd(Z_OK);
    strm.avail_out = 0;
    return true;
  }

  return true;
};


/**
 * Deflate#onData(chunk) -> Void
 * - chunk (Uint8Array|Array|String): output data. Type of array depends
 *   on js engine support. When string output requested, each chunk
 *   will be string.
 *
 * By default, stores data blocks in `chunks[]` property and glue
 * those in `onEnd`. Override this handler, if you need another behaviour.
 **/
Deflate.prototype.onData = function (chunk) {
  this.chunks.push(chunk);
};


/**
 * Deflate#onEnd(status) -> Void
 * - status (Number): deflate status. 0 (Z_OK) on success,
 *   other if not.
 *
 * Called once after you tell deflate that the input stream is
 * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)
 * or if an error happened. By default - join collected chunks,
 * free memory and fill `results` / `err` properties.
 **/
Deflate.prototype.onEnd = function (status) {
  // On success - join
  if (status === Z_OK) {
    if (this.options.to === 'string') {
      this.result = this.chunks.join('');
    } else {
      this.result = utils.flattenChunks(this.chunks);
    }
  }
  this.chunks = [];
  this.err = status;
  this.msg = this.strm.msg;
};


/**
 * deflate(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * Compress `data` with deflate algorithm and `options`.
 *
 * Supported options are:
 *
 * - level
 * - windowBits
 * - memLevel
 * - strategy
 * - dictionary
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Sugar (options):
 *
 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
 *   negative windowBits implicitly.
 * - `to` (String) - if equal to 'string', then result will be "binary string"
 *    (each char code [0..255])
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , data = Uint8Array([1,2,3,4,5,6,7,8,9]);
 *
 * console.log(pako.deflate(data));
 * ```
 **/
function deflate(input, options) {
  var deflator = new Deflate(options);

  deflator.push(input, true);

  // That will never happens, if you don't cheat with options :)
  if (deflator.err) { throw deflator.msg || msg[deflator.err]; }

  return deflator.result;
}


/**
 * deflateRaw(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * The same as [[deflate]], but creates raw data, without wrapper
 * (header and adler32 crc).
 **/
function deflateRaw(input, options) {
  options = options || {};
  options.raw = true;
  return deflate(input, options);
}


/**
 * gzip(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to compress.
 * - options (Object): zlib deflate options.
 *
 * The same as [[deflate]], but create gzip wrapper instead of
 * deflate one.
 **/
function gzip(input, options) {
  options = options || {};
  options.gzip = true;
  return deflate(input, options);
}


exports.Deflate = Deflate;
exports.deflate = deflate;
exports.deflateRaw = deflateRaw;
exports.gzip = gzip;


/***/ }),

/***/ "./node_modules/pako/lib/inflate.js":
/*!******************************************!*\
  !*** ./node_modules/pako/lib/inflate.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";



var zlib_inflate = __webpack_require__(/*! ./zlib/inflate */ "./node_modules/pako/lib/zlib/inflate.js");
var utils        = __webpack_require__(/*! ./utils/common */ "./node_modules/pako/lib/utils/common.js");
var strings      = __webpack_require__(/*! ./utils/strings */ "./node_modules/pako/lib/utils/strings.js");
var c            = __webpack_require__(/*! ./zlib/constants */ "./node_modules/pako/lib/zlib/constants.js");
var msg          = __webpack_require__(/*! ./zlib/messages */ "./node_modules/pako/lib/zlib/messages.js");
var ZStream      = __webpack_require__(/*! ./zlib/zstream */ "./node_modules/pako/lib/zlib/zstream.js");
var GZheader     = __webpack_require__(/*! ./zlib/gzheader */ "./node_modules/pako/lib/zlib/gzheader.js");

var toString = Object.prototype.toString;

/**
 * class Inflate
 *
 * Generic JS-style wrapper for zlib calls. If you don't need
 * streaming behaviour - use more simple functions: [[inflate]]
 * and [[inflateRaw]].
 **/

/* internal
 * inflate.chunks -> Array
 *
 * Chunks of output data, if [[Inflate#onData]] not overridden.
 **/

/**
 * Inflate.result -> Uint8Array|Array|String
 *
 * Uncompressed result, generated by default [[Inflate#onData]]
 * and [[Inflate#onEnd]] handlers. Filled after you push last chunk
 * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you
 * push a chunk with explicit flush (call [[Inflate#push]] with
 * `Z_SYNC_FLUSH` param).
 **/

/**
 * Inflate.err -> Number
 *
 * Error code after inflate finished. 0 (Z_OK) on success.
 * Should be checked if broken data possible.
 **/

/**
 * Inflate.msg -> String
 *
 * Error message, if [[Inflate.err]] != 0
 **/


/**
 * new Inflate(options)
 * - options (Object): zlib inflate options.
 *
 * Creates new inflator instance with specified params. Throws exception
 * on bad params. Supported options:
 *
 * - `windowBits`
 * - `dictionary`
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information on these.
 *
 * Additional options, for internal needs:
 *
 * - `chunkSize` - size of generated data chunks (16K by default)
 * - `raw` (Boolean) - do raw inflate
 * - `to` (String) - if equal to 'string', then result will be converted
 *   from utf8 to utf16 (javascript) string. When string output requested,
 *   chunk length can differ from `chunkSize`, depending on content.
 *
 * By default, when no options set, autodetect deflate/gzip data format via
 * wrapper header.
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])
 *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);
 *
 * var inflate = new pako.Inflate({ level: 3});
 *
 * inflate.push(chunk1, false);
 * inflate.push(chunk2, true);  // true -> last chunk
 *
 * if (inflate.err) { throw new Error(inflate.err); }
 *
 * console.log(inflate.result);
 * ```
 **/
function Inflate(options) {
  if (!(this instanceof Inflate)) return new Inflate(options);

  this.options = utils.assign({
    chunkSize: 16384,
    windowBits: 0,
    to: ''
  }, options || {});

  var opt = this.options;

  // Force window size for `raw` data, if not set directly,
  // because we have no header for autodetect.
  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {
    opt.windowBits = -opt.windowBits;
    if (opt.windowBits === 0) { opt.windowBits = -15; }
  }

  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate
  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&
      !(options && options.windowBits)) {
    opt.windowBits += 32;
  }

  // Gzip header has no info about windows size, we can do autodetect only
  // for deflate. So, if window size not set, force it to max when gzip possible
  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {
    // bit 3 (16) -> gzipped data
    // bit 4 (32) -> autodetect gzip/deflate
    if ((opt.windowBits & 15) === 0) {
      opt.windowBits |= 15;
    }
  }

  this.err    = 0;      // error code, if happens (0 = Z_OK)
  this.msg    = '';     // error message
  this.ended  = false;  // used to avoid multiple onEnd() calls
  this.chunks = [];     // chunks of compressed data

  this.strm   = new ZStream();
  this.strm.avail_out = 0;

  var status  = zlib_inflate.inflateInit2(
    this.strm,
    opt.windowBits
  );

  if (status !== c.Z_OK) {
    throw new Error(msg[status]);
  }

  this.header = new GZheader();

  zlib_inflate.inflateGetHeader(this.strm, this.header);

  // Setup dictionary
  if (opt.dictionary) {
    // Convert data if needed
    if (typeof opt.dictionary === 'string') {
      opt.dictionary = strings.string2buf(opt.dictionary);
    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {
      opt.dictionary = new Uint8Array(opt.dictionary);
    }
    if (opt.raw) { //In raw mode we need to set the dictionary early
      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);
      if (status !== c.Z_OK) {
        throw new Error(msg[status]);
      }
    }
  }
}

/**
 * Inflate#push(data[, mode]) -> Boolean
 * - data (Uint8Array|Array|ArrayBuffer|String): input data
 * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.
 *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.
 *
 * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with
 * new output chunks. Returns `true` on success. The last data block must have
 * mode Z_FINISH (or `true`). That will flush internal pending buffers and call
 * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you
 * can use mode Z_SYNC_FLUSH, keeping the decompression context.
 *
 * On fail call [[Inflate#onEnd]] with error code and return false.
 *
 * We strongly recommend to use `Uint8Array` on input for best speed (output
 * format is detected automatically). Also, don't skip last param and always
 * use the same type in your code (boolean or number). That will improve JS speed.
 *
 * For regular `Array`-s make sure all elements are [0..255].
 *
 * ##### Example
 *
 * ```javascript
 * push(chunk, false); // push one of data chunks
 * ...
 * push(chunk, true);  // push last chunk
 * ```
 **/
Inflate.prototype.push = function (data, mode) {
  var strm = this.strm;
  var chunkSize = this.options.chunkSize;
  var dictionary = this.options.dictionary;
  var status, _mode;
  var next_out_utf8, tail, utf8str;

  // Flag to properly process Z_BUF_ERROR on testing inflate call
  // when we check that all output data was flushed.
  var allowBufError = false;

  if (this.ended) { return false; }
  _mode = (mode === ~~mode) ? mode : ((mode === true) ? c.Z_FINISH : c.Z_NO_FLUSH);

  // Convert data if needed
  if (typeof data === 'string') {
    // Only binary strings can be decompressed on practice
    strm.input = strings.binstring2buf(data);
  } else if (toString.call(data) === '[object ArrayBuffer]') {
    strm.input = new Uint8Array(data);
  } else {
    strm.input = data;
  }

  strm.next_in = 0;
  strm.avail_in = strm.input.length;

  do {
    if (strm.avail_out === 0) {
      strm.output = new utils.Buf8(chunkSize);
      strm.next_out = 0;
      strm.avail_out = chunkSize;
    }

    status = zlib_inflate.inflate(strm, c.Z_NO_FLUSH);    /* no bad return value */

    if (status === c.Z_NEED_DICT && dictionary) {
      status = zlib_inflate.inflateSetDictionary(this.strm, dictionary);
    }

    if (status === c.Z_BUF_ERROR && allowBufError === true) {
      status = c.Z_OK;
      allowBufError = false;
    }

    if (status !== c.Z_STREAM_END && status !== c.Z_OK) {
      this.onEnd(status);
      this.ended = true;
      return false;
    }

    if (strm.next_out) {
      if (strm.avail_out === 0 || status === c.Z_STREAM_END || (strm.avail_in === 0 && (_mode === c.Z_FINISH || _mode === c.Z_SYNC_FLUSH))) {

        if (this.options.to === 'string') {

          next_out_utf8 = strings.utf8border(strm.output, strm.next_out);

          tail = strm.next_out - next_out_utf8;
          utf8str = strings.buf2string(strm.output, next_out_utf8);

          // move tail
          strm.next_out = tail;
          strm.avail_out = chunkSize - tail;
          if (tail) { utils.arraySet(strm.output, strm.output, next_out_utf8, tail, 0); }

          this.onData(utf8str);

        } else {
          this.onData(utils.shrinkBuf(strm.output, strm.next_out));
        }
      }
    }

    // When no more input data, we should check that internal inflate buffers
    // are flushed. The only way to do it when avail_out = 0 - run one more
    // inflate pass. But if output data not exists, inflate return Z_BUF_ERROR.
    // Here we set flag to process this error properly.
    //
    // NOTE. Deflate does not return error in this case and does not needs such
    // logic.
    if (strm.avail_in === 0 && strm.avail_out === 0) {
      allowBufError = true;
    }

  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== c.Z_STREAM_END);

  if (status === c.Z_STREAM_END) {
    _mode = c.Z_FINISH;
  }

  // Finalize on the last chunk.
  if (_mode === c.Z_FINISH) {
    status = zlib_inflate.inflateEnd(this.strm);
    this.onEnd(status);
    this.ended = true;
    return status === c.Z_OK;
  }

  // callback interim results if Z_SYNC_FLUSH.
  if (_mode === c.Z_SYNC_FLUSH) {
    this.onEnd(c.Z_OK);
    strm.avail_out = 0;
    return true;
  }

  return true;
};


/**
 * Inflate#onData(chunk) -> Void
 * - chunk (Uint8Array|Array|String): output data. Type of array depends
 *   on js engine support. When string output requested, each chunk
 *   will be string.
 *
 * By default, stores data blocks in `chunks[]` property and glue
 * those in `onEnd`. Override this handler, if you need another behaviour.
 **/
Inflate.prototype.onData = function (chunk) {
  this.chunks.push(chunk);
};


/**
 * Inflate#onEnd(status) -> Void
 * - status (Number): inflate status. 0 (Z_OK) on success,
 *   other if not.
 *
 * Called either after you tell inflate that the input stream is
 * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)
 * or if an error happened. By default - join collected chunks,
 * free memory and fill `results` / `err` properties.
 **/
Inflate.prototype.onEnd = function (status) {
  // On success - join
  if (status === c.Z_OK) {
    if (this.options.to === 'string') {
      // Glue & convert here, until we teach pako to send
      // utf8 aligned strings to onData
      this.result = this.chunks.join('');
    } else {
      this.result = utils.flattenChunks(this.chunks);
    }
  }
  this.chunks = [];
  this.err = status;
  this.msg = this.strm.msg;
};


/**
 * inflate(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * Decompress `data` with inflate/ungzip and `options`. Autodetect
 * format via wrapper header by default. That's why we don't provide
 * separate `ungzip` method.
 *
 * Supported options are:
 *
 * - windowBits
 *
 * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)
 * for more information.
 *
 * Sugar (options):
 *
 * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify
 *   negative windowBits implicitly.
 * - `to` (String) - if equal to 'string', then result will be converted
 *   from utf8 to utf16 (javascript) string. When string output requested,
 *   chunk length can differ from `chunkSize`, depending on content.
 *
 *
 * ##### Example:
 *
 * ```javascript
 * var pako = require('pako')
 *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])
 *   , output;
 *
 * try {
 *   output = pako.inflate(input);
 * } catch (err)
 *   console.log(err);
 * }
 * ```
 **/
function inflate(input, options) {
  var inflator = new Inflate(options);

  inflator.push(input, true);

  // That will never happens, if you don't cheat with options :)
  if (inflator.err) { throw inflator.msg || msg[inflator.err]; }

  return inflator.result;
}


/**
 * inflateRaw(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * The same as [[inflate]], but creates raw data, without wrapper
 * (header and adler32 crc).
 **/
function inflateRaw(input, options) {
  options = options || {};
  options.raw = true;
  return inflate(input, options);
}


/**
 * ungzip(data[, options]) -> Uint8Array|Array|String
 * - data (Uint8Array|Array|String): input data to decompress.
 * - options (Object): zlib inflate options.
 *
 * Just shortcut to [[inflate]], because it autodetects format
 * by header.content. Done for convenience.
 **/


exports.Inflate = Inflate;
exports.inflate = inflate;
exports.inflateRaw = inflateRaw;
exports.ungzip  = inflate;


/***/ }),

/***/ "./node_modules/pako/lib/utils/common.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/utils/common.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";



var TYPED_OK =  (typeof Uint8Array !== 'undefined') &&
                (typeof Uint16Array !== 'undefined') &&
                (typeof Int32Array !== 'undefined');

function _has(obj, key) {
  return Object.prototype.hasOwnProperty.call(obj, key);
}

exports.assign = function (obj /*from1, from2, from3, ...*/) {
  var sources = Array.prototype.slice.call(arguments, 1);
  while (sources.length) {
    var source = sources.shift();
    if (!source) { continue; }

    if (typeof source !== 'object') {
      throw new TypeError(source + 'must be non-object');
    }

    for (var p in source) {
      if (_has(source, p)) {
        obj[p] = source[p];
      }
    }
  }

  return obj;
};


// reduce buffer size, avoiding mem copy
exports.shrinkBuf = function (buf, size) {
  if (buf.length === size) { return buf; }
  if (buf.subarray) { return buf.subarray(0, size); }
  buf.length = size;
  return buf;
};


var fnTyped = {
  arraySet: function (dest, src, src_offs, len, dest_offs) {
    if (src.subarray && dest.subarray) {
      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);
      return;
    }
    // Fallback to ordinary array
    for (var i = 0; i < len; i++) {
      dest[dest_offs + i] = src[src_offs + i];
    }
  },
  // Join array of chunks to single array.
  flattenChunks: function (chunks) {
    var i, l, len, pos, chunk, result;

    // calculate data length
    len = 0;
    for (i = 0, l = chunks.length; i < l; i++) {
      len += chunks[i].length;
    }

    // join chunks
    result = new Uint8Array(len);
    pos = 0;
    for (i = 0, l = chunks.length; i < l; i++) {
      chunk = chunks[i];
      result.set(chunk, pos);
      pos += chunk.length;
    }

    return result;
  }
};

var fnUntyped = {
  arraySet: function (dest, src, src_offs, len, dest_offs) {
    for (var i = 0; i < len; i++) {
      dest[dest_offs + i] = src[src_offs + i];
    }
  },
  // Join array of chunks to single array.
  flattenChunks: function (chunks) {
    return [].concat.apply([], chunks);
  }
};


// Enable/Disable typed arrays use, for testing
//
exports.setTyped = function (on) {
  if (on) {
    exports.Buf8  = Uint8Array;
    exports.Buf16 = Uint16Array;
    exports.Buf32 = Int32Array;
    exports.assign(exports, fnTyped);
  } else {
    exports.Buf8  = Array;
    exports.Buf16 = Array;
    exports.Buf32 = Array;
    exports.assign(exports, fnUntyped);
  }
};

exports.setTyped(TYPED_OK);


/***/ }),

/***/ "./node_modules/pako/lib/utils/strings.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/utils/strings.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
// String encode/decode helpers



var utils = __webpack_require__(/*! ./common */ "./node_modules/pako/lib/utils/common.js");


// Quick check if we can use fast array to bin string conversion
//
// - apply(Array) can fail on Android 2.2
// - apply(Uint8Array) can fail on iOS 5.1 Safari
//
var STR_APPLY_OK = true;
var STR_APPLY_UIA_OK = true;

try { String.fromCharCode.apply(null, [ 0 ]); } catch (__) { STR_APPLY_OK = false; }
try { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }


// Table with utf8 lengths (calculated by first byte of sequence)
// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,
// because max possible codepoint is 0x10ffff
var _utf8len = new utils.Buf8(256);
for (var q = 0; q < 256; q++) {
  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);
}
_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start


// convert string to array (typed, when possible)
exports.string2buf = function (str) {
  var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;

  // count binary size
  for (m_pos = 0; m_pos < str_len; m_pos++) {
    c = str.charCodeAt(m_pos);
    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {
      c2 = str.charCodeAt(m_pos + 1);
      if ((c2 & 0xfc00) === 0xdc00) {
        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
        m_pos++;
      }
    }
    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;
  }

  // allocate buffer
  buf = new utils.Buf8(buf_len);

  // convert
  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {
    c = str.charCodeAt(m_pos);
    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {
      c2 = str.charCodeAt(m_pos + 1);
      if ((c2 & 0xfc00) === 0xdc00) {
        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);
        m_pos++;
      }
    }
    if (c < 0x80) {
      /* one byte */
      buf[i++] = c;
    } else if (c < 0x800) {
      /* two bytes */
      buf[i++] = 0xC0 | (c >>> 6);
      buf[i++] = 0x80 | (c & 0x3f);
    } else if (c < 0x10000) {
      /* three bytes */
      buf[i++] = 0xE0 | (c >>> 12);
      buf[i++] = 0x80 | (c >>> 6 & 0x3f);
      buf[i++] = 0x80 | (c & 0x3f);
    } else {
      /* four bytes */
      buf[i++] = 0xf0 | (c >>> 18);
      buf[i++] = 0x80 | (c >>> 12 & 0x3f);
      buf[i++] = 0x80 | (c >>> 6 & 0x3f);
      buf[i++] = 0x80 | (c & 0x3f);
    }
  }

  return buf;
};

// Helper (used in 2 places)
function buf2binstring(buf, len) {
  // On Chrome, the arguments in a function call that are allowed is `65534`.
  // If the length of the buffer is smaller than that, we can use this optimization,
  // otherwise we will take a slower path.
  if (len < 65534) {
    if ((buf.subarray && STR_APPLY_UIA_OK) || (!buf.subarray && STR_APPLY_OK)) {
      return String.fromCharCode.apply(null, utils.shrinkBuf(buf, len));
    }
  }

  var result = '';
  for (var i = 0; i < len; i++) {
    result += String.fromCharCode(buf[i]);
  }
  return result;
}


// Convert byte array to binary string
exports.buf2binstring = function (buf) {
  return buf2binstring(buf, buf.length);
};


// Convert binary string (typed, when possible)
exports.binstring2buf = function (str) {
  var buf = new utils.Buf8(str.length);
  for (var i = 0, len = buf.length; i < len; i++) {
    buf[i] = str.charCodeAt(i);
  }
  return buf;
};


// convert array to string
exports.buf2string = function (buf, max) {
  var i, out, c, c_len;
  var len = max || buf.length;

  // Reserve max possible length (2 words per char)
  // NB: by unknown reasons, Array is significantly faster for
  //     String.fromCharCode.apply than Uint16Array.
  var utf16buf = new Array(len * 2);

  for (out = 0, i = 0; i < len;) {
    c = buf[i++];
    // quick process ascii
    if (c < 0x80) { utf16buf[out++] = c; continue; }

    c_len = _utf8len[c];
    // skip 5 & 6 byte codes
    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }

    // apply mask on first byte
    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;
    // join the rest
    while (c_len > 1 && i < len) {
      c = (c << 6) | (buf[i++] & 0x3f);
      c_len--;
    }

    // terminated by end of string?
    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }

    if (c < 0x10000) {
      utf16buf[out++] = c;
    } else {
      c -= 0x10000;
      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);
      utf16buf[out++] = 0xdc00 | (c & 0x3ff);
    }
  }

  return buf2binstring(utf16buf, out);
};


// Calculate max possible position in utf8 buffer,
// that will not break sequence. If that's not possible
// - (very small limits) return max size as is.
//
// buf[] - utf8 bytes array
// max   - length limit (mandatory);
exports.utf8border = function (buf, max) {
  var pos;

  max = max || buf.length;
  if (max > buf.length) { max = buf.length; }

  // go back from last position, until start of sequence found
  pos = max - 1;
  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }

  // Very small and broken sequence,
  // return max, because we should return something anyway.
  if (pos < 0) { return max; }

  // If we came to start of buffer - that means buffer is too small,
  // return max too.
  if (pos === 0) { return max; }

  return (pos + _utf8len[buf[pos]] > max) ? pos : max;
};


/***/ }),

/***/ "./node_modules/pako/lib/zlib/adler32.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/adler32.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// Note: adler32 takes 12% for level 0 and 2% for level 6.
// It isn't worth it to make additional optimizations as in original.
// Small size is preferable.

// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function adler32(adler, buf, len, pos) {
  var s1 = (adler & 0xffff) |0,
      s2 = ((adler >>> 16) & 0xffff) |0,
      n = 0;

  while (len !== 0) {
    // Set limit ~ twice less than 5552, to keep
    // s2 in 31-bits, because we force signed ints.
    // in other case %= will fail.
    n = len > 2000 ? 2000 : len;
    len -= n;

    do {
      s1 = (s1 + buf[pos++]) |0;
      s2 = (s2 + s1) |0;
    } while (--n);

    s1 %= 65521;
    s2 %= 65521;
  }

  return (s1 | (s2 << 16)) |0;
}


module.exports = adler32;


/***/ }),

/***/ "./node_modules/pako/lib/zlib/constants.js":
/*!*************************************************!*\
  !*** ./node_modules/pako/lib/zlib/constants.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

module.exports = {

  /* Allowed flush values; see deflate() and inflate() below for details */
  Z_NO_FLUSH:         0,
  Z_PARTIAL_FLUSH:    1,
  Z_SYNC_FLUSH:       2,
  Z_FULL_FLUSH:       3,
  Z_FINISH:           4,
  Z_BLOCK:            5,
  Z_TREES:            6,

  /* Return codes for the compression/decompression functions. Negative values
  * are errors, positive values are used for special but normal events.
  */
  Z_OK:               0,
  Z_STREAM_END:       1,
  Z_NEED_DICT:        2,
  Z_ERRNO:           -1,
  Z_STREAM_ERROR:    -2,
  Z_DATA_ERROR:      -3,
  //Z_MEM_ERROR:     -4,
  Z_BUF_ERROR:       -5,
  //Z_VERSION_ERROR: -6,

  /* compression levels */
  Z_NO_COMPRESSION:         0,
  Z_BEST_SPEED:             1,
  Z_BEST_COMPRESSION:       9,
  Z_DEFAULT_COMPRESSION:   -1,


  Z_FILTERED:               1,
  Z_HUFFMAN_ONLY:           2,
  Z_RLE:                    3,
  Z_FIXED:                  4,
  Z_DEFAULT_STRATEGY:       0,

  /* Possible values of the data_type field (though see inflate()) */
  Z_BINARY:                 0,
  Z_TEXT:                   1,
  //Z_ASCII:                1, // = Z_TEXT (deprecated)
  Z_UNKNOWN:                2,

  /* The deflate compression method */
  Z_DEFLATED:               8
  //Z_NULL:                 null // Use -1 or null inline, depending on var type
};


/***/ }),

/***/ "./node_modules/pako/lib/zlib/crc32.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/crc32.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// Note: we can't get significant speed boost here.
// So write code to minimize size - no pregenerated tables
// and array tools dependencies.

// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

// Use ordinary array, since untyped makes no boost here
function makeTable() {
  var c, table = [];

  for (var n = 0; n < 256; n++) {
    c = n;
    for (var k = 0; k < 8; k++) {
      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));
    }
    table[n] = c;
  }

  return table;
}

// Create table on load. Just 255 signed longs. Not a problem.
var crcTable = makeTable();


function crc32(crc, buf, len, pos) {
  var t = crcTable,
      end = pos + len;

  crc ^= -1;

  for (var i = pos; i < end; i++) {
    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];
  }

  return (crc ^ (-1)); // >>> 0;
}


module.exports = crc32;


/***/ }),

/***/ "./node_modules/pako/lib/zlib/deflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/deflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils   = __webpack_require__(/*! ../utils/common */ "./node_modules/pako/lib/utils/common.js");
var trees   = __webpack_require__(/*! ./trees */ "./node_modules/pako/lib/zlib/trees.js");
var adler32 = __webpack_require__(/*! ./adler32 */ "./node_modules/pako/lib/zlib/adler32.js");
var crc32   = __webpack_require__(/*! ./crc32 */ "./node_modules/pako/lib/zlib/crc32.js");
var msg     = __webpack_require__(/*! ./messages */ "./node_modules/pako/lib/zlib/messages.js");

/* Public constants ==========================================================*/
/* ===========================================================================*/


/* Allowed flush values; see deflate() and inflate() below for details */
var Z_NO_FLUSH      = 0;
var Z_PARTIAL_FLUSH = 1;
//var Z_SYNC_FLUSH    = 2;
var Z_FULL_FLUSH    = 3;
var Z_FINISH        = 4;
var Z_BLOCK         = 5;
//var Z_TREES         = 6;


/* Return codes for the compression/decompression functions. Negative values
 * are errors, positive values are used for special but normal events.
 */
var Z_OK            = 0;
var Z_STREAM_END    = 1;
//var Z_NEED_DICT     = 2;
//var Z_ERRNO         = -1;
var Z_STREAM_ERROR  = -2;
var Z_DATA_ERROR    = -3;
//var Z_MEM_ERROR     = -4;
var Z_BUF_ERROR     = -5;
//var Z_VERSION_ERROR = -6;


/* compression levels */
//var Z_NO_COMPRESSION      = 0;
//var Z_BEST_SPEED          = 1;
//var Z_BEST_COMPRESSION    = 9;
var Z_DEFAULT_COMPRESSION = -1;


var Z_FILTERED            = 1;
var Z_HUFFMAN_ONLY        = 2;
var Z_RLE                 = 3;
var Z_FIXED               = 4;
var Z_DEFAULT_STRATEGY    = 0;

/* Possible values of the data_type field (though see inflate()) */
//var Z_BINARY              = 0;
//var Z_TEXT                = 1;
//var Z_ASCII               = 1; // = Z_TEXT
var Z_UNKNOWN             = 2;


/* The deflate compression method */
var Z_DEFLATED  = 8;

/*============================================================================*/


var MAX_MEM_LEVEL = 9;
/* Maximum value for memLevel in deflateInit2 */
var MAX_WBITS = 15;
/* 32K LZ77 window */
var DEF_MEM_LEVEL = 8;


var LENGTH_CODES  = 29;
/* number of length codes, not counting the special END_BLOCK code */
var LITERALS      = 256;
/* number of literal bytes 0..255 */
var L_CODES       = LITERALS + 1 + LENGTH_CODES;
/* number of Literal or Length codes, including the END_BLOCK code */
var D_CODES       = 30;
/* number of distance codes */
var BL_CODES      = 19;
/* number of codes used to transfer the bit lengths */
var HEAP_SIZE     = 2 * L_CODES + 1;
/* maximum heap size */
var MAX_BITS  = 15;
/* All codes must not exceed MAX_BITS bits */

var MIN_MATCH = 3;
var MAX_MATCH = 258;
var MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);

var PRESET_DICT = 0x20;

var INIT_STATE = 42;
var EXTRA_STATE = 69;
var NAME_STATE = 73;
var COMMENT_STATE = 91;
var HCRC_STATE = 103;
var BUSY_STATE = 113;
var FINISH_STATE = 666;

var BS_NEED_MORE      = 1; /* block not completed, need more input or more output */
var BS_BLOCK_DONE     = 2; /* block flush performed */
var BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */
var BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */

var OS_CODE = 0x03; // Unix :) . Don't detect, use this default.

function err(strm, errorCode) {
  strm.msg = msg[errorCode];
  return errorCode;
}

function rank(f) {
  return ((f) << 1) - ((f) > 4 ? 9 : 0);
}

function zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }


/* =========================================================================
 * Flush as much pending output as possible. All deflate() output goes
 * through this function so some applications may wish to modify it
 * to avoid allocating a large strm->output buffer and copying into it.
 * (See also read_buf()).
 */
function flush_pending(strm) {
  var s = strm.state;

  //_tr_flush_bits(s);
  var len = s.pending;
  if (len > strm.avail_out) {
    len = strm.avail_out;
  }
  if (len === 0) { return; }

  utils.arraySet(strm.output, s.pending_buf, s.pending_out, len, strm.next_out);
  strm.next_out += len;
  s.pending_out += len;
  strm.total_out += len;
  strm.avail_out -= len;
  s.pending -= len;
  if (s.pending === 0) {
    s.pending_out = 0;
  }
}


function flush_block_only(s, last) {
  trees._tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);
  s.block_start = s.strstart;
  flush_pending(s.strm);
}


function put_byte(s, b) {
  s.pending_buf[s.pending++] = b;
}


/* =========================================================================
 * Put a short in the pending buffer. The 16-bit value is put in MSB order.
 * IN assertion: the stream state is correct and there is enough room in
 * pending_buf.
 */
function putShortMSB(s, b) {
//  put_byte(s, (Byte)(b >> 8));
//  put_byte(s, (Byte)(b & 0xff));
  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;
  s.pending_buf[s.pending++] = b & 0xff;
}


/* ===========================================================================
 * Read a new buffer from the current input stream, update the adler32
 * and total number of bytes read.  All deflate() input goes through
 * this function so some applications may wish to modify it to avoid
 * allocating a large strm->input buffer and copying from it.
 * (See also flush_pending()).
 */
function read_buf(strm, buf, start, size) {
  var len = strm.avail_in;

  if (len > size) { len = size; }
  if (len === 0) { return 0; }

  strm.avail_in -= len;

  // zmemcpy(buf, strm->next_in, len);
  utils.arraySet(buf, strm.input, strm.next_in, len, start);
  if (strm.state.wrap === 1) {
    strm.adler = adler32(strm.adler, buf, len, start);
  }

  else if (strm.state.wrap === 2) {
    strm.adler = crc32(strm.adler, buf, len, start);
  }

  strm.next_in += len;
  strm.total_in += len;

  return len;
}


/* ===========================================================================
 * Set match_start to the longest match starting at the given string and
 * return its length. Matches shorter or equal to prev_length are discarded,
 * in which case the result is equal to prev_length and match_start is
 * garbage.
 * IN assertions: cur_match is the head of the hash chain for the current
 *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1
 * OUT assertion: the match length is not greater than s->lookahead.
 */
function longest_match(s, cur_match) {
  var chain_length = s.max_chain_length;      /* max hash chain length */
  var scan = s.strstart; /* current string */
  var match;                       /* matched string */
  var len;                           /* length of current match */
  var best_len = s.prev_length;              /* best match length so far */
  var nice_match = s.nice_match;             /* stop if match long enough */
  var limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?
      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;

  var _win = s.window; // shortcut

  var wmask = s.w_mask;
  var prev  = s.prev;

  /* Stop when cur_match becomes <= limit. To simplify the code,
   * we prevent matches with the string of window index 0.
   */

  var strend = s.strstart + MAX_MATCH;
  var scan_end1  = _win[scan + best_len - 1];
  var scan_end   = _win[scan + best_len];

  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.
   * It is easy to get rid of this optimization if necessary.
   */
  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, "Code too clever");

  /* Do not waste too much time if we already have a good match: */
  if (s.prev_length >= s.good_match) {
    chain_length >>= 2;
  }
  /* Do not look for matches beyond the end of the input. This is necessary
   * to make deflate deterministic.
   */
  if (nice_match > s.lookahead) { nice_match = s.lookahead; }

  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, "need lookahead");

  do {
    // Assert(cur_match < s->strstart, "no future");
    match = cur_match;

    /* Skip to next match if the match length cannot increase
     * or if the match length is less than 2.  Note that the checks below
     * for insufficient lookahead only occur occasionally for performance
     * reasons.  Therefore uninitialized memory will be accessed, and
     * conditional jumps will be made that depend on those values.
     * However the length of the match is limited to the lookahead, so
     * the output of deflate is not affected by the uninitialized values.
     */

    if (_win[match + best_len]     !== scan_end  ||
        _win[match + best_len - 1] !== scan_end1 ||
        _win[match]                !== _win[scan] ||
        _win[++match]              !== _win[scan + 1]) {
      continue;
    }

    /* The check at best_len-1 can be removed because it will be made
     * again later. (This heuristic is not always a win.)
     * It is not necessary to compare scan[2] and match[2] since they
     * are always equal when the other bytes match, given that
     * the hash keys are equal and that HASH_BITS >= 8.
     */
    scan += 2;
    match++;
    // Assert(*scan == *match, "match[2]?");

    /* We check for insufficient lookahead only every 8th comparison;
     * the 256th check will be made at strstart+258.
     */
    do {
      /*jshint noempty:false*/
    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&
             scan < strend);

    // Assert(scan <= s->window+(unsigned)(s->window_size-1), "wild scan");

    len = MAX_MATCH - (strend - scan);
    scan = strend - MAX_MATCH;

    if (len > best_len) {
      s.match_start = cur_match;
      best_len = len;
      if (len >= nice_match) {
        break;
      }
      scan_end1  = _win[scan + best_len - 1];
      scan_end   = _win[scan + best_len];
    }
  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);

  if (best_len <= s.lookahead) {
    return best_len;
  }
  return s.lookahead;
}


/* ===========================================================================
 * Fill the window when the lookahead becomes insufficient.
 * Updates strstart and lookahead.
 *
 * IN assertion: lookahead < MIN_LOOKAHEAD
 * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD
 *    At least one byte has been read, or avail_in == 0; reads are
 *    performed for at least two bytes (required for the zip translate_eol
 *    option -- not supported here).
 */
function fill_window(s) {
  var _w_size = s.w_size;
  var p, n, m, more, str;

  //Assert(s->lookahead < MIN_LOOKAHEAD, "already enough lookahead");

  do {
    more = s.window_size - s.lookahead - s.strstart;

    // JS ints have 32 bit, block below not needed
    /* Deal with !@#$% 64K limit: */
    //if (sizeof(int) <= 2) {
    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {
    //        more = wsize;
    //
    //  } else if (more == (unsigned)(-1)) {
    //        /* Very unlikely, but possible on 16 bit machine if
    //         * strstart == 0 && lookahead == 1 (input done a byte at time)
    //         */
    //        more--;
    //    }
    //}


    /* If the window is almost full and there is insufficient lookahead,
     * move the upper half to the lower one to make room in the upper half.
     */
    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {

      utils.arraySet(s.window, s.window, _w_size, _w_size, 0);
      s.match_start -= _w_size;
      s.strstart -= _w_size;
      /* we now have strstart >= MAX_DIST */
      s.block_start -= _w_size;

      /* Slide the hash table (could be avoided with 32 bit values
       at the expense of memory usage). We slide even when level == 0
       to keep the hash table consistent if we switch back to level > 0
       later. (Using level 0 permanently is not an optimal usage of
       zlib, so we don't care about this pathological case.)
       */

      n = s.hash_size;
      p = n;
      do {
        m = s.head[--p];
        s.head[p] = (m >= _w_size ? m - _w_size : 0);
      } while (--n);

      n = _w_size;
      p = n;
      do {
        m = s.prev[--p];
        s.prev[p] = (m >= _w_size ? m - _w_size : 0);
        /* If n is not on any hash chain, prev[n] is garbage but
         * its value will never be used.
         */
      } while (--n);

      more += _w_size;
    }
    if (s.strm.avail_in === 0) {
      break;
    }

    /* If there was no sliding:
     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&
     *    more == window_size - lookahead - strstart
     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)
     * => more >= window_size - 2*WSIZE + 2
     * In the BIG_MEM or MMAP case (not yet supported),
     *   window_size == input_size + MIN_LOOKAHEAD  &&
     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.
     * Otherwise, window_size == 2*WSIZE so more >= 2.
     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.
     */
    //Assert(more >= 2, "more < 2");
    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);
    s.lookahead += n;

    /* Initialize the hash value now that we have some input: */
    if (s.lookahead + s.insert >= MIN_MATCH) {
      str = s.strstart - s.insert;
      s.ins_h = s.window[str];

      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + 1]) & s.hash_mask;
//#if MIN_MATCH != 3
//        Call update_hash() MIN_MATCH-3 more times
//#endif
      while (s.insert) {
        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */
        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;

        s.prev[str & s.w_mask] = s.head[s.ins_h];
        s.head[s.ins_h] = str;
        str++;
        s.insert--;
        if (s.lookahead + s.insert < MIN_MATCH) {
          break;
        }
      }
    }
    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,
     * but this is not important since only literal bytes will be emitted.
     */

  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);

  /* If the WIN_INIT bytes after the end of the current data have never been
   * written, then zero those bytes in order to avoid memory check reports of
   * the use of uninitialized (or uninitialised as Julian writes) bytes by
   * the longest match routines.  Update the high water mark for the next
   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match
   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.
   */
//  if (s.high_water < s.window_size) {
//    var curr = s.strstart + s.lookahead;
//    var init = 0;
//
//    if (s.high_water < curr) {
//      /* Previous high water mark below current data -- zero WIN_INIT
//       * bytes or up to end of window, whichever is less.
//       */
//      init = s.window_size - curr;
//      if (init > WIN_INIT)
//        init = WIN_INIT;
//      zmemzero(s->window + curr, (unsigned)init);
//      s->high_water = curr + init;
//    }
//    else if (s->high_water < (ulg)curr + WIN_INIT) {
//      /* High water mark at or above current data, but below current data
//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up
//       * to end of window, whichever is less.
//       */
//      init = (ulg)curr + WIN_INIT - s->high_water;
//      if (init > s->window_size - s->high_water)
//        init = s->window_size - s->high_water;
//      zmemzero(s->window + s->high_water, (unsigned)init);
//      s->high_water += init;
//    }
//  }
//
//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,
//    "not enough room for search");
}

/* ===========================================================================
 * Copy without compression as much as possible from the input stream, return
 * the current block state.
 * This function does not insert new strings in the dictionary since
 * uncompressible data is probably not useful. This function is used
 * only for the level=0 compression option.
 * NOTE: this function should be optimized to avoid extra copying from
 * window to pending_buf.
 */
function deflate_stored(s, flush) {
  /* Stored blocks are limited to 0xffff bytes, pending_buf is limited
   * to pending_buf_size, and each stored block has a 5 byte header:
   */
  var max_block_size = 0xffff;

  if (max_block_size > s.pending_buf_size - 5) {
    max_block_size = s.pending_buf_size - 5;
  }

  /* Copy as much as possible from input to output: */
  for (;;) {
    /* Fill the window as much as possible: */
    if (s.lookahead <= 1) {

      //Assert(s->strstart < s->w_size+MAX_DIST(s) ||
      //  s->block_start >= (long)s->w_size, "slide too late");
//      if (!(s.strstart < s.w_size + (s.w_size - MIN_LOOKAHEAD) ||
//        s.block_start >= s.w_size)) {
//        throw  new Error("slide too late");
//      }

      fill_window(s);
      if (s.lookahead === 0 && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }

      if (s.lookahead === 0) {
        break;
      }
      /* flush the current block */
    }
    //Assert(s->block_start >= 0L, "block gone");
//    if (s.block_start < 0) throw new Error("block gone");

    s.strstart += s.lookahead;
    s.lookahead = 0;

    /* Emit a stored block if pending_buf will be full: */
    var max_start = s.block_start + max_block_size;

    if (s.strstart === 0 || s.strstart >= max_start) {
      /* strstart == 0 is possible when wraparound on 16-bit machine */
      s.lookahead = s.strstart - max_start;
      s.strstart = max_start;
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/


    }
    /* Flush if we may have to slide, otherwise block_start may become
     * negative and the data will be gone:
     */
    if (s.strstart - s.block_start >= (s.w_size - MIN_LOOKAHEAD)) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }

  s.insert = 0;

  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }

  if (s.strstart > s.block_start) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }

  return BS_NEED_MORE;
}

/* ===========================================================================
 * Compress as much as possible from the input stream, return the current
 * block state.
 * This function does not perform lazy evaluation of matches and inserts
 * new strings in the dictionary only for unmatched strings or for short
 * matches. It is used only for the fast compression options.
 */
function deflate_fast(s, flush) {
  var hash_head;        /* head of the hash chain */
  var bflush;           /* set if current block must be flushed */

  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the next match, plus MIN_MATCH bytes to insert the
     * string following the next match.
     */
    if (s.lookahead < MIN_LOOKAHEAD) {
      fill_window(s);
      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) {
        break; /* flush the current block */
      }
    }

    /* Insert the string window[strstart .. strstart+2] in the
     * dictionary, and set hash_head to the head of the hash chain:
     */
    hash_head = 0/*NIL*/;
    if (s.lookahead >= MIN_MATCH) {
      /*** INSERT_STRING(s, s.strstart, hash_head); ***/
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
      s.head[s.ins_h] = s.strstart;
      /***/
    }

    /* Find the longest match, discarding those <= prev_length.
     * At this point we have always match_length < MIN_MATCH
     */
    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {
      /* To simplify the code, we prevent matches with the string
       * of window index 0 (in particular we have to avoid a match
       * of the string with itself at the start of the input file).
       */
      s.match_length = longest_match(s, hash_head);
      /* longest_match() sets match_start */
    }
    if (s.match_length >= MIN_MATCH) {
      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only

      /*** _tr_tally_dist(s, s.strstart - s.match_start,
                     s.match_length - MIN_MATCH, bflush); ***/
      bflush = trees._tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);

      s.lookahead -= s.match_length;

      /* Insert new strings in the hash table only if the match length
       * is not too large. This saves time but degrades compression.
       */
      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {
        s.match_length--; /* string at strstart already in table */
        do {
          s.strstart++;
          /*** INSERT_STRING(s, s.strstart, hash_head); ***/
          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
          s.head[s.ins_h] = s.strstart;
          /***/
          /* strstart never exceeds WSIZE-MAX_MATCH, so there are
           * always MIN_MATCH bytes ahead.
           */
        } while (--s.match_length !== 0);
        s.strstart++;
      } else
      {
        s.strstart += s.match_length;
        s.match_length = 0;
        s.ins_h = s.window[s.strstart];
        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */
        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + 1]) & s.hash_mask;

//#if MIN_MATCH != 3
//                Call UPDATE_HASH() MIN_MATCH-3 more times
//#endif
        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not
         * matter since it will be recomputed at next deflate call.
         */
      }
    } else {
      /* No match, output a literal byte */
      //Tracevv((stderr,"%c", s.window[s.strstart]));
      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);

      s.lookahead--;
      s.strstart++;
    }
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* ===========================================================================
 * Same as above, but achieves better compression. We use a lazy
 * evaluation for matches: a match is finally adopted only if there is
 * no better match at the next window position.
 */
function deflate_slow(s, flush) {
  var hash_head;          /* head of hash chain */
  var bflush;              /* set if current block must be flushed */

  var max_insert;

  /* Process the input block. */
  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the next match, plus MIN_MATCH bytes to insert the
     * string following the next match.
     */
    if (s.lookahead < MIN_LOOKAHEAD) {
      fill_window(s);
      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) { break; } /* flush the current block */
    }

    /* Insert the string window[strstart .. strstart+2] in the
     * dictionary, and set hash_head to the head of the hash chain:
     */
    hash_head = 0/*NIL*/;
    if (s.lookahead >= MIN_MATCH) {
      /*** INSERT_STRING(s, s.strstart, hash_head); ***/
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
      s.head[s.ins_h] = s.strstart;
      /***/
    }

    /* Find the longest match, discarding those <= prev_length.
     */
    s.prev_length = s.match_length;
    s.prev_match = s.match_start;
    s.match_length = MIN_MATCH - 1;

    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&
        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {
      /* To simplify the code, we prevent matches with the string
       * of window index 0 (in particular we have to avoid a match
       * of the string with itself at the start of the input file).
       */
      s.match_length = longest_match(s, hash_head);
      /* longest_match() sets match_start */

      if (s.match_length <= 5 &&
         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {

        /* If prev_match is also MIN_MATCH, match_start is garbage
         * but we will ignore the current match anyway.
         */
        s.match_length = MIN_MATCH - 1;
      }
    }
    /* If there was a match at the previous step and the current
     * match is not better, output the previous match:
     */
    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {
      max_insert = s.strstart + s.lookahead - MIN_MATCH;
      /* Do not insert strings in hash table beyond this. */

      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);

      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,
                     s.prev_length - MIN_MATCH, bflush);***/
      bflush = trees._tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);
      /* Insert in hash table all strings up to the end of the match.
       * strstart-1 and strstart are already inserted. If there is not
       * enough lookahead, the last two strings are not inserted in
       * the hash table.
       */
      s.lookahead -= s.prev_length - 1;
      s.prev_length -= 2;
      do {
        if (++s.strstart <= max_insert) {
          /*** INSERT_STRING(s, s.strstart, hash_head); ***/
          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;
          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];
          s.head[s.ins_h] = s.strstart;
          /***/
        }
      } while (--s.prev_length !== 0);
      s.match_available = 0;
      s.match_length = MIN_MATCH - 1;
      s.strstart++;

      if (bflush) {
        /*** FLUSH_BLOCK(s, 0); ***/
        flush_block_only(s, false);
        if (s.strm.avail_out === 0) {
          return BS_NEED_MORE;
        }
        /***/
      }

    } else if (s.match_available) {
      /* If there was no match at the previous position, output a
       * single literal. If there was a match but the current match
       * is longer, truncate the previous match to a single literal.
       */
      //Tracevv((stderr,"%c", s->window[s->strstart-1]));
      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);

      if (bflush) {
        /*** FLUSH_BLOCK_ONLY(s, 0) ***/
        flush_block_only(s, false);
        /***/
      }
      s.strstart++;
      s.lookahead--;
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
    } else {
      /* There is no previous match to compare with, wait for
       * the next step to decide.
       */
      s.match_available = 1;
      s.strstart++;
      s.lookahead--;
    }
  }
  //Assert (flush != Z_NO_FLUSH, "no flush?");
  if (s.match_available) {
    //Tracevv((stderr,"%c", s->window[s->strstart-1]));
    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/
    bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);

    s.match_available = 0;
  }
  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }

  return BS_BLOCK_DONE;
}


/* ===========================================================================
 * For Z_RLE, simply look for runs of bytes, generate matches only of distance
 * one.  Do not maintain a hash table.  (It will be regenerated if this run of
 * deflate switches away from Z_RLE.)
 */
function deflate_rle(s, flush) {
  var bflush;            /* set if current block must be flushed */
  var prev;              /* byte at distance one to match */
  var scan, strend;      /* scan goes up to strend for length of run */

  var _win = s.window;

  for (;;) {
    /* Make sure that we always have enough lookahead, except
     * at the end of the input file. We need MAX_MATCH bytes
     * for the longest run, plus one for the unrolled loop.
     */
    if (s.lookahead <= MAX_MATCH) {
      fill_window(s);
      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {
        return BS_NEED_MORE;
      }
      if (s.lookahead === 0) { break; } /* flush the current block */
    }

    /* See how many times the previous byte repeats */
    s.match_length = 0;
    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {
      scan = s.strstart - 1;
      prev = _win[scan];
      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {
        strend = s.strstart + MAX_MATCH;
        do {
          /*jshint noempty:false*/
        } while (prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 prev === _win[++scan] && prev === _win[++scan] &&
                 scan < strend);
        s.match_length = MAX_MATCH - (strend - scan);
        if (s.match_length > s.lookahead) {
          s.match_length = s.lookahead;
        }
      }
      //Assert(scan <= s->window+(uInt)(s->window_size-1), "wild scan");
    }

    /* Emit match if have run of MIN_MATCH or longer, else emit literal */
    if (s.match_length >= MIN_MATCH) {
      //check_match(s, s.strstart, s.strstart - 1, s.match_length);

      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/
      bflush = trees._tr_tally(s, 1, s.match_length - MIN_MATCH);

      s.lookahead -= s.match_length;
      s.strstart += s.match_length;
      s.match_length = 0;
    } else {
      /* No match, output a literal byte */
      //Tracevv((stderr,"%c", s->window[s->strstart]));
      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);

      s.lookahead--;
      s.strstart++;
    }
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = 0;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* ===========================================================================
 * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.
 * (It will be regenerated if this run of deflate switches away from Huffman.)
 */
function deflate_huff(s, flush) {
  var bflush;             /* set if current block must be flushed */

  for (;;) {
    /* Make sure that we have a literal to write. */
    if (s.lookahead === 0) {
      fill_window(s);
      if (s.lookahead === 0) {
        if (flush === Z_NO_FLUSH) {
          return BS_NEED_MORE;
        }
        break;      /* flush the current block */
      }
    }

    /* Output a literal byte */
    s.match_length = 0;
    //Tracevv((stderr,"%c", s->window[s->strstart]));
    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/
    bflush = trees._tr_tally(s, 0, s.window[s.strstart]);
    s.lookahead--;
    s.strstart++;
    if (bflush) {
      /*** FLUSH_BLOCK(s, 0); ***/
      flush_block_only(s, false);
      if (s.strm.avail_out === 0) {
        return BS_NEED_MORE;
      }
      /***/
    }
  }
  s.insert = 0;
  if (flush === Z_FINISH) {
    /*** FLUSH_BLOCK(s, 1); ***/
    flush_block_only(s, true);
    if (s.strm.avail_out === 0) {
      return BS_FINISH_STARTED;
    }
    /***/
    return BS_FINISH_DONE;
  }
  if (s.last_lit) {
    /*** FLUSH_BLOCK(s, 0); ***/
    flush_block_only(s, false);
    if (s.strm.avail_out === 0) {
      return BS_NEED_MORE;
    }
    /***/
  }
  return BS_BLOCK_DONE;
}

/* Values for max_lazy_match, good_match and max_chain_length, depending on
 * the desired pack level (0..9). The values given below have been tuned to
 * exclude worst case performance for pathological files. Better values may be
 * found for specific files.
 */
function Config(good_length, max_lazy, nice_length, max_chain, func) {
  this.good_length = good_length;
  this.max_lazy = max_lazy;
  this.nice_length = nice_length;
  this.max_chain = max_chain;
  this.func = func;
}

var configuration_table;

configuration_table = [
  /*      good lazy nice chain */
  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */
  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */
  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */
  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */

  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */
  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */
  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */
  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */
  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */
  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */
];


/* ===========================================================================
 * Initialize the "longest match" routines for a new zlib stream
 */
function lm_init(s) {
  s.window_size = 2 * s.w_size;

  /*** CLEAR_HASH(s); ***/
  zero(s.head); // Fill with NIL (= 0);

  /* Set the default configuration parameters:
   */
  s.max_lazy_match = configuration_table[s.level].max_lazy;
  s.good_match = configuration_table[s.level].good_length;
  s.nice_match = configuration_table[s.level].nice_length;
  s.max_chain_length = configuration_table[s.level].max_chain;

  s.strstart = 0;
  s.block_start = 0;
  s.lookahead = 0;
  s.insert = 0;
  s.match_length = s.prev_length = MIN_MATCH - 1;
  s.match_available = 0;
  s.ins_h = 0;
}


function DeflateState() {
  this.strm = null;            /* pointer back to this zlib stream */
  this.status = 0;            /* as the name implies */
  this.pending_buf = null;      /* output still pending */
  this.pending_buf_size = 0;  /* size of pending_buf */
  this.pending_out = 0;       /* next pending byte to output to the stream */
  this.pending = 0;           /* nb of bytes in the pending buffer */
  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */
  this.gzhead = null;         /* gzip header information to write */
  this.gzindex = 0;           /* where in extra, name, or comment */
  this.method = Z_DEFLATED; /* can only be DEFLATED */
  this.last_flush = -1;   /* value of flush param for previous deflate call */

  this.w_size = 0;  /* LZ77 window size (32K by default) */
  this.w_bits = 0;  /* log2(w_size)  (8..16) */
  this.w_mask = 0;  /* w_size - 1 */

  this.window = null;
  /* Sliding window. Input bytes are read into the second half of the window,
   * and move to the first half later to keep a dictionary of at least wSize
   * bytes. With this organization, matches are limited to a distance of
   * wSize-MAX_MATCH bytes, but this ensures that IO is always
   * performed with a length multiple of the block size.
   */

  this.window_size = 0;
  /* Actual size of window: 2*wSize, except when the user input buffer
   * is directly used as sliding window.
   */

  this.prev = null;
  /* Link to older string with same hash index. To limit the size of this
   * array to 64K, this link is maintained only for the last 32K strings.
   * An index in this array is thus a window index modulo 32K.
   */

  this.head = null;   /* Heads of the hash chains or NIL. */

  this.ins_h = 0;       /* hash index of string to be inserted */
  this.hash_size = 0;   /* number of elements in hash table */
  this.hash_bits = 0;   /* log2(hash_size) */
  this.hash_mask = 0;   /* hash_size-1 */

  this.hash_shift = 0;
  /* Number of bits by which ins_h must be shifted at each input
   * step. It must be such that after MIN_MATCH steps, the oldest
   * byte no longer takes part in the hash key, that is:
   *   hash_shift * MIN_MATCH >= hash_bits
   */

  this.block_start = 0;
  /* Window position at the beginning of the current output block. Gets
   * negative when the window is moved backwards.
   */

  this.match_length = 0;      /* length of best match */
  this.prev_match = 0;        /* previous match */
  this.match_available = 0;   /* set if previous match exists */
  this.strstart = 0;          /* start of string to insert */
  this.match_start = 0;       /* start of matching string */
  this.lookahead = 0;         /* number of valid bytes ahead in window */

  this.prev_length = 0;
  /* Length of the best match at previous step. Matches not greater than this
   * are discarded. This is used in the lazy match evaluation.
   */

  this.max_chain_length = 0;
  /* To speed up deflation, hash chains are never searched beyond this
   * length.  A higher limit improves compression ratio but degrades the
   * speed.
   */

  this.max_lazy_match = 0;
  /* Attempt to find a better match only when the current match is strictly
   * smaller than this value. This mechanism is used only for compression
   * levels >= 4.
   */
  // That's alias to max_lazy_match, don't use directly
  //this.max_insert_length = 0;
  /* Insert new strings in the hash table only if the match length is not
   * greater than this length. This saves time but degrades compression.
   * max_insert_length is used only for compression levels <= 3.
   */

  this.level = 0;     /* compression level (1..9) */
  this.strategy = 0;  /* favor or force Huffman coding*/

  this.good_match = 0;
  /* Use a faster search when the previous match is longer than this */

  this.nice_match = 0; /* Stop searching when current match exceeds this */

              /* used by trees.c: */

  /* Didn't use ct_data typedef below to suppress compiler warning */

  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */
  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */
  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */

  // Use flat array of DOUBLE size, with interleaved fata,
  // because JS does not support effective
  this.dyn_ltree  = new utils.Buf16(HEAP_SIZE * 2);
  this.dyn_dtree  = new utils.Buf16((2 * D_CODES + 1) * 2);
  this.bl_tree    = new utils.Buf16((2 * BL_CODES + 1) * 2);
  zero(this.dyn_ltree);
  zero(this.dyn_dtree);
  zero(this.bl_tree);

  this.l_desc   = null;         /* desc. for literal tree */
  this.d_desc   = null;         /* desc. for distance tree */
  this.bl_desc  = null;         /* desc. for bit length tree */

  //ush bl_count[MAX_BITS+1];
  this.bl_count = new utils.Buf16(MAX_BITS + 1);
  /* number of codes at each bit length for an optimal tree */

  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */
  this.heap = new utils.Buf16(2 * L_CODES + 1);  /* heap used to build the Huffman trees */
  zero(this.heap);

  this.heap_len = 0;               /* number of elements in the heap */
  this.heap_max = 0;               /* element of largest frequency */
  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.
   * The same heap array is used to build all trees.
   */

  this.depth = new utils.Buf16(2 * L_CODES + 1); //uch depth[2*L_CODES+1];
  zero(this.depth);
  /* Depth of each subtree used as tie breaker for trees of equal frequency
   */

  this.l_buf = 0;          /* buffer index for literals or lengths */

  this.lit_bufsize = 0;
  /* Size of match buffer for literals/lengths.  There are 4 reasons for
   * limiting lit_bufsize to 64K:
   *   - frequencies can be kept in 16 bit counters
   *   - if compression is not successful for the first block, all input
   *     data is still in the window so we can still emit a stored block even
   *     when input comes from standard input.  (This can also be done for
   *     all blocks if lit_bufsize is not greater than 32K.)
   *   - if compression is not successful for a file smaller than 64K, we can
   *     even emit a stored file instead of a stored block (saving 5 bytes).
   *     This is applicable only for zip (not gzip or zlib).
   *   - creating new Huffman trees less frequently may not provide fast
   *     adaptation to changes in the input data statistics. (Take for
   *     example a binary file with poorly compressible code followed by
   *     a highly compressible string table.) Smaller buffer sizes give
   *     fast adaptation but have of course the overhead of transmitting
   *     trees more frequently.
   *   - I can't count above 4
   */

  this.last_lit = 0;      /* running index in l_buf */

  this.d_buf = 0;
  /* Buffer index for distances. To simplify the code, d_buf and l_buf have
   * the same number of elements. To use different lengths, an extra flag
   * array would be necessary.
   */

  this.opt_len = 0;       /* bit length of current block with optimal trees */
  this.static_len = 0;    /* bit length of current block with static trees */
  this.matches = 0;       /* number of string matches in current block */
  this.insert = 0;        /* bytes at end of window left to insert */


  this.bi_buf = 0;
  /* Output buffer. bits are inserted starting at the bottom (least
   * significant bits).
   */
  this.bi_valid = 0;
  /* Number of valid bits in bi_buf.  All bits above the last valid bit
   * are always zero.
   */

  // Used for window memory init. We safely ignore it for JS. That makes
  // sense only for pointers and memory check tools.
  //this.high_water = 0;
  /* High water mark offset in window for initialized bytes -- bytes above
   * this are set to zero in order to avoid memory check warnings when
   * longest match routines access bytes past the input.  This is then
   * updated to the new high water mark.
   */
}


function deflateResetKeep(strm) {
  var s;

  if (!strm || !strm.state) {
    return err(strm, Z_STREAM_ERROR);
  }

  strm.total_in = strm.total_out = 0;
  strm.data_type = Z_UNKNOWN;

  s = strm.state;
  s.pending = 0;
  s.pending_out = 0;

  if (s.wrap < 0) {
    s.wrap = -s.wrap;
    /* was made negative by deflate(..., Z_FINISH); */
  }
  s.status = (s.wrap ? INIT_STATE : BUSY_STATE);
  strm.adler = (s.wrap === 2) ?
    0  // crc32(0, Z_NULL, 0)
  :
    1; // adler32(0, Z_NULL, 0)
  s.last_flush = Z_NO_FLUSH;
  trees._tr_init(s);
  return Z_OK;
}


function deflateReset(strm) {
  var ret = deflateResetKeep(strm);
  if (ret === Z_OK) {
    lm_init(strm.state);
  }
  return ret;
}


function deflateSetHeader(strm, head) {
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  if (strm.state.wrap !== 2) { return Z_STREAM_ERROR; }
  strm.state.gzhead = head;
  return Z_OK;
}


function deflateInit2(strm, level, method, windowBits, memLevel, strategy) {
  if (!strm) { // === Z_NULL
    return Z_STREAM_ERROR;
  }
  var wrap = 1;

  if (level === Z_DEFAULT_COMPRESSION) {
    level = 6;
  }

  if (windowBits < 0) { /* suppress zlib wrapper */
    wrap = 0;
    windowBits = -windowBits;
  }

  else if (windowBits > 15) {
    wrap = 2;           /* write gzip wrapper instead */
    windowBits -= 16;
  }


  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||
    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||
    strategy < 0 || strategy > Z_FIXED) {
    return err(strm, Z_STREAM_ERROR);
  }


  if (windowBits === 8) {
    windowBits = 9;
  }
  /* until 256-byte window bug fixed */

  var s = new DeflateState();

  strm.state = s;
  s.strm = strm;

  s.wrap = wrap;
  s.gzhead = null;
  s.w_bits = windowBits;
  s.w_size = 1 << s.w_bits;
  s.w_mask = s.w_size - 1;

  s.hash_bits = memLevel + 7;
  s.hash_size = 1 << s.hash_bits;
  s.hash_mask = s.hash_size - 1;
  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);

  s.window = new utils.Buf8(s.w_size * 2);
  s.head = new utils.Buf16(s.hash_size);
  s.prev = new utils.Buf16(s.w_size);

  // Don't need mem init magic for JS.
  //s.high_water = 0;  /* nothing written to s->window yet */

  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */

  s.pending_buf_size = s.lit_bufsize * 4;

  //overlay = (ushf *) ZALLOC(strm, s->lit_bufsize, sizeof(ush)+2);
  //s->pending_buf = (uchf *) overlay;
  s.pending_buf = new utils.Buf8(s.pending_buf_size);

  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)
  //s->d_buf = overlay + s->lit_bufsize/sizeof(ush);
  s.d_buf = 1 * s.lit_bufsize;

  //s->l_buf = s->pending_buf + (1+sizeof(ush))*s->lit_bufsize;
  s.l_buf = (1 + 2) * s.lit_bufsize;

  s.level = level;
  s.strategy = strategy;
  s.method = method;

  return deflateReset(strm);
}

function deflateInit(strm, level) {
  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);
}


function deflate(strm, flush) {
  var old_flush, s;
  var beg, val; // for gzip header write only

  if (!strm || !strm.state ||
    flush > Z_BLOCK || flush < 0) {
    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;
  }

  s = strm.state;

  if (!strm.output ||
      (!strm.input && strm.avail_in !== 0) ||
      (s.status === FINISH_STATE && flush !== Z_FINISH)) {
    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);
  }

  s.strm = strm; /* just in case */
  old_flush = s.last_flush;
  s.last_flush = flush;

  /* Write the header */
  if (s.status === INIT_STATE) {

    if (s.wrap === 2) { // GZIP header
      strm.adler = 0;  //crc32(0L, Z_NULL, 0);
      put_byte(s, 31);
      put_byte(s, 139);
      put_byte(s, 8);
      if (!s.gzhead) { // s->gzhead == Z_NULL
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, 0);
        put_byte(s, s.level === 9 ? 2 :
                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?
                     4 : 0));
        put_byte(s, OS_CODE);
        s.status = BUSY_STATE;
      }
      else {
        put_byte(s, (s.gzhead.text ? 1 : 0) +
                    (s.gzhead.hcrc ? 2 : 0) +
                    (!s.gzhead.extra ? 0 : 4) +
                    (!s.gzhead.name ? 0 : 8) +
                    (!s.gzhead.comment ? 0 : 16)
        );
        put_byte(s, s.gzhead.time & 0xff);
        put_byte(s, (s.gzhead.time >> 8) & 0xff);
        put_byte(s, (s.gzhead.time >> 16) & 0xff);
        put_byte(s, (s.gzhead.time >> 24) & 0xff);
        put_byte(s, s.level === 9 ? 2 :
                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?
                     4 : 0));
        put_byte(s, s.gzhead.os & 0xff);
        if (s.gzhead.extra && s.gzhead.extra.length) {
          put_byte(s, s.gzhead.extra.length & 0xff);
          put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);
        }
        if (s.gzhead.hcrc) {
          strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);
        }
        s.gzindex = 0;
        s.status = EXTRA_STATE;
      }
    }
    else // DEFLATE header
    {
      var header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;
      var level_flags = -1;

      if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {
        level_flags = 0;
      } else if (s.level < 6) {
        level_flags = 1;
      } else if (s.level === 6) {
        level_flags = 2;
      } else {
        level_flags = 3;
      }
      header |= (level_flags << 6);
      if (s.strstart !== 0) { header |= PRESET_DICT; }
      header += 31 - (header % 31);

      s.status = BUSY_STATE;
      putShortMSB(s, header);

      /* Save the adler32 of the preset dictionary: */
      if (s.strstart !== 0) {
        putShortMSB(s, strm.adler >>> 16);
        putShortMSB(s, strm.adler & 0xffff);
      }
      strm.adler = 1; // adler32(0L, Z_NULL, 0);
    }
  }

//#ifdef GZIP
  if (s.status === EXTRA_STATE) {
    if (s.gzhead.extra/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */

      while (s.gzindex < (s.gzhead.extra.length & 0xffff)) {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            break;
          }
        }
        put_byte(s, s.gzhead.extra[s.gzindex] & 0xff);
        s.gzindex++;
      }
      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (s.gzindex === s.gzhead.extra.length) {
        s.gzindex = 0;
        s.status = NAME_STATE;
      }
    }
    else {
      s.status = NAME_STATE;
    }
  }
  if (s.status === NAME_STATE) {
    if (s.gzhead.name/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */
      //int val;

      do {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            val = 1;
            break;
          }
        }
        // JS specific: little magic to add zero terminator to end of string
        if (s.gzindex < s.gzhead.name.length) {
          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;
        } else {
          val = 0;
        }
        put_byte(s, val);
      } while (val !== 0);

      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (val === 0) {
        s.gzindex = 0;
        s.status = COMMENT_STATE;
      }
    }
    else {
      s.status = COMMENT_STATE;
    }
  }
  if (s.status === COMMENT_STATE) {
    if (s.gzhead.comment/* != Z_NULL*/) {
      beg = s.pending;  /* start of bytes to update crc */
      //int val;

      do {
        if (s.pending === s.pending_buf_size) {
          if (s.gzhead.hcrc && s.pending > beg) {
            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
          }
          flush_pending(strm);
          beg = s.pending;
          if (s.pending === s.pending_buf_size) {
            val = 1;
            break;
          }
        }
        // JS specific: little magic to add zero terminator to end of string
        if (s.gzindex < s.gzhead.comment.length) {
          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;
        } else {
          val = 0;
        }
        put_byte(s, val);
      } while (val !== 0);

      if (s.gzhead.hcrc && s.pending > beg) {
        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);
      }
      if (val === 0) {
        s.status = HCRC_STATE;
      }
    }
    else {
      s.status = HCRC_STATE;
    }
  }
  if (s.status === HCRC_STATE) {
    if (s.gzhead.hcrc) {
      if (s.pending + 2 > s.pending_buf_size) {
        flush_pending(strm);
      }
      if (s.pending + 2 <= s.pending_buf_size) {
        put_byte(s, strm.adler & 0xff);
        put_byte(s, (strm.adler >> 8) & 0xff);
        strm.adler = 0; //crc32(0L, Z_NULL, 0);
        s.status = BUSY_STATE;
      }
    }
    else {
      s.status = BUSY_STATE;
    }
  }
//#endif

  /* Flush as much pending output as possible */
  if (s.pending !== 0) {
    flush_pending(strm);
    if (strm.avail_out === 0) {
      /* Since avail_out is 0, deflate will be called again with
       * more output space, but possibly with both pending and
       * avail_in equal to zero. There won't be anything to do,
       * but this is not an error situation so make sure we
       * return OK instead of BUF_ERROR at next call of deflate:
       */
      s.last_flush = -1;
      return Z_OK;
    }

    /* Make sure there is something to do and avoid duplicate consecutive
     * flushes. For repeated and useless calls with Z_FINISH, we keep
     * returning Z_STREAM_END instead of Z_BUF_ERROR.
     */
  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&
    flush !== Z_FINISH) {
    return err(strm, Z_BUF_ERROR);
  }

  /* User must not provide more input after the first FINISH: */
  if (s.status === FINISH_STATE && strm.avail_in !== 0) {
    return err(strm, Z_BUF_ERROR);
  }

  /* Start a new block or continue the current one.
   */
  if (strm.avail_in !== 0 || s.lookahead !== 0 ||
    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {
    var bstate = (s.strategy === Z_HUFFMAN_ONLY) ? deflate_huff(s, flush) :
      (s.strategy === Z_RLE ? deflate_rle(s, flush) :
        configuration_table[s.level].func(s, flush));

    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {
      s.status = FINISH_STATE;
    }
    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {
      if (strm.avail_out === 0) {
        s.last_flush = -1;
        /* avoid BUF_ERROR next call, see above */
      }
      return Z_OK;
      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call
       * of deflate should use the same flush parameter to make sure
       * that the flush is complete. So we don't have to output an
       * empty block here, this will be done at next call. This also
       * ensures that for a very small output buffer, we emit at most
       * one empty block.
       */
    }
    if (bstate === BS_BLOCK_DONE) {
      if (flush === Z_PARTIAL_FLUSH) {
        trees._tr_align(s);
      }
      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */

        trees._tr_stored_block(s, 0, 0, false);
        /* For a full flush, this empty block will be recognized
         * as a special marker by inflate_sync().
         */
        if (flush === Z_FULL_FLUSH) {
          /*** CLEAR_HASH(s); ***/             /* forget history */
          zero(s.head); // Fill with NIL (= 0);

          if (s.lookahead === 0) {
            s.strstart = 0;
            s.block_start = 0;
            s.insert = 0;
          }
        }
      }
      flush_pending(strm);
      if (strm.avail_out === 0) {
        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */
        return Z_OK;
      }
    }
  }
  //Assert(strm->avail_out > 0, "bug2");
  //if (strm.avail_out <= 0) { throw new Error("bug2");}

  if (flush !== Z_FINISH) { return Z_OK; }
  if (s.wrap <= 0) { return Z_STREAM_END; }

  /* Write the trailer */
  if (s.wrap === 2) {
    put_byte(s, strm.adler & 0xff);
    put_byte(s, (strm.adler >> 8) & 0xff);
    put_byte(s, (strm.adler >> 16) & 0xff);
    put_byte(s, (strm.adler >> 24) & 0xff);
    put_byte(s, strm.total_in & 0xff);
    put_byte(s, (strm.total_in >> 8) & 0xff);
    put_byte(s, (strm.total_in >> 16) & 0xff);
    put_byte(s, (strm.total_in >> 24) & 0xff);
  }
  else
  {
    putShortMSB(s, strm.adler >>> 16);
    putShortMSB(s, strm.adler & 0xffff);
  }

  flush_pending(strm);
  /* If avail_out is zero, the application will call deflate again
   * to flush the rest.
   */
  if (s.wrap > 0) { s.wrap = -s.wrap; }
  /* write the trailer only once! */
  return s.pending !== 0 ? Z_OK : Z_STREAM_END;
}

function deflateEnd(strm) {
  var status;

  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {
    return Z_STREAM_ERROR;
  }

  status = strm.state.status;
  if (status !== INIT_STATE &&
    status !== EXTRA_STATE &&
    status !== NAME_STATE &&
    status !== COMMENT_STATE &&
    status !== HCRC_STATE &&
    status !== BUSY_STATE &&
    status !== FINISH_STATE
  ) {
    return err(strm, Z_STREAM_ERROR);
  }

  strm.state = null;

  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;
}


/* =========================================================================
 * Initializes the compression dictionary from the given byte
 * sequence without producing any compressed output.
 */
function deflateSetDictionary(strm, dictionary) {
  var dictLength = dictionary.length;

  var s;
  var str, n;
  var wrap;
  var avail;
  var next;
  var input;
  var tmpDict;

  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {
    return Z_STREAM_ERROR;
  }

  s = strm.state;
  wrap = s.wrap;

  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {
    return Z_STREAM_ERROR;
  }

  /* when using zlib wrappers, compute Adler-32 for provided dictionary */
  if (wrap === 1) {
    /* adler32(strm->adler, dictionary, dictLength); */
    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);
  }

  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */

  /* if dictionary would fill window, just replace the history */
  if (dictLength >= s.w_size) {
    if (wrap === 0) {            /* already empty otherwise */
      /*** CLEAR_HASH(s); ***/
      zero(s.head); // Fill with NIL (= 0);
      s.strstart = 0;
      s.block_start = 0;
      s.insert = 0;
    }
    /* use the tail */
    // dictionary = dictionary.slice(dictLength - s.w_size);
    tmpDict = new utils.Buf8(s.w_size);
    utils.arraySet(tmpDict, dictionary, dictLength - s.w_size, s.w_size, 0);
    dictionary = tmpDict;
    dictLength = s.w_size;
  }
  /* insert dictionary into window and hash */
  avail = strm.avail_in;
  next = strm.next_in;
  input = strm.input;
  strm.avail_in = dictLength;
  strm.next_in = 0;
  strm.input = dictionary;
  fill_window(s);
  while (s.lookahead >= MIN_MATCH) {
    str = s.strstart;
    n = s.lookahead - (MIN_MATCH - 1);
    do {
      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */
      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;

      s.prev[str & s.w_mask] = s.head[s.ins_h];

      s.head[s.ins_h] = str;
      str++;
    } while (--n);
    s.strstart = str;
    s.lookahead = MIN_MATCH - 1;
    fill_window(s);
  }
  s.strstart += s.lookahead;
  s.block_start = s.strstart;
  s.insert = s.lookahead;
  s.lookahead = 0;
  s.match_length = s.prev_length = MIN_MATCH - 1;
  s.match_available = 0;
  strm.next_in = next;
  strm.input = input;
  strm.avail_in = avail;
  s.wrap = wrap;
  return Z_OK;
}


exports.deflateInit = deflateInit;
exports.deflateInit2 = deflateInit2;
exports.deflateReset = deflateReset;
exports.deflateResetKeep = deflateResetKeep;
exports.deflateSetHeader = deflateSetHeader;
exports.deflate = deflate;
exports.deflateEnd = deflateEnd;
exports.deflateSetDictionary = deflateSetDictionary;
exports.deflateInfo = 'pako deflate (from Nodeca project)';

/* Not implemented
exports.deflateBound = deflateBound;
exports.deflateCopy = deflateCopy;
exports.deflateParams = deflateParams;
exports.deflatePending = deflatePending;
exports.deflatePrime = deflatePrime;
exports.deflateTune = deflateTune;
*/


/***/ }),

/***/ "./node_modules/pako/lib/zlib/gzheader.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/gzheader.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function GZheader() {
  /* true if compressed data believed to be text */
  this.text       = 0;
  /* modification time */
  this.time       = 0;
  /* extra flags (not used when writing a gzip file) */
  this.xflags     = 0;
  /* operating system */
  this.os         = 0;
  /* pointer to extra field or Z_NULL if none */
  this.extra      = null;
  /* extra field length (valid if extra != Z_NULL) */
  this.extra_len  = 0; // Actually, we don't need it in JS,
                       // but leave for few code modifications

  //
  // Setup limits is not necessary because in js we should not preallocate memory
  // for inflate use constant limit in 65536 bytes
  //

  /* space at extra (only when reading header) */
  // this.extra_max  = 0;
  /* pointer to zero-terminated file name or Z_NULL */
  this.name       = '';
  /* space at name (only when reading header) */
  // this.name_max   = 0;
  /* pointer to zero-terminated comment or Z_NULL */
  this.comment    = '';
  /* space at comment (only when reading header) */
  // this.comm_max   = 0;
  /* true if there was or will be a header crc */
  this.hcrc       = 0;
  /* true when done reading gzip header (not used when writing a gzip file) */
  this.done       = false;
}

module.exports = GZheader;


/***/ }),

/***/ "./node_modules/pako/lib/zlib/inffast.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inffast.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

// See state defs from inflate.js
var BAD = 30;       /* got a data error -- remain here until reset */
var TYPE = 12;      /* i: waiting for type bits, including last-flag bit */

/*
   Decode literal, length, and distance codes and write out the resulting
   literal and match bytes until either not enough input or output is
   available, an end-of-block is encountered, or a data error is encountered.
   When large enough input and output buffers are supplied to inflate(), for
   example, a 16K input buffer and a 64K output buffer, more than 95% of the
   inflate execution time is spent in this routine.

   Entry assumptions:

        state.mode === LEN
        strm.avail_in >= 6
        strm.avail_out >= 258
        start >= strm.avail_out
        state.bits < 8

   On return, state.mode is one of:

        LEN -- ran out of enough output space or enough available input
        TYPE -- reached end of block code, inflate() to interpret next block
        BAD -- error in block data

   Notes:

    - The maximum input bits used by a length/distance pair is 15 bits for the
      length code, 5 bits for the length extra, 15 bits for the distance code,
      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.
      Therefore if strm.avail_in >= 6, then there is enough input to avoid
      checking for available input while decoding.

    - The maximum bytes that a single length/distance pair can output is 258
      bytes, which is the maximum length that can be coded.  inflate_fast()
      requires strm.avail_out >= 258 for each loop to avoid checking for
      output space.
 */
module.exports = function inflate_fast(strm, start) {
  var state;
  var _in;                    /* local strm.input */
  var last;                   /* have enough input while in < last */
  var _out;                   /* local strm.output */
  var beg;                    /* inflate()'s initial strm.output */
  var end;                    /* while out < end, enough space available */
//#ifdef INFLATE_STRICT
  var dmax;                   /* maximum distance from zlib header */
//#endif
  var wsize;                  /* window size or zero if not using window */
  var whave;                  /* valid bytes in the window */
  var wnext;                  /* window write index */
  // Use `s_window` instead `window`, avoid conflict with instrumentation tools
  var s_window;               /* allocated sliding window, if wsize != 0 */
  var hold;                   /* local strm.hold */
  var bits;                   /* local strm.bits */
  var lcode;                  /* local strm.lencode */
  var dcode;                  /* local strm.distcode */
  var lmask;                  /* mask for first level of length codes */
  var dmask;                  /* mask for first level of distance codes */
  var here;                   /* retrieved table entry */
  var op;                     /* code bits, operation, extra bits, or */
                              /*  window position, window bytes to copy */
  var len;                    /* match length, unused bytes */
  var dist;                   /* match distance */
  var from;                   /* where to copy match from */
  var from_source;


  var input, output; // JS specific, because we have no pointers

  /* copy state to local variables */
  state = strm.state;
  //here = state.here;
  _in = strm.next_in;
  input = strm.input;
  last = _in + (strm.avail_in - 5);
  _out = strm.next_out;
  output = strm.output;
  beg = _out - (start - strm.avail_out);
  end = _out + (strm.avail_out - 257);
//#ifdef INFLATE_STRICT
  dmax = state.dmax;
//#endif
  wsize = state.wsize;
  whave = state.whave;
  wnext = state.wnext;
  s_window = state.window;
  hold = state.hold;
  bits = state.bits;
  lcode = state.lencode;
  dcode = state.distcode;
  lmask = (1 << state.lenbits) - 1;
  dmask = (1 << state.distbits) - 1;


  /* decode literals and length/distances until end-of-block or not enough
     input data or output space */

  top:
  do {
    if (bits < 15) {
      hold += input[_in++] << bits;
      bits += 8;
      hold += input[_in++] << bits;
      bits += 8;
    }

    here = lcode[hold & lmask];

    dolen:
    for (;;) { // Goto emulation
      op = here >>> 24/*here.bits*/;
      hold >>>= op;
      bits -= op;
      op = (here >>> 16) & 0xff/*here.op*/;
      if (op === 0) {                          /* literal */
        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?
        //        "inflate:         literal '%c'\n" :
        //        "inflate:         literal 0x%02x\n", here.val));
        output[_out++] = here & 0xffff/*here.val*/;
      }
      else if (op & 16) {                     /* length base */
        len = here & 0xffff/*here.val*/;
        op &= 15;                           /* number of extra bits */
        if (op) {
          if (bits < op) {
            hold += input[_in++] << bits;
            bits += 8;
          }
          len += hold & ((1 << op) - 1);
          hold >>>= op;
          bits -= op;
        }
        //Tracevv((stderr, "inflate:         length %u\n", len));
        if (bits < 15) {
          hold += input[_in++] << bits;
          bits += 8;
          hold += input[_in++] << bits;
          bits += 8;
        }
        here = dcode[hold & dmask];

        dodist:
        for (;;) { // goto emulation
          op = here >>> 24/*here.bits*/;
          hold >>>= op;
          bits -= op;
          op = (here >>> 16) & 0xff/*here.op*/;

          if (op & 16) {                      /* distance base */
            dist = here & 0xffff/*here.val*/;
            op &= 15;                       /* number of extra bits */
            if (bits < op) {
              hold += input[_in++] << bits;
              bits += 8;
              if (bits < op) {
                hold += input[_in++] << bits;
                bits += 8;
              }
            }
            dist += hold & ((1 << op) - 1);
//#ifdef INFLATE_STRICT
            if (dist > dmax) {
              strm.msg = 'invalid distance too far back';
              state.mode = BAD;
              break top;
            }
//#endif
            hold >>>= op;
            bits -= op;
            //Tracevv((stderr, "inflate:         distance %u\n", dist));
            op = _out - beg;                /* max distance in output */
            if (dist > op) {                /* see if copy from window */
              op = dist - op;               /* distance back in window */
              if (op > whave) {
                if (state.sane) {
                  strm.msg = 'invalid distance too far back';
                  state.mode = BAD;
                  break top;
                }

// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//                if (len <= op - whave) {
//                  do {
//                    output[_out++] = 0;
//                  } while (--len);
//                  continue top;
//                }
//                len -= op - whave;
//                do {
//                  output[_out++] = 0;
//                } while (--op > whave);
//                if (op === 0) {
//                  from = _out - dist;
//                  do {
//                    output[_out++] = output[from++];
//                  } while (--len);
//                  continue top;
//                }
//#endif
              }
              from = 0; // window index
              from_source = s_window;
              if (wnext === 0) {           /* very common case */
                from += wsize - op;
                if (op < len) {         /* some from window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = _out - dist;  /* rest from output */
                  from_source = output;
                }
              }
              else if (wnext < op) {      /* wrap around window */
                from += wsize + wnext - op;
                op -= wnext;
                if (op < len) {         /* some from end of window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = 0;
                  if (wnext < len) {  /* some from start of window */
                    op = wnext;
                    len -= op;
                    do {
                      output[_out++] = s_window[from++];
                    } while (--op);
                    from = _out - dist;      /* rest from output */
                    from_source = output;
                  }
                }
              }
              else {                      /* contiguous in window */
                from += wnext - op;
                if (op < len) {         /* some from window */
                  len -= op;
                  do {
                    output[_out++] = s_window[from++];
                  } while (--op);
                  from = _out - dist;  /* rest from output */
                  from_source = output;
                }
              }
              while (len > 2) {
                output[_out++] = from_source[from++];
                output[_out++] = from_source[from++];
                output[_out++] = from_source[from++];
                len -= 3;
              }
              if (len) {
                output[_out++] = from_source[from++];
                if (len > 1) {
                  output[_out++] = from_source[from++];
                }
              }
            }
            else {
              from = _out - dist;          /* copy direct from output */
              do {                        /* minimum length is three */
                output[_out++] = output[from++];
                output[_out++] = output[from++];
                output[_out++] = output[from++];
                len -= 3;
              } while (len > 2);
              if (len) {
                output[_out++] = output[from++];
                if (len > 1) {
                  output[_out++] = output[from++];
                }
              }
            }
          }
          else if ((op & 64) === 0) {          /* 2nd level distance code */
            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];
            continue dodist;
          }
          else {
            strm.msg = 'invalid distance code';
            state.mode = BAD;
            break top;
          }

          break; // need to emulate goto via "continue"
        }
      }
      else if ((op & 64) === 0) {              /* 2nd level length code */
        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];
        continue dolen;
      }
      else if (op & 32) {                     /* end-of-block */
        //Tracevv((stderr, "inflate:         end of block\n"));
        state.mode = TYPE;
        break top;
      }
      else {
        strm.msg = 'invalid literal/length code';
        state.mode = BAD;
        break top;
      }

      break; // need to emulate goto via "continue"
    }
  } while (_in < last && _out < end);

  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */
  len = bits >> 3;
  _in -= len;
  bits -= len << 3;
  hold &= (1 << bits) - 1;

  /* update state and return */
  strm.next_in = _in;
  strm.next_out = _out;
  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));
  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));
  state.hold = hold;
  state.bits = bits;
  return;
};


/***/ }),

/***/ "./node_modules/pako/lib/zlib/inflate.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/inflate.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils         = __webpack_require__(/*! ../utils/common */ "./node_modules/pako/lib/utils/common.js");
var adler32       = __webpack_require__(/*! ./adler32 */ "./node_modules/pako/lib/zlib/adler32.js");
var crc32         = __webpack_require__(/*! ./crc32 */ "./node_modules/pako/lib/zlib/crc32.js");
var inflate_fast  = __webpack_require__(/*! ./inffast */ "./node_modules/pako/lib/zlib/inffast.js");
var inflate_table = __webpack_require__(/*! ./inftrees */ "./node_modules/pako/lib/zlib/inftrees.js");

var CODES = 0;
var LENS = 1;
var DISTS = 2;

/* Public constants ==========================================================*/
/* ===========================================================================*/


/* Allowed flush values; see deflate() and inflate() below for details */
//var Z_NO_FLUSH      = 0;
//var Z_PARTIAL_FLUSH = 1;
//var Z_SYNC_FLUSH    = 2;
//var Z_FULL_FLUSH    = 3;
var Z_FINISH        = 4;
var Z_BLOCK         = 5;
var Z_TREES         = 6;


/* Return codes for the compression/decompression functions. Negative values
 * are errors, positive values are used for special but normal events.
 */
var Z_OK            = 0;
var Z_STREAM_END    = 1;
var Z_NEED_DICT     = 2;
//var Z_ERRNO         = -1;
var Z_STREAM_ERROR  = -2;
var Z_DATA_ERROR    = -3;
var Z_MEM_ERROR     = -4;
var Z_BUF_ERROR     = -5;
//var Z_VERSION_ERROR = -6;

/* The deflate compression method */
var Z_DEFLATED  = 8;


/* STATES ====================================================================*/
/* ===========================================================================*/


var    HEAD = 1;       /* i: waiting for magic header */
var    FLAGS = 2;      /* i: waiting for method and flags (gzip) */
var    TIME = 3;       /* i: waiting for modification time (gzip) */
var    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */
var    EXLEN = 5;      /* i: waiting for extra length (gzip) */
var    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */
var    NAME = 7;       /* i: waiting for end of file name (gzip) */
var    COMMENT = 8;    /* i: waiting for end of comment (gzip) */
var    HCRC = 9;       /* i: waiting for header crc (gzip) */
var    DICTID = 10;    /* i: waiting for dictionary check value */
var    DICT = 11;      /* waiting for inflateSetDictionary() call */
var        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */
var        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */
var        STORED = 14;    /* i: waiting for stored size (length and complement) */
var        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */
var        COPY = 16;      /* i/o: waiting for input or output to copy stored block */
var        TABLE = 17;     /* i: waiting for dynamic block table lengths */
var        LENLENS = 18;   /* i: waiting for code length code lengths */
var        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */
var            LEN_ = 20;      /* i: same as LEN below, but only first time in */
var            LEN = 21;       /* i: waiting for length/lit/eob code */
var            LENEXT = 22;    /* i: waiting for length extra bits */
var            DIST = 23;      /* i: waiting for distance code */
var            DISTEXT = 24;   /* i: waiting for distance extra bits */
var            MATCH = 25;     /* o: waiting for output space to copy string */
var            LIT = 26;       /* o: waiting for output space to write literal */
var    CHECK = 27;     /* i: waiting for 32-bit check value */
var    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */
var    DONE = 29;      /* finished check, done -- remain here until reset */
var    BAD = 30;       /* got a data error -- remain here until reset */
var    MEM = 31;       /* got an inflate() memory error -- remain here until reset */
var    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */

/* ===========================================================================*/



var ENOUGH_LENS = 852;
var ENOUGH_DISTS = 592;
//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);

var MAX_WBITS = 15;
/* 32K LZ77 window */
var DEF_WBITS = MAX_WBITS;


function zswap32(q) {
  return  (((q >>> 24) & 0xff) +
          ((q >>> 8) & 0xff00) +
          ((q & 0xff00) << 8) +
          ((q & 0xff) << 24));
}


function InflateState() {
  this.mode = 0;             /* current inflate mode */
  this.last = false;          /* true if processing last block */
  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */
  this.havedict = false;      /* true if dictionary provided */
  this.flags = 0;             /* gzip header method and flags (0 if zlib) */
  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */
  this.check = 0;             /* protected copy of check value */
  this.total = 0;             /* protected copy of output count */
  // TODO: may be {}
  this.head = null;           /* where to save gzip header information */

  /* sliding window */
  this.wbits = 0;             /* log base 2 of requested window size */
  this.wsize = 0;             /* window size or zero if not using window */
  this.whave = 0;             /* valid bytes in the window */
  this.wnext = 0;             /* window write index */
  this.window = null;         /* allocated sliding window, if needed */

  /* bit accumulator */
  this.hold = 0;              /* input bit accumulator */
  this.bits = 0;              /* number of bits in "in" */

  /* for string and stored block copying */
  this.length = 0;            /* literal or length of data to copy */
  this.offset = 0;            /* distance back to copy string from */

  /* for table and code decoding */
  this.extra = 0;             /* extra bits needed */

  /* fixed and dynamic code tables */
  this.lencode = null;          /* starting table for length/literal codes */
  this.distcode = null;         /* starting table for distance codes */
  this.lenbits = 0;           /* index bits for lencode */
  this.distbits = 0;          /* index bits for distcode */

  /* dynamic table building */
  this.ncode = 0;             /* number of code length code lengths */
  this.nlen = 0;              /* number of length code lengths */
  this.ndist = 0;             /* number of distance code lengths */
  this.have = 0;              /* number of code lengths in lens[] */
  this.next = null;              /* next available space in codes[] */

  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */
  this.work = new utils.Buf16(288); /* work area for code table building */

  /*
   because we don't have pointers in js, we use lencode and distcode directly
   as buffers so we don't need codes
  */
  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */
  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */
  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */
  this.sane = 0;                   /* if false, allow invalid distance too far */
  this.back = 0;                   /* bits back of last unprocessed length/lit */
  this.was = 0;                    /* initial length of match */
}

function inflateResetKeep(strm) {
  var state;

  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  strm.total_in = strm.total_out = state.total = 0;
  strm.msg = ''; /*Z_NULL*/
  if (state.wrap) {       /* to support ill-conceived Java test suite */
    strm.adler = state.wrap & 1;
  }
  state.mode = HEAD;
  state.last = 0;
  state.havedict = 0;
  state.dmax = 32768;
  state.head = null/*Z_NULL*/;
  state.hold = 0;
  state.bits = 0;
  //state.lencode = state.distcode = state.next = state.codes;
  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);
  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);

  state.sane = 1;
  state.back = -1;
  //Tracev((stderr, "inflate: reset\n"));
  return Z_OK;
}

function inflateReset(strm) {
  var state;

  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  state.wsize = 0;
  state.whave = 0;
  state.wnext = 0;
  return inflateResetKeep(strm);

}

function inflateReset2(strm, windowBits) {
  var wrap;
  var state;

  /* get the state */
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;

  /* extract wrap request from windowBits parameter */
  if (windowBits < 0) {
    wrap = 0;
    windowBits = -windowBits;
  }
  else {
    wrap = (windowBits >> 4) + 1;
    if (windowBits < 48) {
      windowBits &= 15;
    }
  }

  /* set number of window bits, free window if different */
  if (windowBits && (windowBits < 8 || windowBits > 15)) {
    return Z_STREAM_ERROR;
  }
  if (state.window !== null && state.wbits !== windowBits) {
    state.window = null;
  }

  /* update state and reset the rest of it */
  state.wrap = wrap;
  state.wbits = windowBits;
  return inflateReset(strm);
}

function inflateInit2(strm, windowBits) {
  var ret;
  var state;

  if (!strm) { return Z_STREAM_ERROR; }
  //strm.msg = Z_NULL;                 /* in case we return an error */

  state = new InflateState();

  //if (state === Z_NULL) return Z_MEM_ERROR;
  //Tracev((stderr, "inflate: allocated\n"));
  strm.state = state;
  state.window = null/*Z_NULL*/;
  ret = inflateReset2(strm, windowBits);
  if (ret !== Z_OK) {
    strm.state = null/*Z_NULL*/;
  }
  return ret;
}

function inflateInit(strm) {
  return inflateInit2(strm, DEF_WBITS);
}


/*
 Return state with length and distance decoding tables and index sizes set to
 fixed code decoding.  Normally this returns fixed tables from inffixed.h.
 If BUILDFIXED is defined, then instead this routine builds the tables the
 first time it's called, and returns those tables the first time and
 thereafter.  This reduces the size of the code by about 2K bytes, in
 exchange for a little execution time.  However, BUILDFIXED should not be
 used for threaded applications, since the rewriting of the tables and virgin
 may not be thread-safe.
 */
var virgin = true;

var lenfix, distfix; // We have no pointers in JS, so keep tables separate

function fixedtables(state) {
  /* build fixed huffman tables if first call (may not be thread safe) */
  if (virgin) {
    var sym;

    lenfix = new utils.Buf32(512);
    distfix = new utils.Buf32(32);

    /* literal/length table */
    sym = 0;
    while (sym < 144) { state.lens[sym++] = 8; }
    while (sym < 256) { state.lens[sym++] = 9; }
    while (sym < 280) { state.lens[sym++] = 7; }
    while (sym < 288) { state.lens[sym++] = 8; }

    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });

    /* distance table */
    sym = 0;
    while (sym < 32) { state.lens[sym++] = 5; }

    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });

    /* do this just once */
    virgin = false;
  }

  state.lencode = lenfix;
  state.lenbits = 9;
  state.distcode = distfix;
  state.distbits = 5;
}


/*
 Update the window with the last wsize (normally 32K) bytes written before
 returning.  If window does not exist yet, create it.  This is only called
 when a window is already in use, or when output has been written during this
 inflate call, but the end of the deflate stream has not been reached yet.
 It is also called to create a window for dictionary data when a dictionary
 is loaded.

 Providing output buffers larger than 32K to inflate() should provide a speed
 advantage, since only the last 32K of output is copied to the sliding window
 upon return from inflate(), and since all distances after the first 32K of
 output will fall in the output data, making match copies simpler and faster.
 The advantage may be dependent on the size of the processor's data caches.
 */
function updatewindow(strm, src, end, copy) {
  var dist;
  var state = strm.state;

  /* if it hasn't been done already, allocate space for the window */
  if (state.window === null) {
    state.wsize = 1 << state.wbits;
    state.wnext = 0;
    state.whave = 0;

    state.window = new utils.Buf8(state.wsize);
  }

  /* copy state->wsize or less output bytes into the circular window */
  if (copy >= state.wsize) {
    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);
    state.wnext = 0;
    state.whave = state.wsize;
  }
  else {
    dist = state.wsize - state.wnext;
    if (dist > copy) {
      dist = copy;
    }
    //zmemcpy(state->window + state->wnext, end - copy, dist);
    utils.arraySet(state.window, src, end - copy, dist, state.wnext);
    copy -= dist;
    if (copy) {
      //zmemcpy(state->window, end - copy, copy);
      utils.arraySet(state.window, src, end - copy, copy, 0);
      state.wnext = copy;
      state.whave = state.wsize;
    }
    else {
      state.wnext += dist;
      if (state.wnext === state.wsize) { state.wnext = 0; }
      if (state.whave < state.wsize) { state.whave += dist; }
    }
  }
  return 0;
}

function inflate(strm, flush) {
  var state;
  var input, output;          // input/output buffers
  var next;                   /* next input INDEX */
  var put;                    /* next output INDEX */
  var have, left;             /* available input and output */
  var hold;                   /* bit buffer */
  var bits;                   /* bits in bit buffer */
  var _in, _out;              /* save starting available input and output */
  var copy;                   /* number of stored or match bytes to copy */
  var from;                   /* where to copy match bytes from */
  var from_source;
  var here = 0;               /* current decoding table entry */
  var here_bits, here_op, here_val; // paked "here" denormalized (JS specific)
  //var last;                   /* parent table entry */
  var last_bits, last_op, last_val; // paked "last" denormalized (JS specific)
  var len;                    /* length to copy for repeats, bits to drop */
  var ret;                    /* return code */
  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */
  var opts;

  var n; // temporary var for NEED_BITS

  var order = /* permutation of code lengths */
    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];


  if (!strm || !strm.state || !strm.output ||
      (!strm.input && strm.avail_in !== 0)) {
    return Z_STREAM_ERROR;
  }

  state = strm.state;
  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */


  //--- LOAD() ---
  put = strm.next_out;
  output = strm.output;
  left = strm.avail_out;
  next = strm.next_in;
  input = strm.input;
  have = strm.avail_in;
  hold = state.hold;
  bits = state.bits;
  //---

  _in = have;
  _out = left;
  ret = Z_OK;

  inf_leave: // goto emulation
  for (;;) {
    switch (state.mode) {
      case HEAD:
        if (state.wrap === 0) {
          state.mode = TYPEDO;
          break;
        }
        //=== NEEDBITS(16);
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */
          state.check = 0/*crc32(0L, Z_NULL, 0)*/;
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//

          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          state.mode = FLAGS;
          break;
        }
        state.flags = 0;           /* expect zlib header */
        if (state.head) {
          state.head.done = false;
        }
        if (!(state.wrap & 1) ||   /* check if zlib header allowed */
          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {
          strm.msg = 'incorrect header check';
          state.mode = BAD;
          break;
        }
        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {
          strm.msg = 'unknown compression method';
          state.mode = BAD;
          break;
        }
        //--- DROPBITS(4) ---//
        hold >>>= 4;
        bits -= 4;
        //---//
        len = (hold & 0x0f)/*BITS(4)*/ + 8;
        if (state.wbits === 0) {
          state.wbits = len;
        }
        else if (len > state.wbits) {
          strm.msg = 'invalid window size';
          state.mode = BAD;
          break;
        }
        state.dmax = 1 << len;
        //Tracev((stderr, "inflate:   zlib header ok\n"));
        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;
        state.mode = hold & 0x200 ? DICTID : TYPE;
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        break;
      case FLAGS:
        //=== NEEDBITS(16); */
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.flags = hold;
        if ((state.flags & 0xff) !== Z_DEFLATED) {
          strm.msg = 'unknown compression method';
          state.mode = BAD;
          break;
        }
        if (state.flags & 0xe000) {
          strm.msg = 'unknown header flags set';
          state.mode = BAD;
          break;
        }
        if (state.head) {
          state.head.text = ((hold >> 8) & 1);
        }
        if (state.flags & 0x0200) {
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = TIME;
        /* falls through */
      case TIME:
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if (state.head) {
          state.head.time = hold;
        }
        if (state.flags & 0x0200) {
          //=== CRC4(state.check, hold)
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          hbuf[2] = (hold >>> 16) & 0xff;
          hbuf[3] = (hold >>> 24) & 0xff;
          state.check = crc32(state.check, hbuf, 4, 0);
          //===
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = OS;
        /* falls through */
      case OS:
        //=== NEEDBITS(16); */
        while (bits < 16) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if (state.head) {
          state.head.xflags = (hold & 0xff);
          state.head.os = (hold >> 8);
        }
        if (state.flags & 0x0200) {
          //=== CRC2(state.check, hold);
          hbuf[0] = hold & 0xff;
          hbuf[1] = (hold >>> 8) & 0xff;
          state.check = crc32(state.check, hbuf, 2, 0);
          //===//
        }
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = EXLEN;
        /* falls through */
      case EXLEN:
        if (state.flags & 0x0400) {
          //=== NEEDBITS(16); */
          while (bits < 16) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.length = hold;
          if (state.head) {
            state.head.extra_len = hold;
          }
          if (state.flags & 0x0200) {
            //=== CRC2(state.check, hold);
            hbuf[0] = hold & 0xff;
            hbuf[1] = (hold >>> 8) & 0xff;
            state.check = crc32(state.check, hbuf, 2, 0);
            //===//
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
        }
        else if (state.head) {
          state.head.extra = null/*Z_NULL*/;
        }
        state.mode = EXTRA;
        /* falls through */
      case EXTRA:
        if (state.flags & 0x0400) {
          copy = state.length;
          if (copy > have) { copy = have; }
          if (copy) {
            if (state.head) {
              len = state.head.extra_len - state.length;
              if (!state.head.extra) {
                // Use untyped array for more convenient processing later
                state.head.extra = new Array(state.head.extra_len);
              }
              utils.arraySet(
                state.head.extra,
                input,
                next,
                // extra field is limited to 65536 bytes
                // - no need for additional size check
                copy,
                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/
                len
              );
              //zmemcpy(state.head.extra + len, next,
              //        len + copy > state.head.extra_max ?
              //        state.head.extra_max - len : copy);
            }
            if (state.flags & 0x0200) {
              state.check = crc32(state.check, input, copy, next);
            }
            have -= copy;
            next += copy;
            state.length -= copy;
          }
          if (state.length) { break inf_leave; }
        }
        state.length = 0;
        state.mode = NAME;
        /* falls through */
      case NAME:
        if (state.flags & 0x0800) {
          if (have === 0) { break inf_leave; }
          copy = 0;
          do {
            // TODO: 2 or 1 bytes?
            len = input[next + copy++];
            /* use constant limit because in js we should not preallocate memory */
            if (state.head && len &&
                (state.length < 65536 /*state.head.name_max*/)) {
              state.head.name += String.fromCharCode(len);
            }
          } while (len && copy < have);

          if (state.flags & 0x0200) {
            state.check = crc32(state.check, input, copy, next);
          }
          have -= copy;
          next += copy;
          if (len) { break inf_leave; }
        }
        else if (state.head) {
          state.head.name = null;
        }
        state.length = 0;
        state.mode = COMMENT;
        /* falls through */
      case COMMENT:
        if (state.flags & 0x1000) {
          if (have === 0) { break inf_leave; }
          copy = 0;
          do {
            len = input[next + copy++];
            /* use constant limit because in js we should not preallocate memory */
            if (state.head && len &&
                (state.length < 65536 /*state.head.comm_max*/)) {
              state.head.comment += String.fromCharCode(len);
            }
          } while (len && copy < have);
          if (state.flags & 0x0200) {
            state.check = crc32(state.check, input, copy, next);
          }
          have -= copy;
          next += copy;
          if (len) { break inf_leave; }
        }
        else if (state.head) {
          state.head.comment = null;
        }
        state.mode = HCRC;
        /* falls through */
      case HCRC:
        if (state.flags & 0x0200) {
          //=== NEEDBITS(16); */
          while (bits < 16) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          if (hold !== (state.check & 0xffff)) {
            strm.msg = 'header crc mismatch';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
        }
        if (state.head) {
          state.head.hcrc = ((state.flags >> 9) & 1);
          state.head.done = true;
        }
        strm.adler = state.check = 0;
        state.mode = TYPE;
        break;
      case DICTID:
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        strm.adler = state.check = zswap32(hold);
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = DICT;
        /* falls through */
      case DICT:
        if (state.havedict === 0) {
          //--- RESTORE() ---
          strm.next_out = put;
          strm.avail_out = left;
          strm.next_in = next;
          strm.avail_in = have;
          state.hold = hold;
          state.bits = bits;
          //---
          return Z_NEED_DICT;
        }
        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;
        state.mode = TYPE;
        /* falls through */
      case TYPE:
        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case TYPEDO:
        if (state.last) {
          //--- BYTEBITS() ---//
          hold >>>= bits & 7;
          bits -= bits & 7;
          //---//
          state.mode = CHECK;
          break;
        }
        //=== NEEDBITS(3); */
        while (bits < 3) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.last = (hold & 0x01)/*BITS(1)*/;
        //--- DROPBITS(1) ---//
        hold >>>= 1;
        bits -= 1;
        //---//

        switch ((hold & 0x03)/*BITS(2)*/) {
          case 0:                             /* stored block */
            //Tracev((stderr, "inflate:     stored block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = STORED;
            break;
          case 1:                             /* fixed block */
            fixedtables(state);
            //Tracev((stderr, "inflate:     fixed codes block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = LEN_;             /* decode codes */
            if (flush === Z_TREES) {
              //--- DROPBITS(2) ---//
              hold >>>= 2;
              bits -= 2;
              //---//
              break inf_leave;
            }
            break;
          case 2:                             /* dynamic block */
            //Tracev((stderr, "inflate:     dynamic codes block%s\n",
            //        state.last ? " (last)" : ""));
            state.mode = TABLE;
            break;
          case 3:
            strm.msg = 'invalid block type';
            state.mode = BAD;
        }
        //--- DROPBITS(2) ---//
        hold >>>= 2;
        bits -= 2;
        //---//
        break;
      case STORED:
        //--- BYTEBITS() ---// /* go to byte boundary */
        hold >>>= bits & 7;
        bits -= bits & 7;
        //---//
        //=== NEEDBITS(32); */
        while (bits < 32) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {
          strm.msg = 'invalid stored block lengths';
          state.mode = BAD;
          break;
        }
        state.length = hold & 0xffff;
        //Tracev((stderr, "inflate:       stored length %u\n",
        //        state.length));
        //=== INITBITS();
        hold = 0;
        bits = 0;
        //===//
        state.mode = COPY_;
        if (flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case COPY_:
        state.mode = COPY;
        /* falls through */
      case COPY:
        copy = state.length;
        if (copy) {
          if (copy > have) { copy = have; }
          if (copy > left) { copy = left; }
          if (copy === 0) { break inf_leave; }
          //--- zmemcpy(put, next, copy); ---
          utils.arraySet(output, input, next, copy, put);
          //---//
          have -= copy;
          next += copy;
          left -= copy;
          put += copy;
          state.length -= copy;
          break;
        }
        //Tracev((stderr, "inflate:       stored end\n"));
        state.mode = TYPE;
        break;
      case TABLE:
        //=== NEEDBITS(14); */
        while (bits < 14) {
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
        }
        //===//
        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;
        //--- DROPBITS(5) ---//
        hold >>>= 5;
        bits -= 5;
        //---//
        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;
        //--- DROPBITS(5) ---//
        hold >>>= 5;
        bits -= 5;
        //---//
        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;
        //--- DROPBITS(4) ---//
        hold >>>= 4;
        bits -= 4;
        //---//
//#ifndef PKZIP_BUG_WORKAROUND
        if (state.nlen > 286 || state.ndist > 30) {
          strm.msg = 'too many length or distance symbols';
          state.mode = BAD;
          break;
        }
//#endif
        //Tracev((stderr, "inflate:       table sizes ok\n"));
        state.have = 0;
        state.mode = LENLENS;
        /* falls through */
      case LENLENS:
        while (state.have < state.ncode) {
          //=== NEEDBITS(3);
          while (bits < 3) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);
          //--- DROPBITS(3) ---//
          hold >>>= 3;
          bits -= 3;
          //---//
        }
        while (state.have < 19) {
          state.lens[order[state.have++]] = 0;
        }
        // We have separate tables & no pointers. 2 commented lines below not needed.
        //state.next = state.codes;
        //state.lencode = state.next;
        // Switch to use dynamic table
        state.lencode = state.lendyn;
        state.lenbits = 7;

        opts = { bits: state.lenbits };
        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);
        state.lenbits = opts.bits;

        if (ret) {
          strm.msg = 'invalid code lengths set';
          state.mode = BAD;
          break;
        }
        //Tracev((stderr, "inflate:       code lengths ok\n"));
        state.have = 0;
        state.mode = CODELENS;
        /* falls through */
      case CODELENS:
        while (state.have < state.nlen + state.ndist) {
          for (;;) {
            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          if (here_val < 16) {
            //--- DROPBITS(here.bits) ---//
            hold >>>= here_bits;
            bits -= here_bits;
            //---//
            state.lens[state.have++] = here_val;
          }
          else {
            if (here_val === 16) {
              //=== NEEDBITS(here.bits + 2);
              n = here_bits + 2;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              if (state.have === 0) {
                strm.msg = 'invalid bit length repeat';
                state.mode = BAD;
                break;
              }
              len = state.lens[state.have - 1];
              copy = 3 + (hold & 0x03);//BITS(2);
              //--- DROPBITS(2) ---//
              hold >>>= 2;
              bits -= 2;
              //---//
            }
            else if (here_val === 17) {
              //=== NEEDBITS(here.bits + 3);
              n = here_bits + 3;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              len = 0;
              copy = 3 + (hold & 0x07);//BITS(3);
              //--- DROPBITS(3) ---//
              hold >>>= 3;
              bits -= 3;
              //---//
            }
            else {
              //=== NEEDBITS(here.bits + 7);
              n = here_bits + 7;
              while (bits < n) {
                if (have === 0) { break inf_leave; }
                have--;
                hold += input[next++] << bits;
                bits += 8;
              }
              //===//
              //--- DROPBITS(here.bits) ---//
              hold >>>= here_bits;
              bits -= here_bits;
              //---//
              len = 0;
              copy = 11 + (hold & 0x7f);//BITS(7);
              //--- DROPBITS(7) ---//
              hold >>>= 7;
              bits -= 7;
              //---//
            }
            if (state.have + copy > state.nlen + state.ndist) {
              strm.msg = 'invalid bit length repeat';
              state.mode = BAD;
              break;
            }
            while (copy--) {
              state.lens[state.have++] = len;
            }
          }
        }

        /* handle error breaks in while */
        if (state.mode === BAD) { break; }

        /* check for end-of-block code (better have one) */
        if (state.lens[256] === 0) {
          strm.msg = 'invalid code -- missing end-of-block';
          state.mode = BAD;
          break;
        }

        /* build code tables -- note: do not change the lenbits or distbits
           values here (9 and 6) without reading the comments in inftrees.h
           concerning the ENOUGH constants, which depend on those values */
        state.lenbits = 9;

        opts = { bits: state.lenbits };
        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);
        // We have separate tables & no pointers. 2 commented lines below not needed.
        // state.next_index = opts.table_index;
        state.lenbits = opts.bits;
        // state.lencode = state.next;

        if (ret) {
          strm.msg = 'invalid literal/lengths set';
          state.mode = BAD;
          break;
        }

        state.distbits = 6;
        //state.distcode.copy(state.codes);
        // Switch to use dynamic table
        state.distcode = state.distdyn;
        opts = { bits: state.distbits };
        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);
        // We have separate tables & no pointers. 2 commented lines below not needed.
        // state.next_index = opts.table_index;
        state.distbits = opts.bits;
        // state.distcode = state.next;

        if (ret) {
          strm.msg = 'invalid distances set';
          state.mode = BAD;
          break;
        }
        //Tracev((stderr, 'inflate:       codes ok\n'));
        state.mode = LEN_;
        if (flush === Z_TREES) { break inf_leave; }
        /* falls through */
      case LEN_:
        state.mode = LEN;
        /* falls through */
      case LEN:
        if (have >= 6 && left >= 258) {
          //--- RESTORE() ---
          strm.next_out = put;
          strm.avail_out = left;
          strm.next_in = next;
          strm.avail_in = have;
          state.hold = hold;
          state.bits = bits;
          //---
          inflate_fast(strm, _out);
          //--- LOAD() ---
          put = strm.next_out;
          output = strm.output;
          left = strm.avail_out;
          next = strm.next_in;
          input = strm.input;
          have = strm.avail_in;
          hold = state.hold;
          bits = state.bits;
          //---

          if (state.mode === TYPE) {
            state.back = -1;
          }
          break;
        }
        state.back = 0;
        for (;;) {
          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/
          here_bits = here >>> 24;
          here_op = (here >>> 16) & 0xff;
          here_val = here & 0xffff;

          if (here_bits <= bits) { break; }
          //--- PULLBYTE() ---//
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
          //---//
        }
        if (here_op && (here_op & 0xf0) === 0) {
          last_bits = here_bits;
          last_op = here_op;
          last_val = here_val;
          for (;;) {
            here = state.lencode[last_val +
                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((last_bits + here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          //--- DROPBITS(last.bits) ---//
          hold >>>= last_bits;
          bits -= last_bits;
          //---//
          state.back += last_bits;
        }
        //--- DROPBITS(here.bits) ---//
        hold >>>= here_bits;
        bits -= here_bits;
        //---//
        state.back += here_bits;
        state.length = here_val;
        if (here_op === 0) {
          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?
          //        "inflate:         literal '%c'\n" :
          //        "inflate:         literal 0x%02x\n", here.val));
          state.mode = LIT;
          break;
        }
        if (here_op & 32) {
          //Tracevv((stderr, "inflate:         end of block\n"));
          state.back = -1;
          state.mode = TYPE;
          break;
        }
        if (here_op & 64) {
          strm.msg = 'invalid literal/length code';
          state.mode = BAD;
          break;
        }
        state.extra = here_op & 15;
        state.mode = LENEXT;
        /* falls through */
      case LENEXT:
        if (state.extra) {
          //=== NEEDBITS(state.extra);
          n = state.extra;
          while (bits < n) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;
          //--- DROPBITS(state.extra) ---//
          hold >>>= state.extra;
          bits -= state.extra;
          //---//
          state.back += state.extra;
        }
        //Tracevv((stderr, "inflate:         length %u\n", state.length));
        state.was = state.length;
        state.mode = DIST;
        /* falls through */
      case DIST:
        for (;;) {
          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/
          here_bits = here >>> 24;
          here_op = (here >>> 16) & 0xff;
          here_val = here & 0xffff;

          if ((here_bits) <= bits) { break; }
          //--- PULLBYTE() ---//
          if (have === 0) { break inf_leave; }
          have--;
          hold += input[next++] << bits;
          bits += 8;
          //---//
        }
        if ((here_op & 0xf0) === 0) {
          last_bits = here_bits;
          last_op = here_op;
          last_val = here_val;
          for (;;) {
            here = state.distcode[last_val +
                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];
            here_bits = here >>> 24;
            here_op = (here >>> 16) & 0xff;
            here_val = here & 0xffff;

            if ((last_bits + here_bits) <= bits) { break; }
            //--- PULLBYTE() ---//
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
            //---//
          }
          //--- DROPBITS(last.bits) ---//
          hold >>>= last_bits;
          bits -= last_bits;
          //---//
          state.back += last_bits;
        }
        //--- DROPBITS(here.bits) ---//
        hold >>>= here_bits;
        bits -= here_bits;
        //---//
        state.back += here_bits;
        if (here_op & 64) {
          strm.msg = 'invalid distance code';
          state.mode = BAD;
          break;
        }
        state.offset = here_val;
        state.extra = (here_op) & 15;
        state.mode = DISTEXT;
        /* falls through */
      case DISTEXT:
        if (state.extra) {
          //=== NEEDBITS(state.extra);
          n = state.extra;
          while (bits < n) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;
          //--- DROPBITS(state.extra) ---//
          hold >>>= state.extra;
          bits -= state.extra;
          //---//
          state.back += state.extra;
        }
//#ifdef INFLATE_STRICT
        if (state.offset > state.dmax) {
          strm.msg = 'invalid distance too far back';
          state.mode = BAD;
          break;
        }
//#endif
        //Tracevv((stderr, "inflate:         distance %u\n", state.offset));
        state.mode = MATCH;
        /* falls through */
      case MATCH:
        if (left === 0) { break inf_leave; }
        copy = _out - left;
        if (state.offset > copy) {         /* copy from window */
          copy = state.offset - copy;
          if (copy > state.whave) {
            if (state.sane) {
              strm.msg = 'invalid distance too far back';
              state.mode = BAD;
              break;
            }
// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility
//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR
//          Trace((stderr, "inflate.c too far\n"));
//          copy -= state.whave;
//          if (copy > state.length) { copy = state.length; }
//          if (copy > left) { copy = left; }
//          left -= copy;
//          state.length -= copy;
//          do {
//            output[put++] = 0;
//          } while (--copy);
//          if (state.length === 0) { state.mode = LEN; }
//          break;
//#endif
          }
          if (copy > state.wnext) {
            copy -= state.wnext;
            from = state.wsize - copy;
          }
          else {
            from = state.wnext - copy;
          }
          if (copy > state.length) { copy = state.length; }
          from_source = state.window;
        }
        else {                              /* copy from output */
          from_source = output;
          from = put - state.offset;
          copy = state.length;
        }
        if (copy > left) { copy = left; }
        left -= copy;
        state.length -= copy;
        do {
          output[put++] = from_source[from++];
        } while (--copy);
        if (state.length === 0) { state.mode = LEN; }
        break;
      case LIT:
        if (left === 0) { break inf_leave; }
        output[put++] = state.length;
        left--;
        state.mode = LEN;
        break;
      case CHECK:
        if (state.wrap) {
          //=== NEEDBITS(32);
          while (bits < 32) {
            if (have === 0) { break inf_leave; }
            have--;
            // Use '|' instead of '+' to make sure that result is signed
            hold |= input[next++] << bits;
            bits += 8;
          }
          //===//
          _out -= left;
          strm.total_out += _out;
          state.total += _out;
          if (_out) {
            strm.adler = state.check =
                /*UPDATE(state.check, put - _out, _out);*/
                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));

          }
          _out = left;
          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too
          if ((state.flags ? hold : zswap32(hold)) !== state.check) {
            strm.msg = 'incorrect data check';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          //Tracev((stderr, "inflate:   check matches trailer\n"));
        }
        state.mode = LENGTH;
        /* falls through */
      case LENGTH:
        if (state.wrap && state.flags) {
          //=== NEEDBITS(32);
          while (bits < 32) {
            if (have === 0) { break inf_leave; }
            have--;
            hold += input[next++] << bits;
            bits += 8;
          }
          //===//
          if (hold !== (state.total & 0xffffffff)) {
            strm.msg = 'incorrect length check';
            state.mode = BAD;
            break;
          }
          //=== INITBITS();
          hold = 0;
          bits = 0;
          //===//
          //Tracev((stderr, "inflate:   length matches trailer\n"));
        }
        state.mode = DONE;
        /* falls through */
      case DONE:
        ret = Z_STREAM_END;
        break inf_leave;
      case BAD:
        ret = Z_DATA_ERROR;
        break inf_leave;
      case MEM:
        return Z_MEM_ERROR;
      case SYNC:
        /* falls through */
      default:
        return Z_STREAM_ERROR;
    }
  }

  // inf_leave <- here is real place for "goto inf_leave", emulated via "break inf_leave"

  /*
     Return from inflate(), updating the total counts and the check value.
     If there was no progress during the inflate() call, return a buffer
     error.  Call updatewindow() to create and/or update the window state.
     Note: a memory error from inflate() is non-recoverable.
   */

  //--- RESTORE() ---
  strm.next_out = put;
  strm.avail_out = left;
  strm.next_in = next;
  strm.avail_in = have;
  state.hold = hold;
  state.bits = bits;
  //---

  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&
                      (state.mode < CHECK || flush !== Z_FINISH))) {
    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {
      state.mode = MEM;
      return Z_MEM_ERROR;
    }
  }
  _in -= strm.avail_in;
  _out -= strm.avail_out;
  strm.total_in += _in;
  strm.total_out += _out;
  state.total += _out;
  if (state.wrap && _out) {
    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/
      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));
  }
  strm.data_type = state.bits + (state.last ? 64 : 0) +
                    (state.mode === TYPE ? 128 : 0) +
                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);
  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {
    ret = Z_BUF_ERROR;
  }
  return ret;
}

function inflateEnd(strm) {

  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {
    return Z_STREAM_ERROR;
  }

  var state = strm.state;
  if (state.window) {
    state.window = null;
  }
  strm.state = null;
  return Z_OK;
}

function inflateGetHeader(strm, head) {
  var state;

  /* check state */
  if (!strm || !strm.state) { return Z_STREAM_ERROR; }
  state = strm.state;
  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }

  /* save header structure */
  state.head = head;
  head.done = false;
  return Z_OK;
}

function inflateSetDictionary(strm, dictionary) {
  var dictLength = dictionary.length;

  var state;
  var dictid;
  var ret;

  /* check state */
  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }
  state = strm.state;

  if (state.wrap !== 0 && state.mode !== DICT) {
    return Z_STREAM_ERROR;
  }

  /* check for correct dictionary identifier */
  if (state.mode === DICT) {
    dictid = 1; /* adler32(0, null, 0)*/
    /* dictid = adler32(dictid, dictionary, dictLength); */
    dictid = adler32(dictid, dictionary, dictLength, 0);
    if (dictid !== state.check) {
      return Z_DATA_ERROR;
    }
  }
  /* copy dictionary to window using updatewindow(), which will amend the
   existing dictionary if appropriate */
  ret = updatewindow(strm, dictionary, dictLength, dictLength);
  if (ret) {
    state.mode = MEM;
    return Z_MEM_ERROR;
  }
  state.havedict = 1;
  // Tracev((stderr, "inflate:   dictionary set\n"));
  return Z_OK;
}

exports.inflateReset = inflateReset;
exports.inflateReset2 = inflateReset2;
exports.inflateResetKeep = inflateResetKeep;
exports.inflateInit = inflateInit;
exports.inflateInit2 = inflateInit2;
exports.inflate = inflate;
exports.inflateEnd = inflateEnd;
exports.inflateGetHeader = inflateGetHeader;
exports.inflateSetDictionary = inflateSetDictionary;
exports.inflateInfo = 'pako inflate (from Nodeca project)';

/* Not implemented
exports.inflateCopy = inflateCopy;
exports.inflateGetDictionary = inflateGetDictionary;
exports.inflateMark = inflateMark;
exports.inflatePrime = inflatePrime;
exports.inflateSync = inflateSync;
exports.inflateSyncPoint = inflateSyncPoint;
exports.inflateUndermine = inflateUndermine;
*/


/***/ }),

/***/ "./node_modules/pako/lib/zlib/inftrees.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/inftrees.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

var utils = __webpack_require__(/*! ../utils/common */ "./node_modules/pako/lib/utils/common.js");

var MAXBITS = 15;
var ENOUGH_LENS = 852;
var ENOUGH_DISTS = 592;
//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);

var CODES = 0;
var LENS = 1;
var DISTS = 2;

var lbase = [ /* Length codes 257..285 base */
  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,
  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0
];

var lext = [ /* Length codes 257..285 extra */
  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,
  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78
];

var dbase = [ /* Distance codes 0..29 base */
  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,
  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,
  8193, 12289, 16385, 24577, 0, 0
];

var dext = [ /* Distance codes 0..29 extra */
  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,
  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,
  28, 28, 29, 29, 64, 64
];

module.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)
{
  var bits = opts.bits;
      //here = opts.here; /* table entry for duplication */

  var len = 0;               /* a code's length in bits */
  var sym = 0;               /* index of code symbols */
  var min = 0, max = 0;          /* minimum and maximum code lengths */
  var root = 0;              /* number of index bits for root table */
  var curr = 0;              /* number of index bits for current table */
  var drop = 0;              /* code bits to drop for sub-table */
  var left = 0;                   /* number of prefix codes available */
  var used = 0;              /* code entries in table used */
  var huff = 0;              /* Huffman code */
  var incr;              /* for incrementing code, index */
  var fill;              /* index for replicating entries */
  var low;               /* low bits for current root entry */
  var mask;              /* mask for low root bits */
  var next;             /* next available space in table */
  var base = null;     /* base value table to use */
  var base_index = 0;
//  var shoextra;    /* extra bits table to use */
  var end;                    /* use base and extra for symbol > end */
  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */
  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */
  var extra = null;
  var extra_index = 0;

  var here_bits, here_op, here_val;

  /*
   Process a set of code lengths to create a canonical Huffman code.  The
   code lengths are lens[0..codes-1].  Each length corresponds to the
   symbols 0..codes-1.  The Huffman code is generated by first sorting the
   symbols by length from short to long, and retaining the symbol order
   for codes with equal lengths.  Then the code starts with all zero bits
   for the first code of the shortest length, and the codes are integer
   increments for the same length, and zeros are appended as the length
   increases.  For the deflate format, these bits are stored backwards
   from their more natural integer increment ordering, and so when the
   decoding tables are built in the large loop below, the integer codes
   are incremented backwards.

   This routine assumes, but does not check, that all of the entries in
   lens[] are in the range 0..MAXBITS.  The caller must assure this.
   1..MAXBITS is interpreted as that code length.  zero means that that
   symbol does not occur in this code.

   The codes are sorted by computing a count of codes for each length,
   creating from that a table of starting indices for each length in the
   sorted table, and then entering the symbols in order in the sorted
   table.  The sorted table is work[], with that space being provided by
   the caller.

   The length counts are used for other purposes as well, i.e. finding
   the minimum and maximum length codes, determining if there are any
   codes at all, checking for a valid set of lengths, and looking ahead
   at length counts to determine sub-table sizes when building the
   decoding tables.
   */

  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */
  for (len = 0; len <= MAXBITS; len++) {
    count[len] = 0;
  }
  for (sym = 0; sym < codes; sym++) {
    count[lens[lens_index + sym]]++;
  }

  /* bound code lengths, force root to be within code lengths */
  root = bits;
  for (max = MAXBITS; max >= 1; max--) {
    if (count[max] !== 0) { break; }
  }
  if (root > max) {
    root = max;
  }
  if (max === 0) {                     /* no symbols to code at all */
    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */
    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;
    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;
    table[table_index++] = (1 << 24) | (64 << 16) | 0;


    //table.op[opts.table_index] = 64;
    //table.bits[opts.table_index] = 1;
    //table.val[opts.table_index++] = 0;
    table[table_index++] = (1 << 24) | (64 << 16) | 0;

    opts.bits = 1;
    return 0;     /* no symbols, but wait for decoding to report error */
  }
  for (min = 1; min < max; min++) {
    if (count[min] !== 0) { break; }
  }
  if (root < min) {
    root = min;
  }

  /* check for an over-subscribed or incomplete set of lengths */
  left = 1;
  for (len = 1; len <= MAXBITS; len++) {
    left <<= 1;
    left -= count[len];
    if (left < 0) {
      return -1;
    }        /* over-subscribed */
  }
  if (left > 0 && (type === CODES || max !== 1)) {
    return -1;                      /* incomplete set */
  }

  /* generate offsets into symbol table for each length for sorting */
  offs[1] = 0;
  for (len = 1; len < MAXBITS; len++) {
    offs[len + 1] = offs[len] + count[len];
  }

  /* sort symbols by length, by symbol order within each length */
  for (sym = 0; sym < codes; sym++) {
    if (lens[lens_index + sym] !== 0) {
      work[offs[lens[lens_index + sym]]++] = sym;
    }
  }

  /*
   Create and fill in decoding tables.  In this loop, the table being
   filled is at next and has curr index bits.  The code being used is huff
   with length len.  That code is converted to an index by dropping drop
   bits off of the bottom.  For codes where len is less than drop + curr,
   those top drop + curr - len bits are incremented through all values to
   fill the table with replicated entries.

   root is the number of index bits for the root table.  When len exceeds
   root, sub-tables are created pointed to by the root entry with an index
   of the low root bits of huff.  This is saved in low to check for when a
   new sub-table should be started.  drop is zero when the root table is
   being filled, and drop is root when sub-tables are being filled.

   When a new sub-table is needed, it is necessary to look ahead in the
   code lengths to determine what size sub-table is needed.  The length
   counts are used for this, and so count[] is decremented as codes are
   entered in the tables.

   used keeps track of how many table entries have been allocated from the
   provided *table space.  It is checked for LENS and DIST tables against
   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in
   the initial root table size constants.  See the comments in inftrees.h
   for more information.

   sym increments through all symbols, and the loop terminates when
   all codes of length max, i.e. all codes, have been processed.  This
   routine permits incomplete codes, so another loop after this one fills
   in the rest of the decoding tables with invalid code markers.
   */

  /* set up for code type */
  // poor man optimization - use if-else instead of switch,
  // to avoid deopts in old v8
  if (type === CODES) {
    base = extra = work;    /* dummy value--not used */
    end = 19;

  } else if (type === LENS) {
    base = lbase;
    base_index -= 257;
    extra = lext;
    extra_index -= 257;
    end = 256;

  } else {                    /* DISTS */
    base = dbase;
    extra = dext;
    end = -1;
  }

  /* initialize opts for loop */
  huff = 0;                   /* starting code */
  sym = 0;                    /* starting code symbol */
  len = min;                  /* starting code length */
  next = table_index;              /* current table to fill in */
  curr = root;                /* current table index bits */
  drop = 0;                   /* current bits to drop from code for index */
  low = -1;                   /* trigger new sub-table when len > root */
  used = 1 << root;          /* use root table entries */
  mask = used - 1;            /* mask for comparing low */

  /* check available table space */
  if ((type === LENS && used > ENOUGH_LENS) ||
    (type === DISTS && used > ENOUGH_DISTS)) {
    return 1;
  }

  /* process all codes and make table entries */
  for (;;) {
    /* create table entry */
    here_bits = len - drop;
    if (work[sym] < end) {
      here_op = 0;
      here_val = work[sym];
    }
    else if (work[sym] > end) {
      here_op = extra[extra_index + work[sym]];
      here_val = base[base_index + work[sym]];
    }
    else {
      here_op = 32 + 64;         /* end of block */
      here_val = 0;
    }

    /* replicate for those indices with low len bits equal to huff */
    incr = 1 << (len - drop);
    fill = 1 << curr;
    min = fill;                 /* save offset to next table */
    do {
      fill -= incr;
      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;
    } while (fill !== 0);

    /* backwards increment the len-bit code huff */
    incr = 1 << (len - 1);
    while (huff & incr) {
      incr >>= 1;
    }
    if (incr !== 0) {
      huff &= incr - 1;
      huff += incr;
    } else {
      huff = 0;
    }

    /* go to next symbol, update count, len */
    sym++;
    if (--count[len] === 0) {
      if (len === max) { break; }
      len = lens[lens_index + work[sym]];
    }

    /* create new sub-table if needed */
    if (len > root && (huff & mask) !== low) {
      /* if first time, transition to sub-tables */
      if (drop === 0) {
        drop = root;
      }

      /* increment past last table */
      next += min;            /* here min is 1 << curr */

      /* determine length of next table */
      curr = len - drop;
      left = 1 << curr;
      while (curr + drop < max) {
        left -= count[curr + drop];
        if (left <= 0) { break; }
        curr++;
        left <<= 1;
      }

      /* check for enough space */
      used += 1 << curr;
      if ((type === LENS && used > ENOUGH_LENS) ||
        (type === DISTS && used > ENOUGH_DISTS)) {
        return 1;
      }

      /* point entry in root table to sub-table */
      low = huff & mask;
      /*table.op[low] = curr;
      table.bits[low] = root;
      table.val[low] = next - opts.table_index;*/
      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;
    }
  }

  /* fill in remaining table entry if code is incomplete (guaranteed to have
   at most one remaining entry, since if the code is incomplete, the
   maximum code length that was allowed to get this far is one bit) */
  if (huff !== 0) {
    //table.op[next + huff] = 64;            /* invalid code marker */
    //table.bits[next + huff] = len - drop;
    //table.val[next + huff] = 0;
    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;
  }

  /* set return parameters */
  //opts.table_index += used;
  opts.bits = root;
  return 0;
};


/***/ }),

/***/ "./node_modules/pako/lib/zlib/messages.js":
/*!************************************************!*\
  !*** ./node_modules/pako/lib/zlib/messages.js ***!
  \************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

module.exports = {
  2:      'need dictionary',     /* Z_NEED_DICT       2  */
  1:      'stream end',          /* Z_STREAM_END      1  */
  0:      '',                    /* Z_OK              0  */
  '-1':   'file error',          /* Z_ERRNO         (-1) */
  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */
  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */
  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */
  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */
  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */
};


/***/ }),

/***/ "./node_modules/pako/lib/zlib/trees.js":
/*!*********************************************!*\
  !*** ./node_modules/pako/lib/zlib/trees.js ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

/* eslint-disable space-unary-ops */

var utils = __webpack_require__(/*! ../utils/common */ "./node_modules/pako/lib/utils/common.js");

/* Public constants ==========================================================*/
/* ===========================================================================*/


//var Z_FILTERED          = 1;
//var Z_HUFFMAN_ONLY      = 2;
//var Z_RLE               = 3;
var Z_FIXED               = 4;
//var Z_DEFAULT_STRATEGY  = 0;

/* Possible values of the data_type field (though see inflate()) */
var Z_BINARY              = 0;
var Z_TEXT                = 1;
//var Z_ASCII             = 1; // = Z_TEXT
var Z_UNKNOWN             = 2;

/*============================================================================*/


function zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }

// From zutil.h

var STORED_BLOCK = 0;
var STATIC_TREES = 1;
var DYN_TREES    = 2;
/* The three kinds of block type */

var MIN_MATCH    = 3;
var MAX_MATCH    = 258;
/* The minimum and maximum match lengths */

// From deflate.h
/* ===========================================================================
 * Internal compression state.
 */

var LENGTH_CODES  = 29;
/* number of length codes, not counting the special END_BLOCK code */

var LITERALS      = 256;
/* number of literal bytes 0..255 */

var L_CODES       = LITERALS + 1 + LENGTH_CODES;
/* number of Literal or Length codes, including the END_BLOCK code */

var D_CODES       = 30;
/* number of distance codes */

var BL_CODES      = 19;
/* number of codes used to transfer the bit lengths */

var HEAP_SIZE     = 2 * L_CODES + 1;
/* maximum heap size */

var MAX_BITS      = 15;
/* All codes must not exceed MAX_BITS bits */

var Buf_size      = 16;
/* size of bit buffer in bi_buf */


/* ===========================================================================
 * Constants
 */

var MAX_BL_BITS = 7;
/* Bit length codes must not exceed MAX_BL_BITS bits */

var END_BLOCK   = 256;
/* end of block literal code */

var REP_3_6     = 16;
/* repeat previous bit length 3-6 times (2 bits of repeat count) */

var REPZ_3_10   = 17;
/* repeat a zero length 3-10 times  (3 bits of repeat count) */

var REPZ_11_138 = 18;
/* repeat a zero length 11-138 times  (7 bits of repeat count) */

/* eslint-disable comma-spacing,array-bracket-spacing */
var extra_lbits =   /* extra bits for each length code */
  [0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0];

var extra_dbits =   /* extra bits for each distance code */
  [0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13];

var extra_blbits =  /* extra bits for each bit length code */
  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7];

var bl_order =
  [16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15];
/* eslint-enable comma-spacing,array-bracket-spacing */

/* The lengths of the bit length codes are sent in order of decreasing
 * probability, to avoid transmitting the lengths for unused bit length codes.
 */

/* ===========================================================================
 * Local data. These are initialized only once.
 */

// We pre-fill arrays with 0 to avoid uninitialized gaps

var DIST_CODE_LEN = 512; /* see definition of array dist_code below */

// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1
var static_ltree  = new Array((L_CODES + 2) * 2);
zero(static_ltree);
/* The static literal tree. Since the bit lengths are imposed, there is no
 * need for the L_CODES extra codes used during heap construction. However
 * The codes 286 and 287 are needed to build a canonical tree (see _tr_init
 * below).
 */

var static_dtree  = new Array(D_CODES * 2);
zero(static_dtree);
/* The static distance tree. (Actually a trivial tree since all codes use
 * 5 bits.)
 */

var _dist_code    = new Array(DIST_CODE_LEN);
zero(_dist_code);
/* Distance codes. The first 256 values correspond to the distances
 * 3 .. 258, the last 256 values correspond to the top 8 bits of
 * the 15 bit distances.
 */

var _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);
zero(_length_code);
/* length code for each normalized match length (0 == MIN_MATCH) */

var base_length   = new Array(LENGTH_CODES);
zero(base_length);
/* First normalized length for each code (0 = MIN_MATCH) */

var base_dist     = new Array(D_CODES);
zero(base_dist);
/* First normalized distance for each code (0 = distance of 1) */


function StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {

  this.static_tree  = static_tree;  /* static tree or NULL */
  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */
  this.extra_base   = extra_base;   /* base index for extra_bits */
  this.elems        = elems;        /* max number of elements in the tree */
  this.max_length   = max_length;   /* max bit length for the codes */

  // show if `static_tree` has data or dummy - needed for monomorphic objects
  this.has_stree    = static_tree && static_tree.length;
}


var static_l_desc;
var static_d_desc;
var static_bl_desc;


function TreeDesc(dyn_tree, stat_desc) {
  this.dyn_tree = dyn_tree;     /* the dynamic tree */
  this.max_code = 0;            /* largest code with non zero frequency */
  this.stat_desc = stat_desc;   /* the corresponding static tree */
}



function d_code(dist) {
  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];
}


/* ===========================================================================
 * Output a short LSB first on the stream.
 * IN assertion: there is enough room in pendingBuf.
 */
function put_short(s, w) {
//    put_byte(s, (uch)((w) & 0xff));
//    put_byte(s, (uch)((ush)(w) >> 8));
  s.pending_buf[s.pending++] = (w) & 0xff;
  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;
}


/* ===========================================================================
 * Send a value on a given number of bits.
 * IN assertion: length <= 16 and value fits in length bits.
 */
function send_bits(s, value, length) {
  if (s.bi_valid > (Buf_size - length)) {
    s.bi_buf |= (value << s.bi_valid) & 0xffff;
    put_short(s, s.bi_buf);
    s.bi_buf = value >> (Buf_size - s.bi_valid);
    s.bi_valid += length - Buf_size;
  } else {
    s.bi_buf |= (value << s.bi_valid) & 0xffff;
    s.bi_valid += length;
  }
}


function send_code(s, c, tree) {
  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);
}


/* ===========================================================================
 * Reverse the first len bits of a code, using straightforward code (a faster
 * method would use a table)
 * IN assertion: 1 <= len <= 15
 */
function bi_reverse(code, len) {
  var res = 0;
  do {
    res |= code & 1;
    code >>>= 1;
    res <<= 1;
  } while (--len > 0);
  return res >>> 1;
}


/* ===========================================================================
 * Flush the bit buffer, keeping at most 7 bits in it.
 */
function bi_flush(s) {
  if (s.bi_valid === 16) {
    put_short(s, s.bi_buf);
    s.bi_buf = 0;
    s.bi_valid = 0;

  } else if (s.bi_valid >= 8) {
    s.pending_buf[s.pending++] = s.bi_buf & 0xff;
    s.bi_buf >>= 8;
    s.bi_valid -= 8;
  }
}


/* ===========================================================================
 * Compute the optimal bit lengths for a tree and update the total bit length
 * for the current block.
 * IN assertion: the fields freq and dad are set, heap[heap_max] and
 *    above are the tree nodes sorted by increasing frequency.
 * OUT assertions: the field len is set to the optimal bit length, the
 *     array bl_count contains the frequencies for each bit length.
 *     The length opt_len is updated; static_len is also updated if stree is
 *     not null.
 */
function gen_bitlen(s, desc)
//    deflate_state *s;
//    tree_desc *desc;    /* the tree descriptor */
{
  var tree            = desc.dyn_tree;
  var max_code        = desc.max_code;
  var stree           = desc.stat_desc.static_tree;
  var has_stree       = desc.stat_desc.has_stree;
  var extra           = desc.stat_desc.extra_bits;
  var base            = desc.stat_desc.extra_base;
  var max_length      = desc.stat_desc.max_length;
  var h;              /* heap index */
  var n, m;           /* iterate over the tree elements */
  var bits;           /* bit length */
  var xbits;          /* extra bits */
  var f;              /* frequency */
  var overflow = 0;   /* number of elements with bit length too large */

  for (bits = 0; bits <= MAX_BITS; bits++) {
    s.bl_count[bits] = 0;
  }

  /* In a first pass, compute the optimal bit lengths (which may
   * overflow in the case of the bit length tree).
   */
  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */

  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {
    n = s.heap[h];
    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;
    if (bits > max_length) {
      bits = max_length;
      overflow++;
    }
    tree[n * 2 + 1]/*.Len*/ = bits;
    /* We overwrite tree[n].Dad which is no longer needed */

    if (n > max_code) { continue; } /* not a leaf node */

    s.bl_count[bits]++;
    xbits = 0;
    if (n >= base) {
      xbits = extra[n - base];
    }
    f = tree[n * 2]/*.Freq*/;
    s.opt_len += f * (bits + xbits);
    if (has_stree) {
      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);
    }
  }
  if (overflow === 0) { return; }

  // Trace((stderr,"\nbit length overflow\n"));
  /* This happens for example on obj2 and pic of the Calgary corpus */

  /* Find the first bit length which could increase: */
  do {
    bits = max_length - 1;
    while (s.bl_count[bits] === 0) { bits--; }
    s.bl_count[bits]--;      /* move one leaf down the tree */
    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */
    s.bl_count[max_length]--;
    /* The brother of the overflow item also moves one step up,
     * but this does not affect bl_count[max_length]
     */
    overflow -= 2;
  } while (overflow > 0);

  /* Now recompute all bit lengths, scanning in increasing frequency.
   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all
   * lengths instead of fixing only the wrong ones. This idea is taken
   * from 'ar' written by Haruhiko Okumura.)
   */
  for (bits = max_length; bits !== 0; bits--) {
    n = s.bl_count[bits];
    while (n !== 0) {
      m = s.heap[--h];
      if (m > max_code) { continue; }
      if (tree[m * 2 + 1]/*.Len*/ !== bits) {
        // Trace((stderr,"code %d bits %d->%d\n", m, tree[m].Len, bits));
        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;
        tree[m * 2 + 1]/*.Len*/ = bits;
      }
      n--;
    }
  }
}


/* ===========================================================================
 * Generate the codes for a given tree and bit counts (which need not be
 * optimal).
 * IN assertion: the array bl_count contains the bit length statistics for
 * the given tree and the field len is set for all tree elements.
 * OUT assertion: the field code is set for all tree elements of non
 *     zero code length.
 */
function gen_codes(tree, max_code, bl_count)
//    ct_data *tree;             /* the tree to decorate */
//    int max_code;              /* largest code with non zero frequency */
//    ushf *bl_count;            /* number of codes at each bit length */
{
  var next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */
  var code = 0;              /* running code value */
  var bits;                  /* bit index */
  var n;                     /* code index */

  /* The distribution counts are first used to generate the code values
   * without bit reversal.
   */
  for (bits = 1; bits <= MAX_BITS; bits++) {
    next_code[bits] = code = (code + bl_count[bits - 1]) << 1;
  }
  /* Check that the bit counts in bl_count are consistent. The last code
   * must be all ones.
   */
  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,
  //        "inconsistent bit counts");
  //Tracev((stderr,"\ngen_codes: max_code %d ", max_code));

  for (n = 0;  n <= max_code; n++) {
    var len = tree[n * 2 + 1]/*.Len*/;
    if (len === 0) { continue; }
    /* Now reverse the bits */
    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);

    //Tracecv(tree != static_ltree, (stderr,"\nn %3d %c l %2d c %4x (%x) ",
    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));
  }
}


/* ===========================================================================
 * Initialize the various 'constant' tables.
 */
function tr_static_init() {
  var n;        /* iterates over tree elements */
  var bits;     /* bit counter */
  var length;   /* length value */
  var code;     /* code value */
  var dist;     /* distance index */
  var bl_count = new Array(MAX_BITS + 1);
  /* number of codes at each bit length for an optimal tree */

  // do check in _tr_init()
  //if (static_init_done) return;

  /* For some embedded targets, global variables are not initialized: */
/*#ifdef NO_INIT_GLOBAL_POINTERS
  static_l_desc.static_tree = static_ltree;
  static_l_desc.extra_bits = extra_lbits;
  static_d_desc.static_tree = static_dtree;
  static_d_desc.extra_bits = extra_dbits;
  static_bl_desc.extra_bits = extra_blbits;
#endif*/

  /* Initialize the mapping length (0..255) -> length code (0..28) */
  length = 0;
  for (code = 0; code < LENGTH_CODES - 1; code++) {
    base_length[code] = length;
    for (n = 0; n < (1 << extra_lbits[code]); n++) {
      _length_code[length++] = code;
    }
  }
  //Assert (length == 256, "tr_static_init: length != 256");
  /* Note that the length 255 (match length 258) can be represented
   * in two different ways: code 284 + 5 bits or code 285, so we
   * overwrite length_code[255] to use the best encoding:
   */
  _length_code[length - 1] = code;

  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */
  dist = 0;
  for (code = 0; code < 16; code++) {
    base_dist[code] = dist;
    for (n = 0; n < (1 << extra_dbits[code]); n++) {
      _dist_code[dist++] = code;
    }
  }
  //Assert (dist == 256, "tr_static_init: dist != 256");
  dist >>= 7; /* from now on, all distances are divided by 128 */
  for (; code < D_CODES; code++) {
    base_dist[code] = dist << 7;
    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {
      _dist_code[256 + dist++] = code;
    }
  }
  //Assert (dist == 256, "tr_static_init: 256+dist != 512");

  /* Construct the codes of the static literal tree */
  for (bits = 0; bits <= MAX_BITS; bits++) {
    bl_count[bits] = 0;
  }

  n = 0;
  while (n <= 143) {
    static_ltree[n * 2 + 1]/*.Len*/ = 8;
    n++;
    bl_count[8]++;
  }
  while (n <= 255) {
    static_ltree[n * 2 + 1]/*.Len*/ = 9;
    n++;
    bl_count[9]++;
  }
  while (n <= 279) {
    static_ltree[n * 2 + 1]/*.Len*/ = 7;
    n++;
    bl_count[7]++;
  }
  while (n <= 287) {
    static_ltree[n * 2 + 1]/*.Len*/ = 8;
    n++;
    bl_count[8]++;
  }
  /* Codes 286 and 287 do not exist, but we must include them in the
   * tree construction to get a canonical Huffman tree (longest code
   * all ones)
   */
  gen_codes(static_ltree, L_CODES + 1, bl_count);

  /* The static distance tree is trivial: */
  for (n = 0; n < D_CODES; n++) {
    static_dtree[n * 2 + 1]/*.Len*/ = 5;
    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);
  }

  // Now data ready and we can init static trees
  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);
  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);
  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);

  //static_init_done = true;
}


/* ===========================================================================
 * Initialize a new block.
 */
function init_block(s) {
  var n; /* iterates over tree elements */

  /* Initialize the trees. */
  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }
  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }
  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }

  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;
  s.opt_len = s.static_len = 0;
  s.last_lit = s.matches = 0;
}


/* ===========================================================================
 * Flush the bit buffer and align the output on a byte boundary
 */
function bi_windup(s)
{
  if (s.bi_valid > 8) {
    put_short(s, s.bi_buf);
  } else if (s.bi_valid > 0) {
    //put_byte(s, (Byte)s->bi_buf);
    s.pending_buf[s.pending++] = s.bi_buf;
  }
  s.bi_buf = 0;
  s.bi_valid = 0;
}

/* ===========================================================================
 * Copy a stored block, storing first the length and its
 * one's complement if requested.
 */
function copy_block(s, buf, len, header)
//DeflateState *s;
//charf    *buf;    /* the input data */
//unsigned len;     /* its length */
//int      header;  /* true if block header must be written */
{
  bi_windup(s);        /* align on byte boundary */

  if (header) {
    put_short(s, len);
    put_short(s, ~len);
  }
//  while (len--) {
//    put_byte(s, *buf++);
//  }
  utils.arraySet(s.pending_buf, s.window, buf, len, s.pending);
  s.pending += len;
}

/* ===========================================================================
 * Compares to subtrees, using the tree depth as tie breaker when
 * the subtrees have equal frequency. This minimizes the worst case length.
 */
function smaller(tree, n, m, depth) {
  var _n2 = n * 2;
  var _m2 = m * 2;
  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||
         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));
}

/* ===========================================================================
 * Restore the heap property by moving down the tree starting at node k,
 * exchanging a node with the smallest of its two sons if necessary, stopping
 * when the heap property is re-established (each father smaller than its
 * two sons).
 */
function pqdownheap(s, tree, k)
//    deflate_state *s;
//    ct_data *tree;  /* the tree to restore */
//    int k;               /* node to move down */
{
  var v = s.heap[k];
  var j = k << 1;  /* left son of k */
  while (j <= s.heap_len) {
    /* Set j to the smallest of the two sons: */
    if (j < s.heap_len &&
      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {
      j++;
    }
    /* Exit if v is smaller than both sons */
    if (smaller(tree, v, s.heap[j], s.depth)) { break; }

    /* Exchange v with the smallest son */
    s.heap[k] = s.heap[j];
    k = j;

    /* And continue down the tree, setting j to the left son of k */
    j <<= 1;
  }
  s.heap[k] = v;
}


// inlined manually
// var SMALLEST = 1;

/* ===========================================================================
 * Send the block data compressed using the given Huffman trees
 */
function compress_block(s, ltree, dtree)
//    deflate_state *s;
//    const ct_data *ltree; /* literal tree */
//    const ct_data *dtree; /* distance tree */
{
  var dist;           /* distance of matched string */
  var lc;             /* match length or unmatched char (if dist == 0) */
  var lx = 0;         /* running index in l_buf */
  var code;           /* the code to send */
  var extra;          /* number of extra bits to send */

  if (s.last_lit !== 0) {
    do {
      dist = (s.pending_buf[s.d_buf + lx * 2] << 8) | (s.pending_buf[s.d_buf + lx * 2 + 1]);
      lc = s.pending_buf[s.l_buf + lx];
      lx++;

      if (dist === 0) {
        send_code(s, lc, ltree); /* send a literal byte */
        //Tracecv(isgraph(lc), (stderr," '%c' ", lc));
      } else {
        /* Here, lc is the match length - MIN_MATCH */
        code = _length_code[lc];
        send_code(s, code + LITERALS + 1, ltree); /* send the length code */
        extra = extra_lbits[code];
        if (extra !== 0) {
          lc -= base_length[code];
          send_bits(s, lc, extra);       /* send the extra length bits */
        }
        dist--; /* dist is now the match distance - 1 */
        code = d_code(dist);
        //Assert (code < D_CODES, "bad d_code");

        send_code(s, code, dtree);       /* send the distance code */
        extra = extra_dbits[code];
        if (extra !== 0) {
          dist -= base_dist[code];
          send_bits(s, dist, extra);   /* send the extra distance bits */
        }
      } /* literal or match pair ? */

      /* Check that the overlay between pending_buf and d_buf+l_buf is ok: */
      //Assert((uInt)(s->pending) < s->lit_bufsize + 2*lx,
      //       "pendingBuf overflow");

    } while (lx < s.last_lit);
  }

  send_code(s, END_BLOCK, ltree);
}


/* ===========================================================================
 * Construct one Huffman tree and assigns the code bit strings and lengths.
 * Update the total bit length for the current block.
 * IN assertion: the field freq is set for all tree elements.
 * OUT assertions: the fields len and code are set to the optimal bit length
 *     and corresponding code. The length opt_len is updated; static_len is
 *     also updated if stree is not null. The field max_code is set.
 */
function build_tree(s, desc)
//    deflate_state *s;
//    tree_desc *desc; /* the tree descriptor */
{
  var tree     = desc.dyn_tree;
  var stree    = desc.stat_desc.static_tree;
  var has_stree = desc.stat_desc.has_stree;
  var elems    = desc.stat_desc.elems;
  var n, m;          /* iterate over heap elements */
  var max_code = -1; /* largest code with non zero frequency */
  var node;          /* new node being created */

  /* Construct the initial heap, with least frequent element in
   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].
   * heap[0] is not used.
   */
  s.heap_len = 0;
  s.heap_max = HEAP_SIZE;

  for (n = 0; n < elems; n++) {
    if (tree[n * 2]/*.Freq*/ !== 0) {
      s.heap[++s.heap_len] = max_code = n;
      s.depth[n] = 0;

    } else {
      tree[n * 2 + 1]/*.Len*/ = 0;
    }
  }

  /* The pkzip format requires that at least one distance code exists,
   * and that at least one bit should be sent even if there is only one
   * possible code. So to avoid special checks later on we force at least
   * two codes of non zero frequency.
   */
  while (s.heap_len < 2) {
    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);
    tree[node * 2]/*.Freq*/ = 1;
    s.depth[node] = 0;
    s.opt_len--;

    if (has_stree) {
      s.static_len -= stree[node * 2 + 1]/*.Len*/;
    }
    /* node is 0 or 1 so it does not have extra bits */
  }
  desc.max_code = max_code;

  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,
   * establish sub-heaps of increasing lengths:
   */
  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }

  /* Construct the Huffman tree by repeatedly combining the least two
   * frequent nodes.
   */
  node = elems;              /* next internal node of the tree */
  do {
    //pqremove(s, tree, n);  /* n = node of least frequency */
    /*** pqremove ***/
    n = s.heap[1/*SMALLEST*/];
    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];
    pqdownheap(s, tree, 1/*SMALLEST*/);
    /***/

    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */

    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */
    s.heap[--s.heap_max] = m;

    /* Create a new node father of n and m */
    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;
    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;
    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;

    /* and insert the new node in the heap */
    s.heap[1/*SMALLEST*/] = node++;
    pqdownheap(s, tree, 1/*SMALLEST*/);

  } while (s.heap_len >= 2);

  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];

  /* At this point, the fields freq and dad are set. We can now
   * generate the bit lengths.
   */
  gen_bitlen(s, desc);

  /* The field len is now set, we can generate the bit codes */
  gen_codes(tree, max_code, s.bl_count);
}


/* ===========================================================================
 * Scan a literal or distance tree to determine the frequencies of the codes
 * in the bit length tree.
 */
function scan_tree(s, tree, max_code)
//    deflate_state *s;
//    ct_data *tree;   /* the tree to be scanned */
//    int max_code;    /* and its largest code of non zero frequency */
{
  var n;                     /* iterates over all tree elements */
  var prevlen = -1;          /* last emitted length */
  var curlen;                /* length of current code */

  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */

  var count = 0;             /* repeat count of the current code */
  var max_count = 7;         /* max repeat count */
  var min_count = 4;         /* min repeat count */

  if (nextlen === 0) {
    max_count = 138;
    min_count = 3;
  }
  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */

  for (n = 0; n <= max_code; n++) {
    curlen = nextlen;
    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;

    if (++count < max_count && curlen === nextlen) {
      continue;

    } else if (count < min_count) {
      s.bl_tree[curlen * 2]/*.Freq*/ += count;

    } else if (curlen !== 0) {

      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }
      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;

    } else if (count <= 10) {
      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;

    } else {
      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;
    }

    count = 0;
    prevlen = curlen;

    if (nextlen === 0) {
      max_count = 138;
      min_count = 3;

    } else if (curlen === nextlen) {
      max_count = 6;
      min_count = 3;

    } else {
      max_count = 7;
      min_count = 4;
    }
  }
}


/* ===========================================================================
 * Send a literal or distance tree in compressed form, using the codes in
 * bl_tree.
 */
function send_tree(s, tree, max_code)
//    deflate_state *s;
//    ct_data *tree; /* the tree to be scanned */
//    int max_code;       /* and its largest code of non zero frequency */
{
  var n;                     /* iterates over all tree elements */
  var prevlen = -1;          /* last emitted length */
  var curlen;                /* length of current code */

  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */

  var count = 0;             /* repeat count of the current code */
  var max_count = 7;         /* max repeat count */
  var min_count = 4;         /* min repeat count */

  /* tree[max_code+1].Len = -1; */  /* guard already set */
  if (nextlen === 0) {
    max_count = 138;
    min_count = 3;
  }

  for (n = 0; n <= max_code; n++) {
    curlen = nextlen;
    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;

    if (++count < max_count && curlen === nextlen) {
      continue;

    } else if (count < min_count) {
      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);

    } else if (curlen !== 0) {
      if (curlen !== prevlen) {
        send_code(s, curlen, s.bl_tree);
        count--;
      }
      //Assert(count >= 3 && count <= 6, " 3_6?");
      send_code(s, REP_3_6, s.bl_tree);
      send_bits(s, count - 3, 2);

    } else if (count <= 10) {
      send_code(s, REPZ_3_10, s.bl_tree);
      send_bits(s, count - 3, 3);

    } else {
      send_code(s, REPZ_11_138, s.bl_tree);
      send_bits(s, count - 11, 7);
    }

    count = 0;
    prevlen = curlen;
    if (nextlen === 0) {
      max_count = 138;
      min_count = 3;

    } else if (curlen === nextlen) {
      max_count = 6;
      min_count = 3;

    } else {
      max_count = 7;
      min_count = 4;
    }
  }
}


/* ===========================================================================
 * Construct the Huffman tree for the bit lengths and return the index in
 * bl_order of the last bit length code to send.
 */
function build_bl_tree(s) {
  var max_blindex;  /* index of last bit length code of non zero freq */

  /* Determine the bit length frequencies for literal and distance trees */
  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);
  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);

  /* Build the bit length tree: */
  build_tree(s, s.bl_desc);
  /* opt_len now includes the length of the tree representations, except
   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.
   */

  /* Determine the number of bit length codes to send. The pkzip format
   * requires that at least 4 bit length codes be sent. (appnote.txt says
   * 3 but the actual value used is 4.)
   */
  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {
    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {
      break;
    }
  }
  /* Update opt_len to include the bit length tree and counts */
  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;
  //Tracev((stderr, "\ndyn trees: dyn %ld, stat %ld",
  //        s->opt_len, s->static_len));

  return max_blindex;
}


/* ===========================================================================
 * Send the header for a block using dynamic Huffman trees: the counts, the
 * lengths of the bit length codes, the literal tree and the distance tree.
 * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.
 */
function send_all_trees(s, lcodes, dcodes, blcodes)
//    deflate_state *s;
//    int lcodes, dcodes, blcodes; /* number of codes for each tree */
{
  var rank;                    /* index in bl_order */

  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, "not enough codes");
  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,
  //        "too many codes");
  //Tracev((stderr, "\nbl counts: "));
  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */
  send_bits(s, dcodes - 1,   5);
  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */
  for (rank = 0; rank < blcodes; rank++) {
    //Tracev((stderr, "\nbl code %2d ", bl_order[rank]));
    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);
  }
  //Tracev((stderr, "\nbl tree: sent %ld", s->bits_sent));

  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */
  //Tracev((stderr, "\nlit tree: sent %ld", s->bits_sent));

  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */
  //Tracev((stderr, "\ndist tree: sent %ld", s->bits_sent));
}


/* ===========================================================================
 * Check if the data type is TEXT or BINARY, using the following algorithm:
 * - TEXT if the two conditions below are satisfied:
 *    a) There are no non-portable control characters belonging to the
 *       "black list" (0..6, 14..25, 28..31).
 *    b) There is at least one printable character belonging to the
 *       "white list" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).
 * - BINARY otherwise.
 * - The following partially-portable control characters form a
 *   "gray list" that is ignored in this detection algorithm:
 *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).
 * IN assertion: the fields Freq of dyn_ltree are set.
 */
function detect_data_type(s) {
  /* black_mask is the bit mask of black-listed bytes
   * set bits 0..6, 14..25, and 28..31
   * 0xf3ffc07f = binary 11110011111111111100000001111111
   */
  var black_mask = 0xf3ffc07f;
  var n;

  /* Check for non-textual ("black-listed") bytes. */
  for (n = 0; n <= 31; n++, black_mask >>>= 1) {
    if ((black_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {
      return Z_BINARY;
    }
  }

  /* Check for textual ("white-listed") bytes. */
  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||
      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {
    return Z_TEXT;
  }
  for (n = 32; n < LITERALS; n++) {
    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {
      return Z_TEXT;
    }
  }

  /* There are no "black-listed" or "white-listed" bytes:
   * this stream either is empty or has tolerated ("gray-listed") bytes only.
   */
  return Z_BINARY;
}


var static_init_done = false;

/* ===========================================================================
 * Initialize the tree data structures for a new zlib stream.
 */
function _tr_init(s)
{

  if (!static_init_done) {
    tr_static_init();
    static_init_done = true;
  }

  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);
  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);
  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);

  s.bi_buf = 0;
  s.bi_valid = 0;

  /* Initialize the first block of the first file: */
  init_block(s);
}


/* ===========================================================================
 * Send a stored block
 */
function _tr_stored_block(s, buf, stored_len, last)
//DeflateState *s;
//charf *buf;       /* input block */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{
  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */
  copy_block(s, buf, stored_len, true); /* with header */
}


/* ===========================================================================
 * Send one empty static block to give enough lookahead for inflate.
 * This takes 10 bits, of which 7 may remain in the bit buffer.
 */
function _tr_align(s) {
  send_bits(s, STATIC_TREES << 1, 3);
  send_code(s, END_BLOCK, static_ltree);
  bi_flush(s);
}


/* ===========================================================================
 * Determine the best encoding for the current block: dynamic trees, static
 * trees or store, and output the encoded block to the zip file.
 */
function _tr_flush_block(s, buf, stored_len, last)
//DeflateState *s;
//charf *buf;       /* input block, or NULL if too old */
//ulg stored_len;   /* length of input block */
//int last;         /* one if this is the last block for a file */
{
  var opt_lenb, static_lenb;  /* opt_len and static_len in bytes */
  var max_blindex = 0;        /* index of last bit length code of non zero freq */

  /* Build the Huffman trees unless a stored block is forced */
  if (s.level > 0) {

    /* Check if the file is binary or text */
    if (s.strm.data_type === Z_UNKNOWN) {
      s.strm.data_type = detect_data_type(s);
    }

    /* Construct the literal and distance trees */
    build_tree(s, s.l_desc);
    // Tracev((stderr, "\nlit data: dyn %ld, stat %ld", s->opt_len,
    //        s->static_len));

    build_tree(s, s.d_desc);
    // Tracev((stderr, "\ndist data: dyn %ld, stat %ld", s->opt_len,
    //        s->static_len));
    /* At this point, opt_len and static_len are the total bit lengths of
     * the compressed block data, excluding the tree representations.
     */

    /* Build the bit length tree for the above two trees, and get the index
     * in bl_order of the last bit length code to send.
     */
    max_blindex = build_bl_tree(s);

    /* Determine the best encoding. Compute the block lengths in bytes. */
    opt_lenb = (s.opt_len + 3 + 7) >>> 3;
    static_lenb = (s.static_len + 3 + 7) >>> 3;

    // Tracev((stderr, "\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u ",
    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,
    //        s->last_lit));

    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }

  } else {
    // Assert(buf != (char*)0, "lost buf");
    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */
  }

  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {
    /* 4: two words for the lengths */

    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.
     * Otherwise we can't have processed more than WSIZE input bytes since
     * the last block flush, because compression would have been
     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to
     * transform a block into a stored block.
     */
    _tr_stored_block(s, buf, stored_len, last);

  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {

    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);
    compress_block(s, static_ltree, static_dtree);

  } else {
    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);
    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);
    compress_block(s, s.dyn_ltree, s.dyn_dtree);
  }
  // Assert (s->compressed_len == s->bits_sent, "bad compressed size");
  /* The above check is made mod 2^32, for files larger than 512 MB
   * and uLong implemented on 32 bits.
   */
  init_block(s);

  if (last) {
    bi_windup(s);
  }
  // Tracev((stderr,"\ncomprlen %lu(%lu) ", s->compressed_len>>3,
  //       s->compressed_len-7*last));
}

/* ===========================================================================
 * Save the match info and tally the frequency counts. Return true if
 * the current block must be flushed.
 */
function _tr_tally(s, dist, lc)
//    deflate_state *s;
//    unsigned dist;  /* distance of matched string */
//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */
{
  //var out_length, in_length, dcode;

  s.pending_buf[s.d_buf + s.last_lit * 2]     = (dist >>> 8) & 0xff;
  s.pending_buf[s.d_buf + s.last_lit * 2 + 1] = dist & 0xff;

  s.pending_buf[s.l_buf + s.last_lit] = lc & 0xff;
  s.last_lit++;

  if (dist === 0) {
    /* lc is the unmatched char */
    s.dyn_ltree[lc * 2]/*.Freq*/++;
  } else {
    s.matches++;
    /* Here, lc is the match length - MIN_MATCH */
    dist--;             /* dist = match distance - 1 */
    //Assert((ush)dist < (ush)MAX_DIST(s) &&
    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&
    //       (ush)d_code(dist) < (ush)D_CODES,  "_tr_tally: bad match");

    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;
    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;
  }

// (!) This block is disabled in zlib defaults,
// don't enable it for binary compatibility

//#ifdef TRUNCATE_BLOCK
//  /* Try to guess if it is profitable to stop the current block here */
//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {
//    /* Compute an upper bound for the compressed length */
//    out_length = s.last_lit*8;
//    in_length = s.strstart - s.block_start;
//
//    for (dcode = 0; dcode < D_CODES; dcode++) {
//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);
//    }
//    out_length >>>= 3;
//    //Tracev((stderr,"\nlast_lit %u, in %ld, out ~%ld(%ld%%) ",
//    //       s->last_lit, in_length, out_length,
//    //       100L - out_length*100L/in_length));
//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {
//      return true;
//    }
//  }
//#endif

  return (s.last_lit === s.lit_bufsize - 1);
  /* We avoid equality with lit_bufsize because of wraparound at 64K
   * on 16 bit machines and because stored blocks are restricted to
   * 64K-1 bytes.
   */
}

exports._tr_init  = _tr_init;
exports._tr_stored_block = _tr_stored_block;
exports._tr_flush_block  = _tr_flush_block;
exports._tr_tally = _tr_tally;
exports._tr_align = _tr_align;


/***/ }),

/***/ "./node_modules/pako/lib/zlib/zstream.js":
/*!***********************************************!*\
  !*** ./node_modules/pako/lib/zlib/zstream.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// (C) 1995-2013 Jean-loup Gailly and Mark Adler
// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin
//
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//   claim that you wrote the original software. If you use this software
//   in a product, an acknowledgment in the product documentation would be
//   appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//   misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

function ZStream() {
  /* next input byte */
  this.input = null; // JS specific, because we have no pointers
  this.next_in = 0;
  /* number of bytes available at input */
  this.avail_in = 0;
  /* total number of input bytes read so far */
  this.total_in = 0;
  /* next output byte should be put there */
  this.output = null; // JS specific, because we have no pointers
  this.next_out = 0;
  /* remaining free space at output */
  this.avail_out = 0;
  /* total number of bytes output so far */
  this.total_out = 0;
  /* last error message, NULL if no error */
  this.msg = ''/*Z_NULL*/;
  /* not visible by applications */
  this.state = null;
  /* best guess about the data type: binary or text */
  this.data_type = 2/*Z_UNKNOWN*/;
  /* adler32 value of the uncompressed data */
  this.adler = 0;
}

module.exports = ZStream;


/***/ }),

/***/ "./node_modules/style-loader/lib/addStyles.js":
/*!****************************************************!*\
  !*** ./node_modules/style-loader/lib/addStyles.js ***!
  \****************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

/*
	MIT License http://www.opensource.org/licenses/mit-license.php
	Author Tobias Koppers @sokra
*/

var stylesInDom = {};

var	memoize = function (fn) {
	var memo;

	return function () {
		if (typeof memo === "undefined") memo = fn.apply(this, arguments);
		return memo;
	};
};

var isOldIE = memoize(function () {
	// Test for IE <= 9 as proposed by Browserhacks
	// @see http://browserhacks.com/#hack-e71d8692f65334173fee715c222cb805
	// Tests for existence of standard globals is to allow style-loader
	// to operate correctly into non-standard environments
	// @see https://github.com/webpack-contrib/style-loader/issues/177
	return window && document && document.all && !window.atob;
});

var getTarget = function (target, parent) {
  if (parent){
    return parent.querySelector(target);
  }
  return document.querySelector(target);
};

var getElement = (function (fn) {
	var memo = {};

	return function(target, parent) {
                // If passing function in options, then use it for resolve "head" element.
                // Useful for Shadow Root style i.e
                // {
                //   insertInto: function () { return document.querySelector("#foo").shadowRoot }
                // }
                if (typeof target === 'function') {
                        return target();
                }
                if (typeof memo[target] === "undefined") {
			var styleTarget = getTarget.call(this, target, parent);
			// Special case to return head of iframe instead of iframe itself
			if (window.HTMLIFrameElement && styleTarget instanceof window.HTMLIFrameElement) {
				try {
					// This will throw an exception if access to iframe is blocked
					// due to cross-origin restrictions
					styleTarget = styleTarget.contentDocument.head;
				} catch(e) {
					styleTarget = null;
				}
			}
			memo[target] = styleTarget;
		}
		return memo[target]
	};
})();

var singleton = null;
var	singletonCounter = 0;
var	stylesInsertedAtTop = [];

var	fixUrls = __webpack_require__(/*! ./urls */ "./node_modules/style-loader/lib/urls.js");

module.exports = function(list, options) {
	if (typeof DEBUG !== "undefined" && DEBUG) {
		if (typeof document !== "object") throw new Error("The style-loader cannot be used in a non-browser environment");
	}

	options = options || {};

	options.attrs = typeof options.attrs === "object" ? options.attrs : {};

	// Force single-tag solution on IE6-9, which has a hard limit on the # of <style>
	// tags it will allow on a page
	if (!options.singleton && typeof options.singleton !== "boolean") options.singleton = isOldIE();

	// By default, add <style> tags to the <head> element
        if (!options.insertInto) options.insertInto = "head";

	// By default, add <style> tags to the bottom of the target
	if (!options.insertAt) options.insertAt = "bottom";

	var styles = listToStyles(list, options);

	addStylesToDom(styles, options);

	return function update (newList) {
		var mayRemove = [];

		for (var i = 0; i < styles.length; i++) {
			var item = styles[i];
			var domStyle = stylesInDom[item.id];

			domStyle.refs--;
			mayRemove.push(domStyle);
		}

		if(newList) {
			var newStyles = listToStyles(newList, options);
			addStylesToDom(newStyles, options);
		}

		for (var i = 0; i < mayRemove.length; i++) {
			var domStyle = mayRemove[i];

			if(domStyle.refs === 0) {
				for (var j = 0; j < domStyle.parts.length; j++) domStyle.parts[j]();

				delete stylesInDom[domStyle.id];
			}
		}
	};
};

function addStylesToDom (styles, options) {
	for (var i = 0; i < styles.length; i++) {
		var item = styles[i];
		var domStyle = stylesInDom[item.id];

		if(domStyle) {
			domStyle.refs++;

			for(var j = 0; j < domStyle.parts.length; j++) {
				domStyle.parts[j](item.parts[j]);
			}

			for(; j < item.parts.length; j++) {
				domStyle.parts.push(addStyle(item.parts[j], options));
			}
		} else {
			var parts = [];

			for(var j = 0; j < item.parts.length; j++) {
				parts.push(addStyle(item.parts[j], options));
			}

			stylesInDom[item.id] = {id: item.id, refs: 1, parts: parts};
		}
	}
}

function listToStyles (list, options) {
	var styles = [];
	var newStyles = {};

	for (var i = 0; i < list.length; i++) {
		var item = list[i];
		var id = options.base ? item[0] + options.base : item[0];
		var css = item[1];
		var media = item[2];
		var sourceMap = item[3];
		var part = {css: css, media: media, sourceMap: sourceMap};

		if(!newStyles[id]) styles.push(newStyles[id] = {id: id, parts: [part]});
		else newStyles[id].parts.push(part);
	}

	return styles;
}

function insertStyleElement (options, style) {
	var target = getElement(options.insertInto)

	if (!target) {
		throw new Error("Couldn't find a style target. This probably means that the value for the 'insertInto' parameter is invalid.");
	}

	var lastStyleElementInsertedAtTop = stylesInsertedAtTop[stylesInsertedAtTop.length - 1];

	if (options.insertAt === "top") {
		if (!lastStyleElementInsertedAtTop) {
			target.insertBefore(style, target.firstChild);
		} else if (lastStyleElementInsertedAtTop.nextSibling) {
			target.insertBefore(style, lastStyleElementInsertedAtTop.nextSibling);
		} else {
			target.appendChild(style);
		}
		stylesInsertedAtTop.push(style);
	} else if (options.insertAt === "bottom") {
		target.appendChild(style);
	} else if (typeof options.insertAt === "object" && options.insertAt.before) {
		var nextSibling = getElement(options.insertAt.before, target);
		target.insertBefore(style, nextSibling);
	} else {
		throw new Error("[Style Loader]\n\n Invalid value for parameter 'insertAt' ('options.insertAt') found.\n Must be 'top', 'bottom', or Object.\n (https://github.com/webpack-contrib/style-loader#insertat)\n");
	}
}

function removeStyleElement (style) {
	if (style.parentNode === null) return false;
	style.parentNode.removeChild(style);

	var idx = stylesInsertedAtTop.indexOf(style);
	if(idx >= 0) {
		stylesInsertedAtTop.splice(idx, 1);
	}
}

function createStyleElement (options) {
	var style = document.createElement("style");

	if(options.attrs.type === undefined) {
		options.attrs.type = "text/css";
	}

	if(options.attrs.nonce === undefined) {
		var nonce = getNonce();
		if (nonce) {
			options.attrs.nonce = nonce;
		}
	}

	addAttrs(style, options.attrs);
	insertStyleElement(options, style);

	return style;
}

function createLinkElement (options) {
	var link = document.createElement("link");

	if(options.attrs.type === undefined) {
		options.attrs.type = "text/css";
	}
	options.attrs.rel = "stylesheet";

	addAttrs(link, options.attrs);
	insertStyleElement(options, link);

	return link;
}

function addAttrs (el, attrs) {
	Object.keys(attrs).forEach(function (key) {
		el.setAttribute(key, attrs[key]);
	});
}

function getNonce() {
	if (false) {}

	return __webpack_require__.nc;
}

function addStyle (obj, options) {
	var style, update, remove, result;

	// If a transform function was defined, run it on the css
	if (options.transform && obj.css) {
	    result = typeof options.transform === 'function'
		 ? options.transform(obj.css) 
		 : options.transform.default(obj.css);

	    if (result) {
	    	// If transform returns a value, use that instead of the original css.
	    	// This allows running runtime transformations on the css.
	    	obj.css = result;
	    } else {
	    	// If the transform function returns a falsy value, don't add this css.
	    	// This allows conditional loading of css
	    	return function() {
	    		// noop
	    	};
	    }
	}

	if (options.singleton) {
		var styleIndex = singletonCounter++;

		style = singleton || (singleton = createStyleElement(options));

		update = applyToSingletonTag.bind(null, style, styleIndex, false);
		remove = applyToSingletonTag.bind(null, style, styleIndex, true);

	} else if (
		obj.sourceMap &&
		typeof URL === "function" &&
		typeof URL.createObjectURL === "function" &&
		typeof URL.revokeObjectURL === "function" &&
		typeof Blob === "function" &&
		typeof btoa === "function"
	) {
		style = createLinkElement(options);
		update = updateLink.bind(null, style, options);
		remove = function () {
			removeStyleElement(style);

			if(style.href) URL.revokeObjectURL(style.href);
		};
	} else {
		style = createStyleElement(options);
		update = applyToTag.bind(null, style);
		remove = function () {
			removeStyleElement(style);
		};
	}

	update(obj);

	return function updateStyle (newObj) {
		if (newObj) {
			if (
				newObj.css === obj.css &&
				newObj.media === obj.media &&
				newObj.sourceMap === obj.sourceMap
			) {
				return;
			}

			update(obj = newObj);
		} else {
			remove();
		}
	};
}

var replaceText = (function () {
	var textStore = [];

	return function (index, replacement) {
		textStore[index] = replacement;

		return textStore.filter(Boolean).join('\n');
	};
})();

function applyToSingletonTag (style, index, remove, obj) {
	var css = remove ? "" : obj.css;

	if (style.styleSheet) {
		style.styleSheet.cssText = replaceText(index, css);
	} else {
		var cssNode = document.createTextNode(css);
		var childNodes = style.childNodes;

		if (childNodes[index]) style.removeChild(childNodes[index]);

		if (childNodes.length) {
			style.insertBefore(cssNode, childNodes[index]);
		} else {
			style.appendChild(cssNode);
		}
	}
}

function applyToTag (style, obj) {
	var css = obj.css;
	var media = obj.media;

	if(media) {
		style.setAttribute("media", media)
	}

	if(style.styleSheet) {
		style.styleSheet.cssText = css;
	} else {
		while(style.firstChild) {
			style.removeChild(style.firstChild);
		}

		style.appendChild(document.createTextNode(css));
	}
}

function updateLink (link, options, obj) {
	var css = obj.css;
	var sourceMap = obj.sourceMap;

	/*
		If convertToAbsoluteUrls isn't defined, but sourcemaps are enabled
		and there is no publicPath defined then lets turn convertToAbsoluteUrls
		on by default.  Otherwise default to the convertToAbsoluteUrls option
		directly
	*/
	var autoFixUrls = options.convertToAbsoluteUrls === undefined && sourceMap;

	if (options.convertToAbsoluteUrls || autoFixUrls) {
		css = fixUrls(css);
	}

	if (sourceMap) {
		// http://stackoverflow.com/a/26603875
		css += "\n/*# sourceMappingURL=data:application/json;base64," + btoa(unescape(encodeURIComponent(JSON.stringify(sourceMap)))) + " */";
	}

	var blob = new Blob([css], { type: "text/css" });

	var oldSrc = link.href;

	link.href = URL.createObjectURL(blob);

	if(oldSrc) URL.revokeObjectURL(oldSrc);
}


/***/ }),

/***/ "./node_modules/style-loader/lib/urls.js":
/*!***********************************************!*\
  !*** ./node_modules/style-loader/lib/urls.js ***!
  \***********************************************/
/*! no static exports found */
/***/ (function(module, exports) {


/**
 * When source maps are enabled, `style-loader` uses a link element with a data-uri to
 * embed the css on the page. This breaks all relative urls because now they are relative to a
 * bundle instead of the current page.
 *
 * One solution is to only use full urls, but that may be impossible.
 *
 * Instead, this function "fixes" the relative urls to be absolute according to the current page location.
 *
 * A rudimentary test suite is located at `test/fixUrls.js` and can be run via the `npm test` command.
 *
 */

module.exports = function (css) {
  // get current location
  var location = typeof window !== "undefined" && window.location;

  if (!location) {
    throw new Error("fixUrls requires window.location");
  }

	// blank or null?
	if (!css || typeof css !== "string") {
	  return css;
  }

  var baseUrl = location.protocol + "//" + location.host;
  var currentDir = baseUrl + location.pathname.replace(/\/[^\/]*$/, "/");

	// convert each url(...)
	/*
	This regular expression is just a way to recursively match brackets within
	a string.

	 /url\s*\(  = Match on the word "url" with any whitespace after it and then a parens
	   (  = Start a capturing group
	     (?:  = Start a non-capturing group
	         [^)(]  = Match anything that isn't a parentheses
	         |  = OR
	         \(  = Match a start parentheses
	             (?:  = Start another non-capturing groups
	                 [^)(]+  = Match anything that isn't a parentheses
	                 |  = OR
	                 \(  = Match a start parentheses
	                     [^)(]*  = Match anything that isn't a parentheses
	                 \)  = Match a end parentheses
	             )  = End Group
              *\) = Match anything and then a close parens
          )  = Close non-capturing group
          *  = Match anything
       )  = Close capturing group
	 \)  = Match a close parens

	 /gi  = Get all matches, not the first.  Be case insensitive.
	 */
	var fixedCss = css.replace(/url\s*\(((?:[^)(]|\((?:[^)(]+|\([^)(]*\))*\))*)\)/gi, function(fullMatch, origUrl) {
		// strip quotes (if they exist)
		var unquotedOrigUrl = origUrl
			.trim()
			.replace(/^"(.*)"$/, function(o, $1){ return $1; })
			.replace(/^'(.*)'$/, function(o, $1){ return $1; });

		// already a full url? no change
		if (/^(#|data:|http:\/\/|https:\/\/|file:\/\/\/|\s*$)/i.test(unquotedOrigUrl)) {
		  return fullMatch;
		}

		// convert the url to a full url
		var newUrl;

		if (unquotedOrigUrl.indexOf("//") === 0) {
		  	//TODO: should we add protocol?
			newUrl = unquotedOrigUrl;
		} else if (unquotedOrigUrl.indexOf("/") === 0) {
			// path should be relative to the base url
			newUrl = baseUrl + unquotedOrigUrl; // already starts with '/'
		} else {
			// path should be relative to current directory
			newUrl = currentDir + unquotedOrigUrl.replace(/^\.\//, ""); // Strip leading './'
		}

		// send back the fixed url(...)
		return "url(" + JSON.stringify(newUrl) + ")";
	});

	// send back the fixed css
	return fixedCss;
};


/***/ }),

/***/ "./node_modules/worker-loader/dist/cjs.js?inline!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js":
/*!***************************************************************************************************************************!*\
  !*** ./node_modules/worker-loader/dist/cjs.js?inline!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js ***!
  \***************************************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

module.exports = function() {
  return __webpack_require__(/*! !./node_modules/worker-loader/dist/workers/InlineWorker.js */ "./node_modules/worker-loader/dist/workers/InlineWorker.js")("/*!\n * LMV v7.11.0\n * \n * Copyright 2020 Autodesk, Inc.\n * All rights reserved.\n * \n * This computer source code and related instructions and comments are the\n * unpublished confidential and proprietary information of Autodesk, Inc.\n * and are protected under Federal copyright and state trade secret law.\n * They may not be disclosed to, copied or used by any third party without\n * the prior written consent of Autodesk, Inc.\n * \n * Autodesk Forge Viewer Usage Limitations:\n * \n * The Autodesk Forge viewer can only be used to view files generated by\n * Autodesk Forge services. The Autodesk Forge Viewer JavaScript must be\n * delivered from an Autodesk hosted URL.\n */\n/******/ (function(modules) { // webpackBootstrap\n/******/ \t// The module cache\n/******/ \tvar installedModules = {};\n/******/\n/******/ \t// The require function\n/******/ \tfunction __webpack_require__(moduleId) {\n/******/\n/******/ \t\t// Check if module is in cache\n/******/ \t\tif(installedModules[moduleId]) {\n/******/ \t\t\treturn installedModules[moduleId].exports;\n/******/ \t\t}\n/******/ \t\t// Create a new module (and put it into the cache)\n/******/ \t\tvar module = installedModules[moduleId] = {\n/******/ \t\t\ti: moduleId,\n/******/ \t\t\tl: false,\n/******/ \t\t\texports: {}\n/******/ \t\t};\n/******/\n/******/ \t\t// Execute the module function\n/******/ \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n/******/\n/******/ \t\t// Flag the module as loaded\n/******/ \t\tmodule.l = true;\n/******/\n/******/ \t\t// Return the exports of the module\n/******/ \t\treturn module.exports;\n/******/ \t}\n/******/\n/******/\n/******/ \t// expose the modules object (__webpack_modules__)\n/******/ \t__webpack_require__.m = modules;\n/******/\n/******/ \t// expose the module cache\n/******/ \t__webpack_require__.c = installedModules;\n/******/\n/******/ \t// define getter function for harmony exports\n/******/ \t__webpack_require__.d = function(exports, name, getter) {\n/******/ \t\tif(!__webpack_require__.o(exports, name)) {\n/******/ \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n/******/ \t\t}\n/******/ \t};\n/******/\n/******/ \t// define __esModule on exports\n/******/ \t__webpack_require__.r = function(exports) {\n/******/ \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n/******/ \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n/******/ \t\t}\n/******/ \t\tObject.defineProperty(exports, '__esModule', { value: true });\n/******/ \t};\n/******/\n/******/ \t// create a fake namespace object\n/******/ \t// mode & 1: value is a module id, require it\n/******/ \t// mode & 2: merge all properties of value into the ns\n/******/ \t// mode & 4: return value when already ns object\n/******/ \t// mode & 8|1: behave like require\n/******/ \t__webpack_require__.t = function(value, mode) {\n/******/ \t\tif(mode & 1) value = __webpack_require__(value);\n/******/ \t\tif(mode & 8) return value;\n/******/ \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n/******/ \t\tvar ns = Object.create(null);\n/******/ \t\t__webpack_require__.r(ns);\n/******/ \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n/******/ \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n/******/ \t\treturn ns;\n/******/ \t};\n/******/\n/******/ \t// getDefaultExport function for compatibility with non-harmony modules\n/******/ \t__webpack_require__.n = function(module) {\n/******/ \t\tvar getter = module && module.__esModule ?\n/******/ \t\t\tfunction getDefault() { return module['default']; } :\n/******/ \t\t\tfunction getModuleExports() { return module; };\n/******/ \t\t__webpack_require__.d(getter, 'a', getter);\n/******/ \t\treturn getter;\n/******/ \t};\n/******/\n/******/ \t// Object.prototype.hasOwnProperty.call\n/******/ \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n/******/\n/******/ \t// __webpack_public_path__\n/******/ \t__webpack_require__.p = \"\";\n/******/\n/******/\n/******/ \t// Load entry module and return exports\n/******/ \treturn __webpack_require__(__webpack_require__.s = \"./node_modules/babel-loader/lib/index.js?!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js\");\n/******/ })\n/************************************************************************/\n/******/ ({\n\n/***/ \"./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js\":\n/*!*****************************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js ***!\n  \\*****************************************************************************/\n/*! exports provided: InputStreamML */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"InputStreamML\", function() { return InputStreamML; });\nvar pako = __webpack_require__(/*! pako */ \"./node_modules/pako/index.js\");\n\n\"use strict\";\n\n\n/** @constructor */\n// This class will read value from compressed data,\n// decopress only necessary data and throw away unused.\nfunction InputStreamML(buf, usize) {\n\n  // Offset is the offset to decompressed data.\n  // byteLength is the total size of decompressed data.\n  this.offset = 0;\n  this.byteLength = usize;\n  this.range = 0;\n  // Assume the buffer is compressed.\n  this.compressedBuffer = buf;\n  this.compressedByteLength = buf.length;\n  this.compressedOffset = 0;\n  this.decompressEnd = false;\n  // This is to record how many times decompress from scratch. for debug purpose.\n  this.resetCount = 0;\n\n  //We will use these shared memory arrays to\n  //convert from bytes to the desired data type.\n  this.convBuf = new ArrayBuffer(8);\n  this.convUint8 = new Uint8Array(this.convBuf);\n  this.convUint16 = new Uint16Array(this.convBuf);\n  this.convInt32 = new Int32Array(this.convBuf);\n  this.convUint32 = new Uint32Array(this.convBuf);\n  this.convFloat32 = new Float32Array(this.convBuf);\n  this.convFloat64 = new Float64Array(this.convBuf);\n\n  // Compressed chunk size is the size for decompressing each time.\n  // Decompressed chunk size is the buffer to hold decompressed data.\n  this.COMPRESSED_chunk_SIZE = 512 * 1024;\n  this.DECOMPRESSED_chunk_SIZE = 256 * 1024;\n\n  // chunks for decompressed data.\n  this.chunks = [];\n  this.chunksByteLengthMax = 0;\n  this.chunksByteLengthMin = 0;\n\n  // Maintain chunk and chunk offset for reading current data.\n  this.chunkPointer = null;\n  this.chunkOffset = 0;\n  // temp chunk is for reading data that stride over multiple chunks.\n  this.tempchunk = {\n    startIdx: 0,\n    endIdx: 0,\n    buffer: null };\n\n\n  // Infalte for decompressing incremantally. The lib we used is pako_inflate.min.js\n  this.inflate = this.getInflate();\n\n  // Prepare first 1K data for quick access.\n  this.prepare(0, 1024);\n}\n\nInputStreamML.prototype.getInflate = function () {\n  if (!this.inflate) {\n    this.inflate = new pako.Inflate({ level: 3, chunkSize: this.DECOMPRESSED_chunk_SIZE });\n\n    var self = this;\n    this.inflate.onData = function (chunk) {\n\n      // Remove unused chunk for current decompressing.\n      self.chunksByteLengthMax += chunk.byteLength;\n      if (self.chunksByteLengthMax < self.offset) {\n        chunk = null;\n        self.chunksByteLengthMin = self.chunksByteLengthMax;\n      }\n\n      self.chunks.push(chunk);\n    };\n\n    this.inflate.onEnd = function () {\n      self.decompressEnd = true;\n      self.inflate = null;\n      // Check decompressed size is expected.\n      if (self.chunksByteLengthMax != self.byteLength)\n      throw \"Decompress error, unexpected size.\";\n    };\n  }\n\n  return this.inflate;\n};\n\nInputStreamML.prototype.prepare = function (off, range, donotclear) {\n  // If required data hasn't decompressed yet, let's do it.\n  if (this.chunksByteLengthMin > off) {\n    // In this case, need to reset stream and decompress from scratch again.\n    this.reset();\n    this.offset = off;\n    this.range = range;\n  }\n\n  // Remove unused chunks if no longer used for subsequent reading.\n  if (!donotclear) {\n    var idx = Math.floor(off / this.DECOMPRESSED_chunk_SIZE);\n    var startIdx = Math.floor(this.chunksByteLengthMin / this.DECOMPRESSED_chunk_SIZE);\n    var endIdx = this.chunks.length < idx ? this.chunks.length : idx;\n    for (var i = startIdx; i < endIdx; i++) {\n      this.chunks[i] = null;\n    }\n    this.chunksByteLengthMin = endIdx * this.DECOMPRESSED_chunk_SIZE;\n  }\n\n  // Prepare further decompressed data.\n  var range = range || 1;\n  var expectEnd = off + range;\n  expectEnd = expectEnd > this.byteLength ? this.byteLength : expectEnd;\n  var reachEnd = false;\n  while (expectEnd > this.chunksByteLengthMax)\n  {\n    var len = this.COMPRESSED_chunk_SIZE;\n    if (this.compressedOffset + len >= this.compressedByteLength) {\n      len = this.compressedByteLength - this.compressedOffset;\n      reachEnd = true;\n    }\n\n    // Push another compressed data chunk to decompress.\n    var data = new Uint8Array(this.compressedBuffer.buffer, this.compressedOffset, len);\n    this.getInflate().push(data, reachEnd);\n\n    // Move offset forward as decompress processing.\n    this.compressedOffset += len;\n\n    if (reachEnd) {\n      break;\n    }\n  }\n\n};\n\nInputStreamML.prototype.ensurechunkData = function (len) {\n  // ensure the data is ready for immediate reading.\n  len = len || 1;\n  var chunkLen = this.chunks.length;\n\n  var chunkIdx = Math.floor(this.offset / this.DECOMPRESSED_chunk_SIZE);\n  var endIdx = Math.floor((this.offset + len - 1) / this.DECOMPRESSED_chunk_SIZE);\n  if (endIdx >= chunkLen) {\n    var length = (endIdx - chunkLen + 1) * this.DECOMPRESSED_chunk_SIZE;\n    // When do another prepare in the middle of ensuring data,\n    // do not clear any chunk yet, as it may be still in use.\n    this.prepare(this.DECOMPRESSED_chunk_SIZE * chunkLen, length, true);\n  }\n\n  if (chunkIdx < endIdx) {\n    if (this.tempchunk.startIdx > chunkIdx || this.tempchunk.endIdx < endIdx) {\n      var size = (endIdx - chunkIdx + 1) * this.DECOMPRESSED_chunk_SIZE;\n      this.tempchunk.buffer = new Uint8Array(size);\n      var pos = 0;\n      for (var i = chunkIdx; i <= endIdx; i++) {\n        this.tempchunk.buffer.set(this.chunks[i], pos);\n        pos += this.DECOMPRESSED_chunk_SIZE;\n      }\n      this.tempchunk.startIdx = chunkIdx;\n      this.tempchunk.endIdx = endIdx;\n    }\n    this.chunkPointer = this.tempchunk.buffer;\n  } else\n  {\n    this.chunkPointer = this.chunks[chunkIdx];\n  }\n\n  this.chunkOffset = this.offset - chunkIdx * this.DECOMPRESSED_chunk_SIZE;\n  this.offset += len;\n};\n\nInputStreamML.prototype.seek = function (off, range, donotclear) {\n  this.offset = off;\n  this.range = range;\n  this.prepare(off, range, donotclear);\n};\n\nInputStreamML.prototype.getBytes = function (len) {\n  this.ensurechunkData(len);\n  var ret = new Uint8Array(this.chunkPointer.buffer, this.chunkOffset, len);\n\n  return ret;\n};\n\nInputStreamML.prototype.getVarints = function () {\n  var b;\n  var value = 0;\n  var shiftBy = 0;\n  do {\n    this.ensurechunkData();\n    b = this.chunkPointer[this.chunkOffset];\n    value |= (b & 0x7f) << shiftBy;\n    shiftBy += 7;\n  } while (b & 0x80);\n  return value;\n};\n\nInputStreamML.prototype.getUint8 = function () {\n  this.ensurechunkData();\n  return this.chunkPointer[this.chunkOffset];\n};\n\nInputStreamML.prototype.getUint16 = function () {\n\n  this.ensurechunkData();\n  this.convUint8[0] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  this.convUint8[1] = this.chunkPointer[this.chunkOffset];\n  return this.convUint16[0];\n};\n\nInputStreamML.prototype.getInt16 = function () {\n  var tmp = this.getUint16();\n  //make negative integer if the ushort is negative\n  if (tmp > 0x7fff)\n  tmp = tmp | 0xffff0000;\n  return tmp;\n};\n\nInputStreamML.prototype.getInt32 = function () {\n\n  var dst = this.convUint8;\n\n  this.ensurechunkData();\n  dst[0] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[1] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[2] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[3] = this.chunkPointer[this.chunkOffset];\n\n  return this.convInt32[0];\n};\n\nInputStreamML.prototype.getUint32 = function () {\n\n  var dst = this.convUint8;\n\n  this.ensurechunkData();\n  dst[0] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[1] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[2] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[3] = this.chunkPointer[this.chunkOffset];\n\n  return this.convUint32[0];\n};\n\nInputStreamML.prototype.getFloat32 = function () {\n\n  var dst = this.convUint8;\n\n  this.ensurechunkData();\n  dst[0] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[1] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[2] = this.chunkPointer[this.chunkOffset];\n  this.ensurechunkData();\n  dst[3] = this.chunkPointer[this.chunkOffset];\n\n  return this.convFloat32[0];\n};\n\nInputStreamML.prototype.getFloat64 = function () {\n\n  var dst = this.convUint8;\n  for (var i = 0; i < 8; i++) {\n    this.ensurechunkData();\n    dst[i] = this.chunkPointer[this.chunkOffset];\n  }\n\n  return this.convFloat64[0];\n};\n\nInputStreamML.prototype.getString = function (len) {\n  var dst = \"\";\n  this.ensurechunkData(len);\n  var src = this.chunkPointer;\n\n  for (var i = this.chunkOffset, iEnd = this.chunkOffset + len; i < iEnd; i++) {\n    dst += String.fromCharCode(src[i]);\n  }\n\n  var res;\n  try {\n    res = decodeURIComponent(escape(dst));\n  } catch (e) {\n    res = dst;\n    debug(\"Failed to decode string \" + res);\n  }\n\n  return res;\n};\n\nInputStreamML.prototype.reset = function (buf) {\n  this.resetCount++;\n  debug(\"InputStream Less Reset: \" + this.resetCount);\n\n  if (buf) {\n    this.compressedBuffer = buf;\n    this.compressedByteLength = buf.length;\n  }\n\n  this.offset = 0;\n  this.chunks = [];\n  this.chunksByteLengthMax = 0;\n  this.chunksByteLengthMin = 0;\n  this.compressedOffset = 0;\n  this.decompressEnd = false;\n  this.chunkPointer = null;\n  this.chunkOffset = 0;\n  this.inflate = null;\n\n  this.tempchunk.startIdx = 0;\n  this.tempchunk.endIdx = 0;\n  this.tempchunk.buffer = null;\n};\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackReaderML.js\":\n/*!*************************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackReaderML.js ***!\n  \\*************************************************************************/\n/*! exports provided: PackFileReaderML */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PackFileReaderML\", function() { return PackFileReaderML; });\n/* harmony import */ var _src_file_loaders_lmvtk_svf_PackReader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../../src/file-loaders/lmvtk/svf/PackReader */ \"./src/file-loaders/lmvtk/svf/PackReader.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_common_InputStream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../../../src/file-loaders/lmvtk/common/InputStream */ \"./src/file-loaders/lmvtk/common/InputStream.js\");\n/* harmony import */ var _common_InputStreamML__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../common/InputStreamML */ \"./extensions/MemoryLimited/file-loaders/lmvtk/common/InputStreamML.js\");\n\n\n\nvar pako = __webpack_require__(/*! pako */ \"./node_modules/pako/index.js\");\n\n// [BIM customize] Construct a different pack file reader, that use a different input stream\n// implementation that use much less memory.\nfunction PackFileReaderML(data, usize) {\n\n  // When server side (S3 and viewing service) is configured properly,\n  // browser can decompress the pack file for us.\n  // Here the check is for backward compatibility purpose.\n  // ??? we actually rely on the server doesn't configure to let browser do the compress automatically.\n  // ??? Luckily at the moment, seems this is the case.\n  // ??? TODO: if we can't control the decompress on our own, then we have to\n  // ???       chunk fragment list to a reasonable size.\n  var stream;\n  var chunckStreamEnabled = false;\n  if (data[0] == 31 && data[1] == 139) {\n\n    // If usize is specified, we assume it is going to read pack file in a steaming style.\n    if (usize) {\n      // Decompress in a streaming style.\n\n      // Ok, let's use input steam less to decompress data chunck by chunck,\n      // so as to reduce the overall memory footprint.\n      // In theory, to read all the data there are 2 more times decompress needed.\n      // Round 1, decompress and get the first few values and then all the way to the end,\n      //          and get toc/types offset, then throw all.\n      // Round 2, decompress to read content of toc and types only, then throw all.\n      // Round 3, decompress to each offset of fragment, and throw unused decompressed chunck.\n      // However, we could combine 1 and 2 together.\n      chunckStreamEnabled = true;\n      stream = new _common_InputStreamML__WEBPACK_IMPORTED_MODULE_2__[\"InputStreamML\"](data, usize);\n\n      var len = stream.getInt32();\n      this.type = stream.getString(len);\n      this.version = stream.getInt32();\n\n      // To reduce the times for re-decompress the data, let's prepare the data\n      // for both round 1 and 2 cases.\n      var off = Math.floor(stream.byteLength * 0.9);\n      stream.seek(off, stream.byteLength - off);\n    } else\n    {\n      // Decompress all at once, and use InputStream to read.\n      data = pako.ungzip(data);\n\n      stream = new _src_file_loaders_lmvtk_common_InputStream__WEBPACK_IMPORTED_MODULE_1__[\"InputStream\"](data);\n\n      var len = stream.getInt32();\n      this.type = stream.getString(len);\n      this.version = stream.getInt32();\n\n    }\n  } else\n\n  {\n    // Already decopressed, so use InputStream.\n    // Input stream read data from the source that is alreay decompressed.\n    stream = new _src_file_loaders_lmvtk_common_InputStream__WEBPACK_IMPORTED_MODULE_1__[\"InputStream\"](data);\n  }\n\n  this.stream = stream;\n  this.types = null;\n  this.entryOffsets = [];\n\n  //read the table of contents\n  {\n    // Jump to file footer.\n    stream.seek(stream.byteLength - 8, 8, chunckStreamEnabled);\n\n    // Jump to toc.\n    var tocOffset = stream.getUint32();\n    this.typesOffset = stream.getUint32();\n\n    // Populate type sets.\n    stream.seek(this.typesOffset, 1, chunckStreamEnabled);\n    var typesCount = this.readU32V();\n    this.types = [];\n    for (var i = 0; i < typesCount; ++i) {\n      this.types.push({\n        \"entryClass\": this.readString(),\n        \"entryType\": this.readString(),\n        \"version\": this.readU32V() });}\n\n\n    // Populate data offset list.\n    stream.seek(tocOffset, 1, chunckStreamEnabled);\n    var entryCount = this.readU32V();\n    var dso = this.entryOffsets;\n    for (var i = 0; i < entryCount; ++i) {\n      dso.push(stream.getUint32());}\n\n    // Restore sanity of the world.\n    stream.seek(0);\n  }\n};\n\nPackFileReaderML.prototype = Object.create(_src_file_loaders_lmvtk_svf_PackReader__WEBPACK_IMPORTED_MODULE_0__[\"PackFileReader\"].prototype);\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackageML.js\":\n/*!**********************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackageML.js ***!\n  \\**********************************************************************/\n/*! exports provided: PackageML */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PackageML\", function() { return PackageML; });\n/* harmony import */ var _src_compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../../src/compat */ \"./src/compat.js\");\n/* harmony import */ var _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../../../src/file-loaders/net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\n/* harmony import */ var _src_wgs_scene_BVHBuilder__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../../../src/wgs/scene/BVHBuilder */ \"./src/wgs/scene/BVHBuilder.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../../../src/file-loaders/lmvtk/svf/Package.js */ \"./src/file-loaders/lmvtk/svf/Package.js\");\n/* harmony import */ var _PackReaderML__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./PackReaderML */ \"./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackReaderML.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_common_SvfPlacementUtils__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../../../../src/file-loaders/lmvtk/common/SvfPlacementUtils */ \"./src/file-loaders/lmvtk/common/SvfPlacementUtils.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_svf_Fragments__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ../../../../../src/file-loaders/lmvtk/svf/Fragments */ \"./src/file-loaders/lmvtk/svf/Fragments.js\");\n\n\n\n\n\n\n\n\n\n\n// Threshold to enable loading/handling fragments and geometry metadata in a memory optimized way.\n// 6 Mb for weak device, 32 Mb for others. And the size is the compressed size.\n// TODO: adjust threshold according to different devices.\nvar MAX_FRAGMENT_PACK_SIZE = Object(_src_compat__WEBPACK_IMPORTED_MODULE_0__[\"isMobileDevice\"])() ? 6 * 1024 * 1024 : 32 * 1024 * 1024;\n\nfunction PackageML(zipPack) {\n  _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].call(this, zipPack);\n\n  // This is the flag to represent whether an aggresive memory constrained mode is in use\n  // to read/parse fragment and geometry metadata and how to post process. \n  this.memoryOptimizedMode = false;\n\n  // This is the object that will be used for pending geometry metadata load until fragment is ready,\n  // so that can process the most memory hunger process one by one.\n  this.pendingGeometryMetadataLoad = {};\n};\n\nPackageML.prototype = Object.create(_src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].prototype);\nPackageML.prototype.constructor = PackageML;\n\nPackageML.prototype.loadAsyncResource = function (loadContext, resourcePath, contents, callback, skipDecompress) {\n  // [BIM customize] by passing an additional paramter - skipDecompress, to control\n  //                 whether request to decompress right after getting the data or \n  //                 decompress it later (for memory consumption concern)\n\n  //Data is immediately available from the SVF zip\n  if (contents) {\n    callback(contents);\n    return;\n  }\n\n  //Launch an XHR to load the data from external file\n  var svf = this;\n\n  this.pendingRequests++;\n\n  function xhrCB(responseData) {\n    svf.pendingRequests--;\n\n    callback(responseData);\n\n    if (svf.pendingRequests == 0)\n    svf.postLoad(loadContext);\n  }\n\n  _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_1__[\"ViewingService\"].getItem(loadContext, loadContext.basePath + resourcePath,\n  xhrCB,\n  loadContext.onFailureCallback,\n  {\n    skipDecompress: skipDecompress });\n\n};\n\nPackageML.prototype.parseFragmentList = function (asset, loadContext, path, contents) {\n  // [BIM customize] The main change for parsing the fragment list is that,\n  // 1. If the uncompressed size is larger than the threshold of current allowed size,\n  //    then go with below process,\n  //    1.1 pending geometry metadata loading if it comes first.\n  //    1.2 load fragment list and specify 'skipDecompress' to be true.\n  //    1.3 read and parse fragments, as the data is still gzipped so it will choose a \n  //        different stream reader to read the data chunk by chunk.\n  //    1.4 load geometry metadata and also specify 'skipDecompress' to be true.\n  //    1.5 parse geometry metadata and read it into fragment data directly. \n  //        (this can also reduce some temporary memory used in post load processing.)\n  // 2. Otherwise, go with the normal workflow, which is almost the same as its parent implementation,\n  //    \n\n  // Enable the memory optimized handling when fragment pack file is too big.\n  this.memoryOptimizedMode = loadContext.perfOpt.forceMemoryOptimizedMode || asset[\"size\"] > MAX_FRAGMENT_PACK_SIZE;\n\n  debug(\"PackageML: memory optimized mode: \" + this.memoryOptimizedMode);\n\n  var self = this;\n  this.loadAsyncResource(loadContext, path, contents, function (data) {\n\n    var usize = asset[\"usize\"];\n    var pfr = new _PackReaderML__WEBPACK_IMPORTED_MODULE_4__[\"PackFileReaderML\"](data, usize);\n\n    var frags = self.fragments = new _src_file_loaders_lmvtk_svf_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"FragList\"]();\n    var offset = Object(_src_file_loaders_lmvtk_svf_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"readFragments\"])(pfr, frags, loadContext.globalOffset, loadContext.placementTransform,\n    loadContext.fragmentTransformsDouble, loadContext.objectIds, self.bbox, self.globalOffset);\n\n    pfr = null;\n\n    self.applyLargeBoxOffset(offset);\n\n    // If there is pending geometry metadata load request (as a result of enabled optimization\n    // code path to read geometry metadata directly into fragments instead of read separately then\n    // combine with fragments), then start to load it now after fragment list is ready.\n    if (self.memoryOptimizedMode && self.pendingGeometryMetadataLoad.path) {\n      self.loadAsyncResource(loadContext, self.pendingGeometryMetadataLoad.path, self.pendingGeometryMetadataLoad.contents, function (data) {\n\n        var pfr = new _PackReaderML__WEBPACK_IMPORTED_MODULE_4__[\"PackFileReaderML\"](data, self.pendingGeometryMetadataLoad.usize);\n        debug(\"PackageML: read geometry metadata into fragment directly.\");\n        self.primitiveCount = Object(_src_file_loaders_lmvtk_svf_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"readGeometryMetadataIntoFragments\"])(pfr, self.fragments);\n        self.numGeoms = pfr.getEntryCounts();\n        pfr = null;\n        self.pendingGeometryMetadataLoad.contents = null;\n      }, self.memoryOptimizedMode);\n    }\n  }, self.memoryOptimizedMode);\n\n  // If fragment reading optimization not enabled and there is a pending geometry metadata load request, \n  // then load geometry data right away as usual.\n  if (!this.memoryOptimizedMode && this.pendingGeometryMetadataLoad.path) {\n    var path = this.pendingGeometryMetadataLoad.path;\n    var contents = this.pendingGeometryMetadataLoad.contents;\n    this.pendingGeometryMetadataLoad = {};\n\n    // Then fallback to the normal way of parsing geometry metadata.\n    debug(\"PackageML: read geometry metadata as usual.\");\n    _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].prototype.parseGeometryMetadata.call(this, null, loadContext, path, contents);\n  }\n};\n\nPackageML.prototype.parseGeometryMetadata = function (asset, loadContext, path, contents) {\n  // [BIM customize] the sequence of reading fragment and geometry metadata is not fixed. So, \n  // 1. If fragments is ready first, then load geometry metadata and read into fragment directly,\n  //    no matter memory optimized mode is true or not.\n  // 2. If fragments is not ready yet, pending geometry metadata loading, and decide when to\n  //    load it after memory optimized mode is set.\n\n  var usize = asset[\"usize\"];\n\n  if (this.fragments) {\n    var self = this;\n    this.loadAsyncResource(loadContext, path, contents, function (data) {\n\n      var pfr = new _PackReaderML__WEBPACK_IMPORTED_MODULE_4__[\"PackFileReaderML\"](data, usize);\n      self.primitiveCount = Object(_src_file_loaders_lmvtk_svf_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"readGeometryMetadataIntoFragments\"])(pfr, self.fragments);\n      self.numGeoms = pfr.getEntryCounts();\n      pfr = null;\n    }, self.memoryOptimizedMode);\n  } else\n  {\n    this.pendingGeometryMetadataLoad.path = path;\n    this.pendingGeometryMetadataLoad.contents = contents;\n    this.pendingGeometryMetadataLoad.usize = usize;\n  }\n\n};\n\nPackageML.prototype.postLoadOfFragments = function (loadContext) {\n  // [BIM customize] If memory optimized mode is not set, then go with \n  // the normal workflow.\n  if (!this.memoryOptimizedMode) {\n    _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].prototype.postLoadOfFragments.call(this, loadContext);\n  } else\n  {\n    // Otherwise, only calculate mesh2frag, which may be missing if\n    // this file is old and hasn't got any geometry metadata. Because, \n    // * Geometry metadata has already been read into fragments list.\n    if (!this.fragments.mesh2frag)\n    this.calculateMesh2Frag(this.fragments);\n  }\n};\n\nPackageML.prototype.postLoadOfObjectIds = function (loadContext) {\n  // [BIM customize] If memory optimized mode is not set, then go with \n  // the normal workflow.\n  if (!this.memoryOptimizedMode) {\n    _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].prototype.postLoadOfObjectIds.call(this, loadContext);\n  } else\n  {\n    // Otherwise, clean up unused pack files.\n    // The implementation is different from its parent, because the fragments are\n    // filtered right away after reading it so that the pack ids only represents\n    // the used ones, so can direct remove the geompacks which are not used any more.\n    if (loadContext.objectIds && loadContext.objectIds.length > 0) {\n      // Find out how many pack files are really used.\n      var len = this.geompacks.length,\n      frags = this.fragments,\n      i = 0;\n      var usedPackFile = new Int8Array(len);\n\n      for (i = 0; i < frags.packIds.length; i++) {\n        // Set 0xF to the index which the pack id is used.\n        usedPackFile[frags.packIds[i]] = 0xF;\n      }\n\n      var pt = 0;\n      for (i = 0; i < usedPackFile.length; i++) {\n        if (usedPackFile[i] === 0xF) {\n          this.geompacks[pt] = this.geompacks[i];\n          pt++;\n        }\n      }\n\n      // Cut unused one.\n      if (pt < len) {\n        this.geompacks.splice(pt, len - pt);\n      }\n\n    }\n  }\n};\n\nPackageML.prototype.postLoadComplete = function (loadContext) {\n  // [BIM customize] If memory optimized mode is on, then \n  // Delay posting SVF by waiting until BVH build finishes;\n  // then post both BVH and SVF to main thread together.\n  if (!this.memoryOptimizedMode) {\n    _src_file_loaders_lmvtk_svf_Package_js__WEBPACK_IMPORTED_MODULE_3__[\"Package\"].prototype.postLoadComplete.call(this, loadContext);\n  } else\n  {\n\n    if (this.fragments.polygonCounts) {\n      //Build the R-Tree\n      var t0 = performance.now();\n      var mats = this.materials ? this.materials[\"materials\"] : null;\n      if (mats)\n      this.addTransparencyFlagsToMaterials(mats);\n      this.bvh = new _src_wgs_scene_BVHBuilder__WEBPACK_IMPORTED_MODULE_2__[\"BVHBuilder\"](this.fragments, mats);\n      this.bvh.build(loadContext.bvhOptions);\n      var t1 = performance.now();\n      loadContext.worker.debug(\"BVH build time (worker thread):\" + (t1 - t0));\n\n    }\n\n    loadContext.loadDoneCB(\"svf\");\n\n    loadContext.loadDoneCB(\"done\");\n  }\n};\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/file-loaders/workers/LoadOrderWorker.js\":\n/*!**************************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/workers/LoadOrderWorker.js ***!\n  \\**************************************************************************/\n/*! exports provided: register */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"register\", function() { return register; });\n/* harmony import */ var _src_wgs_scene_FrustumIntersector__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../src/wgs/scene/FrustumIntersector */ \"./src/wgs/scene/FrustumIntersector.js\");\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! three */ \"./extensions/MemoryLimited/thirdparty/three.js/three-worker.js\");\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_1___default = /*#__PURE__*/__webpack_require__.n(three__WEBPACK_IMPORTED_MODULE_1__);\n\n\n\n\"use strict\";\n\nvar FRAGMENTS_STRIDE = 6;\n\n// not necessary, just for prototyping stats gathering\n//var _stat_weighttime_t1, _stat_weighttime_t0, _stat_sorttime_t1, _stat_sorttime_t0, _stat_rbtime_t1, _stat_rbtime_t0;\n\n// set to true to show PF list order\n//var _showGeometryPFlist = false;\n\n/**\n * All rendering and other scene related data associated with a 3D model or 2D Drawing.\n * This variant creates a sorted order and render batches based on the frustum view.\n * @constructor\n */\nfunction SBLOrderCalculator() {\n\n  var _tmpBox = new three__WEBPACK_IMPORTED_MODULE_1__[\"Box3\"]();\n\n  var _frags;\n  var _buildfragCount;\n  var _pixelCullingThreshold = 1;\n\n  var _numPFs;\n  var _minPF, _maxPF;\n  var _pfWeight;\n  var _pfInverse;\n\n  var _fragWeights;\n\n  var _visibleCount;\n\n  var _frustum = new _src_wgs_scene_FrustumIntersector__WEBPACK_IMPORTED_MODULE_0__[\"FrustumIntersector\"]();\n  var _frs = new three__WEBPACK_IMPORTED_MODULE_1__[\"Frustum\"]();\n  var _changed = true;\n\n  // number of visible PFs after culling\n  var _pfVisible = 0;\n\n\n  this.setFragments = function (fragments) {\n    _frags = fragments;\n    _buildfragCount = fragments.packIds.length;\n    _minPF = Infinity, _maxPF = -Infinity;\n\n    // Get the pack Id range\n    for (var i = 0; i < _buildfragCount; i++) {\n      var pf = _frags.packIds[i];\n      _minPF = Math.min(_minPF, pf);\n      _maxPF = Math.max(_maxPF, pf);\n    }\n    _numPFs = _maxPF + 1;\n    if (_numPFs < 0)\n    return { error: \"Empty fragment list\" };\n\n    _pfWeight = new Float32Array(_numPFs);\n    _pfInverse = new Int32Array(_numPFs);\n    _fragWeights = new Float32Array(_buildfragCount);\n    _visibleCount = _buildfragCount;\n    _changed = true;\n  };\n\n  function getFragmentBox(index, dst) {\n    var off = index * FRAGMENTS_STRIDE;\n    var src = _frags.boxes;\n    dst.min.x = src[off];\n    dst.min.y = src[off + 1];\n    dst.min.z = src[off + 2];\n    dst.max.x = src[off + 3];\n    dst.max.y = src[off + 4];\n    dst.max.z = src[off + 5];\n  }\n\n  function weightAndSort() {\n    //_stat_weighttime_t0 = performance.now();\n    var i, tmp;\n    _pfVisible = _numPFs;\n    var pfOrder = new Int32Array(_numPFs);\n    var fragOrder = new Int32Array(_buildfragCount);\n\n    // by default, the load order is the LMVTK order if no other strategy sets it.\n    for (i = 0; i < _numPFs; i++) {\n      pfOrder[i] = i;\n    }\n\n    _visibleCount = 0;\n    var pixelCullArea = _pixelCullingThreshold / _frustum.areaConv;\n    var initialWeight = 0;\n    for (i = 0; i < _numPFs; i++) {\n      _pfWeight[i] = initialWeight;\n    }\n    var weight;\n    for (i = 0; i < _buildfragCount; i++) {\n      // For the distance methods, we run through all fragments again and discard ones with weight of 0.\n      // So we must initialize and not throw away without setting the weight to 0.\n      _fragWeights[i] = 0;\n\n      getFragmentBox(i, _tmpBox);\n      var intersects = _frustum.intersectsBox(_tmpBox);\n\n      // we always use culling\n      if (intersects !== _src_wgs_scene_FrustumIntersector__WEBPACK_IMPORTED_MODULE_0__[\"FrustumIntersector\"].OUTSIDE) {\n        // weight by screen size\n        weight = _frustum.projectedBoxArea(_tmpBox, intersects === _src_wgs_scene_FrustumIntersector__WEBPACK_IMPORTED_MODULE_0__[\"FrustumIntersector\"].CONTAINS);\n\n        //_fragWeights[i] = BVHModule.box_area(this.finfo.boxes, this.finfo.boxStride*i);\n        // is it not tiny?\n        if (weight > pixelCullArea) {\n          // is strategy sorting by packIds?\n          _pfWeight[_frags.packIds[i]] += weight;\n          fragOrder[_visibleCount++] = i;\n        }\n      }\n    }\n\n    //_stat_sorttime_t0 = performance.now();\n\n    //_first_transparent = _fragCount - _numTransparent;\n\n    /*\n    if ( _showGeometryPFlist ) {\n        console.log( \"Unsorted PF list:\" );\n        for (i = 0; i < _numPFs; i++) {\n            console.log( \"  geometry PF \" + i + \" has a weight of \" + _pfWeight[i]);\n        }\n    }\n    */\n\n    // sort the PF list - needed only if we move to returning the PF order instead of fragments\n    Array.prototype.sort.call(pfOrder, function (a, b) {\n      return _pfWeight[b] - _pfWeight[a];\n    });\n\n    //if ( _showGeometryPFlist ) {\n    //    console.log( \"Sorted PF list:\" );\n    //    for (i = 0; i < _numPFs; i++) {\n    //        console.log( \"  \" +i+ \": geometry PF \" + pfOrder[i] + \" has a weight of \" + _pfWeight[pfOrder[i]]);\n    //    }\n    //}\n\n    // Now sort the fragments by their PF order. Give each fragment\n    // the weight of the PF it's in, then sort.\n    // pfOrder is the ideal order for loading PFs, by whatever our criterion is.\n    // Given the packId of the fragment, _frags.packIds[tmp[i]], we\n    // want to set the fragment's weight to the *place* in this \"ideal\" PF order.\n    // For example, if pfOrder is 12,20,88, it means that any fragment in PF=12\n    // wants a weight of 0, PF=20 a weight of 1, PF=88 a weight of 2, etc.\n    // So we need to take the pfOrder and make the inverse lookup:\n    // _pfInverse[12] = 0, _pfInverse[20] = 1, _pfInverse[88] = 2.\n    // Set the weights to be the PF order numbers, sort low to high.\n    for (i = 0; i < _numPFs && _pfWeight[pfOrder[i]] > 0; i++) {\n      _pfInverse[pfOrder[i]] = i;\n    }\n    _pfVisible = i;\n\n    tmp = fragOrder.subarray(0, _visibleCount);\n    for (i = 0; i < _visibleCount; i++) {\n      //_fragWeights[i] = pfOrder[_frags.packIds[fragOrder[i]]];\n      _fragWeights[tmp[i]] = _pfInverse[_frags.packIds[tmp[i]]];\n    }\n    Array.prototype.sort.call(tmp, function (a, b) {\n      return _fragWeights[a] - _fragWeights[b];\n    });\n\n    // purely for code debugging - walk through all fragments and look for one's position\n    /*\n    for (i = 0; i < _visibleCount; i++) {\n        //_fragWeights[i] = pfOrder[_frags.packIds[fragOrder[i]]];\n        if ( tmp[i] === 7812 )\n            tmp[i] === 7812;\n    }\n    */\n\n    //_stat_sorttime_t1 = performance.now();\n    //_stat_weighttime_t1 = performance.now();\n\n    return { fragOrder: fragOrder, packOrder: pfOrder, pfVisible: _pfVisible };\n  }\n\n  function buildList() {\n\n    // given fragment bounding boxes and frustum, figure out a value for each fragment and sort them\n    return weightAndSort();\n  }\n\n  function frustumsEqual(frs, f2) {\n    var i;\n    for (i = 0; i < 6; i++) {\n      var p1 = frs.planes[i];\n      var p2 = f2.planes[i];\n      if (p1.constant !== p2.constant)\n      return false;\n      if (!p1.normal.equals(p2.normal))\n      return false;\n    }\n    return true;\n  }\n\n  this.calculateStep = function () {\n    if (!_changed)\n    return {};\n\n    _changed = false;\n    //var t0 = performance.now();\n    var loadOrder = buildList();\n    //var t1 = performance.now();\n    //console.log(\"SBL total build time: \" + trimPrecision(t1 - t0) + \" for strategy PACKFILE_SUMMED_EXACT\" );\n    //console.log(\"    for weighting: \" + trimPrecision((_stat_weighttime_t1-_stat_weighttime_t0)-(_stat_sorttime_t1-_stat_sorttime_t0))\n    //    + \", for sorting: \" + trimPrecision(_stat_sorttime_t1-_stat_sorttime_t0)\n    //    + \", for render batch creation: \" + trimPrecision(_stat_rbtime_t1-_stat_rbtime_t0));\n    //\n    //console.log(\"  PF stats: for \" + _numPFs + \" PFs, \" + _pfVisible + \" have anything visible; \"\n    //+ trimPrecision(100*_pfVisible/_numPFs) + \"% visible.\");\n\n    return loadOrder;\n  };\n\n  // for making console.log floats show just a few digits of precision\n  //function trimPrecision(val) {\n  //    var mul = 1;\n  //    if ( val >= 1 ) {\n  //        // two decimal places precision for numbers >= 1\n  //        mul = 100;\n  //    } else {\n  //        // untested... TODO. Idea is to give significant bits, i.e. 0.0001123123\n  //        // should have log10 of -3.9... goes to -4, goes to 4, 10^6 is 1000000,\n  //        // gives 112.3123, rounds to 112, then goes back to 0.000112.\n  //        mul = Math.pow(10,2+Math.floor(-Math.log10(val)));\n  //    }\n  //    return Math.round(val*mul)/mul;\n  //}\n\n  // restart iterator\n  this.setFrustum = function (camera, cullingThreshold) {\n    _frustum.reset(camera);\n    _changed = _changed || !frustumsEqual(_frs, _frustum.frustum);\n    _frs.copy(_frustum.frustum);\n    if (typeof cullingThreshold == 'number' && _pixelCullingThreshold != cullingThreshold) {\n      _pixelCullingThreshold = cullingThreshold;\n      _changed = true;\n    }\n    return true;\n  };\n}\n\nfunction calculateLoadOrder(worker, id) {\n  worker.lmv_timer = 0;\n  var result = worker.lmv_calculator.calculateStep();\n  if (result) {\n    var transfer = result.fragOrder ?\n    result.packOrder ? [result.fragOrder.buffer, result.packOrder.buffer] : [result.fragOrder.buffer] :\n    result.packOrder ? [result.packOrder.buffer] : undefined;\n    result.id = id;\n    worker.postMessage(result, transfer);\n  } else {\n    worker.lmv_timer = setTimeout(calculateLoadOrder, 1, worker, id);\n  }\n}\n\nfunction sendError(worker, error) {\n  if (error)\n  worker.postMessage(error);\n}\n\nfunction clearWorkTimer(worker) {\n  if (worker.lmv_timer) {\n    clearTimeout(worker.lmv_timer);\n    worker.lmv_timer = 0;\n  }\n}\n\nfunction doLoadOrder(loadContext) {\n  // Get worker where we keep our work\n  var worker = loadContext.worker;\n\n  var calculator = worker.lmv_calculator;\n  if (!calculator)\n  worker.lmv_calculator = calculator = new SBLOrderCalculator();\n\n  clearWorkTimer(worker);\n\n  // Set the fragment data when we get it\n  if (loadContext.fragments) {\n    sendError(worker, calculator.setFragments(loadContext.fragments));\n  }\n\n  // Calculate the load order when we get a frustum\n  if (loadContext.camera) {\n    calculator.setFrustum(loadContext.camera, loadContext.pixelCullingThreshold);\n    worker.lmv_timer = setTimeout(calculateLoadOrder, 1, worker, loadContext.id);\n  }\n}\n\nfunction register(workerMainML) {\n  workerMainML.register(\"CALCULATE_LOAD_ORDER\", { doOperation: doLoadOrder });\n}\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/file-loaders/workers/MainWorkerML.js\":\n/*!***********************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/workers/MainWorkerML.js ***!\n  \\***********************************************************************/\n/*! exports provided: WorkerMainML, workerMainML */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"WorkerMainML\", function() { return WorkerMainML; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"workerMainML\", function() { return workerMainML; });\n/* harmony import */ var _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../src/file-loaders/net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\n/* harmony import */ var _src_file_loaders_net_endpoints__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../../src/file-loaders/net/endpoints */ \"./src/file-loaders/net/endpoints.js\");\nfunction _classCallCheck(instance, Constructor) {if (!(instance instanceof Constructor)) {throw new TypeError(\"Cannot call a class as a function\");}}function _defineProperties(target, props) {for (var i = 0; i < props.length; i++) {var descriptor = props[i];descriptor.enumerable = descriptor.enumerable || false;descriptor.configurable = true;if (\"value\" in descriptor) descriptor.writable = true;Object.defineProperty(target, descriptor.key, descriptor);}}function _createClass(Constructor, protoProps, staticProps) {if (protoProps) _defineProperties(Constructor.prototype, protoProps);if (staticProps) _defineProperties(Constructor, staticProps);return Constructor;}\n\n\nvar WorkerMainML = /*#__PURE__*/function () {\n\n  function WorkerMainML() {_classCallCheck(this, WorkerMainML);\n    this._workers = {};\n  }_createClass(WorkerMainML, [{ key: \"dispatch\", value: function dispatch(\n    loadContext) {\n\n      if (!loadContext.hasOwnProperty('operation')) {\n        return;\n      }\n\n      //TODO TS:\n      if (loadContext.endpoint)\n      _src_file_loaders_net_endpoints__WEBPACK_IMPORTED_MODULE_1__[\"endpoint\"].setEndpointAndApi(loadContext.endpoint, loadContext.api);\n\n\n      var target = this._workers[loadContext.operation];\n      if (!target)\n      return;\n\n      //Initialize the path that contains the requested\n      //file. It's the root for other relative paths referenced\n      //by the base file.\n      loadContext.basePath = \"\";\n      if (loadContext.url) {\n        var lastSlash = loadContext.url.lastIndexOf(\"/\");\n        if (lastSlash != -1)\n        loadContext.basePath = loadContext.url.substr(0, lastSlash + 1);\n      }\n\n      // Create the default failure callback.\n      //\n      loadContext.raiseError = function () {\n        loadContext.worker.raiseError.apply(loadContext.worker, arguments);\n      };\n      loadContext.onFailureCallback = _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_0__[\"ViewingService\"].defaultFailureCallback.bind(loadContext);\n\n      target.doOperation(loadContext);\n    } }, { key: \"register\", value: function register(\n\n    operation, worker) {\n      this._workers[operation] = worker;\n    } }, { key: \"unregister\", value: function unregister(\n\n    operation) {\n      delete this._workers[operation];\n    } }]);return WorkerMainML;}();\n\n\nvar workerMainML = new WorkerMainML();\n\n//Add all the worker entry points.\n//Those need to execute in order to register themselves\n//with the web worker operation dispatcher\n__webpack_require__(/*! ./SvfWorkerML */ \"./extensions/MemoryLimited/file-loaders/workers/SvfWorkerML.js\").register(workerMainML);\n__webpack_require__(/*! ../../../../src/file-loaders/workers/GeomWorker */ \"./src/file-loaders/workers/GeomWorker.js\").register(workerMainML);\n\n//Not used by Fluent\n__webpack_require__(/*! ./LoadOrderWorker */ \"./extensions/MemoryLimited/file-loaders/workers/LoadOrderWorker.js\").register(workerMainML);\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/file-loaders/workers/SvfWorkerML.js\":\n/*!**********************************************************************!*\\\n  !*** ./extensions/MemoryLimited/file-loaders/workers/SvfWorkerML.js ***!\n  \\**********************************************************************/\n/*! exports provided: register */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"register\", function() { return register; });\n/* harmony import */ var _src_file_loaders_lmvtk_gltf_Gltf__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../../src/file-loaders/lmvtk/gltf/Gltf */ \"./src/file-loaders/lmvtk/gltf/Gltf.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_svf_Package__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../../src/file-loaders/lmvtk/svf/Package */ \"./src/file-loaders/lmvtk/svf/Package.js\");\n/* harmony import */ var _lmvtk_svf_PackageML__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lmvtk/svf/PackageML */ \"./extensions/MemoryLimited/file-loaders/lmvtk/svf/PackageML.js\");\n/* harmony import */ var _src_file_loaders_lmvtk_common_InputStream__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../../src/file-loaders/lmvtk/common/InputStream */ \"./src/file-loaders/lmvtk/common/InputStream.js\");\n/* harmony import */ var _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../../src/file-loaders/net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\n/* harmony import */ var _src_file_loaders_net_ErrorCodes__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ../../../../src/file-loaders/net/ErrorCodes */ \"./src/file-loaders/net/ErrorCodes.js\");\n\n\n\n\n\n\n\nfunction guardFunction(loadContext, func)\n{\n  try {\n    func();\n  }\n  catch (exc) {\n    loadContext.worker.raiseError(\n    _src_file_loaders_net_ErrorCodes__WEBPACK_IMPORTED_MODULE_5__[\"ErrorCodes\"].BAD_DATA, \"Unhandled exception while loading SVF\",\n    { \"url\": loadContext.url, \"exception\": exc.toString(), \"stack\": exc.stack });\n    loadContext.worker.postMessage(null);\n  }\n}\n\nfunction doLoadSvfContinued(loadContext)\n{\n  var _this = loadContext.worker;\n\n  guardFunction(loadContext, function () {\n    var svf = loadContext.svf;\n    function loadDoneCallback(type, meshMessage) {\n      if (type == \"svf\") {\n\n        var msg, xfer;\n        var frags = svf.fragments;\n        var transferable = [\n        frags.transforms.buffer,\n        frags.packIds.buffer,\n        frags.entityIndexes.buffer,\n        frags.fragId2dbId.buffer,\n        frags.visibilityFlags.buffer];\n\n\n        if (svf.bvh) {\n          // BVH is posted together with svf,\n          // so can add more buffer to transfer.\n          xfer = {\n            nodes: svf.bvh.nodes.getRawData(),\n            primitives: svf.bvh.primitives,\n            useLeanNodes: svf.bvh.nodes.bytes_per_node == 32 };\n\n          transferable.push(xfer.nodes);\n          transferable.push(xfer.primitives.buffer);\n\n          // Then can safely transfer following buffers from fragments.\n          transferable.push(frags.boxes.buffer);\n          transferable.push(frags.polygonCounts.buffer);\n          transferable.push(frags.materials.buffer);\n\n          msg = { \"svf\": svf, \"bvh\": xfer, progress: 1.0 };\n        } else\n        {\n          msg = { \"svf\": svf, progress: 0.8 };\n        }\n\n        _this.postMessage(msg, transferable);\n      } else if (type == \"bvh\") {\n        xfer = {\n          nodes: svf.bvh.nodes.getRawData(),\n          primitives: svf.bvh.primitives,\n          useLeanNodes: svf.bvh.nodes.bytes_per_node == 32 };\n\n\n        _this.postMessage({ \"bvh\": xfer, basePath: svf.basePath, progress: 1.0 },\n        [xfer.nodes, xfer.primitives.buffer]);\n\n      } else if (type == \"mesh\") {\n\n        var transferList = [];\n        if (meshMessage.mesh)\n        transferList.push(meshMessage.mesh.vb.buffer);\n\n        _this.postMessage(meshMessage, transferList);\n\n      } else if (type == \"done\") {\n        _this.postMessage({ progress: 1.0 });\n      } else\n      {\n        _this.raiseError(\n        _src_file_loaders_net_ErrorCodes__WEBPACK_IMPORTED_MODULE_5__[\"ErrorCodes\"].BAD_DATA, \"Failure while loading SVF\",\n        { \"url\": loadContext.url });\n        _this.postMessage(null);\n      }\n    }\n\n    loadContext.loadDoneCB = loadDoneCallback;\n\n    svf.loadRemainingSvf(loadContext);\n  });\n}\n\nfunction doLoadSvf(loadContext) {\n\n  var _this = loadContext.worker;\n\n  _this.postMessage({ progress: 0.01 }); //Tell the main thread we are alive\n\n  var type = \"svf\";\n  var url = loadContext.url.toLocaleLowerCase();\n  if (url.lastIndexOf(\".gltf\") === url.length - 5)\n  type = \"gltf\";\n  if (url.lastIndexOf(\".glb\") === url.length - 4)\n  type = \"glb\";\n\n  function onSuccess(result) {\n\n    _this.postMessage({ progress: 0.5 }); //rough progress reporting -- can do better\n\n    guardFunction(loadContext, function () {\n\n      var svf;\n      var packageConfig = {\n        max_pf_files: loadContext.max_pf_files };\n\n      if (type === \"gltf\" || type === \"glb\") {\n        // result is json\n        svf = new _src_file_loaders_lmvtk_gltf_Gltf__WEBPACK_IMPORTED_MODULE_0__[\"GltfPackage\"](result);\n      } else {\n        // result is arraybuffer\n        if (loadContext.perfOpt &&\n        loadContext.perfOpt.memoryOptimizedSvfLoading) {\n          svf = new _lmvtk_svf_PackageML__WEBPACK_IMPORTED_MODULE_2__[\"PackageML\"](new Uint8Array(result));\n        } else\n        {\n          svf = new _src_file_loaders_lmvtk_svf_Package__WEBPACK_IMPORTED_MODULE_1__[\"Package\"](new Uint8Array(result), packageConfig);\n        }\n      }\n      loadContext.svf = svf;\n      svf.loadManifest(loadContext);\n\n\n      if (loadContext.interceptManifest) {\n        _this.postMessage({ \"manifest\": svf.manifest });\n      } else {\n        loadContext.manifest = svf.manifest;\n        doLoadSvfContinued(loadContext);\n      }\n    });\n  }\n\n  var options = {\n    responseType: type === \"gltf\" ? \"json\" : \"arraybuffer\" };\n\n  _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_4__[\"ViewingService\"].getItem(loadContext, loadContext.url, onSuccess, loadContext.onFailureCallback, options);\n\n  //Prefetch the first geometry pack (we assume there is one), to mask some latency\n  //We intentionally ignore any errors here.\n  if (type === \"svf\") {\n    _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_4__[\"ViewingService\"].getItem(loadContext, loadContext.basePath + \"0.pf\", function () {}, function () {}, options);\n  }\n}\n\n\nfunction doFetchTopology(loadContext) {\n\n  var _this = loadContext.worker;\n  _src_file_loaders_net_Xhr__WEBPACK_IMPORTED_MODULE_4__[\"ViewingService\"].getItem(loadContext, loadContext.path, onSuccess, onFailure);\n\n  // on success\n  function onSuccess(data) {\n\n    _this.postMessage({ \"status-topology\": {} }); // download is complete\n\n    // This lines below may take a while...\n    var topology = null;\n    try {\n      var jdr = new _src_file_loaders_lmvtk_common_InputStream__WEBPACK_IMPORTED_MODULE_3__[\"InputStream\"](data);\n      var byteLength = data.byteLength;\n      if (0 < byteLength) {\n        topology = JSON.parse(jdr.getString(byteLength));\n      }\n      if (topology) {\n        _this.postMessage({ \"fetch-topology\": { error: null, topology: topology } }); // parsing is complete\n      } else {\n        onFailure('topology-no-content');\n      }\n    } catch (eee) {\n      onFailure(eee);\n    }\n  }\n\n  // on-failure\n  function onFailure(err) {\n    _this.postMessage({ \"fetch-topology\": { error: err, topology: null } }); // something went wrong\n  }\n}\n\nfunction register(workerMainML) {\n  workerMainML.register(\"LOAD_SVF\", { doOperation: doLoadSvf });\n  workerMainML.register(\"LOAD_SVF_CONTD\", { doOperation: doLoadSvfContinued });\n  workerMainML.register(\"FETCH_TOPOLOGY\", { doOperation: doFetchTopology });\n}\n\n/***/ }),\n\n/***/ \"./extensions/MemoryLimited/thirdparty/three.js/three-worker.js\":\n/*!**********************************************************************!*\\\n  !*** ./extensions/MemoryLimited/thirdparty/three.js/three-worker.js ***!\n  \\**********************************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n/* WEBPACK VAR INJECTION */(function(module) {function _typeof(obj) {if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {_typeof = function _typeof(obj) {return typeof obj;};} else {_typeof = function _typeof(obj) {return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;};}return _typeof(obj);} // File:src/Three.js\n\n/**\n * @author mrdoob / http://mrdoob.com/\n */\n\nvar THREE = { REVISION: '71' };\n\n// browserify support\n\nif (( false ? undefined : _typeof(module)) === 'object') {\n\n  module.exports = THREE;\n\n}\n\n// polyfills\n\nif (Math.sign === undefined) {\n\n  // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/sign\n\n  Math.sign = function (x) {\n\n    return x < 0 ? -1 : x > 0 ? 1 : +x;\n\n  };\n\n}\n\n\n// set the default log handlers\nTHREE.log = function () {console.log.apply(console, arguments);};\nTHREE.warn = function () {console.warn.apply(console, arguments);};\nTHREE.error = function () {console.error.apply(console, arguments);};\n\n\n// https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent.button\n\nTHREE.MOUSE = { LEFT: 0, MIDDLE: 1, RIGHT: 2 };\n\n// GL STATE CONSTANTS\n\nTHREE.CullFaceNone = 0;\nTHREE.CullFaceBack = 1;\nTHREE.CullFaceFront = 2;\nTHREE.CullFaceFrontBack = 3;\n\nTHREE.FrontFaceDirectionCW = 0;\nTHREE.FrontFaceDirectionCCW = 1;\n\n// SHADOWING TYPES\n\nTHREE.BasicShadowMap = 0;\nTHREE.PCFShadowMap = 1;\nTHREE.PCFSoftShadowMap = 2;\n\n// MATERIAL CONSTANTS\n\n// side\n\nTHREE.FrontSide = 0;\nTHREE.BackSide = 1;\nTHREE.DoubleSide = 2;\n\n// shading\n\nTHREE.NoShading = 0;\nTHREE.FlatShading = 1;\nTHREE.SmoothShading = 2;\n\n// colors\n\nTHREE.NoColors = 0;\nTHREE.FaceColors = 1;\nTHREE.VertexColors = 2;\n\n// blending modes\n\nTHREE.NoBlending = 0;\nTHREE.NormalBlending = 1;\nTHREE.AdditiveBlending = 2;\nTHREE.SubtractiveBlending = 3;\nTHREE.MultiplyBlending = 4;\nTHREE.CustomBlending = 5;\n\n// custom blending equations\n// (numbers start from 100 not to clash with other\n//  mappings to OpenGL constants defined in Texture.js)\n\nTHREE.AddEquation = 100;\nTHREE.SubtractEquation = 101;\nTHREE.ReverseSubtractEquation = 102;\nTHREE.MinEquation = 103;\nTHREE.MaxEquation = 104;\n\n// custom blending destination factors\n\nTHREE.ZeroFactor = 200;\nTHREE.OneFactor = 201;\nTHREE.SrcColorFactor = 202;\nTHREE.OneMinusSrcColorFactor = 203;\nTHREE.SrcAlphaFactor = 204;\nTHREE.OneMinusSrcAlphaFactor = 205;\nTHREE.DstAlphaFactor = 206;\nTHREE.OneMinusDstAlphaFactor = 207;\n\n// custom blending source factors\n\n//THREE.ZeroFactor = 200;\n//THREE.OneFactor = 201;\n//THREE.SrcAlphaFactor = 204;\n//THREE.OneMinusSrcAlphaFactor = 205;\n//THREE.DstAlphaFactor = 206;\n//THREE.OneMinusDstAlphaFactor = 207;\nTHREE.DstColorFactor = 208;\nTHREE.OneMinusDstColorFactor = 209;\nTHREE.SrcAlphaSaturateFactor = 210;\n\n\n// TEXTURE CONSTANTS\n\nTHREE.MultiplyOperation = 0;\nTHREE.MixOperation = 1;\nTHREE.AddOperation = 2;\n\n// Mapping modes\n\nTHREE.UVMapping = 300;\n\nTHREE.CubeReflectionMapping = 301;\nTHREE.CubeRefractionMapping = 302;\n\nTHREE.EquirectangularReflectionMapping = 303;\nTHREE.EquirectangularRefractionMapping = 304;\n\nTHREE.SphericalReflectionMapping = 305;\n\n// Wrapping modes\n\nTHREE.RepeatWrapping = 1000;\nTHREE.ClampToEdgeWrapping = 1001;\nTHREE.MirroredRepeatWrapping = 1002;\n\n// Filters\n\nTHREE.NearestFilter = 1003;\nTHREE.NearestMipMapNearestFilter = 1004;\nTHREE.NearestMipMapLinearFilter = 1005;\nTHREE.LinearFilter = 1006;\nTHREE.LinearMipMapNearestFilter = 1007;\nTHREE.LinearMipMapLinearFilter = 1008;\n\n// Data types\n\nTHREE.UnsignedByteType = 1009;\nTHREE.ByteType = 1010;\nTHREE.ShortType = 1011;\nTHREE.UnsignedShortType = 1012;\nTHREE.IntType = 1013;\nTHREE.UnsignedIntType = 1014;\nTHREE.FloatType = 1015;\nTHREE.HalfFloatType = 1025;\n\n// Pixel types\n\n//THREE.UnsignedByteType = 1009;\nTHREE.UnsignedShort4444Type = 1016;\nTHREE.UnsignedShort5551Type = 1017;\nTHREE.UnsignedShort565Type = 1018;\n\n// Pixel formats\n\nTHREE.AlphaFormat = 1019;\nTHREE.RGBFormat = 1020;\nTHREE.RGBAFormat = 1021;\nTHREE.LuminanceFormat = 1022;\nTHREE.LuminanceAlphaFormat = 1023;\n// THREE.RGBEFormat handled as THREE.RGBAFormat in shaders\nTHREE.RGBEFormat = THREE.RGBAFormat; //1024;\n\n// DDS / ST3C Compressed texture formats\n\nTHREE.RGB_S3TC_DXT1_Format = 2001;\nTHREE.RGBA_S3TC_DXT1_Format = 2002;\nTHREE.RGBA_S3TC_DXT3_Format = 2003;\nTHREE.RGBA_S3TC_DXT5_Format = 2004;\n\n\n// PVRTC compressed texture formats\n\nTHREE.RGB_PVRTC_4BPPV1_Format = 2100;\nTHREE.RGB_PVRTC_2BPPV1_Format = 2101;\nTHREE.RGBA_PVRTC_4BPPV1_Format = 2102;\nTHREE.RGBA_PVRTC_2BPPV1_Format = 2103;\n\n\n// DEPRECATED\n\nTHREE.Projector = function () {\n\n  THREE.error('THREE.Projector has been moved to /examples/js/renderers/Projector.js.');\n\n  this.projectVector = function (vector, camera) {\n\n    THREE.warn('THREE.Projector: .projectVector() is now vector.project().');\n    vector.project(camera);\n\n  };\n\n  this.unprojectVector = function (vector, camera) {\n\n    THREE.warn('THREE.Projector: .unprojectVector() is now vector.unproject().');\n    vector.unproject(camera);\n\n  };\n\n  this.pickingRay = function (vector, camera) {\n\n    THREE.error('THREE.Projector: .pickingRay() is now raycaster.setFromCamera().');\n\n  };\n\n};\n\nTHREE.CanvasRenderer = function () {\n\n  THREE.error('THREE.CanvasRenderer has been moved to /examples/js/renderers/CanvasRenderer.js');\n\n  this.domElement = document.createElement('canvas');\n  this.clear = function () {};\n  this.render = function () {};\n  this.setClearColor = function () {};\n  this.setSize = function () {};\n\n};\n\n// File:src/math/Quaternion.js\n\n/**\n * @author mikael emtinger / http://gomo.se/\n * @author alteredq / http://alteredqualia.com/\n * @author WestLangley / http://github.com/WestLangley\n * @author bhouston / http://exocortex.com\n */\n\nTHREE.Quaternion = function (x, y, z, w) {\n\n  this._x = x || 0;\n  this._y = y || 0;\n  this._z = z || 0;\n  this._w = w !== undefined ? w : 1;\n\n};\n\nTHREE.Quaternion.prototype = {\n\n  constructor: THREE.Quaternion,\n\n  _x: 0, _y: 0, _z: 0, _w: 0,\n\n  get x() {\n\n    return this._x;\n\n  },\n\n  set x(value) {\n\n    this._x = value;\n    this.onChangeCallback();\n\n  },\n\n  get y() {\n\n    return this._y;\n\n  },\n\n  set y(value) {\n\n    this._y = value;\n    this.onChangeCallback();\n\n  },\n\n  get z() {\n\n    return this._z;\n\n  },\n\n  set z(value) {\n\n    this._z = value;\n    this.onChangeCallback();\n\n  },\n\n  get w() {\n\n    return this._w;\n\n  },\n\n  set w(value) {\n\n    this._w = value;\n    this.onChangeCallback();\n\n  },\n\n  set: function set(x, y, z, w) {\n\n    this._x = x;\n    this._y = y;\n    this._z = z;\n    this._w = w;\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  copy: function copy(quaternion) {\n\n    this._x = quaternion.x;\n    this._y = quaternion.y;\n    this._z = quaternion.z;\n    this._w = quaternion.w;\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  setFromEuler: function setFromEuler(euler, update) {\n\n    if (euler instanceof THREE.Euler === false) {\n\n      throw new Error('THREE.Quaternion: .setFromEuler() now expects a Euler rotation rather than a Vector3 and order.');\n    }\n\n    // http://www.mathworks.com/matlabcentral/fileexchange/\n    // \t20696-function-to-convert-between-dcm-euler-angles-quaternions-and-euler-vectors/\n    //\tcontent/SpinCalc.m\n\n    var c1 = Math.cos(euler._x / 2);\n    var c2 = Math.cos(euler._y / 2);\n    var c3 = Math.cos(euler._z / 2);\n    var s1 = Math.sin(euler._x / 2);\n    var s2 = Math.sin(euler._y / 2);\n    var s3 = Math.sin(euler._z / 2);\n\n    if (euler.order === 'XYZ') {\n\n      this._x = s1 * c2 * c3 + c1 * s2 * s3;\n      this._y = c1 * s2 * c3 - s1 * c2 * s3;\n      this._z = c1 * c2 * s3 + s1 * s2 * c3;\n      this._w = c1 * c2 * c3 - s1 * s2 * s3;\n\n    } else if (euler.order === 'YXZ') {\n\n      this._x = s1 * c2 * c3 + c1 * s2 * s3;\n      this._y = c1 * s2 * c3 - s1 * c2 * s3;\n      this._z = c1 * c2 * s3 - s1 * s2 * c3;\n      this._w = c1 * c2 * c3 + s1 * s2 * s3;\n\n    } else if (euler.order === 'ZXY') {\n\n      this._x = s1 * c2 * c3 - c1 * s2 * s3;\n      this._y = c1 * s2 * c3 + s1 * c2 * s3;\n      this._z = c1 * c2 * s3 + s1 * s2 * c3;\n      this._w = c1 * c2 * c3 - s1 * s2 * s3;\n\n    } else if (euler.order === 'ZYX') {\n\n      this._x = s1 * c2 * c3 - c1 * s2 * s3;\n      this._y = c1 * s2 * c3 + s1 * c2 * s3;\n      this._z = c1 * c2 * s3 - s1 * s2 * c3;\n      this._w = c1 * c2 * c3 + s1 * s2 * s3;\n\n    } else if (euler.order === 'YZX') {\n\n      this._x = s1 * c2 * c3 + c1 * s2 * s3;\n      this._y = c1 * s2 * c3 + s1 * c2 * s3;\n      this._z = c1 * c2 * s3 - s1 * s2 * c3;\n      this._w = c1 * c2 * c3 - s1 * s2 * s3;\n\n    } else if (euler.order === 'XZY') {\n\n      this._x = s1 * c2 * c3 - c1 * s2 * s3;\n      this._y = c1 * s2 * c3 - s1 * c2 * s3;\n      this._z = c1 * c2 * s3 + s1 * s2 * c3;\n      this._w = c1 * c2 * c3 + s1 * s2 * s3;\n\n    }\n\n    if (update !== false) this.onChangeCallback();\n\n    return this;\n\n  },\n\n  setFromAxisAngle: function setFromAxisAngle(axis, angle) {\n\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm\n\n    // assumes axis is normalized\n\n    var halfAngle = angle / 2,s = Math.sin(halfAngle);\n\n    this._x = axis.x * s;\n    this._y = axis.y * s;\n    this._z = axis.z * s;\n    this._w = Math.cos(halfAngle);\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  setFromRotationMatrix: function setFromRotationMatrix(m) {\n\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm\n\n    // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n    var te = m.elements,\n\n    m11 = te[0],m12 = te[4],m13 = te[8],\n    m21 = te[1],m22 = te[5],m23 = te[9],\n    m31 = te[2],m32 = te[6],m33 = te[10],\n\n    trace = m11 + m22 + m33,\n    s;\n\n    if (trace > 0) {\n\n      s = 0.5 / Math.sqrt(trace + 1.0);\n\n      this._w = 0.25 / s;\n      this._x = (m32 - m23) * s;\n      this._y = (m13 - m31) * s;\n      this._z = (m21 - m12) * s;\n\n    } else if (m11 > m22 && m11 > m33) {\n\n      s = 2.0 * Math.sqrt(1.0 + m11 - m22 - m33);\n\n      this._w = (m32 - m23) / s;\n      this._x = 0.25 * s;\n      this._y = (m12 + m21) / s;\n      this._z = (m13 + m31) / s;\n\n    } else if (m22 > m33) {\n\n      s = 2.0 * Math.sqrt(1.0 + m22 - m11 - m33);\n\n      this._w = (m13 - m31) / s;\n      this._x = (m12 + m21) / s;\n      this._y = 0.25 * s;\n      this._z = (m23 + m32) / s;\n\n    } else {\n\n      s = 2.0 * Math.sqrt(1.0 + m33 - m11 - m22);\n\n      this._w = (m21 - m12) / s;\n      this._x = (m13 + m31) / s;\n      this._y = (m23 + m32) / s;\n      this._z = 0.25 * s;\n\n    }\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  setFromUnitVectors: function () {\n\n    // http://lolengine.net/blog/2014/02/24/quaternion-from-two-vectors-final\n\n    // assumes direction vectors vFrom and vTo are normalized\n\n    var v1, r;\n\n    var EPS = 0.000001;\n\n    return function (vFrom, vTo) {\n\n      if (v1 === undefined) v1 = new THREE.Vector3();\n\n      r = vFrom.dot(vTo) + 1;\n\n      if (r < EPS) {\n\n        r = 0;\n\n        if (Math.abs(vFrom.x) > Math.abs(vFrom.z)) {\n\n          v1.set(-vFrom.y, vFrom.x, 0);\n\n        } else {\n\n          v1.set(0, -vFrom.z, vFrom.y);\n\n        }\n\n      } else {\n\n        v1.crossVectors(vFrom, vTo);\n\n      }\n\n      this._x = v1.x;\n      this._y = v1.y;\n      this._z = v1.z;\n      this._w = r;\n\n      this.normalize();\n\n      return this;\n\n    };\n\n  }(),\n\n  inverse: function inverse() {\n\n    this.conjugate().normalize();\n\n    return this;\n\n  },\n\n  conjugate: function conjugate() {\n\n    this._x *= -1;\n    this._y *= -1;\n    this._z *= -1;\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  dot: function dot(v) {\n\n    return this._x * v._x + this._y * v._y + this._z * v._z + this._w * v._w;\n\n  },\n\n  lengthSq: function lengthSq() {\n\n    return this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;\n\n  },\n\n  length: function length() {\n\n    return Math.sqrt(this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w);\n\n  },\n\n  normalize: function normalize() {\n\n    var l = this.length();\n\n    if (l === 0) {\n\n      this._x = 0;\n      this._y = 0;\n      this._z = 0;\n      this._w = 1;\n\n    } else {\n\n      l = 1 / l;\n\n      this._x = this._x * l;\n      this._y = this._y * l;\n      this._z = this._z * l;\n      this._w = this._w * l;\n\n    }\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  multiply: function multiply(q, p) {\n\n    if (p !== undefined) {\n\n      THREE.warn('THREE.Quaternion: .multiply() now only accepts one argument. Use .multiplyQuaternions( a, b ) instead.');\n      return this.multiplyQuaternions(q, p);\n\n    }\n\n    return this.multiplyQuaternions(this, q);\n\n  },\n\n  multiplyQuaternions: function multiplyQuaternions(a, b) {\n\n    // from http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/code/index.htm\n\n    var qax = a._x,qay = a._y,qaz = a._z,qaw = a._w;\n    var qbx = b._x,qby = b._y,qbz = b._z,qbw = b._w;\n\n    this._x = qax * qbw + qaw * qbx + qay * qbz - qaz * qby;\n    this._y = qay * qbw + qaw * qby + qaz * qbx - qax * qbz;\n    this._z = qaz * qbw + qaw * qbz + qax * qby - qay * qbx;\n    this._w = qaw * qbw - qax * qbx - qay * qby - qaz * qbz;\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  multiplyVector3: function multiplyVector3(vector) {\n\n    THREE.warn('THREE.Quaternion: .multiplyVector3() has been removed. Use is now vector.applyQuaternion( quaternion ) instead.');\n    return vector.applyQuaternion(this);\n\n  },\n\n  slerp: function slerp(qb, t) {\n\n    if (t === 0) return this;\n    if (t === 1) return this.copy(qb);\n\n    var x = this._x,y = this._y,z = this._z,w = this._w;\n\n    // http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/slerp/\n\n    var cosHalfTheta = w * qb._w + x * qb._x + y * qb._y + z * qb._z;\n\n    if (cosHalfTheta < 0) {\n\n      this._w = -qb._w;\n      this._x = -qb._x;\n      this._y = -qb._y;\n      this._z = -qb._z;\n\n      cosHalfTheta = -cosHalfTheta;\n\n    } else {\n\n      this.copy(qb);\n\n    }\n\n    if (cosHalfTheta >= 1.0) {\n\n      this._w = w;\n      this._x = x;\n      this._y = y;\n      this._z = z;\n\n      return this;\n\n    }\n\n    var halfTheta = Math.acos(cosHalfTheta);\n    var sinHalfTheta = Math.sqrt(1.0 - cosHalfTheta * cosHalfTheta);\n\n    if (Math.abs(sinHalfTheta) < 0.001) {\n\n      this._w = 0.5 * (w + this._w);\n      this._x = 0.5 * (x + this._x);\n      this._y = 0.5 * (y + this._y);\n      this._z = 0.5 * (z + this._z);\n\n      return this;\n\n    }\n\n    var ratioA = Math.sin((1 - t) * halfTheta) / sinHalfTheta,\n    ratioB = Math.sin(t * halfTheta) / sinHalfTheta;\n\n    this._w = w * ratioA + this._w * ratioB;\n    this._x = x * ratioA + this._x * ratioB;\n    this._y = y * ratioA + this._y * ratioB;\n    this._z = z * ratioA + this._z * ratioB;\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  equals: function equals(quaternion) {\n\n    return quaternion._x === this._x && quaternion._y === this._y && quaternion._z === this._z && quaternion._w === this._w;\n\n  },\n\n  fromArray: function fromArray(array, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    this._x = array[offset];\n    this._y = array[offset + 1];\n    this._z = array[offset + 2];\n    this._w = array[offset + 3];\n\n    this.onChangeCallback();\n\n    return this;\n\n  },\n\n  toArray: function toArray(array, offset) {\n\n    if (array === undefined) array = [];\n    if (offset === undefined) offset = 0;\n\n    array[offset] = this._x;\n    array[offset + 1] = this._y;\n    array[offset + 2] = this._z;\n    array[offset + 3] = this._w;\n\n    return array;\n\n  },\n\n  onChange: function onChange(callback) {\n\n    this.onChangeCallback = callback;\n\n    return this;\n\n  },\n\n  onChangeCallback: function onChangeCallback() {},\n\n  clone: function clone() {\n\n    return new THREE.Quaternion(this._x, this._y, this._z, this._w);\n\n  } };\n\n\n\nTHREE.Quaternion.slerp = function (qa, qb, qm, t) {\n\n  return qm.copy(qa).slerp(qb, t);\n\n};\n\n// File:src/math/Vector2.js\n\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author philogb / http://blog.thejit.org/\n * @author egraether / http://egraether.com/\n * @author zz85 / http://www.lab4games.net/zz85/blog\n */\n\nTHREE.Vector2 = function (x, y) {\n\n  this.x = x || 0;\n  this.y = y || 0;\n\n};\n\nTHREE.Vector2.prototype = {\n\n  constructor: THREE.Vector2,\n\n  set: function set(x, y) {\n\n    this.x = x;\n    this.y = y;\n\n    return this;\n\n  },\n\n  setX: function setX(x) {\n\n    this.x = x;\n\n    return this;\n\n  },\n\n  setY: function setY(y) {\n\n    this.y = y;\n\n    return this;\n\n  },\n\n  setComponent: function setComponent(index, value) {\n\n    switch (index) {\n\n      case 0:this.x = value;break;\n      case 1:this.y = value;break;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  getComponent: function getComponent(index) {\n\n    switch (index) {\n\n      case 0:return this.x;\n      case 1:return this.y;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  copy: function copy(v) {\n\n    this.x = v.x;\n    this.y = v.y;\n\n    return this;\n\n  },\n\n  add: function add(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector2: .add() now only accepts one argument. Use .addVectors( a, b ) instead.');\n      return this.addVectors(v, w);\n\n    }\n\n    this.x += v.x;\n    this.y += v.y;\n\n    return this;\n\n  },\n\n  addScalar: function addScalar(s) {\n\n    this.x += s;\n    this.y += s;\n\n    return this;\n\n  },\n\n  addVectors: function addVectors(a, b) {\n\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n\n    return this;\n\n  },\n\n  sub: function sub(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector2: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.');\n      return this.subVectors(v, w);\n\n    }\n\n    this.x -= v.x;\n    this.y -= v.y;\n\n    return this;\n\n  },\n\n  subScalar: function subScalar(s) {\n\n    this.x -= s;\n    this.y -= s;\n\n    return this;\n\n  },\n\n  subVectors: function subVectors(a, b) {\n\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n\n    return this;\n\n  },\n\n  multiply: function multiply(v) {\n\n    this.x *= v.x;\n    this.y *= v.y;\n\n    return this;\n\n  },\n\n  multiplyScalar: function multiplyScalar(s) {\n\n    this.x *= s;\n    this.y *= s;\n\n    return this;\n\n  },\n\n  divide: function divide(v) {\n\n    this.x /= v.x;\n    this.y /= v.y;\n\n    return this;\n\n  },\n\n  divideScalar: function divideScalar(scalar) {\n\n    if (scalar !== 0) {\n\n      var invScalar = 1 / scalar;\n\n      this.x *= invScalar;\n      this.y *= invScalar;\n\n    } else {\n\n      this.x = 0;\n      this.y = 0;\n\n    }\n\n    return this;\n\n  },\n\n  min: function min(v) {\n\n    if (this.x > v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y > v.y) {\n\n      this.y = v.y;\n\n    }\n\n    return this;\n\n  },\n\n  max: function max(v) {\n\n    if (this.x < v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y < v.y) {\n\n      this.y = v.y;\n\n    }\n\n    return this;\n\n  },\n\n  clamp: function clamp(min, max) {\n\n    // This function assumes min < max, if this assumption isn't true it will not operate correctly\n\n    if (this.x < min.x) {\n\n      this.x = min.x;\n\n    } else if (this.x > max.x) {\n\n      this.x = max.x;\n\n    }\n\n    if (this.y < min.y) {\n\n      this.y = min.y;\n\n    } else if (this.y > max.y) {\n\n      this.y = max.y;\n\n    }\n\n    return this;\n  },\n\n  clampScalar: function () {\n\n    var min, max;\n\n    return function (minVal, maxVal) {\n\n      if (min === undefined) {\n\n        min = new THREE.Vector2();\n        max = new THREE.Vector2();\n\n      }\n\n      min.set(minVal, minVal);\n      max.set(maxVal, maxVal);\n\n      return this.clamp(min, max);\n\n    };\n\n  }(),\n\n  floor: function floor() {\n\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n\n    return this;\n\n  },\n\n  ceil: function ceil() {\n\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n\n    return this;\n\n  },\n\n  round: function round() {\n\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n\n    return this;\n\n  },\n\n  roundToZero: function roundToZero() {\n\n    this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x);\n    this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y);\n\n    return this;\n\n  },\n\n  negate: function negate() {\n\n    this.x = -this.x;\n    this.y = -this.y;\n\n    return this;\n\n  },\n\n  dot: function dot(v) {\n\n    return this.x * v.x + this.y * v.y;\n\n  },\n\n  lengthSq: function lengthSq() {\n\n    return this.x * this.x + this.y * this.y;\n\n  },\n\n  length: function length() {\n\n    return Math.sqrt(this.x * this.x + this.y * this.y);\n\n  },\n\n  normalize: function normalize() {\n\n    return this.divideScalar(this.length());\n\n  },\n\n  distanceTo: function distanceTo(v) {\n\n    return Math.sqrt(this.distanceToSquared(v));\n\n  },\n\n  distanceToSquared: function distanceToSquared(v) {\n\n    var dx = this.x - v.x,dy = this.y - v.y;\n    return dx * dx + dy * dy;\n\n  },\n\n  setLength: function setLength(l) {\n\n    var oldLength = this.length();\n\n    if (oldLength !== 0 && l !== oldLength) {\n\n      this.multiplyScalar(l / oldLength);\n    }\n\n    return this;\n\n  },\n\n  lerp: function lerp(v, alpha) {\n\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n\n    return this;\n\n  },\n\n  lerpVectors: function lerpVectors(v1, v2, alpha) {\n\n    this.subVectors(v2, v1).multiplyScalar(alpha).add(v1);\n\n    return this;\n\n  },\n\n  equals: function equals(v) {\n\n    return v.x === this.x && v.y === this.y;\n\n  },\n\n  fromArray: function fromArray(array, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    this.x = array[offset];\n    this.y = array[offset + 1];\n\n    return this;\n\n  },\n\n  toArray: function toArray(array, offset) {\n\n    if (array === undefined) array = [];\n    if (offset === undefined) offset = 0;\n\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n\n    return array;\n\n  },\n\n  fromAttribute: function fromAttribute(attribute, index, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    index = index * attribute.itemSize + offset;\n\n    this.x = attribute.array[index];\n    this.y = attribute.array[index + 1];\n\n    return this;\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Vector2(this.x, this.y);\n\n  } };\n\n\n\n// File:src/math/Vector3.js\n\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author *kile / http://kile.stravaganza.org/\n * @author philogb / http://blog.thejit.org/\n * @author mikael emtinger / http://gomo.se/\n * @author egraether / http://egraether.com/\n * @author WestLangley / http://github.com/WestLangley\n */\n\nTHREE.Vector3 = function (x, y, z) {\n\n  this.x = x || 0;\n  this.y = y || 0;\n  this.z = z || 0;\n\n};\n\nTHREE.Vector3.prototype = {\n\n  constructor: THREE.Vector3,\n\n  set: function set(x, y, z) {\n\n    this.x = x;\n    this.y = y;\n    this.z = z;\n\n    return this;\n\n  },\n\n  setX: function setX(x) {\n\n    this.x = x;\n\n    return this;\n\n  },\n\n  setY: function setY(y) {\n\n    this.y = y;\n\n    return this;\n\n  },\n\n  setZ: function setZ(z) {\n\n    this.z = z;\n\n    return this;\n\n  },\n\n  setComponent: function setComponent(index, value) {\n\n    switch (index) {\n\n      case 0:this.x = value;break;\n      case 1:this.y = value;break;\n      case 2:this.z = value;break;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  getComponent: function getComponent(index) {\n\n    switch (index) {\n\n      case 0:return this.x;\n      case 1:return this.y;\n      case 2:return this.z;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  copy: function copy(v) {\n\n    this.x = v.x;\n    this.y = v.y;\n    this.z = v.z;\n\n    return this;\n\n  },\n\n  add: function add(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead.');\n      return this.addVectors(v, w);\n\n    }\n\n    this.x += v.x;\n    this.y += v.y;\n    this.z += v.z;\n\n    return this;\n\n  },\n\n  addScalar: function addScalar(s) {\n\n    this.x += s;\n    this.y += s;\n    this.z += s;\n\n    return this;\n\n  },\n\n  addVectors: function addVectors(a, b) {\n\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n    this.z = a.z + b.z;\n\n    return this;\n\n  },\n\n  sub: function sub(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.');\n      return this.subVectors(v, w);\n\n    }\n\n    this.x -= v.x;\n    this.y -= v.y;\n    this.z -= v.z;\n\n    return this;\n\n  },\n\n  subScalar: function subScalar(s) {\n\n    this.x -= s;\n    this.y -= s;\n    this.z -= s;\n\n    return this;\n\n  },\n\n  subVectors: function subVectors(a, b) {\n\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n    this.z = a.z - b.z;\n\n    return this;\n\n  },\n\n  multiply: function multiply(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead.');\n      return this.multiplyVectors(v, w);\n\n    }\n\n    this.x *= v.x;\n    this.y *= v.y;\n    this.z *= v.z;\n\n    return this;\n\n  },\n\n  multiplyScalar: function multiplyScalar(scalar) {\n\n    this.x *= scalar;\n    this.y *= scalar;\n    this.z *= scalar;\n\n    return this;\n\n  },\n\n  multiplyVectors: function multiplyVectors(a, b) {\n\n    this.x = a.x * b.x;\n    this.y = a.y * b.y;\n    this.z = a.z * b.z;\n\n    return this;\n\n  },\n\n  applyEuler: function () {\n\n    var quaternion;\n\n    return function (euler) {\n\n      if (euler instanceof THREE.Euler === false) {\n\n        THREE.error('THREE.Vector3: .applyEuler() now expects a Euler rotation rather than a Vector3 and order.');\n\n      }\n\n      if (quaternion === undefined) quaternion = new THREE.Quaternion();\n\n      this.applyQuaternion(quaternion.setFromEuler(euler));\n\n      return this;\n\n    };\n\n  }(),\n\n  applyAxisAngle: function () {\n\n    var quaternion;\n\n    return function (axis, angle) {\n\n      if (quaternion === undefined) quaternion = new THREE.Quaternion();\n\n      this.applyQuaternion(quaternion.setFromAxisAngle(axis, angle));\n\n      return this;\n\n    };\n\n  }(),\n\n  applyMatrix3: function applyMatrix3(m) {\n\n    var x = this.x;\n    var y = this.y;\n    var z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[3] * y + e[6] * z;\n    this.y = e[1] * x + e[4] * y + e[7] * z;\n    this.z = e[2] * x + e[5] * y + e[8] * z;\n\n    return this;\n\n  },\n\n  applyMatrix4: function applyMatrix4(m) {\n\n    // input: THREE.Matrix4 affine matrix\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[4] * y + e[8] * z + e[12];\n    this.y = e[1] * x + e[5] * y + e[9] * z + e[13];\n    this.z = e[2] * x + e[6] * y + e[10] * z + e[14];\n\n    return this;\n\n  },\n\n  applyProjection: function applyProjection(m) {\n\n    // input: THREE.Matrix4 projection matrix\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n    var d = 1 / (e[3] * x + e[7] * y + e[11] * z + e[15]); // perspective divide\n\n    this.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;\n    this.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;\n    this.z = (e[2] * x + e[6] * y + e[10] * z + e[14]) * d;\n\n    return this;\n\n  },\n\n  applyQuaternion: function applyQuaternion(q) {\n\n    var x = this.x;\n    var y = this.y;\n    var z = this.z;\n\n    var qx = q.x;\n    var qy = q.y;\n    var qz = q.z;\n    var qw = q.w;\n\n    // calculate quat * vector\n\n    var ix = qw * x + qy * z - qz * y;\n    var iy = qw * y + qz * x - qx * z;\n    var iz = qw * z + qx * y - qy * x;\n    var iw = -qx * x - qy * y - qz * z;\n\n    // calculate result * inverse quat\n\n    this.x = ix * qw + iw * -qx + iy * -qz - iz * -qy;\n    this.y = iy * qw + iw * -qy + iz * -qx - ix * -qz;\n    this.z = iz * qw + iw * -qz + ix * -qy - iy * -qx;\n\n    return this;\n\n  },\n\n  project: function () {\n\n    var matrix;\n\n    return function (camera) {\n\n      if (matrix === undefined) matrix = new THREE.Matrix4();\n\n      matrix.multiplyMatrices(camera.projectionMatrix, matrix.getInverse(camera.matrixWorld));\n      return this.applyProjection(matrix);\n\n    };\n\n  }(),\n\n  unproject: function () {\n\n    var matrix;\n\n    return function (camera) {\n\n      if (matrix === undefined) matrix = new THREE.Matrix4();\n\n      matrix.multiplyMatrices(camera.matrixWorld, matrix.getInverse(camera.projectionMatrix));\n      return this.applyProjection(matrix);\n\n    };\n\n  }(),\n\n  transformDirection: function transformDirection(m) {\n\n    // input: THREE.Matrix4 affine matrix\n    // vector interpreted as a direction\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[4] * y + e[8] * z;\n    this.y = e[1] * x + e[5] * y + e[9] * z;\n    this.z = e[2] * x + e[6] * y + e[10] * z;\n\n    this.normalize();\n\n    return this;\n\n  },\n\n  divide: function divide(v) {\n\n    this.x /= v.x;\n    this.y /= v.y;\n    this.z /= v.z;\n\n    return this;\n\n  },\n\n  divideScalar: function divideScalar(scalar) {\n\n    if (scalar !== 0) {\n\n      var invScalar = 1 / scalar;\n\n      this.x *= invScalar;\n      this.y *= invScalar;\n      this.z *= invScalar;\n\n    } else {\n\n      this.x = 0;\n      this.y = 0;\n      this.z = 0;\n\n    }\n\n    return this;\n\n  },\n\n  min: function min(v) {\n\n    if (this.x > v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y > v.y) {\n\n      this.y = v.y;\n\n    }\n\n    if (this.z > v.z) {\n\n      this.z = v.z;\n\n    }\n\n    return this;\n\n  },\n\n  max: function max(v) {\n\n    if (this.x < v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y < v.y) {\n\n      this.y = v.y;\n\n    }\n\n    if (this.z < v.z) {\n\n      this.z = v.z;\n\n    }\n\n    return this;\n\n  },\n\n  clamp: function clamp(min, max) {\n\n    // This function assumes min < max, if this assumption isn't true it will not operate correctly\n\n    if (this.x < min.x) {\n\n      this.x = min.x;\n\n    } else if (this.x > max.x) {\n\n      this.x = max.x;\n\n    }\n\n    if (this.y < min.y) {\n\n      this.y = min.y;\n\n    } else if (this.y > max.y) {\n\n      this.y = max.y;\n\n    }\n\n    if (this.z < min.z) {\n\n      this.z = min.z;\n\n    } else if (this.z > max.z) {\n\n      this.z = max.z;\n\n    }\n\n    return this;\n\n  },\n\n  clampScalar: function () {\n\n    var min, max;\n\n    return function (minVal, maxVal) {\n\n      if (min === undefined) {\n\n        min = new THREE.Vector3();\n        max = new THREE.Vector3();\n\n      }\n\n      min.set(minVal, minVal, minVal);\n      max.set(maxVal, maxVal, maxVal);\n\n      return this.clamp(min, max);\n\n    };\n\n  }(),\n\n  floor: function floor() {\n\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n    this.z = Math.floor(this.z);\n\n    return this;\n\n  },\n\n  ceil: function ceil() {\n\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n    this.z = Math.ceil(this.z);\n\n    return this;\n\n  },\n\n  round: function round() {\n\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n    this.z = Math.round(this.z);\n\n    return this;\n\n  },\n\n  roundToZero: function roundToZero() {\n\n    this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x);\n    this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y);\n    this.z = this.z < 0 ? Math.ceil(this.z) : Math.floor(this.z);\n\n    return this;\n\n  },\n\n  negate: function negate() {\n\n    this.x = -this.x;\n    this.y = -this.y;\n    this.z = -this.z;\n\n    return this;\n\n  },\n\n  dot: function dot(v) {\n\n    return this.x * v.x + this.y * v.y + this.z * v.z;\n\n  },\n\n  lengthSq: function lengthSq() {\n\n    return this.x * this.x + this.y * this.y + this.z * this.z;\n\n  },\n\n  length: function length() {\n\n    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);\n\n  },\n\n  lengthManhattan: function lengthManhattan() {\n\n    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);\n\n  },\n\n  normalize: function normalize() {\n\n    return this.divideScalar(this.length());\n\n  },\n\n  setLength: function setLength(l) {\n\n    var oldLength = this.length();\n\n    if (oldLength !== 0 && l !== oldLength) {\n\n      this.multiplyScalar(l / oldLength);\n    }\n\n    return this;\n\n  },\n\n  lerp: function lerp(v, alpha) {\n\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n    this.z += (v.z - this.z) * alpha;\n\n    return this;\n\n  },\n\n  lerpVectors: function lerpVectors(v1, v2, alpha) {\n\n    this.subVectors(v2, v1).multiplyScalar(alpha).add(v1);\n\n    return this;\n\n  },\n\n  cross: function cross(v, w) {\n\n    if (w !== undefined) {\n\n      THREE.warn('THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead.');\n      return this.crossVectors(v, w);\n\n    }\n\n    var x = this.x,y = this.y,z = this.z;\n\n    this.x = y * v.z - z * v.y;\n    this.y = z * v.x - x * v.z;\n    this.z = x * v.y - y * v.x;\n\n    return this;\n\n  },\n\n  crossVectors: function crossVectors(a, b) {\n\n    var ax = a.x,ay = a.y,az = a.z;\n    var bx = b.x,by = b.y,bz = b.z;\n\n    this.x = ay * bz - az * by;\n    this.y = az * bx - ax * bz;\n    this.z = ax * by - ay * bx;\n\n    return this;\n\n  },\n\n  projectOnVector: function () {\n\n    var v1, dot;\n\n    return function (vector) {\n\n      if (v1 === undefined) v1 = new THREE.Vector3();\n\n      v1.copy(vector).normalize();\n\n      dot = this.dot(v1);\n\n      return this.copy(v1).multiplyScalar(dot);\n\n    };\n\n  }(),\n\n  projectOnPlane: function () {\n\n    var v1;\n\n    return function (planeNormal) {\n\n      if (v1 === undefined) v1 = new THREE.Vector3();\n\n      v1.copy(this).projectOnVector(planeNormal);\n\n      return this.sub(v1);\n\n    };\n\n  }(),\n\n  reflect: function () {\n\n    // reflect incident vector off plane orthogonal to normal\n    // normal is assumed to have unit length\n\n    var v1;\n\n    return function (normal) {\n\n      if (v1 === undefined) v1 = new THREE.Vector3();\n\n      return this.sub(v1.copy(normal).multiplyScalar(2 * this.dot(normal)));\n\n    };\n\n  }(),\n\n  angleTo: function angleTo(v) {\n\n    var theta = this.dot(v) / (this.length() * v.length());\n\n    // clamp, to handle numerical problems\n\n    return Math.acos(THREE.Math.clamp(theta, -1, 1));\n\n  },\n\n  distanceTo: function distanceTo(v) {\n\n    return Math.sqrt(this.distanceToSquared(v));\n\n  },\n\n  distanceToSquared: function distanceToSquared(v) {\n\n    var dx = this.x - v.x;\n    var dy = this.y - v.y;\n    var dz = this.z - v.z;\n\n    return dx * dx + dy * dy + dz * dz;\n\n  },\n\n  setEulerFromRotationMatrix: function setEulerFromRotationMatrix(m, order) {\n\n    THREE.error('THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.');\n\n  },\n\n  setEulerFromQuaternion: function setEulerFromQuaternion(q, order) {\n\n    THREE.error('THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.');\n\n  },\n\n  getPositionFromMatrix: function getPositionFromMatrix(m) {\n\n    THREE.warn('THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition().');\n\n    return this.setFromMatrixPosition(m);\n\n  },\n\n  getScaleFromMatrix: function getScaleFromMatrix(m) {\n\n    THREE.warn('THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale().');\n\n    return this.setFromMatrixScale(m);\n  },\n\n  getColumnFromMatrix: function getColumnFromMatrix(index, matrix) {\n\n    THREE.warn('THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn().');\n\n    return this.setFromMatrixColumn(index, matrix);\n\n  },\n\n  setFromMatrixPosition: function setFromMatrixPosition(m) {\n\n    this.x = m.elements[12];\n    this.y = m.elements[13];\n    this.z = m.elements[14];\n\n    return this;\n\n  },\n\n  setFromMatrixScale: function setFromMatrixScale(m) {\n\n    var sx = this.set(m.elements[0], m.elements[1], m.elements[2]).length();\n    var sy = this.set(m.elements[4], m.elements[5], m.elements[6]).length();\n    var sz = this.set(m.elements[8], m.elements[9], m.elements[10]).length();\n\n    this.x = sx;\n    this.y = sy;\n    this.z = sz;\n\n    return this;\n  },\n\n  setFromMatrixColumn: function setFromMatrixColumn(index, matrix) {\n\n    var offset = index * 4;\n\n    var me = matrix.elements;\n\n    this.x = me[offset];\n    this.y = me[offset + 1];\n    this.z = me[offset + 2];\n\n    return this;\n\n  },\n\n  equals: function equals(v) {\n\n    return v.x === this.x && v.y === this.y && v.z === this.z;\n\n  },\n\n  fromArray: function fromArray(array, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    this.x = array[offset];\n    this.y = array[offset + 1];\n    this.z = array[offset + 2];\n\n    return this;\n\n  },\n\n  toArray: function toArray(array, offset) {\n\n    if (array === undefined) array = [];\n    if (offset === undefined) offset = 0;\n\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n    array[offset + 2] = this.z;\n\n    return array;\n\n  },\n\n  fromAttribute: function fromAttribute(attribute, index, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    index = index * attribute.itemSize + offset;\n\n    this.x = attribute.array[index];\n    this.y = attribute.array[index + 1];\n    this.z = attribute.array[index + 2];\n\n    return this;\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Vector3(this.x, this.y, this.z);\n\n  } };\n\n\n\n// File:src/math/Box2.js\n\n/**\n * @author bhouston / http://exocortex.com\n */\n\nTHREE.Box2 = function (min, max) {\n\n  this.min = min !== undefined ? min : new THREE.Vector2(Infinity, Infinity);\n  this.max = max !== undefined ? max : new THREE.Vector2(-Infinity, -Infinity);\n\n};\n\nTHREE.Box2.prototype = {\n\n  constructor: THREE.Box2,\n\n  set: function set(min, max) {\n\n    this.min.copy(min);\n    this.max.copy(max);\n\n    return this;\n\n  },\n\n  setFromPoints: function setFromPoints(points) {\n\n    this.makeEmpty();\n\n    for (var i = 0, il = points.length; i < il; i++) {\n\n      this.expandByPoint(points[i]);\n\n    }\n\n    return this;\n\n  },\n\n  setFromCenterAndSize: function () {\n\n    var v1 = new THREE.Vector2();\n\n    return function (center, size) {\n\n      var halfSize = v1.copy(size).multiplyScalar(0.5);\n      this.min.copy(center).sub(halfSize);\n      this.max.copy(center).add(halfSize);\n\n      return this;\n\n    };\n\n  }(),\n\n  copy: function copy(box) {\n\n    this.min.copy(box.min);\n    this.max.copy(box.max);\n\n    return this;\n\n  },\n\n  makeEmpty: function makeEmpty() {\n\n    this.min.x = this.min.y = Infinity;\n    this.max.x = this.max.y = -Infinity;\n\n    return this;\n\n  },\n\n  empty: function empty() {\n\n    // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n    return this.max.x < this.min.x || this.max.y < this.min.y;\n\n  },\n\n  center: function center(optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector2();\n    return result.addVectors(this.min, this.max).multiplyScalar(0.5);\n\n  },\n\n  size: function size(optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector2();\n    return result.subVectors(this.max, this.min);\n\n  },\n\n  expandByPoint: function expandByPoint(point) {\n\n    this.min.min(point);\n    this.max.max(point);\n\n    return this;\n  },\n\n  expandByVector: function expandByVector(vector) {\n\n    this.min.sub(vector);\n    this.max.add(vector);\n\n    return this;\n  },\n\n  expandByScalar: function expandByScalar(scalar) {\n\n    this.min.addScalar(-scalar);\n    this.max.addScalar(scalar);\n\n    return this;\n  },\n\n  containsPoint: function containsPoint(point) {\n\n    if (point.x < this.min.x || point.x > this.max.x ||\n    point.y < this.min.y || point.y > this.max.y) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  containsBox: function containsBox(box) {\n\n    if (this.min.x <= box.min.x && box.max.x <= this.max.x &&\n    this.min.y <= box.min.y && box.max.y <= this.max.y) {\n\n      return true;\n\n    }\n\n    return false;\n\n  },\n\n  getParameter: function getParameter(point, optionalTarget) {\n\n    // This can potentially have a divide by zero if the box\n    // has a size dimension of 0.\n\n    var result = optionalTarget || new THREE.Vector2();\n\n    return result.set(\n    (point.x - this.min.x) / (this.max.x - this.min.x),\n    (point.y - this.min.y) / (this.max.y - this.min.y));\n\n\n  },\n\n  isIntersectionBox: function isIntersectionBox(box) {\n\n    // using 6 splitting planes to rule out intersections.\n\n    if (box.max.x < this.min.x || box.min.x > this.max.x ||\n    box.max.y < this.min.y || box.min.y > this.max.y) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  clampPoint: function clampPoint(point, optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector2();\n    return result.copy(point).clamp(this.min, this.max);\n\n  },\n\n  distanceToPoint: function () {\n\n    var v1 = new THREE.Vector2();\n\n    return function (point) {\n\n      var clampedPoint = v1.copy(point).clamp(this.min, this.max);\n      return clampedPoint.sub(point).length();\n\n    };\n\n  }(),\n\n  intersect: function intersect(box) {\n\n    this.min.max(box.min);\n    this.max.min(box.max);\n\n    return this;\n\n  },\n\n  union: function union(box) {\n\n    this.min.min(box.min);\n    this.max.max(box.max);\n\n    return this;\n\n  },\n\n  translate: function translate(offset) {\n\n    this.min.add(offset);\n    this.max.add(offset);\n\n    return this;\n\n  },\n\n  equals: function equals(box) {\n\n    return box.min.equals(this.min) && box.max.equals(this.max);\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Box2().copy(this);\n\n  } };\n\n\n\n// File:src/math/Box3.js\n\n/**\n * @author bhouston / http://exocortex.com\n * @author WestLangley / http://github.com/WestLangley\n */\n\nTHREE.Box3 = function (min, max) {\n\n  this.min = min !== undefined ? min : new THREE.Vector3(Infinity, Infinity, Infinity);\n  this.max = max !== undefined ? max : new THREE.Vector3(-Infinity, -Infinity, -Infinity);\n\n};\n\nTHREE.Box3.prototype = {\n\n  constructor: THREE.Box3,\n\n  set: function set(min, max) {\n\n    this.min.copy(min);\n    this.max.copy(max);\n\n    return this;\n\n  },\n\n  setFromPoints: function setFromPoints(points) {\n\n    this.makeEmpty();\n\n    for (var i = 0, il = points.length; i < il; i++) {\n\n      this.expandByPoint(points[i]);\n\n    }\n\n    return this;\n\n  },\n\n  setFromCenterAndSize: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (center, size) {\n\n      var halfSize = v1.copy(size).multiplyScalar(0.5);\n\n      this.min.copy(center).sub(halfSize);\n      this.max.copy(center).add(halfSize);\n\n      return this;\n\n    };\n\n  }(),\n\n  setFromObject: function () {\n\n    // Computes the world-axis-aligned bounding box of an object (including its children),\n    // accounting for both the object's, and childrens', world transforms\n\n    var v1 = new THREE.Vector3();\n\n    return function (object) {\n\n      var scope = this;\n\n      object.updateMatrixWorld(true);\n\n      this.makeEmpty();\n\n      object.traverse(function (node) {\n\n        var geometry = node.geometry;\n\n        if (geometry !== undefined) {\n\n          if (geometry instanceof THREE.Geometry) {\n\n            var vertices = geometry.vertices;\n\n            for (var i = 0, il = vertices.length; i < il; i++) {\n\n              v1.copy(vertices[i]);\n\n              v1.applyMatrix4(node.matrixWorld);\n\n              scope.expandByPoint(v1);\n\n            }\n\n          } else if (geometry instanceof THREE.BufferGeometry && geometry.attributes['position'] !== undefined) {\n\n            var positions = geometry.attributes['position'].array;\n\n            for (var i = 0, il = positions.length; i < il; i += 3) {\n\n              v1.set(positions[i], positions[i + 1], positions[i + 2]);\n\n              v1.applyMatrix4(node.matrixWorld);\n\n              scope.expandByPoint(v1);\n\n            }\n\n          }\n\n        }\n\n      });\n\n      return this;\n\n    };\n\n  }(),\n\n  copy: function copy(box) {\n\n    this.min.copy(box.min);\n    this.max.copy(box.max);\n\n    return this;\n\n  },\n\n  makeEmpty: function makeEmpty() {\n\n    this.min.x = this.min.y = this.min.z = Infinity;\n    this.max.x = this.max.y = this.max.z = -Infinity;\n\n    return this;\n\n  },\n\n  empty: function empty() {\n\n    // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n    return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;\n\n  },\n\n  center: function center(optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector3();\n    return result.addVectors(this.min, this.max).multiplyScalar(0.5);\n\n  },\n\n  size: function size(optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector3();\n    return result.subVectors(this.max, this.min);\n\n  },\n\n  expandByPoint: function expandByPoint(point) {\n\n    this.min.min(point);\n    this.max.max(point);\n\n    return this;\n\n  },\n\n  expandByVector: function expandByVector(vector) {\n\n    this.min.sub(vector);\n    this.max.add(vector);\n\n    return this;\n\n  },\n\n  expandByScalar: function expandByScalar(scalar) {\n\n    this.min.addScalar(-scalar);\n    this.max.addScalar(scalar);\n\n    return this;\n\n  },\n\n  containsPoint: function containsPoint(point) {\n\n    if (point.x < this.min.x || point.x > this.max.x ||\n    point.y < this.min.y || point.y > this.max.y ||\n    point.z < this.min.z || point.z > this.max.z) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  containsBox: function containsBox(box) {\n\n    if (this.min.x <= box.min.x && box.max.x <= this.max.x &&\n    this.min.y <= box.min.y && box.max.y <= this.max.y &&\n    this.min.z <= box.min.z && box.max.z <= this.max.z) {\n\n      return true;\n\n    }\n\n    return false;\n\n  },\n\n  getParameter: function getParameter(point, optionalTarget) {\n\n    // This can potentially have a divide by zero if the box\n    // has a size dimension of 0.\n\n    var result = optionalTarget || new THREE.Vector3();\n\n    return result.set(\n    (point.x - this.min.x) / (this.max.x - this.min.x),\n    (point.y - this.min.y) / (this.max.y - this.min.y),\n    (point.z - this.min.z) / (this.max.z - this.min.z));\n\n\n  },\n\n  isIntersectionBox: function isIntersectionBox(box) {\n\n    // using 6 splitting planes to rule out intersections.\n\n    if (box.max.x < this.min.x || box.min.x > this.max.x ||\n    box.max.y < this.min.y || box.min.y > this.max.y ||\n    box.max.z < this.min.z || box.min.z > this.max.z) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  clampPoint: function clampPoint(point, optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector3();\n    return result.copy(point).clamp(this.min, this.max);\n\n  },\n\n  distanceToPoint: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (point) {\n\n      var clampedPoint = v1.copy(point).clamp(this.min, this.max);\n      return clampedPoint.sub(point).length();\n\n    };\n\n  }(),\n\n  getBoundingSphere: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (optionalTarget) {\n\n      var result = optionalTarget || new THREE.Sphere();\n\n      result.center = this.center();\n      result.radius = this.size(v1).length() * 0.5;\n\n      return result;\n\n    };\n\n  }(),\n\n  intersect: function intersect(box) {\n\n    this.min.max(box.min);\n    this.max.min(box.max);\n\n    return this;\n\n  },\n\n  union: function union(box) {\n\n    this.min.min(box.min);\n    this.max.max(box.max);\n\n    return this;\n\n  },\n\n  applyMatrix4: function () {\n\n    var points = [\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3(),\n    new THREE.Vector3()];\n\n\n    return function (matrix) {\n\n      // NOTE: I am using a binary pattern to specify all 2^3 combinations below\n      points[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(matrix); // 000\n      points[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(matrix); // 001\n      points[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(matrix); // 010\n      points[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(matrix); // 011\n      points[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(matrix); // 100\n      points[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(matrix); // 101\n      points[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(matrix); // 110\n      points[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(matrix); // 111\n\n      this.makeEmpty();\n      this.setFromPoints(points);\n\n      return this;\n\n    };\n\n  }(),\n\n  translate: function translate(offset) {\n\n    this.min.add(offset);\n    this.max.add(offset);\n\n    return this;\n\n  },\n\n  equals: function equals(box) {\n\n    return box.min.equals(this.min) && box.max.equals(this.max);\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Box3().copy(this);\n\n  } };\n\n\n\n// File:src/math/Matrix3.js\n\n/**\n * @author alteredq / http://alteredqualia.com/\n * @author WestLangley / http://github.com/WestLangley\n * @author bhouston / http://exocortex.com\n */\n\nTHREE.Matrix3 = function () {\n\n  this.elements = new Float32Array([\n\n  1, 0, 0,\n  0, 1, 0,\n  0, 0, 1]);\n\n\n\n  if (arguments.length > 0) {\n\n    THREE.error('THREE.Matrix3: the constructor no longer reads arguments. use .set() instead.');\n\n  }\n\n};\n\nTHREE.Matrix3.prototype = {\n\n  constructor: THREE.Matrix3,\n\n  set: function set(n11, n12, n13, n21, n22, n23, n31, n32, n33) {\n\n    var te = this.elements;\n\n    te[0] = n11;te[3] = n12;te[6] = n13;\n    te[1] = n21;te[4] = n22;te[7] = n23;\n    te[2] = n31;te[5] = n32;te[8] = n33;\n\n    return this;\n\n  },\n\n  identity: function identity() {\n\n    this.set(\n\n    1, 0, 0,\n    0, 1, 0,\n    0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  copy: function copy(m) {\n\n    var me = m.elements;\n\n    this.set(\n\n    me[0], me[3], me[6],\n    me[1], me[4], me[7],\n    me[2], me[5], me[8]);\n\n\n\n    return this;\n\n  },\n\n  multiplyVector3: function multiplyVector3(vector) {\n\n    THREE.warn('THREE.Matrix3: .multiplyVector3() has been removed. Use vector.applyMatrix3( matrix ) instead.');\n    return vector.applyMatrix3(this);\n\n  },\n\n  multiplyVector3Array: function multiplyVector3Array(a) {\n\n    THREE.warn('THREE.Matrix3: .multiplyVector3Array() has been renamed. Use matrix.applyToVector3Array( array ) instead.');\n    return this.applyToVector3Array(a);\n\n  },\n\n  applyToVector3Array: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (array, offset, length) {\n\n      if (offset === undefined) offset = 0;\n      if (length === undefined) length = array.length;\n\n      for (var i = 0, j = offset; i < length; i += 3, j += 3) {\n\n        v1.x = array[j];\n        v1.y = array[j + 1];\n        v1.z = array[j + 2];\n\n        v1.applyMatrix3(this);\n\n        array[j] = v1.x;\n        array[j + 1] = v1.y;\n        array[j + 2] = v1.z;\n\n      }\n\n      return array;\n\n    };\n\n  }(),\n\n  multiplyScalar: function multiplyScalar(s) {\n\n    var te = this.elements;\n\n    te[0] *= s;te[3] *= s;te[6] *= s;\n    te[1] *= s;te[4] *= s;te[7] *= s;\n    te[2] *= s;te[5] *= s;te[8] *= s;\n\n    return this;\n\n  },\n\n  determinant: function determinant() {\n\n    var te = this.elements;\n\n    var a = te[0],b = te[1],c = te[2],\n    d = te[3],e = te[4],f = te[5],\n    g = te[6],h = te[7],i = te[8];\n\n    return a * e * i - a * f * h - b * d * i + b * f * g + c * d * h - c * e * g;\n\n  },\n\n  getInverse: function getInverse(matrix, throwOnInvertible) {\n\n    // input: THREE.Matrix4\n    // ( based on http://code.google.com/p/webgl-mjs/ )\n\n    var me = matrix.elements;\n    var te = this.elements;\n\n    te[0] = me[10] * me[5] - me[6] * me[9];\n    te[1] = -me[10] * me[1] + me[2] * me[9];\n    te[2] = me[6] * me[1] - me[2] * me[5];\n    te[3] = -me[10] * me[4] + me[6] * me[8];\n    te[4] = me[10] * me[0] - me[2] * me[8];\n    te[5] = -me[6] * me[0] + me[2] * me[4];\n    te[6] = me[9] * me[4] - me[5] * me[8];\n    te[7] = -me[9] * me[0] + me[1] * me[8];\n    te[8] = me[5] * me[0] - me[1] * me[4];\n\n    var det = me[0] * te[0] + me[1] * te[3] + me[2] * te[6];\n\n    // no inverse\n\n    if (det === 0) {\n\n      var msg = \"Matrix3.getInverse(): can't invert matrix, determinant is 0\";\n\n      if (throwOnInvertible || false) {\n\n        throw new Error(msg);\n\n      } else {\n\n        THREE.warn(msg);\n\n      }\n\n      this.identity();\n\n      return this;\n\n    }\n\n    this.multiplyScalar(1.0 / det);\n\n    return this;\n\n  },\n\n  transpose: function transpose() {\n\n    var tmp,m = this.elements;\n\n    tmp = m[1];m[1] = m[3];m[3] = tmp;\n    tmp = m[2];m[2] = m[6];m[6] = tmp;\n    tmp = m[5];m[5] = m[7];m[7] = tmp;\n\n    return this;\n\n  },\n\n  flattenToArrayOffset: function flattenToArrayOffset(array, offset) {\n\n    var te = this.elements;\n\n    array[offset] = te[0];\n    array[offset + 1] = te[1];\n    array[offset + 2] = te[2];\n\n    array[offset + 3] = te[3];\n    array[offset + 4] = te[4];\n    array[offset + 5] = te[5];\n\n    array[offset + 6] = te[6];\n    array[offset + 7] = te[7];\n    array[offset + 8] = te[8];\n\n    return array;\n\n  },\n\n  getNormalMatrix: function getNormalMatrix(m) {\n\n    // input: THREE.Matrix4\n\n    this.getInverse(m).transpose();\n\n    return this;\n\n  },\n\n  transposeIntoArray: function transposeIntoArray(r) {\n\n    var m = this.elements;\n\n    r[0] = m[0];\n    r[1] = m[3];\n    r[2] = m[6];\n    r[3] = m[1];\n    r[4] = m[4];\n    r[5] = m[7];\n    r[6] = m[2];\n    r[7] = m[5];\n    r[8] = m[8];\n\n    return this;\n\n  },\n\n  fromArray: function fromArray(array) {\n\n    this.elements.set(array);\n\n    return this;\n\n  },\n\n  toArray: function toArray() {\n\n    var te = this.elements;\n\n    return [\n    te[0], te[1], te[2],\n    te[3], te[4], te[5],\n    te[6], te[7], te[8]];\n\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Matrix3().fromArray(this.elements);\n\n  } };\n\n\n\n// File:src/math/Matrix4.js\n\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author supereggbert / http://www.paulbrunt.co.uk/\n * @author philogb / http://blog.thejit.org/\n * @author jordi_ros / http://plattsoft.com\n * @author D1plo1d / http://github.com/D1plo1d\n * @author alteredq / http://alteredqualia.com/\n * @author mikael emtinger / http://gomo.se/\n * @author timknip / http://www.floorplanner.com/\n * @author bhouston / http://exocortex.com\n * @author WestLangley / http://github.com/WestLangley\n */\n\nTHREE.Matrix4 = function () {\n\n  this.elements = new Float32Array([\n\n  1, 0, 0, 0,\n  0, 1, 0, 0,\n  0, 0, 1, 0,\n  0, 0, 0, 1]);\n\n\n\n  if (arguments.length > 0) {\n\n    THREE.error('THREE.Matrix4: the constructor no longer reads arguments. use .set() instead.');\n\n  }\n\n};\n\nTHREE.Matrix4.prototype = {\n\n  constructor: THREE.Matrix4,\n\n  set: function set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {\n\n    var te = this.elements;\n\n    te[0] = n11;te[4] = n12;te[8] = n13;te[12] = n14;\n    te[1] = n21;te[5] = n22;te[9] = n23;te[13] = n24;\n    te[2] = n31;te[6] = n32;te[10] = n33;te[14] = n34;\n    te[3] = n41;te[7] = n42;te[11] = n43;te[15] = n44;\n\n    return this;\n\n  },\n\n  identity: function identity() {\n\n    this.set(\n\n    1, 0, 0, 0,\n    0, 1, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  copy: function copy(m) {\n\n    this.elements.set(m.elements);\n\n    return this;\n\n  },\n\n  extractPosition: function extractPosition(m) {\n\n    THREE.warn('THREE.Matrix4: .extractPosition() has been renamed to .copyPosition().');\n    return this.copyPosition(m);\n\n  },\n\n  copyPosition: function copyPosition(m) {\n\n    var te = this.elements;\n    var me = m.elements;\n\n    te[12] = me[12];\n    te[13] = me[13];\n    te[14] = me[14];\n\n    return this;\n\n  },\n\n  extractBasis: function extractBasis(xAxis, yAxis, zAxis) {\n\n    var te = this.elements;\n\n    xAxis.set(te[0], te[1], te[2]);\n    yAxis.set(te[4], te[5], te[6]);\n    zAxis.set(te[8], te[9], te[10]);\n\n    return this;\n\n  },\n\n  makeBasis: function makeBasis(xAxis, yAxis, zAxis) {\n\n    this.set(\n    xAxis.x, yAxis.x, zAxis.x, 0,\n    xAxis.y, yAxis.y, zAxis.y, 0,\n    xAxis.z, yAxis.z, zAxis.z, 0,\n    0, 0, 0, 1);\n\n\n    return this;\n\n  },\n\n  extractRotation: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (m) {\n\n      var te = this.elements;\n      var me = m.elements;\n\n      var scaleX = 1 / v1.set(me[0], me[1], me[2]).length();\n      var scaleY = 1 / v1.set(me[4], me[5], me[6]).length();\n      var scaleZ = 1 / v1.set(me[8], me[9], me[10]).length();\n\n      te[0] = me[0] * scaleX;\n      te[1] = me[1] * scaleX;\n      te[2] = me[2] * scaleX;\n\n      te[4] = me[4] * scaleY;\n      te[5] = me[5] * scaleY;\n      te[6] = me[6] * scaleY;\n\n      te[8] = me[8] * scaleZ;\n      te[9] = me[9] * scaleZ;\n      te[10] = me[10] * scaleZ;\n\n      return this;\n\n    };\n\n  }(),\n\n  makeRotationFromEuler: function makeRotationFromEuler(euler) {\n\n    if (euler instanceof THREE.Euler === false) {\n\n      THREE.error('THREE.Matrix: .makeRotationFromEuler() now expects a Euler rotation rather than a Vector3 and order.');\n\n    }\n\n    var te = this.elements;\n\n    var x = euler.x,y = euler.y,z = euler.z;\n    var a = Math.cos(x),b = Math.sin(x);\n    var c = Math.cos(y),d = Math.sin(y);\n    var e = Math.cos(z),f = Math.sin(z);\n\n    if (euler.order === 'XYZ') {\n\n      var ae = a * e,af = a * f,be = b * e,bf = b * f;\n\n      te[0] = c * e;\n      te[4] = -c * f;\n      te[8] = d;\n\n      te[1] = af + be * d;\n      te[5] = ae - bf * d;\n      te[9] = -b * c;\n\n      te[2] = bf - ae * d;\n      te[6] = be + af * d;\n      te[10] = a * c;\n\n    } else if (euler.order === 'YXZ') {\n\n      var ce = c * e,cf = c * f,de = d * e,df = d * f;\n\n      te[0] = ce + df * b;\n      te[4] = de * b - cf;\n      te[8] = a * d;\n\n      te[1] = a * f;\n      te[5] = a * e;\n      te[9] = -b;\n\n      te[2] = cf * b - de;\n      te[6] = df + ce * b;\n      te[10] = a * c;\n\n    } else if (euler.order === 'ZXY') {\n\n      var ce = c * e,cf = c * f,de = d * e,df = d * f;\n\n      te[0] = ce - df * b;\n      te[4] = -a * f;\n      te[8] = de + cf * b;\n\n      te[1] = cf + de * b;\n      te[5] = a * e;\n      te[9] = df - ce * b;\n\n      te[2] = -a * d;\n      te[6] = b;\n      te[10] = a * c;\n\n    } else if (euler.order === 'ZYX') {\n\n      var ae = a * e,af = a * f,be = b * e,bf = b * f;\n\n      te[0] = c * e;\n      te[4] = be * d - af;\n      te[8] = ae * d + bf;\n\n      te[1] = c * f;\n      te[5] = bf * d + ae;\n      te[9] = af * d - be;\n\n      te[2] = -d;\n      te[6] = b * c;\n      te[10] = a * c;\n\n    } else if (euler.order === 'YZX') {\n\n      var ac = a * c,ad = a * d,bc = b * c,bd = b * d;\n\n      te[0] = c * e;\n      te[4] = bd - ac * f;\n      te[8] = bc * f + ad;\n\n      te[1] = f;\n      te[5] = a * e;\n      te[9] = -b * e;\n\n      te[2] = -d * e;\n      te[6] = ad * f + bc;\n      te[10] = ac - bd * f;\n\n    } else if (euler.order === 'XZY') {\n\n      var ac = a * c,ad = a * d,bc = b * c,bd = b * d;\n\n      te[0] = c * e;\n      te[4] = -f;\n      te[8] = d * e;\n\n      te[1] = ac * f + bd;\n      te[5] = a * e;\n      te[9] = ad * f - bc;\n\n      te[2] = bc * f - ad;\n      te[6] = b * e;\n      te[10] = bd * f + ac;\n\n    }\n\n    // last column\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = 0;\n\n    // bottom row\n    te[12] = 0;\n    te[13] = 0;\n    te[14] = 0;\n    te[15] = 1;\n\n    return this;\n\n  },\n\n  setRotationFromQuaternion: function setRotationFromQuaternion(q) {\n\n    THREE.warn('THREE.Matrix4: .setRotationFromQuaternion() has been renamed to .makeRotationFromQuaternion().');\n\n    return this.makeRotationFromQuaternion(q);\n\n  },\n\n  makeRotationFromQuaternion: function makeRotationFromQuaternion(q) {\n\n    var te = this.elements;\n\n    var x = q.x,y = q.y,z = q.z,w = q.w;\n    var x2 = x + x,y2 = y + y,z2 = z + z;\n    var xx = x * x2,xy = x * y2,xz = x * z2;\n    var yy = y * y2,yz = y * z2,zz = z * z2;\n    var wx = w * x2,wy = w * y2,wz = w * z2;\n\n    te[0] = 1 - (yy + zz);\n    te[4] = xy - wz;\n    te[8] = xz + wy;\n\n    te[1] = xy + wz;\n    te[5] = 1 - (xx + zz);\n    te[9] = yz - wx;\n\n    te[2] = xz - wy;\n    te[6] = yz + wx;\n    te[10] = 1 - (xx + yy);\n\n    // last column\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = 0;\n\n    // bottom row\n    te[12] = 0;\n    te[13] = 0;\n    te[14] = 0;\n    te[15] = 1;\n\n    return this;\n\n  },\n\n  lookAt: function () {\n\n    var x = new THREE.Vector3();\n    var y = new THREE.Vector3();\n    var z = new THREE.Vector3();\n\n    return function (eye, target, up) {\n\n      var te = this.elements;\n\n      z.subVectors(eye, target).normalize();\n\n      if (z.length() === 0) {\n\n        z.z = 1;\n\n      }\n\n      x.crossVectors(up, z).normalize();\n\n      if (x.length() === 0) {\n\n        z.x += 0.0001;\n        x.crossVectors(up, z).normalize();\n\n      }\n\n      y.crossVectors(z, x);\n\n\n      te[0] = x.x;te[4] = y.x;te[8] = z.x;\n      te[1] = x.y;te[5] = y.y;te[9] = z.y;\n      te[2] = x.z;te[6] = y.z;te[10] = z.z;\n\n      return this;\n\n    };\n\n  }(),\n\n  multiply: function multiply(m, n) {\n\n    if (n !== undefined) {\n\n      THREE.warn('THREE.Matrix4: .multiply() now only accepts one argument. Use .multiplyMatrices( a, b ) instead.');\n      return this.multiplyMatrices(m, n);\n\n    }\n\n    return this.multiplyMatrices(this, m);\n\n  },\n\n  multiplyMatrices: function multiplyMatrices(a, b) {\n\n    var ae = a.elements;\n    var be = b.elements;\n    var te = this.elements;\n\n    var a11 = ae[0],a12 = ae[4],a13 = ae[8],a14 = ae[12];\n    var a21 = ae[1],a22 = ae[5],a23 = ae[9],a24 = ae[13];\n    var a31 = ae[2],a32 = ae[6],a33 = ae[10],a34 = ae[14];\n    var a41 = ae[3],a42 = ae[7],a43 = ae[11],a44 = ae[15];\n\n    var b11 = be[0],b12 = be[4],b13 = be[8],b14 = be[12];\n    var b21 = be[1],b22 = be[5],b23 = be[9],b24 = be[13];\n    var b31 = be[2],b32 = be[6],b33 = be[10],b34 = be[14];\n    var b41 = be[3],b42 = be[7],b43 = be[11],b44 = be[15];\n\n    te[0] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;\n    te[4] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;\n    te[8] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;\n    te[12] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;\n\n    te[1] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;\n    te[5] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;\n    te[9] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;\n    te[13] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;\n\n    te[2] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;\n    te[6] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;\n    te[10] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;\n    te[14] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;\n\n    te[3] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;\n    te[7] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;\n    te[11] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;\n    te[15] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;\n\n    return this;\n\n  },\n\n  multiplyToArray: function multiplyToArray(a, b, r) {\n\n    var te = this.elements;\n\n    this.multiplyMatrices(a, b);\n\n    r[0] = te[0];r[1] = te[1];r[2] = te[2];r[3] = te[3];\n    r[4] = te[4];r[5] = te[5];r[6] = te[6];r[7] = te[7];\n    r[8] = te[8];r[9] = te[9];r[10] = te[10];r[11] = te[11];\n    r[12] = te[12];r[13] = te[13];r[14] = te[14];r[15] = te[15];\n\n    return this;\n\n  },\n\n  multiplyScalar: function multiplyScalar(s) {\n\n    var te = this.elements;\n\n    te[0] *= s;te[4] *= s;te[8] *= s;te[12] *= s;\n    te[1] *= s;te[5] *= s;te[9] *= s;te[13] *= s;\n    te[2] *= s;te[6] *= s;te[10] *= s;te[14] *= s;\n    te[3] *= s;te[7] *= s;te[11] *= s;te[15] *= s;\n\n    return this;\n\n  },\n\n  multiplyVector3: function multiplyVector3(vector) {\n\n    THREE.warn('THREE.Matrix4: .multiplyVector3() has been removed. Use vector.applyMatrix4( matrix ) or vector.applyProjection( matrix ) instead.');\n    return vector.applyProjection(this);\n\n  },\n\n  multiplyVector4: function multiplyVector4(vector) {\n\n    THREE.warn('THREE.Matrix4: .multiplyVector4() has been removed. Use vector.applyMatrix4( matrix ) instead.');\n    return vector.applyMatrix4(this);\n\n  },\n\n  multiplyVector3Array: function multiplyVector3Array(a) {\n\n    THREE.warn('THREE.Matrix4: .multiplyVector3Array() has been renamed. Use matrix.applyToVector3Array( array ) instead.');\n    return this.applyToVector3Array(a);\n\n  },\n\n  applyToVector3Array: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (array, offset, length) {\n\n      if (offset === undefined) offset = 0;\n      if (length === undefined) length = array.length;\n\n      for (var i = 0, j = offset; i < length; i += 3, j += 3) {\n\n        v1.x = array[j];\n        v1.y = array[j + 1];\n        v1.z = array[j + 2];\n\n        v1.applyMatrix4(this);\n\n        array[j] = v1.x;\n        array[j + 1] = v1.y;\n        array[j + 2] = v1.z;\n\n      }\n\n      return array;\n\n    };\n\n  }(),\n\n  rotateAxis: function rotateAxis(v) {\n\n    THREE.warn('THREE.Matrix4: .rotateAxis() has been removed. Use Vector3.transformDirection( matrix ) instead.');\n\n    v.transformDirection(this);\n\n  },\n\n  crossVector: function crossVector(vector) {\n\n    THREE.warn('THREE.Matrix4: .crossVector() has been removed. Use vector.applyMatrix4( matrix ) instead.');\n    return vector.applyMatrix4(this);\n\n  },\n\n  determinant: function determinant() {\n\n    var te = this.elements;\n\n    var n11 = te[0],n12 = te[4],n13 = te[8],n14 = te[12];\n    var n21 = te[1],n22 = te[5],n23 = te[9],n24 = te[13];\n    var n31 = te[2],n32 = te[6],n33 = te[10],n34 = te[14];\n    var n41 = te[3],n42 = te[7],n43 = te[11],n44 = te[15];\n\n    //TODO: make this more efficient\n    //( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )\n\n    return (\n      n41 * (\n      +n14 * n23 * n32 -\n      n13 * n24 * n32 -\n      n14 * n22 * n33 +\n      n12 * n24 * n33 +\n      n13 * n22 * n34 -\n      n12 * n23 * n34) +\n\n      n42 * (\n      +n11 * n23 * n34 -\n      n11 * n24 * n33 +\n      n14 * n21 * n33 -\n      n13 * n21 * n34 +\n      n13 * n24 * n31 -\n      n14 * n23 * n31) +\n\n      n43 * (\n      +n11 * n24 * n32 -\n      n11 * n22 * n34 -\n      n14 * n21 * n32 +\n      n12 * n21 * n34 +\n      n14 * n22 * n31 -\n      n12 * n24 * n31) +\n\n      n44 * (\n      -n13 * n22 * n31 -\n      n11 * n23 * n32 +\n      n11 * n22 * n33 +\n      n13 * n21 * n32 -\n      n12 * n21 * n33 +\n      n12 * n23 * n31));\n\n\n\n\n  },\n\n  transpose: function transpose() {\n\n    var te = this.elements;\n    var tmp;\n\n    tmp = te[1];te[1] = te[4];te[4] = tmp;\n    tmp = te[2];te[2] = te[8];te[8] = tmp;\n    tmp = te[6];te[6] = te[9];te[9] = tmp;\n\n    tmp = te[3];te[3] = te[12];te[12] = tmp;\n    tmp = te[7];te[7] = te[13];te[13] = tmp;\n    tmp = te[11];te[11] = te[14];te[14] = tmp;\n\n    return this;\n\n  },\n\n  flattenToArrayOffset: function flattenToArrayOffset(array, offset) {\n\n    var te = this.elements;\n\n    array[offset] = te[0];\n    array[offset + 1] = te[1];\n    array[offset + 2] = te[2];\n    array[offset + 3] = te[3];\n\n    array[offset + 4] = te[4];\n    array[offset + 5] = te[5];\n    array[offset + 6] = te[6];\n    array[offset + 7] = te[7];\n\n    array[offset + 8] = te[8];\n    array[offset + 9] = te[9];\n    array[offset + 10] = te[10];\n    array[offset + 11] = te[11];\n\n    array[offset + 12] = te[12];\n    array[offset + 13] = te[13];\n    array[offset + 14] = te[14];\n    array[offset + 15] = te[15];\n\n    return array;\n\n  },\n\n  getPosition: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function () {\n\n      THREE.warn('THREE.Matrix4: .getPosition() has been removed. Use Vector3.setFromMatrixPosition( matrix ) instead.');\n\n      var te = this.elements;\n      return v1.set(te[12], te[13], te[14]);\n\n    };\n\n  }(),\n\n  setPosition: function setPosition(v) {\n\n    var te = this.elements;\n\n    te[12] = v.x;\n    te[13] = v.y;\n    te[14] = v.z;\n\n    return this;\n\n  },\n\n  getInverse: function getInverse(m, throwOnInvertible) {\n\n    // based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm\n    var te = this.elements;\n    var me = m.elements;\n\n    var n11 = me[0],n12 = me[4],n13 = me[8],n14 = me[12];\n    var n21 = me[1],n22 = me[5],n23 = me[9],n24 = me[13];\n    var n31 = me[2],n32 = me[6],n33 = me[10],n34 = me[14];\n    var n41 = me[3],n42 = me[7],n43 = me[11],n44 = me[15];\n\n    te[0] = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;\n    te[4] = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;\n    te[8] = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;\n    te[12] = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;\n    te[1] = n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44;\n    te[5] = n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44;\n    te[9] = n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44;\n    te[13] = n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34;\n    te[2] = n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44;\n    te[6] = n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44;\n    te[10] = n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44;\n    te[14] = n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34;\n    te[3] = n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43;\n    te[7] = n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43;\n    te[11] = n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43;\n    te[15] = n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33;\n\n    var det = n11 * te[0] + n21 * te[4] + n31 * te[8] + n41 * te[12];\n\n    if (det == 0) {\n\n      var msg = \"THREE.Matrix4.getInverse(): can't invert matrix, determinant is 0\";\n\n      if (throwOnInvertible || false) {\n\n        throw new Error(msg);\n\n      } else {\n\n        THREE.warn(msg);\n\n      }\n\n      this.identity();\n\n      return this;\n    }\n\n    this.multiplyScalar(1 / det);\n\n    return this;\n\n  },\n\n  translate: function translate(v) {\n\n    THREE.error('THREE.Matrix4: .translate() has been removed.');\n\n  },\n\n  rotateX: function rotateX(angle) {\n\n    THREE.error('THREE.Matrix4: .rotateX() has been removed.');\n\n  },\n\n  rotateY: function rotateY(angle) {\n\n    THREE.error('THREE.Matrix4: .rotateY() has been removed.');\n\n  },\n\n  rotateZ: function rotateZ(angle) {\n\n    THREE.error('THREE.Matrix4: .rotateZ() has been removed.');\n\n  },\n\n  rotateByAxis: function rotateByAxis(axis, angle) {\n\n    THREE.error('THREE.Matrix4: .rotateByAxis() has been removed.');\n\n  },\n\n  scale: function scale(v) {\n\n    var te = this.elements;\n    var x = v.x,y = v.y,z = v.z;\n\n    te[0] *= x;te[4] *= y;te[8] *= z;\n    te[1] *= x;te[5] *= y;te[9] *= z;\n    te[2] *= x;te[6] *= y;te[10] *= z;\n    te[3] *= x;te[7] *= y;te[11] *= z;\n\n    return this;\n\n  },\n\n  getMaxScaleOnAxis: function getMaxScaleOnAxis() {\n\n    var te = this.elements;\n\n    var scaleXSq = te[0] * te[0] + te[1] * te[1] + te[2] * te[2];\n    var scaleYSq = te[4] * te[4] + te[5] * te[5] + te[6] * te[6];\n    var scaleZSq = te[8] * te[8] + te[9] * te[9] + te[10] * te[10];\n\n    return Math.sqrt(Math.max(scaleXSq, Math.max(scaleYSq, scaleZSq)));\n\n  },\n\n  makeTranslation: function makeTranslation(x, y, z) {\n\n    this.set(\n\n    1, 0, 0, x,\n    0, 1, 0, y,\n    0, 0, 1, z,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationX: function makeRotationX(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    1, 0, 0, 0,\n    0, c, -s, 0,\n    0, s, c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationY: function makeRotationY(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    c, 0, s, 0,\n    0, 1, 0, 0,\n    -s, 0, c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationZ: function makeRotationZ(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    c, -s, 0, 0,\n    s, c, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationAxis: function makeRotationAxis(axis, angle) {\n\n    // Based on http://www.gamedev.net/reference/articles/article1199.asp\n\n    var c = Math.cos(angle);\n    var s = Math.sin(angle);\n    var t = 1 - c;\n    var x = axis.x,y = axis.y,z = axis.z;\n    var tx = t * x,ty = t * y;\n\n    this.set(\n\n    tx * x + c, tx * y - s * z, tx * z + s * y, 0,\n    tx * y + s * z, ty * y + c, ty * z - s * x, 0,\n    tx * z - s * y, ty * z + s * x, t * z * z + c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeScale: function makeScale(x, y, z) {\n\n    this.set(\n\n    x, 0, 0, 0,\n    0, y, 0, 0,\n    0, 0, z, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  compose: function compose(position, quaternion, scale) {\n\n    this.makeRotationFromQuaternion(quaternion);\n    this.scale(scale);\n    this.setPosition(position);\n\n    return this;\n\n  },\n\n  decompose: function () {\n\n    var vector = new THREE.Vector3();\n    var matrix = new THREE.Matrix4();\n\n    return function (position, quaternion, scale) {\n\n      var te = this.elements;\n\n      var sx = vector.set(te[0], te[1], te[2]).length();\n      var sy = vector.set(te[4], te[5], te[6]).length();\n      var sz = vector.set(te[8], te[9], te[10]).length();\n\n      // if determine is negative, we need to invert one scale\n      var det = this.determinant();\n      if (det < 0) {\n        sx = -sx;\n      }\n\n      position.x = te[12];\n      position.y = te[13];\n      position.z = te[14];\n\n      // scale the rotation part\n\n      matrix.elements.set(this.elements); // at this point matrix is incomplete so we can't use .copy()\n\n      var invSX = 1 / sx;\n      var invSY = 1 / sy;\n      var invSZ = 1 / sz;\n\n      matrix.elements[0] *= invSX;\n      matrix.elements[1] *= invSX;\n      matrix.elements[2] *= invSX;\n\n      matrix.elements[4] *= invSY;\n      matrix.elements[5] *= invSY;\n      matrix.elements[6] *= invSY;\n\n      matrix.elements[8] *= invSZ;\n      matrix.elements[9] *= invSZ;\n      matrix.elements[10] *= invSZ;\n\n      quaternion.setFromRotationMatrix(matrix);\n\n      scale.x = sx;\n      scale.y = sy;\n      scale.z = sz;\n\n      return this;\n\n    };\n\n  }(),\n\n  makeFrustum: function makeFrustum(left, right, bottom, top, near, far) {\n\n    var te = this.elements;\n    var x = 2 * near / (right - left);\n    var y = 2 * near / (top - bottom);\n\n    var a = (right + left) / (right - left);\n    var b = (top + bottom) / (top - bottom);\n    var c = -(far + near) / (far - near);\n    var d = -2 * far * near / (far - near);\n\n    te[0] = x;te[4] = 0;te[8] = a;te[12] = 0;\n    te[1] = 0;te[5] = y;te[9] = b;te[13] = 0;\n    te[2] = 0;te[6] = 0;te[10] = c;te[14] = d;\n    te[3] = 0;te[7] = 0;te[11] = -1;te[15] = 0;\n\n    return this;\n\n  },\n\n  makePerspective: function makePerspective(fov, aspect, near, far) {\n\n    var ymax = near * Math.tan(THREE.Math.degToRad(fov * 0.5));\n    var ymin = -ymax;\n    var xmin = ymin * aspect;\n    var xmax = ymax * aspect;\n\n    return this.makeFrustum(xmin, xmax, ymin, ymax, near, far);\n\n  },\n\n  makeOrthographic: function makeOrthographic(left, right, top, bottom, near, far) {\n\n    var te = this.elements;\n    var w = right - left;\n    var h = top - bottom;\n    var p = far - near;\n\n    var x = (right + left) / w;\n    var y = (top + bottom) / h;\n    var z = (far + near) / p;\n\n    te[0] = 2 / w;te[4] = 0;te[8] = 0;te[12] = -x;\n    te[1] = 0;te[5] = 2 / h;te[9] = 0;te[13] = -y;\n    te[2] = 0;te[6] = 0;te[10] = -2 / p;te[14] = -z;\n    te[3] = 0;te[7] = 0;te[11] = 0;te[15] = 1;\n\n    return this;\n\n  },\n\n  fromArray: function fromArray(array) {\n\n    this.elements.set(array);\n\n    return this;\n\n  },\n\n  toArray: function toArray() {\n\n    var te = this.elements;\n\n    return [\n    te[0], te[1], te[2], te[3],\n    te[4], te[5], te[6], te[7],\n    te[8], te[9], te[10], te[11],\n    te[12], te[13], te[14], te[15]];\n\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Matrix4().fromArray(this.elements);\n\n  } };\n\n\n\n// File:src/math/Sphere.js\n\n/**\n * @author bhouston / http://exocortex.com\n * @author mrdoob / http://mrdoob.com/\n */\n\nTHREE.Sphere = function (center, radius) {\n\n  this.center = center !== undefined ? center : new THREE.Vector3();\n  this.radius = radius !== undefined ? radius : 0;\n\n};\n\nTHREE.Sphere.prototype = {\n\n  constructor: THREE.Sphere,\n\n  set: function set(center, radius) {\n\n    this.center.copy(center);\n    this.radius = radius;\n\n    return this;\n  },\n\n  setFromPoints: function () {\n\n    var box = new THREE.Box3();\n\n    return function (points, optionalCenter) {\n\n      var center = this.center;\n\n      if (optionalCenter !== undefined) {\n\n        center.copy(optionalCenter);\n\n      } else {\n\n        box.setFromPoints(points).center(center);\n\n      }\n\n      var maxRadiusSq = 0;\n\n      for (var i = 0, il = points.length; i < il; i++) {\n\n        maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(points[i]));\n\n      }\n\n      this.radius = Math.sqrt(maxRadiusSq);\n\n      return this;\n\n    };\n\n  }(),\n\n  copy: function copy(sphere) {\n\n    this.center.copy(sphere.center);\n    this.radius = sphere.radius;\n\n    return this;\n\n  },\n\n  empty: function empty() {\n\n    return this.radius <= 0;\n\n  },\n\n  containsPoint: function containsPoint(point) {\n\n    return point.distanceToSquared(this.center) <= this.radius * this.radius;\n\n  },\n\n  distanceToPoint: function distanceToPoint(point) {\n\n    return point.distanceTo(this.center) - this.radius;\n\n  },\n\n  intersectsSphere: function intersectsSphere(sphere) {\n\n    var radiusSum = this.radius + sphere.radius;\n\n    return sphere.center.distanceToSquared(this.center) <= radiusSum * radiusSum;\n\n  },\n\n  clampPoint: function clampPoint(point, optionalTarget) {\n\n    var deltaLengthSq = this.center.distanceToSquared(point);\n\n    var result = optionalTarget || new THREE.Vector3();\n    result.copy(point);\n\n    if (deltaLengthSq > this.radius * this.radius) {\n\n      result.sub(this.center).normalize();\n      result.multiplyScalar(this.radius).add(this.center);\n\n    }\n\n    return result;\n\n  },\n\n  getBoundingBox: function getBoundingBox(optionalTarget) {\n\n    var box = optionalTarget || new THREE.Box3();\n\n    box.set(this.center, this.center);\n    box.expandByScalar(this.radius);\n\n    return box;\n\n  },\n\n  applyMatrix4: function applyMatrix4(matrix) {\n\n    this.center.applyMatrix4(matrix);\n    this.radius = this.radius * matrix.getMaxScaleOnAxis();\n\n    return this;\n\n  },\n\n  translate: function translate(offset) {\n\n    this.center.add(offset);\n\n    return this;\n\n  },\n\n  equals: function equals(sphere) {\n\n    return sphere.center.equals(this.center) && sphere.radius === this.radius;\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Sphere().copy(this);\n\n  } };\n\n\n\n// File:src/math/Frustum.js\n\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author alteredq / http://alteredqualia.com/\n * @author bhouston / http://exocortex.com\n */\n\nTHREE.Frustum = function (p0, p1, p2, p3, p4, p5) {\n\n  this.planes = [\n\n  p0 !== undefined ? p0 : new THREE.Plane(),\n  p1 !== undefined ? p1 : new THREE.Plane(),\n  p2 !== undefined ? p2 : new THREE.Plane(),\n  p3 !== undefined ? p3 : new THREE.Plane(),\n  p4 !== undefined ? p4 : new THREE.Plane(),\n  p5 !== undefined ? p5 : new THREE.Plane()];\n\n\n\n};\n\nTHREE.Frustum.prototype = {\n\n  constructor: THREE.Frustum,\n\n  set: function set(p0, p1, p2, p3, p4, p5) {\n\n    var planes = this.planes;\n\n    planes[0].copy(p0);\n    planes[1].copy(p1);\n    planes[2].copy(p2);\n    planes[3].copy(p3);\n    planes[4].copy(p4);\n    planes[5].copy(p5);\n\n    return this;\n\n  },\n\n  copy: function copy(frustum) {\n\n    var planes = this.planes;\n\n    for (var i = 0; i < 6; i++) {\n\n      planes[i].copy(frustum.planes[i]);\n\n    }\n\n    return this;\n\n  },\n\n  setFromMatrix: function setFromMatrix(m) {\n\n    var planes = this.planes;\n    var me = m.elements;\n    var me0 = me[0],me1 = me[1],me2 = me[2],me3 = me[3];\n    var me4 = me[4],me5 = me[5],me6 = me[6],me7 = me[7];\n    var me8 = me[8],me9 = me[9],me10 = me[10],me11 = me[11];\n    var me12 = me[12],me13 = me[13],me14 = me[14],me15 = me[15];\n\n    planes[0].setComponents(me3 - me0, me7 - me4, me11 - me8, me15 - me12).normalize();\n    planes[1].setComponents(me3 + me0, me7 + me4, me11 + me8, me15 + me12).normalize();\n    planes[2].setComponents(me3 + me1, me7 + me5, me11 + me9, me15 + me13).normalize();\n    planes[3].setComponents(me3 - me1, me7 - me5, me11 - me9, me15 - me13).normalize();\n    planes[4].setComponents(me3 - me2, me7 - me6, me11 - me10, me15 - me14).normalize();\n    planes[5].setComponents(me3 + me2, me7 + me6, me11 + me10, me15 + me14).normalize();\n\n    return this;\n\n  },\n\n  intersectsObject: function () {\n\n    var sphere = new THREE.Sphere();\n\n    return function (object) {\n\n      var geometry = object.geometry;\n\n      if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n\n      sphere.copy(geometry.boundingSphere);\n      sphere.applyMatrix4(object.matrixWorld);\n\n      return this.intersectsSphere(sphere);\n\n    };\n\n  }(),\n\n  intersectsSphere: function intersectsSphere(sphere) {\n\n    var planes = this.planes;\n    var center = sphere.center;\n    var negRadius = -sphere.radius;\n\n    for (var i = 0; i < 6; i++) {\n\n      var distance = planes[i].distanceToPoint(center);\n\n      if (distance < negRadius) {\n\n        return false;\n\n      }\n\n    }\n\n    return true;\n\n  },\n\n  intersectsBox: function () {\n\n    var p1 = new THREE.Vector3(),\n    p2 = new THREE.Vector3();\n\n    return function (box) {\n\n      var planes = this.planes;\n\n      for (var i = 0; i < 6; i++) {\n\n        var plane = planes[i];\n\n        p1.x = plane.normal.x > 0 ? box.min.x : box.max.x;\n        p2.x = plane.normal.x > 0 ? box.max.x : box.min.x;\n        p1.y = plane.normal.y > 0 ? box.min.y : box.max.y;\n        p2.y = plane.normal.y > 0 ? box.max.y : box.min.y;\n        p1.z = plane.normal.z > 0 ? box.min.z : box.max.z;\n        p2.z = plane.normal.z > 0 ? box.max.z : box.min.z;\n\n        var d1 = plane.distanceToPoint(p1);\n        var d2 = plane.distanceToPoint(p2);\n\n        // if both outside plane, no intersection\n\n        if (d1 < 0 && d2 < 0) {\n\n          return false;\n\n        }\n      }\n\n      return true;\n    };\n\n  }(),\n\n\n  containsPoint: function containsPoint(point) {\n\n    var planes = this.planes;\n\n    for (var i = 0; i < 6; i++) {\n\n      if (planes[i].distanceToPoint(point) < 0) {\n\n        return false;\n\n      }\n\n    }\n\n    return true;\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Frustum().copy(this);\n\n  } };\n\n\n\n// File:src/math/Plane.js\n\n/**\n * @author bhouston / http://exocortex.com\n */\n\nTHREE.Plane = function (normal, constant) {\n\n  this.normal = normal !== undefined ? normal : new THREE.Vector3(1, 0, 0);\n  this.constant = constant !== undefined ? constant : 0;\n\n};\n\nTHREE.Plane.prototype = {\n\n  constructor: THREE.Plane,\n\n  set: function set(normal, constant) {\n\n    this.normal.copy(normal);\n    this.constant = constant;\n\n    return this;\n\n  },\n\n  setComponents: function setComponents(x, y, z, w) {\n\n    this.normal.set(x, y, z);\n    this.constant = w;\n\n    return this;\n\n  },\n\n  setFromNormalAndCoplanarPoint: function setFromNormalAndCoplanarPoint(normal, point) {\n\n    this.normal.copy(normal);\n    this.constant = -point.dot(this.normal); // must be this.normal, not normal, as this.normal is normalized\n\n    return this;\n\n  },\n\n  setFromCoplanarPoints: function () {\n\n    var v1 = new THREE.Vector3();\n    var v2 = new THREE.Vector3();\n\n    return function (a, b, c) {\n\n      var normal = v1.subVectors(c, b).cross(v2.subVectors(a, b)).normalize();\n\n      // Q: should an error be thrown if normal is zero (e.g. degenerate plane)?\n\n      this.setFromNormalAndCoplanarPoint(normal, a);\n\n      return this;\n\n    };\n\n  }(),\n\n\n  copy: function copy(plane) {\n\n    this.normal.copy(plane.normal);\n    this.constant = plane.constant;\n\n    return this;\n\n  },\n\n  normalize: function normalize() {\n\n    // Note: will lead to a divide by zero if the plane is invalid.\n\n    var inverseNormalLength = 1.0 / this.normal.length();\n    this.normal.multiplyScalar(inverseNormalLength);\n    this.constant *= inverseNormalLength;\n\n    return this;\n\n  },\n\n  negate: function negate() {\n\n    this.constant *= -1;\n    this.normal.negate();\n\n    return this;\n\n  },\n\n  distanceToPoint: function distanceToPoint(point) {\n\n    return this.normal.dot(point) + this.constant;\n\n  },\n\n  distanceToSphere: function distanceToSphere(sphere) {\n\n    return this.distanceToPoint(sphere.center) - sphere.radius;\n\n  },\n\n  projectPoint: function projectPoint(point, optionalTarget) {\n\n    return this.orthoPoint(point, optionalTarget).sub(point).negate();\n\n  },\n\n  orthoPoint: function orthoPoint(point, optionalTarget) {\n\n    var perpendicularMagnitude = this.distanceToPoint(point);\n\n    var result = optionalTarget || new THREE.Vector3();\n    return result.copy(this.normal).multiplyScalar(perpendicularMagnitude);\n\n  },\n\n  isIntersectionLine: function isIntersectionLine(line) {\n\n    // Note: this tests if a line intersects the plane, not whether it (or its end-points) are coplanar with it.\n\n    var startSign = this.distanceToPoint(line.start);\n    var endSign = this.distanceToPoint(line.end);\n\n    return startSign < 0 && endSign > 0 || endSign < 0 && startSign > 0;\n\n  },\n\n  intersectLine: function () {\n\n    var v1 = new THREE.Vector3();\n\n    return function (line, optionalTarget) {\n\n      var result = optionalTarget || new THREE.Vector3();\n\n      var direction = line.delta(v1);\n\n      var denominator = this.normal.dot(direction);\n\n      if (denominator == 0) {\n\n        // line is coplanar, return origin\n        if (this.distanceToPoint(line.start) == 0) {\n\n          return result.copy(line.start);\n\n        }\n\n        // Unsure if this is the correct method to handle this case.\n        return undefined;\n\n      }\n\n      var t = -(line.start.dot(this.normal) + this.constant) / denominator;\n\n      if (t < 0 || t > 1) {\n\n        return undefined;\n\n      }\n\n      return result.copy(direction).multiplyScalar(t).add(line.start);\n\n    };\n\n  }(),\n\n\n  coplanarPoint: function coplanarPoint(optionalTarget) {\n\n    var result = optionalTarget || new THREE.Vector3();\n    return result.copy(this.normal).multiplyScalar(-this.constant);\n\n  },\n\n  applyMatrix4: function () {\n\n    var v1 = new THREE.Vector3();\n    var v2 = new THREE.Vector3();\n    var m1 = new THREE.Matrix3();\n\n    return function (matrix, optionalNormalMatrix) {\n\n      // compute new normal based on theory here:\n      // http://www.songho.ca/opengl/gl_normaltransform.html\n      var normalMatrix = optionalNormalMatrix || m1.getNormalMatrix(matrix);\n      var newNormal = v1.copy(this.normal).applyMatrix3(normalMatrix);\n\n      var newCoplanarPoint = this.coplanarPoint(v2);\n      newCoplanarPoint.applyMatrix4(matrix);\n\n      this.setFromNormalAndCoplanarPoint(newNormal, newCoplanarPoint);\n\n      return this;\n\n    };\n\n  }(),\n\n  translate: function translate(offset) {\n\n    this.constant = this.constant - offset.dot(this.normal);\n\n    return this;\n\n  },\n\n  equals: function equals(plane) {\n\n    return plane.normal.equals(this.normal) && plane.constant == this.constant;\n\n  },\n\n  clone: function clone() {\n\n    return new THREE.Plane().copy(this);\n\n  } };\n\n\n\n// File:src/math/Math.js\n\n/**\n * @author alteredq / http://alteredqualia.com/\n * @author mrdoob / http://mrdoob.com/\n */\n\nTHREE.Math = {\n\n  generateUUID: function () {\n\n    // http://www.broofa.com/Tools/Math.uuid.htm\n\n    var chars = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'.split('');\n    var uuid = new Array(36);\n    var rnd = 0,r;\n\n    return function () {\n\n      for (var i = 0; i < 36; i++) {\n\n        if (i == 8 || i == 13 || i == 18 || i == 23) {\n\n          uuid[i] = '-';\n\n        } else if (i == 14) {\n\n          uuid[i] = '4';\n\n        } else {\n\n          if (rnd <= 0x02) rnd = 0x2000000 + Math.random() * 0x1000000 | 0;\n          r = rnd & 0xf;\n          rnd = rnd >> 4;\n          uuid[i] = chars[i == 19 ? r & 0x3 | 0x8 : r];\n\n        }\n      }\n\n      return uuid.join('');\n\n    };\n\n  }(),\n\n  // Clamp value to range <a, b>\n\n  clamp: function clamp(x, a, b) {\n\n    return x < a ? a : x > b ? b : x;\n\n  },\n\n  // Clamp value to range <a, inf)\n\n  clampBottom: function clampBottom(x, a) {\n\n    return x < a ? a : x;\n\n  },\n\n  // Linear mapping from range <a1, a2> to range <b1, b2>\n\n  mapLinear: function mapLinear(x, a1, a2, b1, b2) {\n\n    return b1 + (x - a1) * (b2 - b1) / (a2 - a1);\n\n  },\n\n  // http://en.wikipedia.org/wiki/Smoothstep\n\n  smoothstep: function smoothstep(x, min, max) {\n\n    if (x <= min) return 0;\n    if (x >= max) return 1;\n\n    x = (x - min) / (max - min);\n\n    return x * x * (3 - 2 * x);\n\n  },\n\n  smootherstep: function smootherstep(x, min, max) {\n\n    if (x <= min) return 0;\n    if (x >= max) return 1;\n\n    x = (x - min) / (max - min);\n\n    return x * x * x * (x * (x * 6 - 15) + 10);\n\n  },\n\n  // Random float from <0, 1> with 16 bits of randomness\n  // (standard Math.random() creates repetitive patterns when applied over larger space)\n\n  random16: function random16() {\n\n    return (65280 * Math.random() + 255 * Math.random()) / 65535;\n\n  },\n\n  // Random integer from <low, high> interval\n\n  randInt: function randInt(low, high) {\n\n    return Math.floor(this.randFloat(low, high));\n\n  },\n\n  // Random float from <low, high> interval\n\n  randFloat: function randFloat(low, high) {\n\n    return low + Math.random() * (high - low);\n\n  },\n\n  // Random float from <-range/2, range/2> interval\n\n  randFloatSpread: function randFloatSpread(range) {\n\n    return range * (0.5 - Math.random());\n\n  },\n\n  degToRad: function () {\n\n    var degreeToRadiansFactor = Math.PI / 180;\n\n    return function (degrees) {\n\n      return degrees * degreeToRadiansFactor;\n\n    };\n\n  }(),\n\n  radToDeg: function () {\n\n    var radianToDegreesFactor = 180 / Math.PI;\n\n    return function (radians) {\n\n      return radians * radianToDegreesFactor;\n\n    };\n\n  }(),\n\n  isPowerOfTwo: function isPowerOfTwo(value) {\n\n    return (value & value - 1) === 0 && value !== 0;\n\n  },\n\n  nextPowerOfTwo: function nextPowerOfTwo(value) {\n\n    value--;\n    value |= value >> 1;\n    value |= value >> 2;\n    value |= value >> 4;\n    value |= value >> 8;\n    value |= value >> 16;\n    value++;\n\n    return value;\n\n  } };\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../../../../node_modules/webpack/buildin/module.js */ \"./node_modules/webpack/buildin/module.js\")(module)))\n\n/***/ }),\n\n/***/ \"./node_modules/babel-loader/lib/index.js?!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js\":\n/*!*******************************************************************************************************************!*\\\n  !*** ./node_modules/babel-loader/lib??ref--4!./extensions/MemoryLimited/file-loaders/workers/MainWorker-webML.js ***!\n  \\*******************************************************************************************************************/\n/*! no exports provided */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _MainWorkerML__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./MainWorkerML */ \"./extensions/MemoryLimited/file-loaders/workers/MainWorkerML.js\");\n\n\n\n//Web worker dispatcher function -- received a message\n//from the main thread and calls the appropriate handler\nself.addEventListener('message', function (e) {\n\n  var loadContext = e.data;\n  loadContext.worker = self;\n\n  _MainWorkerML__WEBPACK_IMPORTED_MODULE_0__[\"workerMainML\"].dispatch(loadContext);\n\n}, false);\n\n\nself.raiseError = function (code, msg, args) {\n  self.postMessage({ \"error\": { \"code\": code, \"msg\": msg, \"args\": args } });\n};\n\n// Shared by all workers to output debug message on console of main thread.\nfunction debug(msg) {\n  self.postMessage({ debug: 1, message: msg });\n}\n\nself.debug = debug;\n\n/***/ }),\n\n/***/ \"./node_modules/node-libs-browser/mock/empty.js\":\n/*!******************************************************!*\\\n  !*** ./node_modules/node-libs-browser/mock/empty.js ***!\n  \\******************************************************/\n/*! no static exports found */\n/***/ (function(module, exports) {\n\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/index.js\":\n/*!************************************!*\\\n  !*** ./node_modules/pako/index.js ***!\n  \\************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// Top level file is just a mixin of submodules & constants\n\n\nvar assign    = __webpack_require__(/*! ./lib/utils/common */ \"./node_modules/pako/lib/utils/common.js\").assign;\n\nvar deflate   = __webpack_require__(/*! ./lib/deflate */ \"./node_modules/pako/lib/deflate.js\");\nvar inflate   = __webpack_require__(/*! ./lib/inflate */ \"./node_modules/pako/lib/inflate.js\");\nvar constants = __webpack_require__(/*! ./lib/zlib/constants */ \"./node_modules/pako/lib/zlib/constants.js\");\n\nvar pako = {};\n\nassign(pako, deflate, inflate, constants);\n\nmodule.exports = pako;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/deflate.js\":\n/*!******************************************!*\\\n  !*** ./node_modules/pako/lib/deflate.js ***!\n  \\******************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n\nvar zlib_deflate = __webpack_require__(/*! ./zlib/deflate */ \"./node_modules/pako/lib/zlib/deflate.js\");\nvar utils        = __webpack_require__(/*! ./utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar strings      = __webpack_require__(/*! ./utils/strings */ \"./node_modules/pako/lib/utils/strings.js\");\nvar msg          = __webpack_require__(/*! ./zlib/messages */ \"./node_modules/pako/lib/zlib/messages.js\");\nvar ZStream      = __webpack_require__(/*! ./zlib/zstream */ \"./node_modules/pako/lib/zlib/zstream.js\");\n\nvar toString = Object.prototype.toString;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\nvar Z_NO_FLUSH      = 0;\nvar Z_FINISH        = 4;\n\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_SYNC_FLUSH    = 2;\n\nvar Z_DEFAULT_COMPRESSION = -1;\n\nvar Z_DEFAULT_STRATEGY    = 0;\n\nvar Z_DEFLATED  = 8;\n\n/* ===========================================================================*/\n\n\n/**\n * class Deflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[deflate]],\n * [[deflateRaw]] and [[gzip]].\n **/\n\n/* internal\n * Deflate.chunks -> Array\n *\n * Chunks of output data, if [[Deflate#onData]] not overridden.\n **/\n\n/**\n * Deflate.result -> Uint8Array|Array\n *\n * Compressed result, generated by default [[Deflate#onData]]\n * and [[Deflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Deflate#push]] with `Z_FINISH` / `true` param)  or if you\n * push a chunk with explicit flush (call [[Deflate#push]] with\n * `Z_SYNC_FLUSH` param).\n **/\n\n/**\n * Deflate.err -> Number\n *\n * Error code after deflate finished. 0 (Z_OK) on success.\n * You will not need it in real life, because deflate errors\n * are possible only on wrong options or bad `onData` / `onEnd`\n * custom handlers.\n **/\n\n/**\n * Deflate.msg -> String\n *\n * Error message, if [[Deflate.err]] != 0\n **/\n\n\n/**\n * new Deflate(options)\n * - options (Object): zlib deflate options.\n *\n * Creates new deflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `level`\n * - `windowBits`\n * - `memLevel`\n * - `strategy`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw deflate\n * - `gzip` (Boolean) - create gzip wrapper\n * - `to` (String) - if equal to 'string', then result will be \"binary string\"\n *    (each char code [0..255])\n * - `header` (Object) - custom header for gzip\n *   - `text` (Boolean) - true if compressed data believed to be text\n *   - `time` (Number) - modification time, unix timestamp\n *   - `os` (Number) - operation system code\n *   - `extra` (Array) - array of bytes with extra data (max 65536)\n *   - `name` (String) - file name (binary string)\n *   - `comment` (String) - comment (binary string)\n *   - `hcrc` (Boolean) - true if header crc should be added\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * var deflate = new pako.Deflate({ level: 3});\n *\n * deflate.push(chunk1, false);\n * deflate.push(chunk2, true);  // true -> last chunk\n *\n * if (deflate.err) { throw new Error(deflate.err); }\n *\n * console.log(deflate.result);\n * ```\n **/\nfunction Deflate(options) {\n  if (!(this instanceof Deflate)) return new Deflate(options);\n\n  this.options = utils.assign({\n    level: Z_DEFAULT_COMPRESSION,\n    method: Z_DEFLATED,\n    chunkSize: 16384,\n    windowBits: 15,\n    memLevel: 8,\n    strategy: Z_DEFAULT_STRATEGY,\n    to: ''\n  }, options || {});\n\n  var opt = this.options;\n\n  if (opt.raw && (opt.windowBits > 0)) {\n    opt.windowBits = -opt.windowBits;\n  }\n\n  else if (opt.gzip && (opt.windowBits > 0) && (opt.windowBits < 16)) {\n    opt.windowBits += 16;\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm = new ZStream();\n  this.strm.avail_out = 0;\n\n  var status = zlib_deflate.deflateInit2(\n    this.strm,\n    opt.level,\n    opt.method,\n    opt.windowBits,\n    opt.memLevel,\n    opt.strategy\n  );\n\n  if (status !== Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  if (opt.header) {\n    zlib_deflate.deflateSetHeader(this.strm, opt.header);\n  }\n\n  if (opt.dictionary) {\n    var dict;\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      // If we need to compress text, change encoding to utf8.\n      dict = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      dict = new Uint8Array(opt.dictionary);\n    } else {\n      dict = opt.dictionary;\n    }\n\n    status = zlib_deflate.deflateSetDictionary(this.strm, dict);\n\n    if (status !== Z_OK) {\n      throw new Error(msg[status]);\n    }\n\n    this._dict_set = true;\n  }\n}\n\n/**\n * Deflate#push(data[, mode]) -> Boolean\n * - data (Uint8Array|Array|ArrayBuffer|String): input data. Strings will be\n *   converted to utf8 byte sequence.\n * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to deflate pipe, generating [[Deflate#onData]] calls with\n * new compressed chunks. Returns `true` on success. The last data block must have\n * mode Z_FINISH (or `true`). That will flush internal pending buffers and call\n * [[Deflate#onEnd]]. For interim explicit flushes (without ending the stream) you\n * can use mode Z_SYNC_FLUSH, keeping the compression context.\n *\n * On fail call [[Deflate#onEnd]] with error code and return false.\n *\n * We strongly recommend to use `Uint8Array` on input for best speed (output\n * array format is detected automatically). Also, don't skip last param and always\n * use the same type in your code (boolean or number). That will improve JS speed.\n *\n * For regular `Array`-s make sure all elements are [0..255].\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nDeflate.prototype.push = function (data, mode) {\n  var strm = this.strm;\n  var chunkSize = this.options.chunkSize;\n  var status, _mode;\n\n  if (this.ended) { return false; }\n\n  _mode = (mode === ~~mode) ? mode : ((mode === true) ? Z_FINISH : Z_NO_FLUSH);\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // If we need to compress text, change encoding to utf8.\n    strm.input = strings.string2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  do {\n    if (strm.avail_out === 0) {\n      strm.output = new utils.Buf8(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n    status = zlib_deflate.deflate(strm, _mode);    /* no bad return value */\n\n    if (status !== Z_STREAM_END && status !== Z_OK) {\n      this.onEnd(status);\n      this.ended = true;\n      return false;\n    }\n    if (strm.avail_out === 0 || (strm.avail_in === 0 && (_mode === Z_FINISH || _mode === Z_SYNC_FLUSH))) {\n      if (this.options.to === 'string') {\n        this.onData(strings.buf2binstring(utils.shrinkBuf(strm.output, strm.next_out)));\n      } else {\n        this.onData(utils.shrinkBuf(strm.output, strm.next_out));\n      }\n    }\n  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== Z_STREAM_END);\n\n  // Finalize on the last chunk.\n  if (_mode === Z_FINISH) {\n    status = zlib_deflate.deflateEnd(this.strm);\n    this.onEnd(status);\n    this.ended = true;\n    return status === Z_OK;\n  }\n\n  // callback interim results if Z_SYNC_FLUSH.\n  if (_mode === Z_SYNC_FLUSH) {\n    this.onEnd(Z_OK);\n    strm.avail_out = 0;\n    return true;\n  }\n\n  return true;\n};\n\n\n/**\n * Deflate#onData(chunk) -> Void\n * - chunk (Uint8Array|Array|String): output data. Type of array depends\n *   on js engine support. When string output requested, each chunk\n *   will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nDeflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Deflate#onEnd(status) -> Void\n * - status (Number): deflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called once after you tell deflate that the input stream is\n * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)\n * or if an error happened. By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nDeflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === Z_OK) {\n    if (this.options.to === 'string') {\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * deflate(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * Compress `data` with deflate algorithm and `options`.\n *\n * Supported options are:\n *\n * - level\n * - windowBits\n * - memLevel\n * - strategy\n * - dictionary\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be \"binary string\"\n *    (each char code [0..255])\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , data = Uint8Array([1,2,3,4,5,6,7,8,9]);\n *\n * console.log(pako.deflate(data));\n * ```\n **/\nfunction deflate(input, options) {\n  var deflator = new Deflate(options);\n\n  deflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (deflator.err) { throw deflator.msg || msg[deflator.err]; }\n\n  return deflator.result;\n}\n\n\n/**\n * deflateRaw(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction deflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return deflate(input, options);\n}\n\n\n/**\n * gzip(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to compress.\n * - options (Object): zlib deflate options.\n *\n * The same as [[deflate]], but create gzip wrapper instead of\n * deflate one.\n **/\nfunction gzip(input, options) {\n  options = options || {};\n  options.gzip = true;\n  return deflate(input, options);\n}\n\n\nexports.Deflate = Deflate;\nexports.deflate = deflate;\nexports.deflateRaw = deflateRaw;\nexports.gzip = gzip;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/inflate.js\":\n/*!******************************************!*\\\n  !*** ./node_modules/pako/lib/inflate.js ***!\n  \\******************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n\nvar zlib_inflate = __webpack_require__(/*! ./zlib/inflate */ \"./node_modules/pako/lib/zlib/inflate.js\");\nvar utils        = __webpack_require__(/*! ./utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar strings      = __webpack_require__(/*! ./utils/strings */ \"./node_modules/pako/lib/utils/strings.js\");\nvar c            = __webpack_require__(/*! ./zlib/constants */ \"./node_modules/pako/lib/zlib/constants.js\");\nvar msg          = __webpack_require__(/*! ./zlib/messages */ \"./node_modules/pako/lib/zlib/messages.js\");\nvar ZStream      = __webpack_require__(/*! ./zlib/zstream */ \"./node_modules/pako/lib/zlib/zstream.js\");\nvar GZheader     = __webpack_require__(/*! ./zlib/gzheader */ \"./node_modules/pako/lib/zlib/gzheader.js\");\n\nvar toString = Object.prototype.toString;\n\n/**\n * class Inflate\n *\n * Generic JS-style wrapper for zlib calls. If you don't need\n * streaming behaviour - use more simple functions: [[inflate]]\n * and [[inflateRaw]].\n **/\n\n/* internal\n * inflate.chunks -> Array\n *\n * Chunks of output data, if [[Inflate#onData]] not overridden.\n **/\n\n/**\n * Inflate.result -> Uint8Array|Array|String\n *\n * Uncompressed result, generated by default [[Inflate#onData]]\n * and [[Inflate#onEnd]] handlers. Filled after you push last chunk\n * (call [[Inflate#push]] with `Z_FINISH` / `true` param) or if you\n * push a chunk with explicit flush (call [[Inflate#push]] with\n * `Z_SYNC_FLUSH` param).\n **/\n\n/**\n * Inflate.err -> Number\n *\n * Error code after inflate finished. 0 (Z_OK) on success.\n * Should be checked if broken data possible.\n **/\n\n/**\n * Inflate.msg -> String\n *\n * Error message, if [[Inflate.err]] != 0\n **/\n\n\n/**\n * new Inflate(options)\n * - options (Object): zlib inflate options.\n *\n * Creates new inflator instance with specified params. Throws exception\n * on bad params. Supported options:\n *\n * - `windowBits`\n * - `dictionary`\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information on these.\n *\n * Additional options, for internal needs:\n *\n * - `chunkSize` - size of generated data chunks (16K by default)\n * - `raw` (Boolean) - do raw inflate\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n * By default, when no options set, autodetect deflate/gzip data format via\n * wrapper header.\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , chunk1 = Uint8Array([1,2,3,4,5,6,7,8,9])\n *   , chunk2 = Uint8Array([10,11,12,13,14,15,16,17,18,19]);\n *\n * var inflate = new pako.Inflate({ level: 3});\n *\n * inflate.push(chunk1, false);\n * inflate.push(chunk2, true);  // true -> last chunk\n *\n * if (inflate.err) { throw new Error(inflate.err); }\n *\n * console.log(inflate.result);\n * ```\n **/\nfunction Inflate(options) {\n  if (!(this instanceof Inflate)) return new Inflate(options);\n\n  this.options = utils.assign({\n    chunkSize: 16384,\n    windowBits: 0,\n    to: ''\n  }, options || {});\n\n  var opt = this.options;\n\n  // Force window size for `raw` data, if not set directly,\n  // because we have no header for autodetect.\n  if (opt.raw && (opt.windowBits >= 0) && (opt.windowBits < 16)) {\n    opt.windowBits = -opt.windowBits;\n    if (opt.windowBits === 0) { opt.windowBits = -15; }\n  }\n\n  // If `windowBits` not defined (and mode not raw) - set autodetect flag for gzip/deflate\n  if ((opt.windowBits >= 0) && (opt.windowBits < 16) &&\n      !(options && options.windowBits)) {\n    opt.windowBits += 32;\n  }\n\n  // Gzip header has no info about windows size, we can do autodetect only\n  // for deflate. So, if window size not set, force it to max when gzip possible\n  if ((opt.windowBits > 15) && (opt.windowBits < 48)) {\n    // bit 3 (16) -> gzipped data\n    // bit 4 (32) -> autodetect gzip/deflate\n    if ((opt.windowBits & 15) === 0) {\n      opt.windowBits |= 15;\n    }\n  }\n\n  this.err    = 0;      // error code, if happens (0 = Z_OK)\n  this.msg    = '';     // error message\n  this.ended  = false;  // used to avoid multiple onEnd() calls\n  this.chunks = [];     // chunks of compressed data\n\n  this.strm   = new ZStream();\n  this.strm.avail_out = 0;\n\n  var status  = zlib_inflate.inflateInit2(\n    this.strm,\n    opt.windowBits\n  );\n\n  if (status !== c.Z_OK) {\n    throw new Error(msg[status]);\n  }\n\n  this.header = new GZheader();\n\n  zlib_inflate.inflateGetHeader(this.strm, this.header);\n\n  // Setup dictionary\n  if (opt.dictionary) {\n    // Convert data if needed\n    if (typeof opt.dictionary === 'string') {\n      opt.dictionary = strings.string2buf(opt.dictionary);\n    } else if (toString.call(opt.dictionary) === '[object ArrayBuffer]') {\n      opt.dictionary = new Uint8Array(opt.dictionary);\n    }\n    if (opt.raw) { //In raw mode we need to set the dictionary early\n      status = zlib_inflate.inflateSetDictionary(this.strm, opt.dictionary);\n      if (status !== c.Z_OK) {\n        throw new Error(msg[status]);\n      }\n    }\n  }\n}\n\n/**\n * Inflate#push(data[, mode]) -> Boolean\n * - data (Uint8Array|Array|ArrayBuffer|String): input data\n * - mode (Number|Boolean): 0..6 for corresponding Z_NO_FLUSH..Z_TREE modes.\n *   See constants. Skipped or `false` means Z_NO_FLUSH, `true` means Z_FINISH.\n *\n * Sends input data to inflate pipe, generating [[Inflate#onData]] calls with\n * new output chunks. Returns `true` on success. The last data block must have\n * mode Z_FINISH (or `true`). That will flush internal pending buffers and call\n * [[Inflate#onEnd]]. For interim explicit flushes (without ending the stream) you\n * can use mode Z_SYNC_FLUSH, keeping the decompression context.\n *\n * On fail call [[Inflate#onEnd]] with error code and return false.\n *\n * We strongly recommend to use `Uint8Array` on input for best speed (output\n * format is detected automatically). Also, don't skip last param and always\n * use the same type in your code (boolean or number). That will improve JS speed.\n *\n * For regular `Array`-s make sure all elements are [0..255].\n *\n * ##### Example\n *\n * ```javascript\n * push(chunk, false); // push one of data chunks\n * ...\n * push(chunk, true);  // push last chunk\n * ```\n **/\nInflate.prototype.push = function (data, mode) {\n  var strm = this.strm;\n  var chunkSize = this.options.chunkSize;\n  var dictionary = this.options.dictionary;\n  var status, _mode;\n  var next_out_utf8, tail, utf8str;\n\n  // Flag to properly process Z_BUF_ERROR on testing inflate call\n  // when we check that all output data was flushed.\n  var allowBufError = false;\n\n  if (this.ended) { return false; }\n  _mode = (mode === ~~mode) ? mode : ((mode === true) ? c.Z_FINISH : c.Z_NO_FLUSH);\n\n  // Convert data if needed\n  if (typeof data === 'string') {\n    // Only binary strings can be decompressed on practice\n    strm.input = strings.binstring2buf(data);\n  } else if (toString.call(data) === '[object ArrayBuffer]') {\n    strm.input = new Uint8Array(data);\n  } else {\n    strm.input = data;\n  }\n\n  strm.next_in = 0;\n  strm.avail_in = strm.input.length;\n\n  do {\n    if (strm.avail_out === 0) {\n      strm.output = new utils.Buf8(chunkSize);\n      strm.next_out = 0;\n      strm.avail_out = chunkSize;\n    }\n\n    status = zlib_inflate.inflate(strm, c.Z_NO_FLUSH);    /* no bad return value */\n\n    if (status === c.Z_NEED_DICT && dictionary) {\n      status = zlib_inflate.inflateSetDictionary(this.strm, dictionary);\n    }\n\n    if (status === c.Z_BUF_ERROR && allowBufError === true) {\n      status = c.Z_OK;\n      allowBufError = false;\n    }\n\n    if (status !== c.Z_STREAM_END && status !== c.Z_OK) {\n      this.onEnd(status);\n      this.ended = true;\n      return false;\n    }\n\n    if (strm.next_out) {\n      if (strm.avail_out === 0 || status === c.Z_STREAM_END || (strm.avail_in === 0 && (_mode === c.Z_FINISH || _mode === c.Z_SYNC_FLUSH))) {\n\n        if (this.options.to === 'string') {\n\n          next_out_utf8 = strings.utf8border(strm.output, strm.next_out);\n\n          tail = strm.next_out - next_out_utf8;\n          utf8str = strings.buf2string(strm.output, next_out_utf8);\n\n          // move tail\n          strm.next_out = tail;\n          strm.avail_out = chunkSize - tail;\n          if (tail) { utils.arraySet(strm.output, strm.output, next_out_utf8, tail, 0); }\n\n          this.onData(utf8str);\n\n        } else {\n          this.onData(utils.shrinkBuf(strm.output, strm.next_out));\n        }\n      }\n    }\n\n    // When no more input data, we should check that internal inflate buffers\n    // are flushed. The only way to do it when avail_out = 0 - run one more\n    // inflate pass. But if output data not exists, inflate return Z_BUF_ERROR.\n    // Here we set flag to process this error properly.\n    //\n    // NOTE. Deflate does not return error in this case and does not needs such\n    // logic.\n    if (strm.avail_in === 0 && strm.avail_out === 0) {\n      allowBufError = true;\n    }\n\n  } while ((strm.avail_in > 0 || strm.avail_out === 0) && status !== c.Z_STREAM_END);\n\n  if (status === c.Z_STREAM_END) {\n    _mode = c.Z_FINISH;\n  }\n\n  // Finalize on the last chunk.\n  if (_mode === c.Z_FINISH) {\n    status = zlib_inflate.inflateEnd(this.strm);\n    this.onEnd(status);\n    this.ended = true;\n    return status === c.Z_OK;\n  }\n\n  // callback interim results if Z_SYNC_FLUSH.\n  if (_mode === c.Z_SYNC_FLUSH) {\n    this.onEnd(c.Z_OK);\n    strm.avail_out = 0;\n    return true;\n  }\n\n  return true;\n};\n\n\n/**\n * Inflate#onData(chunk) -> Void\n * - chunk (Uint8Array|Array|String): output data. Type of array depends\n *   on js engine support. When string output requested, each chunk\n *   will be string.\n *\n * By default, stores data blocks in `chunks[]` property and glue\n * those in `onEnd`. Override this handler, if you need another behaviour.\n **/\nInflate.prototype.onData = function (chunk) {\n  this.chunks.push(chunk);\n};\n\n\n/**\n * Inflate#onEnd(status) -> Void\n * - status (Number): inflate status. 0 (Z_OK) on success,\n *   other if not.\n *\n * Called either after you tell inflate that the input stream is\n * complete (Z_FINISH) or should be flushed (Z_SYNC_FLUSH)\n * or if an error happened. By default - join collected chunks,\n * free memory and fill `results` / `err` properties.\n **/\nInflate.prototype.onEnd = function (status) {\n  // On success - join\n  if (status === c.Z_OK) {\n    if (this.options.to === 'string') {\n      // Glue & convert here, until we teach pako to send\n      // utf8 aligned strings to onData\n      this.result = this.chunks.join('');\n    } else {\n      this.result = utils.flattenChunks(this.chunks);\n    }\n  }\n  this.chunks = [];\n  this.err = status;\n  this.msg = this.strm.msg;\n};\n\n\n/**\n * inflate(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Decompress `data` with inflate/ungzip and `options`. Autodetect\n * format via wrapper header by default. That's why we don't provide\n * separate `ungzip` method.\n *\n * Supported options are:\n *\n * - windowBits\n *\n * [http://zlib.net/manual.html#Advanced](http://zlib.net/manual.html#Advanced)\n * for more information.\n *\n * Sugar (options):\n *\n * - `raw` (Boolean) - say that we work with raw stream, if you don't wish to specify\n *   negative windowBits implicitly.\n * - `to` (String) - if equal to 'string', then result will be converted\n *   from utf8 to utf16 (javascript) string. When string output requested,\n *   chunk length can differ from `chunkSize`, depending on content.\n *\n *\n * ##### Example:\n *\n * ```javascript\n * var pako = require('pako')\n *   , input = pako.deflate([1,2,3,4,5,6,7,8,9])\n *   , output;\n *\n * try {\n *   output = pako.inflate(input);\n * } catch (err)\n *   console.log(err);\n * }\n * ```\n **/\nfunction inflate(input, options) {\n  var inflator = new Inflate(options);\n\n  inflator.push(input, true);\n\n  // That will never happens, if you don't cheat with options :)\n  if (inflator.err) { throw inflator.msg || msg[inflator.err]; }\n\n  return inflator.result;\n}\n\n\n/**\n * inflateRaw(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * The same as [[inflate]], but creates raw data, without wrapper\n * (header and adler32 crc).\n **/\nfunction inflateRaw(input, options) {\n  options = options || {};\n  options.raw = true;\n  return inflate(input, options);\n}\n\n\n/**\n * ungzip(data[, options]) -> Uint8Array|Array|String\n * - data (Uint8Array|Array|String): input data to decompress.\n * - options (Object): zlib inflate options.\n *\n * Just shortcut to [[inflate]], because it autodetects format\n * by header.content. Done for convenience.\n **/\n\n\nexports.Inflate = Inflate;\nexports.inflate = inflate;\nexports.inflateRaw = inflateRaw;\nexports.ungzip  = inflate;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/utils/common.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/utils/common.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n\nvar TYPED_OK =  (typeof Uint8Array !== 'undefined') &&\n                (typeof Uint16Array !== 'undefined') &&\n                (typeof Int32Array !== 'undefined');\n\nfunction _has(obj, key) {\n  return Object.prototype.hasOwnProperty.call(obj, key);\n}\n\nexports.assign = function (obj /*from1, from2, from3, ...*/) {\n  var sources = Array.prototype.slice.call(arguments, 1);\n  while (sources.length) {\n    var source = sources.shift();\n    if (!source) { continue; }\n\n    if (typeof source !== 'object') {\n      throw new TypeError(source + 'must be non-object');\n    }\n\n    for (var p in source) {\n      if (_has(source, p)) {\n        obj[p] = source[p];\n      }\n    }\n  }\n\n  return obj;\n};\n\n\n// reduce buffer size, avoiding mem copy\nexports.shrinkBuf = function (buf, size) {\n  if (buf.length === size) { return buf; }\n  if (buf.subarray) { return buf.subarray(0, size); }\n  buf.length = size;\n  return buf;\n};\n\n\nvar fnTyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    if (src.subarray && dest.subarray) {\n      dest.set(src.subarray(src_offs, src_offs + len), dest_offs);\n      return;\n    }\n    // Fallback to ordinary array\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    var i, l, len, pos, chunk, result;\n\n    // calculate data length\n    len = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      len += chunks[i].length;\n    }\n\n    // join chunks\n    result = new Uint8Array(len);\n    pos = 0;\n    for (i = 0, l = chunks.length; i < l; i++) {\n      chunk = chunks[i];\n      result.set(chunk, pos);\n      pos += chunk.length;\n    }\n\n    return result;\n  }\n};\n\nvar fnUntyped = {\n  arraySet: function (dest, src, src_offs, len, dest_offs) {\n    for (var i = 0; i < len; i++) {\n      dest[dest_offs + i] = src[src_offs + i];\n    }\n  },\n  // Join array of chunks to single array.\n  flattenChunks: function (chunks) {\n    return [].concat.apply([], chunks);\n  }\n};\n\n\n// Enable/Disable typed arrays use, for testing\n//\nexports.setTyped = function (on) {\n  if (on) {\n    exports.Buf8  = Uint8Array;\n    exports.Buf16 = Uint16Array;\n    exports.Buf32 = Int32Array;\n    exports.assign(exports, fnTyped);\n  } else {\n    exports.Buf8  = Array;\n    exports.Buf16 = Array;\n    exports.Buf32 = Array;\n    exports.assign(exports, fnUntyped);\n  }\n};\n\nexports.setTyped(TYPED_OK);\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/utils/strings.js\":\n/*!************************************************!*\\\n  !*** ./node_modules/pako/lib/utils/strings.js ***!\n  \\************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n// String encode/decode helpers\n\n\n\nvar utils = __webpack_require__(/*! ./common */ \"./node_modules/pako/lib/utils/common.js\");\n\n\n// Quick check if we can use fast array to bin string conversion\n//\n// - apply(Array) can fail on Android 2.2\n// - apply(Uint8Array) can fail on iOS 5.1 Safari\n//\nvar STR_APPLY_OK = true;\nvar STR_APPLY_UIA_OK = true;\n\ntry { String.fromCharCode.apply(null, [ 0 ]); } catch (__) { STR_APPLY_OK = false; }\ntry { String.fromCharCode.apply(null, new Uint8Array(1)); } catch (__) { STR_APPLY_UIA_OK = false; }\n\n\n// Table with utf8 lengths (calculated by first byte of sequence)\n// Note, that 5 & 6-byte values and some 4-byte values can not be represented in JS,\n// because max possible codepoint is 0x10ffff\nvar _utf8len = new utils.Buf8(256);\nfor (var q = 0; q < 256; q++) {\n  _utf8len[q] = (q >= 252 ? 6 : q >= 248 ? 5 : q >= 240 ? 4 : q >= 224 ? 3 : q >= 192 ? 2 : 1);\n}\n_utf8len[254] = _utf8len[254] = 1; // Invalid sequence start\n\n\n// convert string to array (typed, when possible)\nexports.string2buf = function (str) {\n  var buf, c, c2, m_pos, i, str_len = str.length, buf_len = 0;\n\n  // count binary size\n  for (m_pos = 0; m_pos < str_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    buf_len += c < 0x80 ? 1 : c < 0x800 ? 2 : c < 0x10000 ? 3 : 4;\n  }\n\n  // allocate buffer\n  buf = new utils.Buf8(buf_len);\n\n  // convert\n  for (i = 0, m_pos = 0; i < buf_len; m_pos++) {\n    c = str.charCodeAt(m_pos);\n    if ((c & 0xfc00) === 0xd800 && (m_pos + 1 < str_len)) {\n      c2 = str.charCodeAt(m_pos + 1);\n      if ((c2 & 0xfc00) === 0xdc00) {\n        c = 0x10000 + ((c - 0xd800) << 10) + (c2 - 0xdc00);\n        m_pos++;\n      }\n    }\n    if (c < 0x80) {\n      /* one byte */\n      buf[i++] = c;\n    } else if (c < 0x800) {\n      /* two bytes */\n      buf[i++] = 0xC0 | (c >>> 6);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else if (c < 0x10000) {\n      /* three bytes */\n      buf[i++] = 0xE0 | (c >>> 12);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    } else {\n      /* four bytes */\n      buf[i++] = 0xf0 | (c >>> 18);\n      buf[i++] = 0x80 | (c >>> 12 & 0x3f);\n      buf[i++] = 0x80 | (c >>> 6 & 0x3f);\n      buf[i++] = 0x80 | (c & 0x3f);\n    }\n  }\n\n  return buf;\n};\n\n// Helper (used in 2 places)\nfunction buf2binstring(buf, len) {\n  // On Chrome, the arguments in a function call that are allowed is `65534`.\n  // If the length of the buffer is smaller than that, we can use this optimization,\n  // otherwise we will take a slower path.\n  if (len < 65534) {\n    if ((buf.subarray && STR_APPLY_UIA_OK) || (!buf.subarray && STR_APPLY_OK)) {\n      return String.fromCharCode.apply(null, utils.shrinkBuf(buf, len));\n    }\n  }\n\n  var result = '';\n  for (var i = 0; i < len; i++) {\n    result += String.fromCharCode(buf[i]);\n  }\n  return result;\n}\n\n\n// Convert byte array to binary string\nexports.buf2binstring = function (buf) {\n  return buf2binstring(buf, buf.length);\n};\n\n\n// Convert binary string (typed, when possible)\nexports.binstring2buf = function (str) {\n  var buf = new utils.Buf8(str.length);\n  for (var i = 0, len = buf.length; i < len; i++) {\n    buf[i] = str.charCodeAt(i);\n  }\n  return buf;\n};\n\n\n// convert array to string\nexports.buf2string = function (buf, max) {\n  var i, out, c, c_len;\n  var len = max || buf.length;\n\n  // Reserve max possible length (2 words per char)\n  // NB: by unknown reasons, Array is significantly faster for\n  //     String.fromCharCode.apply than Uint16Array.\n  var utf16buf = new Array(len * 2);\n\n  for (out = 0, i = 0; i < len;) {\n    c = buf[i++];\n    // quick process ascii\n    if (c < 0x80) { utf16buf[out++] = c; continue; }\n\n    c_len = _utf8len[c];\n    // skip 5 & 6 byte codes\n    if (c_len > 4) { utf16buf[out++] = 0xfffd; i += c_len - 1; continue; }\n\n    // apply mask on first byte\n    c &= c_len === 2 ? 0x1f : c_len === 3 ? 0x0f : 0x07;\n    // join the rest\n    while (c_len > 1 && i < len) {\n      c = (c << 6) | (buf[i++] & 0x3f);\n      c_len--;\n    }\n\n    // terminated by end of string?\n    if (c_len > 1) { utf16buf[out++] = 0xfffd; continue; }\n\n    if (c < 0x10000) {\n      utf16buf[out++] = c;\n    } else {\n      c -= 0x10000;\n      utf16buf[out++] = 0xd800 | ((c >> 10) & 0x3ff);\n      utf16buf[out++] = 0xdc00 | (c & 0x3ff);\n    }\n  }\n\n  return buf2binstring(utf16buf, out);\n};\n\n\n// Calculate max possible position in utf8 buffer,\n// that will not break sequence. If that's not possible\n// - (very small limits) return max size as is.\n//\n// buf[] - utf8 bytes array\n// max   - length limit (mandatory);\nexports.utf8border = function (buf, max) {\n  var pos;\n\n  max = max || buf.length;\n  if (max > buf.length) { max = buf.length; }\n\n  // go back from last position, until start of sequence found\n  pos = max - 1;\n  while (pos >= 0 && (buf[pos] & 0xC0) === 0x80) { pos--; }\n\n  // Very small and broken sequence,\n  // return max, because we should return something anyway.\n  if (pos < 0) { return max; }\n\n  // If we came to start of buffer - that means buffer is too small,\n  // return max too.\n  if (pos === 0) { return max; }\n\n  return (pos + _utf8len[buf[pos]] > max) ? pos : max;\n};\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/adler32.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/adler32.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// Note: adler32 takes 12% for level 0 and 2% for level 6.\n// It isn't worth it to make additional optimizations as in original.\n// Small size is preferable.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction adler32(adler, buf, len, pos) {\n  var s1 = (adler & 0xffff) |0,\n      s2 = ((adler >>> 16) & 0xffff) |0,\n      n = 0;\n\n  while (len !== 0) {\n    // Set limit ~ twice less than 5552, to keep\n    // s2 in 31-bits, because we force signed ints.\n    // in other case %= will fail.\n    n = len > 2000 ? 2000 : len;\n    len -= n;\n\n    do {\n      s1 = (s1 + buf[pos++]) |0;\n      s2 = (s2 + s1) |0;\n    } while (--n);\n\n    s1 %= 65521;\n    s2 %= 65521;\n  }\n\n  return (s1 | (s2 << 16)) |0;\n}\n\n\nmodule.exports = adler32;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/constants.js\":\n/*!*************************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/constants.js ***!\n  \\*************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n\n  /* Allowed flush values; see deflate() and inflate() below for details */\n  Z_NO_FLUSH:         0,\n  Z_PARTIAL_FLUSH:    1,\n  Z_SYNC_FLUSH:       2,\n  Z_FULL_FLUSH:       3,\n  Z_FINISH:           4,\n  Z_BLOCK:            5,\n  Z_TREES:            6,\n\n  /* Return codes for the compression/decompression functions. Negative values\n  * are errors, positive values are used for special but normal events.\n  */\n  Z_OK:               0,\n  Z_STREAM_END:       1,\n  Z_NEED_DICT:        2,\n  Z_ERRNO:           -1,\n  Z_STREAM_ERROR:    -2,\n  Z_DATA_ERROR:      -3,\n  //Z_MEM_ERROR:     -4,\n  Z_BUF_ERROR:       -5,\n  //Z_VERSION_ERROR: -6,\n\n  /* compression levels */\n  Z_NO_COMPRESSION:         0,\n  Z_BEST_SPEED:             1,\n  Z_BEST_COMPRESSION:       9,\n  Z_DEFAULT_COMPRESSION:   -1,\n\n\n  Z_FILTERED:               1,\n  Z_HUFFMAN_ONLY:           2,\n  Z_RLE:                    3,\n  Z_FIXED:                  4,\n  Z_DEFAULT_STRATEGY:       0,\n\n  /* Possible values of the data_type field (though see inflate()) */\n  Z_BINARY:                 0,\n  Z_TEXT:                   1,\n  //Z_ASCII:                1, // = Z_TEXT (deprecated)\n  Z_UNKNOWN:                2,\n\n  /* The deflate compression method */\n  Z_DEFLATED:               8\n  //Z_NULL:                 null // Use -1 or null inline, depending on var type\n};\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/crc32.js\":\n/*!*********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/crc32.js ***!\n  \\*********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// Note: we can't get significant speed boost here.\n// So write code to minimize size - no pregenerated tables\n// and array tools dependencies.\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// Use ordinary array, since untyped makes no boost here\nfunction makeTable() {\n  var c, table = [];\n\n  for (var n = 0; n < 256; n++) {\n    c = n;\n    for (var k = 0; k < 8; k++) {\n      c = ((c & 1) ? (0xEDB88320 ^ (c >>> 1)) : (c >>> 1));\n    }\n    table[n] = c;\n  }\n\n  return table;\n}\n\n// Create table on load. Just 255 signed longs. Not a problem.\nvar crcTable = makeTable();\n\n\nfunction crc32(crc, buf, len, pos) {\n  var t = crcTable,\n      end = pos + len;\n\n  crc ^= -1;\n\n  for (var i = pos; i < end; i++) {\n    crc = (crc >>> 8) ^ t[(crc ^ buf[i]) & 0xFF];\n  }\n\n  return (crc ^ (-1)); // >>> 0;\n}\n\n\nmodule.exports = crc32;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/deflate.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/deflate.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils   = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar trees   = __webpack_require__(/*! ./trees */ \"./node_modules/pako/lib/zlib/trees.js\");\nvar adler32 = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32   = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar msg     = __webpack_require__(/*! ./messages */ \"./node_modules/pako/lib/zlib/messages.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\nvar Z_NO_FLUSH      = 0;\nvar Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\nvar Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\n//var Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\n//var Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\n//var Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n\n/* compression levels */\n//var Z_NO_COMPRESSION      = 0;\n//var Z_BEST_SPEED          = 1;\n//var Z_BEST_COMPRESSION    = 9;\nvar Z_DEFAULT_COMPRESSION = -1;\n\n\nvar Z_FILTERED            = 1;\nvar Z_HUFFMAN_ONLY        = 2;\nvar Z_RLE                 = 3;\nvar Z_FIXED               = 4;\nvar Z_DEFAULT_STRATEGY    = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\n//var Z_BINARY              = 0;\n//var Z_TEXT                = 1;\n//var Z_ASCII               = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n/*============================================================================*/\n\n\nvar MAX_MEM_LEVEL = 9;\n/* Maximum value for memLevel in deflateInit2 */\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_MEM_LEVEL = 8;\n\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\nvar D_CODES       = 30;\n/* number of distance codes */\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\nvar MAX_BITS  = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar MIN_MATCH = 3;\nvar MAX_MATCH = 258;\nvar MIN_LOOKAHEAD = (MAX_MATCH + MIN_MATCH + 1);\n\nvar PRESET_DICT = 0x20;\n\nvar INIT_STATE = 42;\nvar EXTRA_STATE = 69;\nvar NAME_STATE = 73;\nvar COMMENT_STATE = 91;\nvar HCRC_STATE = 103;\nvar BUSY_STATE = 113;\nvar FINISH_STATE = 666;\n\nvar BS_NEED_MORE      = 1; /* block not completed, need more input or more output */\nvar BS_BLOCK_DONE     = 2; /* block flush performed */\nvar BS_FINISH_STARTED = 3; /* finish started, need only more output at next deflate */\nvar BS_FINISH_DONE    = 4; /* finish done, accept no more input or output */\n\nvar OS_CODE = 0x03; // Unix :) . Don't detect, use this default.\n\nfunction err(strm, errorCode) {\n  strm.msg = msg[errorCode];\n  return errorCode;\n}\n\nfunction rank(f) {\n  return ((f) << 1) - ((f) > 4 ? 9 : 0);\n}\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n\n/* =========================================================================\n * Flush as much pending output as possible. All deflate() output goes\n * through this function so some applications may wish to modify it\n * to avoid allocating a large strm->output buffer and copying into it.\n * (See also read_buf()).\n */\nfunction flush_pending(strm) {\n  var s = strm.state;\n\n  //_tr_flush_bits(s);\n  var len = s.pending;\n  if (len > strm.avail_out) {\n    len = strm.avail_out;\n  }\n  if (len === 0) { return; }\n\n  utils.arraySet(strm.output, s.pending_buf, s.pending_out, len, strm.next_out);\n  strm.next_out += len;\n  s.pending_out += len;\n  strm.total_out += len;\n  strm.avail_out -= len;\n  s.pending -= len;\n  if (s.pending === 0) {\n    s.pending_out = 0;\n  }\n}\n\n\nfunction flush_block_only(s, last) {\n  trees._tr_flush_block(s, (s.block_start >= 0 ? s.block_start : -1), s.strstart - s.block_start, last);\n  s.block_start = s.strstart;\n  flush_pending(s.strm);\n}\n\n\nfunction put_byte(s, b) {\n  s.pending_buf[s.pending++] = b;\n}\n\n\n/* =========================================================================\n * Put a short in the pending buffer. The 16-bit value is put in MSB order.\n * IN assertion: the stream state is correct and there is enough room in\n * pending_buf.\n */\nfunction putShortMSB(s, b) {\n//  put_byte(s, (Byte)(b >> 8));\n//  put_byte(s, (Byte)(b & 0xff));\n  s.pending_buf[s.pending++] = (b >>> 8) & 0xff;\n  s.pending_buf[s.pending++] = b & 0xff;\n}\n\n\n/* ===========================================================================\n * Read a new buffer from the current input stream, update the adler32\n * and total number of bytes read.  All deflate() input goes through\n * this function so some applications may wish to modify it to avoid\n * allocating a large strm->input buffer and copying from it.\n * (See also flush_pending()).\n */\nfunction read_buf(strm, buf, start, size) {\n  var len = strm.avail_in;\n\n  if (len > size) { len = size; }\n  if (len === 0) { return 0; }\n\n  strm.avail_in -= len;\n\n  // zmemcpy(buf, strm->next_in, len);\n  utils.arraySet(buf, strm.input, strm.next_in, len, start);\n  if (strm.state.wrap === 1) {\n    strm.adler = adler32(strm.adler, buf, len, start);\n  }\n\n  else if (strm.state.wrap === 2) {\n    strm.adler = crc32(strm.adler, buf, len, start);\n  }\n\n  strm.next_in += len;\n  strm.total_in += len;\n\n  return len;\n}\n\n\n/* ===========================================================================\n * Set match_start to the longest match starting at the given string and\n * return its length. Matches shorter or equal to prev_length are discarded,\n * in which case the result is equal to prev_length and match_start is\n * garbage.\n * IN assertions: cur_match is the head of the hash chain for the current\n *   string (strstart) and its distance is <= MAX_DIST, and prev_length >= 1\n * OUT assertion: the match length is not greater than s->lookahead.\n */\nfunction longest_match(s, cur_match) {\n  var chain_length = s.max_chain_length;      /* max hash chain length */\n  var scan = s.strstart; /* current string */\n  var match;                       /* matched string */\n  var len;                           /* length of current match */\n  var best_len = s.prev_length;              /* best match length so far */\n  var nice_match = s.nice_match;             /* stop if match long enough */\n  var limit = (s.strstart > (s.w_size - MIN_LOOKAHEAD)) ?\n      s.strstart - (s.w_size - MIN_LOOKAHEAD) : 0/*NIL*/;\n\n  var _win = s.window; // shortcut\n\n  var wmask = s.w_mask;\n  var prev  = s.prev;\n\n  /* Stop when cur_match becomes <= limit. To simplify the code,\n   * we prevent matches with the string of window index 0.\n   */\n\n  var strend = s.strstart + MAX_MATCH;\n  var scan_end1  = _win[scan + best_len - 1];\n  var scan_end   = _win[scan + best_len];\n\n  /* The code is optimized for HASH_BITS >= 8 and MAX_MATCH-2 multiple of 16.\n   * It is easy to get rid of this optimization if necessary.\n   */\n  // Assert(s->hash_bits >= 8 && MAX_MATCH == 258, \"Code too clever\");\n\n  /* Do not waste too much time if we already have a good match: */\n  if (s.prev_length >= s.good_match) {\n    chain_length >>= 2;\n  }\n  /* Do not look for matches beyond the end of the input. This is necessary\n   * to make deflate deterministic.\n   */\n  if (nice_match > s.lookahead) { nice_match = s.lookahead; }\n\n  // Assert((ulg)s->strstart <= s->window_size-MIN_LOOKAHEAD, \"need lookahead\");\n\n  do {\n    // Assert(cur_match < s->strstart, \"no future\");\n    match = cur_match;\n\n    /* Skip to next match if the match length cannot increase\n     * or if the match length is less than 2.  Note that the checks below\n     * for insufficient lookahead only occur occasionally for performance\n     * reasons.  Therefore uninitialized memory will be accessed, and\n     * conditional jumps will be made that depend on those values.\n     * However the length of the match is limited to the lookahead, so\n     * the output of deflate is not affected by the uninitialized values.\n     */\n\n    if (_win[match + best_len]     !== scan_end  ||\n        _win[match + best_len - 1] !== scan_end1 ||\n        _win[match]                !== _win[scan] ||\n        _win[++match]              !== _win[scan + 1]) {\n      continue;\n    }\n\n    /* The check at best_len-1 can be removed because it will be made\n     * again later. (This heuristic is not always a win.)\n     * It is not necessary to compare scan[2] and match[2] since they\n     * are always equal when the other bytes match, given that\n     * the hash keys are equal and that HASH_BITS >= 8.\n     */\n    scan += 2;\n    match++;\n    // Assert(*scan == *match, \"match[2]?\");\n\n    /* We check for insufficient lookahead only every 8th comparison;\n     * the 256th check will be made at strstart+258.\n     */\n    do {\n      /*jshint noempty:false*/\n    } while (_win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             _win[++scan] === _win[++match] && _win[++scan] === _win[++match] &&\n             scan < strend);\n\n    // Assert(scan <= s->window+(unsigned)(s->window_size-1), \"wild scan\");\n\n    len = MAX_MATCH - (strend - scan);\n    scan = strend - MAX_MATCH;\n\n    if (len > best_len) {\n      s.match_start = cur_match;\n      best_len = len;\n      if (len >= nice_match) {\n        break;\n      }\n      scan_end1  = _win[scan + best_len - 1];\n      scan_end   = _win[scan + best_len];\n    }\n  } while ((cur_match = prev[cur_match & wmask]) > limit && --chain_length !== 0);\n\n  if (best_len <= s.lookahead) {\n    return best_len;\n  }\n  return s.lookahead;\n}\n\n\n/* ===========================================================================\n * Fill the window when the lookahead becomes insufficient.\n * Updates strstart and lookahead.\n *\n * IN assertion: lookahead < MIN_LOOKAHEAD\n * OUT assertions: strstart <= window_size-MIN_LOOKAHEAD\n *    At least one byte has been read, or avail_in == 0; reads are\n *    performed for at least two bytes (required for the zip translate_eol\n *    option -- not supported here).\n */\nfunction fill_window(s) {\n  var _w_size = s.w_size;\n  var p, n, m, more, str;\n\n  //Assert(s->lookahead < MIN_LOOKAHEAD, \"already enough lookahead\");\n\n  do {\n    more = s.window_size - s.lookahead - s.strstart;\n\n    // JS ints have 32 bit, block below not needed\n    /* Deal with !@#$% 64K limit: */\n    //if (sizeof(int) <= 2) {\n    //    if (more == 0 && s->strstart == 0 && s->lookahead == 0) {\n    //        more = wsize;\n    //\n    //  } else if (more == (unsigned)(-1)) {\n    //        /* Very unlikely, but possible on 16 bit machine if\n    //         * strstart == 0 && lookahead == 1 (input done a byte at time)\n    //         */\n    //        more--;\n    //    }\n    //}\n\n\n    /* If the window is almost full and there is insufficient lookahead,\n     * move the upper half to the lower one to make room in the upper half.\n     */\n    if (s.strstart >= _w_size + (_w_size - MIN_LOOKAHEAD)) {\n\n      utils.arraySet(s.window, s.window, _w_size, _w_size, 0);\n      s.match_start -= _w_size;\n      s.strstart -= _w_size;\n      /* we now have strstart >= MAX_DIST */\n      s.block_start -= _w_size;\n\n      /* Slide the hash table (could be avoided with 32 bit values\n       at the expense of memory usage). We slide even when level == 0\n       to keep the hash table consistent if we switch back to level > 0\n       later. (Using level 0 permanently is not an optimal usage of\n       zlib, so we don't care about this pathological case.)\n       */\n\n      n = s.hash_size;\n      p = n;\n      do {\n        m = s.head[--p];\n        s.head[p] = (m >= _w_size ? m - _w_size : 0);\n      } while (--n);\n\n      n = _w_size;\n      p = n;\n      do {\n        m = s.prev[--p];\n        s.prev[p] = (m >= _w_size ? m - _w_size : 0);\n        /* If n is not on any hash chain, prev[n] is garbage but\n         * its value will never be used.\n         */\n      } while (--n);\n\n      more += _w_size;\n    }\n    if (s.strm.avail_in === 0) {\n      break;\n    }\n\n    /* If there was no sliding:\n     *    strstart <= WSIZE+MAX_DIST-1 && lookahead <= MIN_LOOKAHEAD - 1 &&\n     *    more == window_size - lookahead - strstart\n     * => more >= window_size - (MIN_LOOKAHEAD-1 + WSIZE + MAX_DIST-1)\n     * => more >= window_size - 2*WSIZE + 2\n     * In the BIG_MEM or MMAP case (not yet supported),\n     *   window_size == input_size + MIN_LOOKAHEAD  &&\n     *   strstart + s->lookahead <= input_size => more >= MIN_LOOKAHEAD.\n     * Otherwise, window_size == 2*WSIZE so more >= 2.\n     * If there was sliding, more >= WSIZE. So in all cases, more >= 2.\n     */\n    //Assert(more >= 2, \"more < 2\");\n    n = read_buf(s.strm, s.window, s.strstart + s.lookahead, more);\n    s.lookahead += n;\n\n    /* Initialize the hash value now that we have some input: */\n    if (s.lookahead + s.insert >= MIN_MATCH) {\n      str = s.strstart - s.insert;\n      s.ins_h = s.window[str];\n\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + 1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + 1]) & s.hash_mask;\n//#if MIN_MATCH != 3\n//        Call update_hash() MIN_MATCH-3 more times\n//#endif\n      while (s.insert) {\n        /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n        s.prev[str & s.w_mask] = s.head[s.ins_h];\n        s.head[s.ins_h] = str;\n        str++;\n        s.insert--;\n        if (s.lookahead + s.insert < MIN_MATCH) {\n          break;\n        }\n      }\n    }\n    /* If the whole input has less than MIN_MATCH bytes, ins_h is garbage,\n     * but this is not important since only literal bytes will be emitted.\n     */\n\n  } while (s.lookahead < MIN_LOOKAHEAD && s.strm.avail_in !== 0);\n\n  /* If the WIN_INIT bytes after the end of the current data have never been\n   * written, then zero those bytes in order to avoid memory check reports of\n   * the use of uninitialized (or uninitialised as Julian writes) bytes by\n   * the longest match routines.  Update the high water mark for the next\n   * time through here.  WIN_INIT is set to MAX_MATCH since the longest match\n   * routines allow scanning to strstart + MAX_MATCH, ignoring lookahead.\n   */\n//  if (s.high_water < s.window_size) {\n//    var curr = s.strstart + s.lookahead;\n//    var init = 0;\n//\n//    if (s.high_water < curr) {\n//      /* Previous high water mark below current data -- zero WIN_INIT\n//       * bytes or up to end of window, whichever is less.\n//       */\n//      init = s.window_size - curr;\n//      if (init > WIN_INIT)\n//        init = WIN_INIT;\n//      zmemzero(s->window + curr, (unsigned)init);\n//      s->high_water = curr + init;\n//    }\n//    else if (s->high_water < (ulg)curr + WIN_INIT) {\n//      /* High water mark at or above current data, but below current data\n//       * plus WIN_INIT -- zero out to current data plus WIN_INIT, or up\n//       * to end of window, whichever is less.\n//       */\n//      init = (ulg)curr + WIN_INIT - s->high_water;\n//      if (init > s->window_size - s->high_water)\n//        init = s->window_size - s->high_water;\n//      zmemzero(s->window + s->high_water, (unsigned)init);\n//      s->high_water += init;\n//    }\n//  }\n//\n//  Assert((ulg)s->strstart <= s->window_size - MIN_LOOKAHEAD,\n//    \"not enough room for search\");\n}\n\n/* ===========================================================================\n * Copy without compression as much as possible from the input stream, return\n * the current block state.\n * This function does not insert new strings in the dictionary since\n * uncompressible data is probably not useful. This function is used\n * only for the level=0 compression option.\n * NOTE: this function should be optimized to avoid extra copying from\n * window to pending_buf.\n */\nfunction deflate_stored(s, flush) {\n  /* Stored blocks are limited to 0xffff bytes, pending_buf is limited\n   * to pending_buf_size, and each stored block has a 5 byte header:\n   */\n  var max_block_size = 0xffff;\n\n  if (max_block_size > s.pending_buf_size - 5) {\n    max_block_size = s.pending_buf_size - 5;\n  }\n\n  /* Copy as much as possible from input to output: */\n  for (;;) {\n    /* Fill the window as much as possible: */\n    if (s.lookahead <= 1) {\n\n      //Assert(s->strstart < s->w_size+MAX_DIST(s) ||\n      //  s->block_start >= (long)s->w_size, \"slide too late\");\n//      if (!(s.strstart < s.w_size + (s.w_size - MIN_LOOKAHEAD) ||\n//        s.block_start >= s.w_size)) {\n//        throw  new Error(\"slide too late\");\n//      }\n\n      fill_window(s);\n      if (s.lookahead === 0 && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n\n      if (s.lookahead === 0) {\n        break;\n      }\n      /* flush the current block */\n    }\n    //Assert(s->block_start >= 0L, \"block gone\");\n//    if (s.block_start < 0) throw new Error(\"block gone\");\n\n    s.strstart += s.lookahead;\n    s.lookahead = 0;\n\n    /* Emit a stored block if pending_buf will be full: */\n    var max_start = s.block_start + max_block_size;\n\n    if (s.strstart === 0 || s.strstart >= max_start) {\n      /* strstart == 0 is possible when wraparound on 16-bit machine */\n      s.lookahead = s.strstart - max_start;\n      s.strstart = max_start;\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n\n\n    }\n    /* Flush if we may have to slide, otherwise block_start may become\n     * negative and the data will be gone:\n     */\n    if (s.strstart - s.block_start >= (s.w_size - MIN_LOOKAHEAD)) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n\n  s.insert = 0;\n\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n\n  if (s.strstart > s.block_start) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_NEED_MORE;\n}\n\n/* ===========================================================================\n * Compress as much as possible from the input stream, return the current\n * block state.\n * This function does not perform lazy evaluation of matches and inserts\n * new strings in the dictionary only for unmatched strings or for short\n * matches. It is used only for the fast compression options.\n */\nfunction deflate_fast(s, flush) {\n  var hash_head;        /* head of the hash chain */\n  var bflush;           /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) {\n        break; /* flush the current block */\n      }\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     * At this point we have always match_length < MIN_MATCH\n     */\n    if (hash_head !== 0/*NIL*/ && ((s.strstart - hash_head) <= (s.w_size - MIN_LOOKAHEAD))) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n    }\n    if (s.match_length >= MIN_MATCH) {\n      // check_match(s, s.strstart, s.match_start, s.match_length); // for debug only\n\n      /*** _tr_tally_dist(s, s.strstart - s.match_start,\n                     s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, s.strstart - s.match_start, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n\n      /* Insert new strings in the hash table only if the match length\n       * is not too large. This saves time but degrades compression.\n       */\n      if (s.match_length <= s.max_lazy_match/*max_insert_length*/ && s.lookahead >= MIN_MATCH) {\n        s.match_length--; /* string at strstart already in table */\n        do {\n          s.strstart++;\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n          /* strstart never exceeds WSIZE-MAX_MATCH, so there are\n           * always MIN_MATCH bytes ahead.\n           */\n        } while (--s.match_length !== 0);\n        s.strstart++;\n      } else\n      {\n        s.strstart += s.match_length;\n        s.match_length = 0;\n        s.ins_h = s.window[s.strstart];\n        /* UPDATE_HASH(s, s.ins_h, s.window[s.strstart+1]); */\n        s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + 1]) & s.hash_mask;\n\n//#if MIN_MATCH != 3\n//                Call UPDATE_HASH() MIN_MATCH-3 more times\n//#endif\n        /* If lookahead < MIN_MATCH, ins_h is garbage, but it does not\n         * matter since it will be recomputed at next deflate call.\n         */\n      }\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s.window[s.strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = ((s.strstart < (MIN_MATCH - 1)) ? s.strstart : MIN_MATCH - 1);\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * Same as above, but achieves better compression. We use a lazy\n * evaluation for matches: a match is finally adopted only if there is\n * no better match at the next window position.\n */\nfunction deflate_slow(s, flush) {\n  var hash_head;          /* head of hash chain */\n  var bflush;              /* set if current block must be flushed */\n\n  var max_insert;\n\n  /* Process the input block. */\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the next match, plus MIN_MATCH bytes to insert the\n     * string following the next match.\n     */\n    if (s.lookahead < MIN_LOOKAHEAD) {\n      fill_window(s);\n      if (s.lookahead < MIN_LOOKAHEAD && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* Insert the string window[strstart .. strstart+2] in the\n     * dictionary, and set hash_head to the head of the hash chain:\n     */\n    hash_head = 0/*NIL*/;\n    if (s.lookahead >= MIN_MATCH) {\n      /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n      hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n      s.head[s.ins_h] = s.strstart;\n      /***/\n    }\n\n    /* Find the longest match, discarding those <= prev_length.\n     */\n    s.prev_length = s.match_length;\n    s.prev_match = s.match_start;\n    s.match_length = MIN_MATCH - 1;\n\n    if (hash_head !== 0/*NIL*/ && s.prev_length < s.max_lazy_match &&\n        s.strstart - hash_head <= (s.w_size - MIN_LOOKAHEAD)/*MAX_DIST(s)*/) {\n      /* To simplify the code, we prevent matches with the string\n       * of window index 0 (in particular we have to avoid a match\n       * of the string with itself at the start of the input file).\n       */\n      s.match_length = longest_match(s, hash_head);\n      /* longest_match() sets match_start */\n\n      if (s.match_length <= 5 &&\n         (s.strategy === Z_FILTERED || (s.match_length === MIN_MATCH && s.strstart - s.match_start > 4096/*TOO_FAR*/))) {\n\n        /* If prev_match is also MIN_MATCH, match_start is garbage\n         * but we will ignore the current match anyway.\n         */\n        s.match_length = MIN_MATCH - 1;\n      }\n    }\n    /* If there was a match at the previous step and the current\n     * match is not better, output the previous match:\n     */\n    if (s.prev_length >= MIN_MATCH && s.match_length <= s.prev_length) {\n      max_insert = s.strstart + s.lookahead - MIN_MATCH;\n      /* Do not insert strings in hash table beyond this. */\n\n      //check_match(s, s.strstart-1, s.prev_match, s.prev_length);\n\n      /***_tr_tally_dist(s, s.strstart - 1 - s.prev_match,\n                     s.prev_length - MIN_MATCH, bflush);***/\n      bflush = trees._tr_tally(s, s.strstart - 1 - s.prev_match, s.prev_length - MIN_MATCH);\n      /* Insert in hash table all strings up to the end of the match.\n       * strstart-1 and strstart are already inserted. If there is not\n       * enough lookahead, the last two strings are not inserted in\n       * the hash table.\n       */\n      s.lookahead -= s.prev_length - 1;\n      s.prev_length -= 2;\n      do {\n        if (++s.strstart <= max_insert) {\n          /*** INSERT_STRING(s, s.strstart, hash_head); ***/\n          s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[s.strstart + MIN_MATCH - 1]) & s.hash_mask;\n          hash_head = s.prev[s.strstart & s.w_mask] = s.head[s.ins_h];\n          s.head[s.ins_h] = s.strstart;\n          /***/\n        }\n      } while (--s.prev_length !== 0);\n      s.match_available = 0;\n      s.match_length = MIN_MATCH - 1;\n      s.strstart++;\n\n      if (bflush) {\n        /*** FLUSH_BLOCK(s, 0); ***/\n        flush_block_only(s, false);\n        if (s.strm.avail_out === 0) {\n          return BS_NEED_MORE;\n        }\n        /***/\n      }\n\n    } else if (s.match_available) {\n      /* If there was no match at the previous position, output a\n       * single literal. If there was a match but the current match\n       * is longer, truncate the previous match to a single literal.\n       */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n      /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n      if (bflush) {\n        /*** FLUSH_BLOCK_ONLY(s, 0) ***/\n        flush_block_only(s, false);\n        /***/\n      }\n      s.strstart++;\n      s.lookahead--;\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n    } else {\n      /* There is no previous match to compare with, wait for\n       * the next step to decide.\n       */\n      s.match_available = 1;\n      s.strstart++;\n      s.lookahead--;\n    }\n  }\n  //Assert (flush != Z_NO_FLUSH, \"no flush?\");\n  if (s.match_available) {\n    //Tracevv((stderr,\"%c\", s->window[s->strstart-1]));\n    /*** _tr_tally_lit(s, s.window[s.strstart-1], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart - 1]);\n\n    s.match_available = 0;\n  }\n  s.insert = s.strstart < MIN_MATCH - 1 ? s.strstart : MIN_MATCH - 1;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n\n  return BS_BLOCK_DONE;\n}\n\n\n/* ===========================================================================\n * For Z_RLE, simply look for runs of bytes, generate matches only of distance\n * one.  Do not maintain a hash table.  (It will be regenerated if this run of\n * deflate switches away from Z_RLE.)\n */\nfunction deflate_rle(s, flush) {\n  var bflush;            /* set if current block must be flushed */\n  var prev;              /* byte at distance one to match */\n  var scan, strend;      /* scan goes up to strend for length of run */\n\n  var _win = s.window;\n\n  for (;;) {\n    /* Make sure that we always have enough lookahead, except\n     * at the end of the input file. We need MAX_MATCH bytes\n     * for the longest run, plus one for the unrolled loop.\n     */\n    if (s.lookahead <= MAX_MATCH) {\n      fill_window(s);\n      if (s.lookahead <= MAX_MATCH && flush === Z_NO_FLUSH) {\n        return BS_NEED_MORE;\n      }\n      if (s.lookahead === 0) { break; } /* flush the current block */\n    }\n\n    /* See how many times the previous byte repeats */\n    s.match_length = 0;\n    if (s.lookahead >= MIN_MATCH && s.strstart > 0) {\n      scan = s.strstart - 1;\n      prev = _win[scan];\n      if (prev === _win[++scan] && prev === _win[++scan] && prev === _win[++scan]) {\n        strend = s.strstart + MAX_MATCH;\n        do {\n          /*jshint noempty:false*/\n        } while (prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 prev === _win[++scan] && prev === _win[++scan] &&\n                 scan < strend);\n        s.match_length = MAX_MATCH - (strend - scan);\n        if (s.match_length > s.lookahead) {\n          s.match_length = s.lookahead;\n        }\n      }\n      //Assert(scan <= s->window+(uInt)(s->window_size-1), \"wild scan\");\n    }\n\n    /* Emit match if have run of MIN_MATCH or longer, else emit literal */\n    if (s.match_length >= MIN_MATCH) {\n      //check_match(s, s.strstart, s.strstart - 1, s.match_length);\n\n      /*** _tr_tally_dist(s, 1, s.match_length - MIN_MATCH, bflush); ***/\n      bflush = trees._tr_tally(s, 1, s.match_length - MIN_MATCH);\n\n      s.lookahead -= s.match_length;\n      s.strstart += s.match_length;\n      s.match_length = 0;\n    } else {\n      /* No match, output a literal byte */\n      //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n      /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n      bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n\n      s.lookahead--;\n      s.strstart++;\n    }\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* ===========================================================================\n * For Z_HUFFMAN_ONLY, do not look for matches.  Do not maintain a hash table.\n * (It will be regenerated if this run of deflate switches away from Huffman.)\n */\nfunction deflate_huff(s, flush) {\n  var bflush;             /* set if current block must be flushed */\n\n  for (;;) {\n    /* Make sure that we have a literal to write. */\n    if (s.lookahead === 0) {\n      fill_window(s);\n      if (s.lookahead === 0) {\n        if (flush === Z_NO_FLUSH) {\n          return BS_NEED_MORE;\n        }\n        break;      /* flush the current block */\n      }\n    }\n\n    /* Output a literal byte */\n    s.match_length = 0;\n    //Tracevv((stderr,\"%c\", s->window[s->strstart]));\n    /*** _tr_tally_lit(s, s.window[s.strstart], bflush); ***/\n    bflush = trees._tr_tally(s, 0, s.window[s.strstart]);\n    s.lookahead--;\n    s.strstart++;\n    if (bflush) {\n      /*** FLUSH_BLOCK(s, 0); ***/\n      flush_block_only(s, false);\n      if (s.strm.avail_out === 0) {\n        return BS_NEED_MORE;\n      }\n      /***/\n    }\n  }\n  s.insert = 0;\n  if (flush === Z_FINISH) {\n    /*** FLUSH_BLOCK(s, 1); ***/\n    flush_block_only(s, true);\n    if (s.strm.avail_out === 0) {\n      return BS_FINISH_STARTED;\n    }\n    /***/\n    return BS_FINISH_DONE;\n  }\n  if (s.last_lit) {\n    /*** FLUSH_BLOCK(s, 0); ***/\n    flush_block_only(s, false);\n    if (s.strm.avail_out === 0) {\n      return BS_NEED_MORE;\n    }\n    /***/\n  }\n  return BS_BLOCK_DONE;\n}\n\n/* Values for max_lazy_match, good_match and max_chain_length, depending on\n * the desired pack level (0..9). The values given below have been tuned to\n * exclude worst case performance for pathological files. Better values may be\n * found for specific files.\n */\nfunction Config(good_length, max_lazy, nice_length, max_chain, func) {\n  this.good_length = good_length;\n  this.max_lazy = max_lazy;\n  this.nice_length = nice_length;\n  this.max_chain = max_chain;\n  this.func = func;\n}\n\nvar configuration_table;\n\nconfiguration_table = [\n  /*      good lazy nice chain */\n  new Config(0, 0, 0, 0, deflate_stored),          /* 0 store only */\n  new Config(4, 4, 8, 4, deflate_fast),            /* 1 max speed, no lazy matches */\n  new Config(4, 5, 16, 8, deflate_fast),           /* 2 */\n  new Config(4, 6, 32, 32, deflate_fast),          /* 3 */\n\n  new Config(4, 4, 16, 16, deflate_slow),          /* 4 lazy matches */\n  new Config(8, 16, 32, 32, deflate_slow),         /* 5 */\n  new Config(8, 16, 128, 128, deflate_slow),       /* 6 */\n  new Config(8, 32, 128, 256, deflate_slow),       /* 7 */\n  new Config(32, 128, 258, 1024, deflate_slow),    /* 8 */\n  new Config(32, 258, 258, 4096, deflate_slow)     /* 9 max compression */\n];\n\n\n/* ===========================================================================\n * Initialize the \"longest match\" routines for a new zlib stream\n */\nfunction lm_init(s) {\n  s.window_size = 2 * s.w_size;\n\n  /*** CLEAR_HASH(s); ***/\n  zero(s.head); // Fill with NIL (= 0);\n\n  /* Set the default configuration parameters:\n   */\n  s.max_lazy_match = configuration_table[s.level].max_lazy;\n  s.good_match = configuration_table[s.level].good_length;\n  s.nice_match = configuration_table[s.level].nice_length;\n  s.max_chain_length = configuration_table[s.level].max_chain;\n\n  s.strstart = 0;\n  s.block_start = 0;\n  s.lookahead = 0;\n  s.insert = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  s.ins_h = 0;\n}\n\n\nfunction DeflateState() {\n  this.strm = null;            /* pointer back to this zlib stream */\n  this.status = 0;            /* as the name implies */\n  this.pending_buf = null;      /* output still pending */\n  this.pending_buf_size = 0;  /* size of pending_buf */\n  this.pending_out = 0;       /* next pending byte to output to the stream */\n  this.pending = 0;           /* nb of bytes in the pending buffer */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.gzhead = null;         /* gzip header information to write */\n  this.gzindex = 0;           /* where in extra, name, or comment */\n  this.method = Z_DEFLATED; /* can only be DEFLATED */\n  this.last_flush = -1;   /* value of flush param for previous deflate call */\n\n  this.w_size = 0;  /* LZ77 window size (32K by default) */\n  this.w_bits = 0;  /* log2(w_size)  (8..16) */\n  this.w_mask = 0;  /* w_size - 1 */\n\n  this.window = null;\n  /* Sliding window. Input bytes are read into the second half of the window,\n   * and move to the first half later to keep a dictionary of at least wSize\n   * bytes. With this organization, matches are limited to a distance of\n   * wSize-MAX_MATCH bytes, but this ensures that IO is always\n   * performed with a length multiple of the block size.\n   */\n\n  this.window_size = 0;\n  /* Actual size of window: 2*wSize, except when the user input buffer\n   * is directly used as sliding window.\n   */\n\n  this.prev = null;\n  /* Link to older string with same hash index. To limit the size of this\n   * array to 64K, this link is maintained only for the last 32K strings.\n   * An index in this array is thus a window index modulo 32K.\n   */\n\n  this.head = null;   /* Heads of the hash chains or NIL. */\n\n  this.ins_h = 0;       /* hash index of string to be inserted */\n  this.hash_size = 0;   /* number of elements in hash table */\n  this.hash_bits = 0;   /* log2(hash_size) */\n  this.hash_mask = 0;   /* hash_size-1 */\n\n  this.hash_shift = 0;\n  /* Number of bits by which ins_h must be shifted at each input\n   * step. It must be such that after MIN_MATCH steps, the oldest\n   * byte no longer takes part in the hash key, that is:\n   *   hash_shift * MIN_MATCH >= hash_bits\n   */\n\n  this.block_start = 0;\n  /* Window position at the beginning of the current output block. Gets\n   * negative when the window is moved backwards.\n   */\n\n  this.match_length = 0;      /* length of best match */\n  this.prev_match = 0;        /* previous match */\n  this.match_available = 0;   /* set if previous match exists */\n  this.strstart = 0;          /* start of string to insert */\n  this.match_start = 0;       /* start of matching string */\n  this.lookahead = 0;         /* number of valid bytes ahead in window */\n\n  this.prev_length = 0;\n  /* Length of the best match at previous step. Matches not greater than this\n   * are discarded. This is used in the lazy match evaluation.\n   */\n\n  this.max_chain_length = 0;\n  /* To speed up deflation, hash chains are never searched beyond this\n   * length.  A higher limit improves compression ratio but degrades the\n   * speed.\n   */\n\n  this.max_lazy_match = 0;\n  /* Attempt to find a better match only when the current match is strictly\n   * smaller than this value. This mechanism is used only for compression\n   * levels >= 4.\n   */\n  // That's alias to max_lazy_match, don't use directly\n  //this.max_insert_length = 0;\n  /* Insert new strings in the hash table only if the match length is not\n   * greater than this length. This saves time but degrades compression.\n   * max_insert_length is used only for compression levels <= 3.\n   */\n\n  this.level = 0;     /* compression level (1..9) */\n  this.strategy = 0;  /* favor or force Huffman coding*/\n\n  this.good_match = 0;\n  /* Use a faster search when the previous match is longer than this */\n\n  this.nice_match = 0; /* Stop searching when current match exceeds this */\n\n              /* used by trees.c: */\n\n  /* Didn't use ct_data typedef below to suppress compiler warning */\n\n  // struct ct_data_s dyn_ltree[HEAP_SIZE];   /* literal and length tree */\n  // struct ct_data_s dyn_dtree[2*D_CODES+1]; /* distance tree */\n  // struct ct_data_s bl_tree[2*BL_CODES+1];  /* Huffman tree for bit lengths */\n\n  // Use flat array of DOUBLE size, with interleaved fata,\n  // because JS does not support effective\n  this.dyn_ltree  = new utils.Buf16(HEAP_SIZE * 2);\n  this.dyn_dtree  = new utils.Buf16((2 * D_CODES + 1) * 2);\n  this.bl_tree    = new utils.Buf16((2 * BL_CODES + 1) * 2);\n  zero(this.dyn_ltree);\n  zero(this.dyn_dtree);\n  zero(this.bl_tree);\n\n  this.l_desc   = null;         /* desc. for literal tree */\n  this.d_desc   = null;         /* desc. for distance tree */\n  this.bl_desc  = null;         /* desc. for bit length tree */\n\n  //ush bl_count[MAX_BITS+1];\n  this.bl_count = new utils.Buf16(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  //int heap[2*L_CODES+1];      /* heap used to build the Huffman trees */\n  this.heap = new utils.Buf16(2 * L_CODES + 1);  /* heap used to build the Huffman trees */\n  zero(this.heap);\n\n  this.heap_len = 0;               /* number of elements in the heap */\n  this.heap_max = 0;               /* element of largest frequency */\n  /* The sons of heap[n] are heap[2*n] and heap[2*n+1]. heap[0] is not used.\n   * The same heap array is used to build all trees.\n   */\n\n  this.depth = new utils.Buf16(2 * L_CODES + 1); //uch depth[2*L_CODES+1];\n  zero(this.depth);\n  /* Depth of each subtree used as tie breaker for trees of equal frequency\n   */\n\n  this.l_buf = 0;          /* buffer index for literals or lengths */\n\n  this.lit_bufsize = 0;\n  /* Size of match buffer for literals/lengths.  There are 4 reasons for\n   * limiting lit_bufsize to 64K:\n   *   - frequencies can be kept in 16 bit counters\n   *   - if compression is not successful for the first block, all input\n   *     data is still in the window so we can still emit a stored block even\n   *     when input comes from standard input.  (This can also be done for\n   *     all blocks if lit_bufsize is not greater than 32K.)\n   *   - if compression is not successful for a file smaller than 64K, we can\n   *     even emit a stored file instead of a stored block (saving 5 bytes).\n   *     This is applicable only for zip (not gzip or zlib).\n   *   - creating new Huffman trees less frequently may not provide fast\n   *     adaptation to changes in the input data statistics. (Take for\n   *     example a binary file with poorly compressible code followed by\n   *     a highly compressible string table.) Smaller buffer sizes give\n   *     fast adaptation but have of course the overhead of transmitting\n   *     trees more frequently.\n   *   - I can't count above 4\n   */\n\n  this.last_lit = 0;      /* running index in l_buf */\n\n  this.d_buf = 0;\n  /* Buffer index for distances. To simplify the code, d_buf and l_buf have\n   * the same number of elements. To use different lengths, an extra flag\n   * array would be necessary.\n   */\n\n  this.opt_len = 0;       /* bit length of current block with optimal trees */\n  this.static_len = 0;    /* bit length of current block with static trees */\n  this.matches = 0;       /* number of string matches in current block */\n  this.insert = 0;        /* bytes at end of window left to insert */\n\n\n  this.bi_buf = 0;\n  /* Output buffer. bits are inserted starting at the bottom (least\n   * significant bits).\n   */\n  this.bi_valid = 0;\n  /* Number of valid bits in bi_buf.  All bits above the last valid bit\n   * are always zero.\n   */\n\n  // Used for window memory init. We safely ignore it for JS. That makes\n  // sense only for pointers and memory check tools.\n  //this.high_water = 0;\n  /* High water mark offset in window for initialized bytes -- bytes above\n   * this are set to zero in order to avoid memory check warnings when\n   * longest match routines access bytes past the input.  This is then\n   * updated to the new high water mark.\n   */\n}\n\n\nfunction deflateResetKeep(strm) {\n  var s;\n\n  if (!strm || !strm.state) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.total_in = strm.total_out = 0;\n  strm.data_type = Z_UNKNOWN;\n\n  s = strm.state;\n  s.pending = 0;\n  s.pending_out = 0;\n\n  if (s.wrap < 0) {\n    s.wrap = -s.wrap;\n    /* was made negative by deflate(..., Z_FINISH); */\n  }\n  s.status = (s.wrap ? INIT_STATE : BUSY_STATE);\n  strm.adler = (s.wrap === 2) ?\n    0  // crc32(0, Z_NULL, 0)\n  :\n    1; // adler32(0, Z_NULL, 0)\n  s.last_flush = Z_NO_FLUSH;\n  trees._tr_init(s);\n  return Z_OK;\n}\n\n\nfunction deflateReset(strm) {\n  var ret = deflateResetKeep(strm);\n  if (ret === Z_OK) {\n    lm_init(strm.state);\n  }\n  return ret;\n}\n\n\nfunction deflateSetHeader(strm, head) {\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  if (strm.state.wrap !== 2) { return Z_STREAM_ERROR; }\n  strm.state.gzhead = head;\n  return Z_OK;\n}\n\n\nfunction deflateInit2(strm, level, method, windowBits, memLevel, strategy) {\n  if (!strm) { // === Z_NULL\n    return Z_STREAM_ERROR;\n  }\n  var wrap = 1;\n\n  if (level === Z_DEFAULT_COMPRESSION) {\n    level = 6;\n  }\n\n  if (windowBits < 0) { /* suppress zlib wrapper */\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n\n  else if (windowBits > 15) {\n    wrap = 2;           /* write gzip wrapper instead */\n    windowBits -= 16;\n  }\n\n\n  if (memLevel < 1 || memLevel > MAX_MEM_LEVEL || method !== Z_DEFLATED ||\n    windowBits < 8 || windowBits > 15 || level < 0 || level > 9 ||\n    strategy < 0 || strategy > Z_FIXED) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n\n  if (windowBits === 8) {\n    windowBits = 9;\n  }\n  /* until 256-byte window bug fixed */\n\n  var s = new DeflateState();\n\n  strm.state = s;\n  s.strm = strm;\n\n  s.wrap = wrap;\n  s.gzhead = null;\n  s.w_bits = windowBits;\n  s.w_size = 1 << s.w_bits;\n  s.w_mask = s.w_size - 1;\n\n  s.hash_bits = memLevel + 7;\n  s.hash_size = 1 << s.hash_bits;\n  s.hash_mask = s.hash_size - 1;\n  s.hash_shift = ~~((s.hash_bits + MIN_MATCH - 1) / MIN_MATCH);\n\n  s.window = new utils.Buf8(s.w_size * 2);\n  s.head = new utils.Buf16(s.hash_size);\n  s.prev = new utils.Buf16(s.w_size);\n\n  // Don't need mem init magic for JS.\n  //s.high_water = 0;  /* nothing written to s->window yet */\n\n  s.lit_bufsize = 1 << (memLevel + 6); /* 16K elements by default */\n\n  s.pending_buf_size = s.lit_bufsize * 4;\n\n  //overlay = (ushf *) ZALLOC(strm, s->lit_bufsize, sizeof(ush)+2);\n  //s->pending_buf = (uchf *) overlay;\n  s.pending_buf = new utils.Buf8(s.pending_buf_size);\n\n  // It is offset from `s.pending_buf` (size is `s.lit_bufsize * 2`)\n  //s->d_buf = overlay + s->lit_bufsize/sizeof(ush);\n  s.d_buf = 1 * s.lit_bufsize;\n\n  //s->l_buf = s->pending_buf + (1+sizeof(ush))*s->lit_bufsize;\n  s.l_buf = (1 + 2) * s.lit_bufsize;\n\n  s.level = level;\n  s.strategy = strategy;\n  s.method = method;\n\n  return deflateReset(strm);\n}\n\nfunction deflateInit(strm, level) {\n  return deflateInit2(strm, level, Z_DEFLATED, MAX_WBITS, DEF_MEM_LEVEL, Z_DEFAULT_STRATEGY);\n}\n\n\nfunction deflate(strm, flush) {\n  var old_flush, s;\n  var beg, val; // for gzip header write only\n\n  if (!strm || !strm.state ||\n    flush > Z_BLOCK || flush < 0) {\n    return strm ? err(strm, Z_STREAM_ERROR) : Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n\n  if (!strm.output ||\n      (!strm.input && strm.avail_in !== 0) ||\n      (s.status === FINISH_STATE && flush !== Z_FINISH)) {\n    return err(strm, (strm.avail_out === 0) ? Z_BUF_ERROR : Z_STREAM_ERROR);\n  }\n\n  s.strm = strm; /* just in case */\n  old_flush = s.last_flush;\n  s.last_flush = flush;\n\n  /* Write the header */\n  if (s.status === INIT_STATE) {\n\n    if (s.wrap === 2) { // GZIP header\n      strm.adler = 0;  //crc32(0L, Z_NULL, 0);\n      put_byte(s, 31);\n      put_byte(s, 139);\n      put_byte(s, 8);\n      if (!s.gzhead) { // s->gzhead == Z_NULL\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, 0);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, OS_CODE);\n        s.status = BUSY_STATE;\n      }\n      else {\n        put_byte(s, (s.gzhead.text ? 1 : 0) +\n                    (s.gzhead.hcrc ? 2 : 0) +\n                    (!s.gzhead.extra ? 0 : 4) +\n                    (!s.gzhead.name ? 0 : 8) +\n                    (!s.gzhead.comment ? 0 : 16)\n        );\n        put_byte(s, s.gzhead.time & 0xff);\n        put_byte(s, (s.gzhead.time >> 8) & 0xff);\n        put_byte(s, (s.gzhead.time >> 16) & 0xff);\n        put_byte(s, (s.gzhead.time >> 24) & 0xff);\n        put_byte(s, s.level === 9 ? 2 :\n                    (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2 ?\n                     4 : 0));\n        put_byte(s, s.gzhead.os & 0xff);\n        if (s.gzhead.extra && s.gzhead.extra.length) {\n          put_byte(s, s.gzhead.extra.length & 0xff);\n          put_byte(s, (s.gzhead.extra.length >> 8) & 0xff);\n        }\n        if (s.gzhead.hcrc) {\n          strm.adler = crc32(strm.adler, s.pending_buf, s.pending, 0);\n        }\n        s.gzindex = 0;\n        s.status = EXTRA_STATE;\n      }\n    }\n    else // DEFLATE header\n    {\n      var header = (Z_DEFLATED + ((s.w_bits - 8) << 4)) << 8;\n      var level_flags = -1;\n\n      if (s.strategy >= Z_HUFFMAN_ONLY || s.level < 2) {\n        level_flags = 0;\n      } else if (s.level < 6) {\n        level_flags = 1;\n      } else if (s.level === 6) {\n        level_flags = 2;\n      } else {\n        level_flags = 3;\n      }\n      header |= (level_flags << 6);\n      if (s.strstart !== 0) { header |= PRESET_DICT; }\n      header += 31 - (header % 31);\n\n      s.status = BUSY_STATE;\n      putShortMSB(s, header);\n\n      /* Save the adler32 of the preset dictionary: */\n      if (s.strstart !== 0) {\n        putShortMSB(s, strm.adler >>> 16);\n        putShortMSB(s, strm.adler & 0xffff);\n      }\n      strm.adler = 1; // adler32(0L, Z_NULL, 0);\n    }\n  }\n\n//#ifdef GZIP\n  if (s.status === EXTRA_STATE) {\n    if (s.gzhead.extra/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n\n      while (s.gzindex < (s.gzhead.extra.length & 0xffff)) {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            break;\n          }\n        }\n        put_byte(s, s.gzhead.extra[s.gzindex] & 0xff);\n        s.gzindex++;\n      }\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (s.gzindex === s.gzhead.extra.length) {\n        s.gzindex = 0;\n        s.status = NAME_STATE;\n      }\n    }\n    else {\n      s.status = NAME_STATE;\n    }\n  }\n  if (s.status === NAME_STATE) {\n    if (s.gzhead.name/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.name.length) {\n          val = s.gzhead.name.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.gzindex = 0;\n        s.status = COMMENT_STATE;\n      }\n    }\n    else {\n      s.status = COMMENT_STATE;\n    }\n  }\n  if (s.status === COMMENT_STATE) {\n    if (s.gzhead.comment/* != Z_NULL*/) {\n      beg = s.pending;  /* start of bytes to update crc */\n      //int val;\n\n      do {\n        if (s.pending === s.pending_buf_size) {\n          if (s.gzhead.hcrc && s.pending > beg) {\n            strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n          }\n          flush_pending(strm);\n          beg = s.pending;\n          if (s.pending === s.pending_buf_size) {\n            val = 1;\n            break;\n          }\n        }\n        // JS specific: little magic to add zero terminator to end of string\n        if (s.gzindex < s.gzhead.comment.length) {\n          val = s.gzhead.comment.charCodeAt(s.gzindex++) & 0xff;\n        } else {\n          val = 0;\n        }\n        put_byte(s, val);\n      } while (val !== 0);\n\n      if (s.gzhead.hcrc && s.pending > beg) {\n        strm.adler = crc32(strm.adler, s.pending_buf, s.pending - beg, beg);\n      }\n      if (val === 0) {\n        s.status = HCRC_STATE;\n      }\n    }\n    else {\n      s.status = HCRC_STATE;\n    }\n  }\n  if (s.status === HCRC_STATE) {\n    if (s.gzhead.hcrc) {\n      if (s.pending + 2 > s.pending_buf_size) {\n        flush_pending(strm);\n      }\n      if (s.pending + 2 <= s.pending_buf_size) {\n        put_byte(s, strm.adler & 0xff);\n        put_byte(s, (strm.adler >> 8) & 0xff);\n        strm.adler = 0; //crc32(0L, Z_NULL, 0);\n        s.status = BUSY_STATE;\n      }\n    }\n    else {\n      s.status = BUSY_STATE;\n    }\n  }\n//#endif\n\n  /* Flush as much pending output as possible */\n  if (s.pending !== 0) {\n    flush_pending(strm);\n    if (strm.avail_out === 0) {\n      /* Since avail_out is 0, deflate will be called again with\n       * more output space, but possibly with both pending and\n       * avail_in equal to zero. There won't be anything to do,\n       * but this is not an error situation so make sure we\n       * return OK instead of BUF_ERROR at next call of deflate:\n       */\n      s.last_flush = -1;\n      return Z_OK;\n    }\n\n    /* Make sure there is something to do and avoid duplicate consecutive\n     * flushes. For repeated and useless calls with Z_FINISH, we keep\n     * returning Z_STREAM_END instead of Z_BUF_ERROR.\n     */\n  } else if (strm.avail_in === 0 && rank(flush) <= rank(old_flush) &&\n    flush !== Z_FINISH) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* User must not provide more input after the first FINISH: */\n  if (s.status === FINISH_STATE && strm.avail_in !== 0) {\n    return err(strm, Z_BUF_ERROR);\n  }\n\n  /* Start a new block or continue the current one.\n   */\n  if (strm.avail_in !== 0 || s.lookahead !== 0 ||\n    (flush !== Z_NO_FLUSH && s.status !== FINISH_STATE)) {\n    var bstate = (s.strategy === Z_HUFFMAN_ONLY) ? deflate_huff(s, flush) :\n      (s.strategy === Z_RLE ? deflate_rle(s, flush) :\n        configuration_table[s.level].func(s, flush));\n\n    if (bstate === BS_FINISH_STARTED || bstate === BS_FINISH_DONE) {\n      s.status = FINISH_STATE;\n    }\n    if (bstate === BS_NEED_MORE || bstate === BS_FINISH_STARTED) {\n      if (strm.avail_out === 0) {\n        s.last_flush = -1;\n        /* avoid BUF_ERROR next call, see above */\n      }\n      return Z_OK;\n      /* If flush != Z_NO_FLUSH && avail_out == 0, the next call\n       * of deflate should use the same flush parameter to make sure\n       * that the flush is complete. So we don't have to output an\n       * empty block here, this will be done at next call. This also\n       * ensures that for a very small output buffer, we emit at most\n       * one empty block.\n       */\n    }\n    if (bstate === BS_BLOCK_DONE) {\n      if (flush === Z_PARTIAL_FLUSH) {\n        trees._tr_align(s);\n      }\n      else if (flush !== Z_BLOCK) { /* FULL_FLUSH or SYNC_FLUSH */\n\n        trees._tr_stored_block(s, 0, 0, false);\n        /* For a full flush, this empty block will be recognized\n         * as a special marker by inflate_sync().\n         */\n        if (flush === Z_FULL_FLUSH) {\n          /*** CLEAR_HASH(s); ***/             /* forget history */\n          zero(s.head); // Fill with NIL (= 0);\n\n          if (s.lookahead === 0) {\n            s.strstart = 0;\n            s.block_start = 0;\n            s.insert = 0;\n          }\n        }\n      }\n      flush_pending(strm);\n      if (strm.avail_out === 0) {\n        s.last_flush = -1; /* avoid BUF_ERROR at next call, see above */\n        return Z_OK;\n      }\n    }\n  }\n  //Assert(strm->avail_out > 0, \"bug2\");\n  //if (strm.avail_out <= 0) { throw new Error(\"bug2\");}\n\n  if (flush !== Z_FINISH) { return Z_OK; }\n  if (s.wrap <= 0) { return Z_STREAM_END; }\n\n  /* Write the trailer */\n  if (s.wrap === 2) {\n    put_byte(s, strm.adler & 0xff);\n    put_byte(s, (strm.adler >> 8) & 0xff);\n    put_byte(s, (strm.adler >> 16) & 0xff);\n    put_byte(s, (strm.adler >> 24) & 0xff);\n    put_byte(s, strm.total_in & 0xff);\n    put_byte(s, (strm.total_in >> 8) & 0xff);\n    put_byte(s, (strm.total_in >> 16) & 0xff);\n    put_byte(s, (strm.total_in >> 24) & 0xff);\n  }\n  else\n  {\n    putShortMSB(s, strm.adler >>> 16);\n    putShortMSB(s, strm.adler & 0xffff);\n  }\n\n  flush_pending(strm);\n  /* If avail_out is zero, the application will call deflate again\n   * to flush the rest.\n   */\n  if (s.wrap > 0) { s.wrap = -s.wrap; }\n  /* write the trailer only once! */\n  return s.pending !== 0 ? Z_OK : Z_STREAM_END;\n}\n\nfunction deflateEnd(strm) {\n  var status;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  status = strm.state.status;\n  if (status !== INIT_STATE &&\n    status !== EXTRA_STATE &&\n    status !== NAME_STATE &&\n    status !== COMMENT_STATE &&\n    status !== HCRC_STATE &&\n    status !== BUSY_STATE &&\n    status !== FINISH_STATE\n  ) {\n    return err(strm, Z_STREAM_ERROR);\n  }\n\n  strm.state = null;\n\n  return status === BUSY_STATE ? err(strm, Z_DATA_ERROR) : Z_OK;\n}\n\n\n/* =========================================================================\n * Initializes the compression dictionary from the given byte\n * sequence without producing any compressed output.\n */\nfunction deflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var s;\n  var str, n;\n  var wrap;\n  var avail;\n  var next;\n  var input;\n  var tmpDict;\n\n  if (!strm/*== Z_NULL*/ || !strm.state/*== Z_NULL*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  s = strm.state;\n  wrap = s.wrap;\n\n  if (wrap === 2 || (wrap === 1 && s.status !== INIT_STATE) || s.lookahead) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* when using zlib wrappers, compute Adler-32 for provided dictionary */\n  if (wrap === 1) {\n    /* adler32(strm->adler, dictionary, dictLength); */\n    strm.adler = adler32(strm.adler, dictionary, dictLength, 0);\n  }\n\n  s.wrap = 0;   /* avoid computing Adler-32 in read_buf */\n\n  /* if dictionary would fill window, just replace the history */\n  if (dictLength >= s.w_size) {\n    if (wrap === 0) {            /* already empty otherwise */\n      /*** CLEAR_HASH(s); ***/\n      zero(s.head); // Fill with NIL (= 0);\n      s.strstart = 0;\n      s.block_start = 0;\n      s.insert = 0;\n    }\n    /* use the tail */\n    // dictionary = dictionary.slice(dictLength - s.w_size);\n    tmpDict = new utils.Buf8(s.w_size);\n    utils.arraySet(tmpDict, dictionary, dictLength - s.w_size, s.w_size, 0);\n    dictionary = tmpDict;\n    dictLength = s.w_size;\n  }\n  /* insert dictionary into window and hash */\n  avail = strm.avail_in;\n  next = strm.next_in;\n  input = strm.input;\n  strm.avail_in = dictLength;\n  strm.next_in = 0;\n  strm.input = dictionary;\n  fill_window(s);\n  while (s.lookahead >= MIN_MATCH) {\n    str = s.strstart;\n    n = s.lookahead - (MIN_MATCH - 1);\n    do {\n      /* UPDATE_HASH(s, s->ins_h, s->window[str + MIN_MATCH-1]); */\n      s.ins_h = ((s.ins_h << s.hash_shift) ^ s.window[str + MIN_MATCH - 1]) & s.hash_mask;\n\n      s.prev[str & s.w_mask] = s.head[s.ins_h];\n\n      s.head[s.ins_h] = str;\n      str++;\n    } while (--n);\n    s.strstart = str;\n    s.lookahead = MIN_MATCH - 1;\n    fill_window(s);\n  }\n  s.strstart += s.lookahead;\n  s.block_start = s.strstart;\n  s.insert = s.lookahead;\n  s.lookahead = 0;\n  s.match_length = s.prev_length = MIN_MATCH - 1;\n  s.match_available = 0;\n  strm.next_in = next;\n  strm.input = input;\n  strm.avail_in = avail;\n  s.wrap = wrap;\n  return Z_OK;\n}\n\n\nexports.deflateInit = deflateInit;\nexports.deflateInit2 = deflateInit2;\nexports.deflateReset = deflateReset;\nexports.deflateResetKeep = deflateResetKeep;\nexports.deflateSetHeader = deflateSetHeader;\nexports.deflate = deflate;\nexports.deflateEnd = deflateEnd;\nexports.deflateSetDictionary = deflateSetDictionary;\nexports.deflateInfo = 'pako deflate (from Nodeca project)';\n\n/* Not implemented\nexports.deflateBound = deflateBound;\nexports.deflateCopy = deflateCopy;\nexports.deflateParams = deflateParams;\nexports.deflatePending = deflatePending;\nexports.deflatePrime = deflatePrime;\nexports.deflateTune = deflateTune;\n*/\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/gzheader.js\":\n/*!************************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/gzheader.js ***!\n  \\************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction GZheader() {\n  /* true if compressed data believed to be text */\n  this.text       = 0;\n  /* modification time */\n  this.time       = 0;\n  /* extra flags (not used when writing a gzip file) */\n  this.xflags     = 0;\n  /* operating system */\n  this.os         = 0;\n  /* pointer to extra field or Z_NULL if none */\n  this.extra      = null;\n  /* extra field length (valid if extra != Z_NULL) */\n  this.extra_len  = 0; // Actually, we don't need it in JS,\n                       // but leave for few code modifications\n\n  //\n  // Setup limits is not necessary because in js we should not preallocate memory\n  // for inflate use constant limit in 65536 bytes\n  //\n\n  /* space at extra (only when reading header) */\n  // this.extra_max  = 0;\n  /* pointer to zero-terminated file name or Z_NULL */\n  this.name       = '';\n  /* space at name (only when reading header) */\n  // this.name_max   = 0;\n  /* pointer to zero-terminated comment or Z_NULL */\n  this.comment    = '';\n  /* space at comment (only when reading header) */\n  // this.comm_max   = 0;\n  /* true if there was or will be a header crc */\n  this.hcrc       = 0;\n  /* true when done reading gzip header (not used when writing a gzip file) */\n  this.done       = false;\n}\n\nmodule.exports = GZheader;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/inffast.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/inffast.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n// See state defs from inflate.js\nvar BAD = 30;       /* got a data error -- remain here until reset */\nvar TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\n\n/*\n   Decode literal, length, and distance codes and write out the resulting\n   literal and match bytes until either not enough input or output is\n   available, an end-of-block is encountered, or a data error is encountered.\n   When large enough input and output buffers are supplied to inflate(), for\n   example, a 16K input buffer and a 64K output buffer, more than 95% of the\n   inflate execution time is spent in this routine.\n\n   Entry assumptions:\n\n        state.mode === LEN\n        strm.avail_in >= 6\n        strm.avail_out >= 258\n        start >= strm.avail_out\n        state.bits < 8\n\n   On return, state.mode is one of:\n\n        LEN -- ran out of enough output space or enough available input\n        TYPE -- reached end of block code, inflate() to interpret next block\n        BAD -- error in block data\n\n   Notes:\n\n    - The maximum input bits used by a length/distance pair is 15 bits for the\n      length code, 5 bits for the length extra, 15 bits for the distance code,\n      and 13 bits for the distance extra.  This totals 48 bits, or six bytes.\n      Therefore if strm.avail_in >= 6, then there is enough input to avoid\n      checking for available input while decoding.\n\n    - The maximum bytes that a single length/distance pair can output is 258\n      bytes, which is the maximum length that can be coded.  inflate_fast()\n      requires strm.avail_out >= 258 for each loop to avoid checking for\n      output space.\n */\nmodule.exports = function inflate_fast(strm, start) {\n  var state;\n  var _in;                    /* local strm.input */\n  var last;                   /* have enough input while in < last */\n  var _out;                   /* local strm.output */\n  var beg;                    /* inflate()'s initial strm.output */\n  var end;                    /* while out < end, enough space available */\n//#ifdef INFLATE_STRICT\n  var dmax;                   /* maximum distance from zlib header */\n//#endif\n  var wsize;                  /* window size or zero if not using window */\n  var whave;                  /* valid bytes in the window */\n  var wnext;                  /* window write index */\n  // Use `s_window` instead `window`, avoid conflict with instrumentation tools\n  var s_window;               /* allocated sliding window, if wsize != 0 */\n  var hold;                   /* local strm.hold */\n  var bits;                   /* local strm.bits */\n  var lcode;                  /* local strm.lencode */\n  var dcode;                  /* local strm.distcode */\n  var lmask;                  /* mask for first level of length codes */\n  var dmask;                  /* mask for first level of distance codes */\n  var here;                   /* retrieved table entry */\n  var op;                     /* code bits, operation, extra bits, or */\n                              /*  window position, window bytes to copy */\n  var len;                    /* match length, unused bytes */\n  var dist;                   /* match distance */\n  var from;                   /* where to copy match from */\n  var from_source;\n\n\n  var input, output; // JS specific, because we have no pointers\n\n  /* copy state to local variables */\n  state = strm.state;\n  //here = state.here;\n  _in = strm.next_in;\n  input = strm.input;\n  last = _in + (strm.avail_in - 5);\n  _out = strm.next_out;\n  output = strm.output;\n  beg = _out - (start - strm.avail_out);\n  end = _out + (strm.avail_out - 257);\n//#ifdef INFLATE_STRICT\n  dmax = state.dmax;\n//#endif\n  wsize = state.wsize;\n  whave = state.whave;\n  wnext = state.wnext;\n  s_window = state.window;\n  hold = state.hold;\n  bits = state.bits;\n  lcode = state.lencode;\n  dcode = state.distcode;\n  lmask = (1 << state.lenbits) - 1;\n  dmask = (1 << state.distbits) - 1;\n\n\n  /* decode literals and length/distances until end-of-block or not enough\n     input data or output space */\n\n  top:\n  do {\n    if (bits < 15) {\n      hold += input[_in++] << bits;\n      bits += 8;\n      hold += input[_in++] << bits;\n      bits += 8;\n    }\n\n    here = lcode[hold & lmask];\n\n    dolen:\n    for (;;) { // Goto emulation\n      op = here >>> 24/*here.bits*/;\n      hold >>>= op;\n      bits -= op;\n      op = (here >>> 16) & 0xff/*here.op*/;\n      if (op === 0) {                          /* literal */\n        //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n        //        \"inflate:         literal '%c'\\n\" :\n        //        \"inflate:         literal 0x%02x\\n\", here.val));\n        output[_out++] = here & 0xffff/*here.val*/;\n      }\n      else if (op & 16) {                     /* length base */\n        len = here & 0xffff/*here.val*/;\n        op &= 15;                           /* number of extra bits */\n        if (op) {\n          if (bits < op) {\n            hold += input[_in++] << bits;\n            bits += 8;\n          }\n          len += hold & ((1 << op) - 1);\n          hold >>>= op;\n          bits -= op;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", len));\n        if (bits < 15) {\n          hold += input[_in++] << bits;\n          bits += 8;\n          hold += input[_in++] << bits;\n          bits += 8;\n        }\n        here = dcode[hold & dmask];\n\n        dodist:\n        for (;;) { // goto emulation\n          op = here >>> 24/*here.bits*/;\n          hold >>>= op;\n          bits -= op;\n          op = (here >>> 16) & 0xff/*here.op*/;\n\n          if (op & 16) {                      /* distance base */\n            dist = here & 0xffff/*here.val*/;\n            op &= 15;                       /* number of extra bits */\n            if (bits < op) {\n              hold += input[_in++] << bits;\n              bits += 8;\n              if (bits < op) {\n                hold += input[_in++] << bits;\n                bits += 8;\n              }\n            }\n            dist += hold & ((1 << op) - 1);\n//#ifdef INFLATE_STRICT\n            if (dist > dmax) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break top;\n            }\n//#endif\n            hold >>>= op;\n            bits -= op;\n            //Tracevv((stderr, \"inflate:         distance %u\\n\", dist));\n            op = _out - beg;                /* max distance in output */\n            if (dist > op) {                /* see if copy from window */\n              op = dist - op;               /* distance back in window */\n              if (op > whave) {\n                if (state.sane) {\n                  strm.msg = 'invalid distance too far back';\n                  state.mode = BAD;\n                  break top;\n                }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//                if (len <= op - whave) {\n//                  do {\n//                    output[_out++] = 0;\n//                  } while (--len);\n//                  continue top;\n//                }\n//                len -= op - whave;\n//                do {\n//                  output[_out++] = 0;\n//                } while (--op > whave);\n//                if (op === 0) {\n//                  from = _out - dist;\n//                  do {\n//                    output[_out++] = output[from++];\n//                  } while (--len);\n//                  continue top;\n//                }\n//#endif\n              }\n              from = 0; // window index\n              from_source = s_window;\n              if (wnext === 0) {           /* very common case */\n                from += wsize - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              else if (wnext < op) {      /* wrap around window */\n                from += wsize + wnext - op;\n                op -= wnext;\n                if (op < len) {         /* some from end of window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = 0;\n                  if (wnext < len) {  /* some from start of window */\n                    op = wnext;\n                    len -= op;\n                    do {\n                      output[_out++] = s_window[from++];\n                    } while (--op);\n                    from = _out - dist;      /* rest from output */\n                    from_source = output;\n                  }\n                }\n              }\n              else {                      /* contiguous in window */\n                from += wnext - op;\n                if (op < len) {         /* some from window */\n                  len -= op;\n                  do {\n                    output[_out++] = s_window[from++];\n                  } while (--op);\n                  from = _out - dist;  /* rest from output */\n                  from_source = output;\n                }\n              }\n              while (len > 2) {\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                output[_out++] = from_source[from++];\n                len -= 3;\n              }\n              if (len) {\n                output[_out++] = from_source[from++];\n                if (len > 1) {\n                  output[_out++] = from_source[from++];\n                }\n              }\n            }\n            else {\n              from = _out - dist;          /* copy direct from output */\n              do {                        /* minimum length is three */\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                output[_out++] = output[from++];\n                len -= 3;\n              } while (len > 2);\n              if (len) {\n                output[_out++] = output[from++];\n                if (len > 1) {\n                  output[_out++] = output[from++];\n                }\n              }\n            }\n          }\n          else if ((op & 64) === 0) {          /* 2nd level distance code */\n            here = dcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n            continue dodist;\n          }\n          else {\n            strm.msg = 'invalid distance code';\n            state.mode = BAD;\n            break top;\n          }\n\n          break; // need to emulate goto via \"continue\"\n        }\n      }\n      else if ((op & 64) === 0) {              /* 2nd level length code */\n        here = lcode[(here & 0xffff)/*here.val*/ + (hold & ((1 << op) - 1))];\n        continue dolen;\n      }\n      else if (op & 32) {                     /* end-of-block */\n        //Tracevv((stderr, \"inflate:         end of block\\n\"));\n        state.mode = TYPE;\n        break top;\n      }\n      else {\n        strm.msg = 'invalid literal/length code';\n        state.mode = BAD;\n        break top;\n      }\n\n      break; // need to emulate goto via \"continue\"\n    }\n  } while (_in < last && _out < end);\n\n  /* return unused bytes (on entry, bits < 8, so in won't go too far back) */\n  len = bits >> 3;\n  _in -= len;\n  bits -= len << 3;\n  hold &= (1 << bits) - 1;\n\n  /* update state and return */\n  strm.next_in = _in;\n  strm.next_out = _out;\n  strm.avail_in = (_in < last ? 5 + (last - _in) : 5 - (_in - last));\n  strm.avail_out = (_out < end ? 257 + (end - _out) : 257 - (_out - end));\n  state.hold = hold;\n  state.bits = bits;\n  return;\n};\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/inflate.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/inflate.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils         = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\nvar adler32       = __webpack_require__(/*! ./adler32 */ \"./node_modules/pako/lib/zlib/adler32.js\");\nvar crc32         = __webpack_require__(/*! ./crc32 */ \"./node_modules/pako/lib/zlib/crc32.js\");\nvar inflate_fast  = __webpack_require__(/*! ./inffast */ \"./node_modules/pako/lib/zlib/inffast.js\");\nvar inflate_table = __webpack_require__(/*! ./inftrees */ \"./node_modules/pako/lib/zlib/inftrees.js\");\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n/* Allowed flush values; see deflate() and inflate() below for details */\n//var Z_NO_FLUSH      = 0;\n//var Z_PARTIAL_FLUSH = 1;\n//var Z_SYNC_FLUSH    = 2;\n//var Z_FULL_FLUSH    = 3;\nvar Z_FINISH        = 4;\nvar Z_BLOCK         = 5;\nvar Z_TREES         = 6;\n\n\n/* Return codes for the compression/decompression functions. Negative values\n * are errors, positive values are used for special but normal events.\n */\nvar Z_OK            = 0;\nvar Z_STREAM_END    = 1;\nvar Z_NEED_DICT     = 2;\n//var Z_ERRNO         = -1;\nvar Z_STREAM_ERROR  = -2;\nvar Z_DATA_ERROR    = -3;\nvar Z_MEM_ERROR     = -4;\nvar Z_BUF_ERROR     = -5;\n//var Z_VERSION_ERROR = -6;\n\n/* The deflate compression method */\nvar Z_DEFLATED  = 8;\n\n\n/* STATES ====================================================================*/\n/* ===========================================================================*/\n\n\nvar    HEAD = 1;       /* i: waiting for magic header */\nvar    FLAGS = 2;      /* i: waiting for method and flags (gzip) */\nvar    TIME = 3;       /* i: waiting for modification time (gzip) */\nvar    OS = 4;         /* i: waiting for extra flags and operating system (gzip) */\nvar    EXLEN = 5;      /* i: waiting for extra length (gzip) */\nvar    EXTRA = 6;      /* i: waiting for extra bytes (gzip) */\nvar    NAME = 7;       /* i: waiting for end of file name (gzip) */\nvar    COMMENT = 8;    /* i: waiting for end of comment (gzip) */\nvar    HCRC = 9;       /* i: waiting for header crc (gzip) */\nvar    DICTID = 10;    /* i: waiting for dictionary check value */\nvar    DICT = 11;      /* waiting for inflateSetDictionary() call */\nvar        TYPE = 12;      /* i: waiting for type bits, including last-flag bit */\nvar        TYPEDO = 13;    /* i: same, but skip check to exit inflate on new block */\nvar        STORED = 14;    /* i: waiting for stored size (length and complement) */\nvar        COPY_ = 15;     /* i/o: same as COPY below, but only first time in */\nvar        COPY = 16;      /* i/o: waiting for input or output to copy stored block */\nvar        TABLE = 17;     /* i: waiting for dynamic block table lengths */\nvar        LENLENS = 18;   /* i: waiting for code length code lengths */\nvar        CODELENS = 19;  /* i: waiting for length/lit and distance code lengths */\nvar            LEN_ = 20;      /* i: same as LEN below, but only first time in */\nvar            LEN = 21;       /* i: waiting for length/lit/eob code */\nvar            LENEXT = 22;    /* i: waiting for length extra bits */\nvar            DIST = 23;      /* i: waiting for distance code */\nvar            DISTEXT = 24;   /* i: waiting for distance extra bits */\nvar            MATCH = 25;     /* o: waiting for output space to copy string */\nvar            LIT = 26;       /* o: waiting for output space to write literal */\nvar    CHECK = 27;     /* i: waiting for 32-bit check value */\nvar    LENGTH = 28;    /* i: waiting for 32-bit length (gzip) */\nvar    DONE = 29;      /* finished check, done -- remain here until reset */\nvar    BAD = 30;       /* got a data error -- remain here until reset */\nvar    MEM = 31;       /* got an inflate() memory error -- remain here until reset */\nvar    SYNC = 32;      /* looking for synchronization bytes to restart inflate() */\n\n/* ===========================================================================*/\n\n\n\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH =  (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar MAX_WBITS = 15;\n/* 32K LZ77 window */\nvar DEF_WBITS = MAX_WBITS;\n\n\nfunction zswap32(q) {\n  return  (((q >>> 24) & 0xff) +\n          ((q >>> 8) & 0xff00) +\n          ((q & 0xff00) << 8) +\n          ((q & 0xff) << 24));\n}\n\n\nfunction InflateState() {\n  this.mode = 0;             /* current inflate mode */\n  this.last = false;          /* true if processing last block */\n  this.wrap = 0;              /* bit 0 true for zlib, bit 1 true for gzip */\n  this.havedict = false;      /* true if dictionary provided */\n  this.flags = 0;             /* gzip header method and flags (0 if zlib) */\n  this.dmax = 0;              /* zlib header max distance (INFLATE_STRICT) */\n  this.check = 0;             /* protected copy of check value */\n  this.total = 0;             /* protected copy of output count */\n  // TODO: may be {}\n  this.head = null;           /* where to save gzip header information */\n\n  /* sliding window */\n  this.wbits = 0;             /* log base 2 of requested window size */\n  this.wsize = 0;             /* window size or zero if not using window */\n  this.whave = 0;             /* valid bytes in the window */\n  this.wnext = 0;             /* window write index */\n  this.window = null;         /* allocated sliding window, if needed */\n\n  /* bit accumulator */\n  this.hold = 0;              /* input bit accumulator */\n  this.bits = 0;              /* number of bits in \"in\" */\n\n  /* for string and stored block copying */\n  this.length = 0;            /* literal or length of data to copy */\n  this.offset = 0;            /* distance back to copy string from */\n\n  /* for table and code decoding */\n  this.extra = 0;             /* extra bits needed */\n\n  /* fixed and dynamic code tables */\n  this.lencode = null;          /* starting table for length/literal codes */\n  this.distcode = null;         /* starting table for distance codes */\n  this.lenbits = 0;           /* index bits for lencode */\n  this.distbits = 0;          /* index bits for distcode */\n\n  /* dynamic table building */\n  this.ncode = 0;             /* number of code length code lengths */\n  this.nlen = 0;              /* number of length code lengths */\n  this.ndist = 0;             /* number of distance code lengths */\n  this.have = 0;              /* number of code lengths in lens[] */\n  this.next = null;              /* next available space in codes[] */\n\n  this.lens = new utils.Buf16(320); /* temporary storage for code lengths */\n  this.work = new utils.Buf16(288); /* work area for code table building */\n\n  /*\n   because we don't have pointers in js, we use lencode and distcode directly\n   as buffers so we don't need codes\n  */\n  //this.codes = new utils.Buf32(ENOUGH);       /* space for code tables */\n  this.lendyn = null;              /* dynamic table for length/literal codes (JS specific) */\n  this.distdyn = null;             /* dynamic table for distance codes (JS specific) */\n  this.sane = 0;                   /* if false, allow invalid distance too far */\n  this.back = 0;                   /* bits back of last unprocessed length/lit */\n  this.was = 0;                    /* initial length of match */\n}\n\nfunction inflateResetKeep(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  strm.total_in = strm.total_out = state.total = 0;\n  strm.msg = ''; /*Z_NULL*/\n  if (state.wrap) {       /* to support ill-conceived Java test suite */\n    strm.adler = state.wrap & 1;\n  }\n  state.mode = HEAD;\n  state.last = 0;\n  state.havedict = 0;\n  state.dmax = 32768;\n  state.head = null/*Z_NULL*/;\n  state.hold = 0;\n  state.bits = 0;\n  //state.lencode = state.distcode = state.next = state.codes;\n  state.lencode = state.lendyn = new utils.Buf32(ENOUGH_LENS);\n  state.distcode = state.distdyn = new utils.Buf32(ENOUGH_DISTS);\n\n  state.sane = 1;\n  state.back = -1;\n  //Tracev((stderr, \"inflate: reset\\n\"));\n  return Z_OK;\n}\n\nfunction inflateReset(strm) {\n  var state;\n\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  state.wsize = 0;\n  state.whave = 0;\n  state.wnext = 0;\n  return inflateResetKeep(strm);\n\n}\n\nfunction inflateReset2(strm, windowBits) {\n  var wrap;\n  var state;\n\n  /* get the state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  /* extract wrap request from windowBits parameter */\n  if (windowBits < 0) {\n    wrap = 0;\n    windowBits = -windowBits;\n  }\n  else {\n    wrap = (windowBits >> 4) + 1;\n    if (windowBits < 48) {\n      windowBits &= 15;\n    }\n  }\n\n  /* set number of window bits, free window if different */\n  if (windowBits && (windowBits < 8 || windowBits > 15)) {\n    return Z_STREAM_ERROR;\n  }\n  if (state.window !== null && state.wbits !== windowBits) {\n    state.window = null;\n  }\n\n  /* update state and reset the rest of it */\n  state.wrap = wrap;\n  state.wbits = windowBits;\n  return inflateReset(strm);\n}\n\nfunction inflateInit2(strm, windowBits) {\n  var ret;\n  var state;\n\n  if (!strm) { return Z_STREAM_ERROR; }\n  //strm.msg = Z_NULL;                 /* in case we return an error */\n\n  state = new InflateState();\n\n  //if (state === Z_NULL) return Z_MEM_ERROR;\n  //Tracev((stderr, \"inflate: allocated\\n\"));\n  strm.state = state;\n  state.window = null/*Z_NULL*/;\n  ret = inflateReset2(strm, windowBits);\n  if (ret !== Z_OK) {\n    strm.state = null/*Z_NULL*/;\n  }\n  return ret;\n}\n\nfunction inflateInit(strm) {\n  return inflateInit2(strm, DEF_WBITS);\n}\n\n\n/*\n Return state with length and distance decoding tables and index sizes set to\n fixed code decoding.  Normally this returns fixed tables from inffixed.h.\n If BUILDFIXED is defined, then instead this routine builds the tables the\n first time it's called, and returns those tables the first time and\n thereafter.  This reduces the size of the code by about 2K bytes, in\n exchange for a little execution time.  However, BUILDFIXED should not be\n used for threaded applications, since the rewriting of the tables and virgin\n may not be thread-safe.\n */\nvar virgin = true;\n\nvar lenfix, distfix; // We have no pointers in JS, so keep tables separate\n\nfunction fixedtables(state) {\n  /* build fixed huffman tables if first call (may not be thread safe) */\n  if (virgin) {\n    var sym;\n\n    lenfix = new utils.Buf32(512);\n    distfix = new utils.Buf32(32);\n\n    /* literal/length table */\n    sym = 0;\n    while (sym < 144) { state.lens[sym++] = 8; }\n    while (sym < 256) { state.lens[sym++] = 9; }\n    while (sym < 280) { state.lens[sym++] = 7; }\n    while (sym < 288) { state.lens[sym++] = 8; }\n\n    inflate_table(LENS,  state.lens, 0, 288, lenfix,   0, state.work, { bits: 9 });\n\n    /* distance table */\n    sym = 0;\n    while (sym < 32) { state.lens[sym++] = 5; }\n\n    inflate_table(DISTS, state.lens, 0, 32,   distfix, 0, state.work, { bits: 5 });\n\n    /* do this just once */\n    virgin = false;\n  }\n\n  state.lencode = lenfix;\n  state.lenbits = 9;\n  state.distcode = distfix;\n  state.distbits = 5;\n}\n\n\n/*\n Update the window with the last wsize (normally 32K) bytes written before\n returning.  If window does not exist yet, create it.  This is only called\n when a window is already in use, or when output has been written during this\n inflate call, but the end of the deflate stream has not been reached yet.\n It is also called to create a window for dictionary data when a dictionary\n is loaded.\n\n Providing output buffers larger than 32K to inflate() should provide a speed\n advantage, since only the last 32K of output is copied to the sliding window\n upon return from inflate(), and since all distances after the first 32K of\n output will fall in the output data, making match copies simpler and faster.\n The advantage may be dependent on the size of the processor's data caches.\n */\nfunction updatewindow(strm, src, end, copy) {\n  var dist;\n  var state = strm.state;\n\n  /* if it hasn't been done already, allocate space for the window */\n  if (state.window === null) {\n    state.wsize = 1 << state.wbits;\n    state.wnext = 0;\n    state.whave = 0;\n\n    state.window = new utils.Buf8(state.wsize);\n  }\n\n  /* copy state->wsize or less output bytes into the circular window */\n  if (copy >= state.wsize) {\n    utils.arraySet(state.window, src, end - state.wsize, state.wsize, 0);\n    state.wnext = 0;\n    state.whave = state.wsize;\n  }\n  else {\n    dist = state.wsize - state.wnext;\n    if (dist > copy) {\n      dist = copy;\n    }\n    //zmemcpy(state->window + state->wnext, end - copy, dist);\n    utils.arraySet(state.window, src, end - copy, dist, state.wnext);\n    copy -= dist;\n    if (copy) {\n      //zmemcpy(state->window, end - copy, copy);\n      utils.arraySet(state.window, src, end - copy, copy, 0);\n      state.wnext = copy;\n      state.whave = state.wsize;\n    }\n    else {\n      state.wnext += dist;\n      if (state.wnext === state.wsize) { state.wnext = 0; }\n      if (state.whave < state.wsize) { state.whave += dist; }\n    }\n  }\n  return 0;\n}\n\nfunction inflate(strm, flush) {\n  var state;\n  var input, output;          // input/output buffers\n  var next;                   /* next input INDEX */\n  var put;                    /* next output INDEX */\n  var have, left;             /* available input and output */\n  var hold;                   /* bit buffer */\n  var bits;                   /* bits in bit buffer */\n  var _in, _out;              /* save starting available input and output */\n  var copy;                   /* number of stored or match bytes to copy */\n  var from;                   /* where to copy match bytes from */\n  var from_source;\n  var here = 0;               /* current decoding table entry */\n  var here_bits, here_op, here_val; // paked \"here\" denormalized (JS specific)\n  //var last;                   /* parent table entry */\n  var last_bits, last_op, last_val; // paked \"last\" denormalized (JS specific)\n  var len;                    /* length to copy for repeats, bits to drop */\n  var ret;                    /* return code */\n  var hbuf = new utils.Buf8(4);    /* buffer for gzip header crc calculation */\n  var opts;\n\n  var n; // temporary var for NEED_BITS\n\n  var order = /* permutation of code lengths */\n    [ 16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15 ];\n\n\n  if (!strm || !strm.state || !strm.output ||\n      (!strm.input && strm.avail_in !== 0)) {\n    return Z_STREAM_ERROR;\n  }\n\n  state = strm.state;\n  if (state.mode === TYPE) { state.mode = TYPEDO; }    /* skip check */\n\n\n  //--- LOAD() ---\n  put = strm.next_out;\n  output = strm.output;\n  left = strm.avail_out;\n  next = strm.next_in;\n  input = strm.input;\n  have = strm.avail_in;\n  hold = state.hold;\n  bits = state.bits;\n  //---\n\n  _in = have;\n  _out = left;\n  ret = Z_OK;\n\n  inf_leave: // goto emulation\n  for (;;) {\n    switch (state.mode) {\n      case HEAD:\n        if (state.wrap === 0) {\n          state.mode = TYPEDO;\n          break;\n        }\n        //=== NEEDBITS(16);\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((state.wrap & 2) && hold === 0x8b1f) {  /* gzip header */\n          state.check = 0/*crc32(0L, Z_NULL, 0)*/;\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          state.mode = FLAGS;\n          break;\n        }\n        state.flags = 0;           /* expect zlib header */\n        if (state.head) {\n          state.head.done = false;\n        }\n        if (!(state.wrap & 1) ||   /* check if zlib header allowed */\n          (((hold & 0xff)/*BITS(8)*/ << 8) + (hold >> 8)) % 31) {\n          strm.msg = 'incorrect header check';\n          state.mode = BAD;\n          break;\n        }\n        if ((hold & 0x0f)/*BITS(4)*/ !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n        len = (hold & 0x0f)/*BITS(4)*/ + 8;\n        if (state.wbits === 0) {\n          state.wbits = len;\n        }\n        else if (len > state.wbits) {\n          strm.msg = 'invalid window size';\n          state.mode = BAD;\n          break;\n        }\n        state.dmax = 1 << len;\n        //Tracev((stderr, \"inflate:   zlib header ok\\n\"));\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = hold & 0x200 ? DICTID : TYPE;\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        break;\n      case FLAGS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.flags = hold;\n        if ((state.flags & 0xff) !== Z_DEFLATED) {\n          strm.msg = 'unknown compression method';\n          state.mode = BAD;\n          break;\n        }\n        if (state.flags & 0xe000) {\n          strm.msg = 'unknown header flags set';\n          state.mode = BAD;\n          break;\n        }\n        if (state.head) {\n          state.head.text = ((hold >> 8) & 1);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = TIME;\n        /* falls through */\n      case TIME:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.time = hold;\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC4(state.check, hold)\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          hbuf[2] = (hold >>> 16) & 0xff;\n          hbuf[3] = (hold >>> 24) & 0xff;\n          state.check = crc32(state.check, hbuf, 4, 0);\n          //===\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = OS;\n        /* falls through */\n      case OS:\n        //=== NEEDBITS(16); */\n        while (bits < 16) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if (state.head) {\n          state.head.xflags = (hold & 0xff);\n          state.head.os = (hold >> 8);\n        }\n        if (state.flags & 0x0200) {\n          //=== CRC2(state.check, hold);\n          hbuf[0] = hold & 0xff;\n          hbuf[1] = (hold >>> 8) & 0xff;\n          state.check = crc32(state.check, hbuf, 2, 0);\n          //===//\n        }\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = EXLEN;\n        /* falls through */\n      case EXLEN:\n        if (state.flags & 0x0400) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length = hold;\n          if (state.head) {\n            state.head.extra_len = hold;\n          }\n          if (state.flags & 0x0200) {\n            //=== CRC2(state.check, hold);\n            hbuf[0] = hold & 0xff;\n            hbuf[1] = (hold >>> 8) & 0xff;\n            state.check = crc32(state.check, hbuf, 2, 0);\n            //===//\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        else if (state.head) {\n          state.head.extra = null/*Z_NULL*/;\n        }\n        state.mode = EXTRA;\n        /* falls through */\n      case EXTRA:\n        if (state.flags & 0x0400) {\n          copy = state.length;\n          if (copy > have) { copy = have; }\n          if (copy) {\n            if (state.head) {\n              len = state.head.extra_len - state.length;\n              if (!state.head.extra) {\n                // Use untyped array for more convenient processing later\n                state.head.extra = new Array(state.head.extra_len);\n              }\n              utils.arraySet(\n                state.head.extra,\n                input,\n                next,\n                // extra field is limited to 65536 bytes\n                // - no need for additional size check\n                copy,\n                /*len + copy > state.head.extra_max - len ? state.head.extra_max : copy,*/\n                len\n              );\n              //zmemcpy(state.head.extra + len, next,\n              //        len + copy > state.head.extra_max ?\n              //        state.head.extra_max - len : copy);\n            }\n            if (state.flags & 0x0200) {\n              state.check = crc32(state.check, input, copy, next);\n            }\n            have -= copy;\n            next += copy;\n            state.length -= copy;\n          }\n          if (state.length) { break inf_leave; }\n        }\n        state.length = 0;\n        state.mode = NAME;\n        /* falls through */\n      case NAME:\n        if (state.flags & 0x0800) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            // TODO: 2 or 1 bytes?\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.name_max*/)) {\n              state.head.name += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.name = null;\n        }\n        state.length = 0;\n        state.mode = COMMENT;\n        /* falls through */\n      case COMMENT:\n        if (state.flags & 0x1000) {\n          if (have === 0) { break inf_leave; }\n          copy = 0;\n          do {\n            len = input[next + copy++];\n            /* use constant limit because in js we should not preallocate memory */\n            if (state.head && len &&\n                (state.length < 65536 /*state.head.comm_max*/)) {\n              state.head.comment += String.fromCharCode(len);\n            }\n          } while (len && copy < have);\n          if (state.flags & 0x0200) {\n            state.check = crc32(state.check, input, copy, next);\n          }\n          have -= copy;\n          next += copy;\n          if (len) { break inf_leave; }\n        }\n        else if (state.head) {\n          state.head.comment = null;\n        }\n        state.mode = HCRC;\n        /* falls through */\n      case HCRC:\n        if (state.flags & 0x0200) {\n          //=== NEEDBITS(16); */\n          while (bits < 16) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.check & 0xffff)) {\n            strm.msg = 'header crc mismatch';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n        }\n        if (state.head) {\n          state.head.hcrc = ((state.flags >> 9) & 1);\n          state.head.done = true;\n        }\n        strm.adler = state.check = 0;\n        state.mode = TYPE;\n        break;\n      case DICTID:\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        strm.adler = state.check = zswap32(hold);\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = DICT;\n        /* falls through */\n      case DICT:\n        if (state.havedict === 0) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          return Z_NEED_DICT;\n        }\n        strm.adler = state.check = 1/*adler32(0L, Z_NULL, 0)*/;\n        state.mode = TYPE;\n        /* falls through */\n      case TYPE:\n        if (flush === Z_BLOCK || flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case TYPEDO:\n        if (state.last) {\n          //--- BYTEBITS() ---//\n          hold >>>= bits & 7;\n          bits -= bits & 7;\n          //---//\n          state.mode = CHECK;\n          break;\n        }\n        //=== NEEDBITS(3); */\n        while (bits < 3) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.last = (hold & 0x01)/*BITS(1)*/;\n        //--- DROPBITS(1) ---//\n        hold >>>= 1;\n        bits -= 1;\n        //---//\n\n        switch ((hold & 0x03)/*BITS(2)*/) {\n          case 0:                             /* stored block */\n            //Tracev((stderr, \"inflate:     stored block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = STORED;\n            break;\n          case 1:                             /* fixed block */\n            fixedtables(state);\n            //Tracev((stderr, \"inflate:     fixed codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = LEN_;             /* decode codes */\n            if (flush === Z_TREES) {\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n              break inf_leave;\n            }\n            break;\n          case 2:                             /* dynamic block */\n            //Tracev((stderr, \"inflate:     dynamic codes block%s\\n\",\n            //        state.last ? \" (last)\" : \"\"));\n            state.mode = TABLE;\n            break;\n          case 3:\n            strm.msg = 'invalid block type';\n            state.mode = BAD;\n        }\n        //--- DROPBITS(2) ---//\n        hold >>>= 2;\n        bits -= 2;\n        //---//\n        break;\n      case STORED:\n        //--- BYTEBITS() ---// /* go to byte boundary */\n        hold >>>= bits & 7;\n        bits -= bits & 7;\n        //---//\n        //=== NEEDBITS(32); */\n        while (bits < 32) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        if ((hold & 0xffff) !== ((hold >>> 16) ^ 0xffff)) {\n          strm.msg = 'invalid stored block lengths';\n          state.mode = BAD;\n          break;\n        }\n        state.length = hold & 0xffff;\n        //Tracev((stderr, \"inflate:       stored length %u\\n\",\n        //        state.length));\n        //=== INITBITS();\n        hold = 0;\n        bits = 0;\n        //===//\n        state.mode = COPY_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case COPY_:\n        state.mode = COPY;\n        /* falls through */\n      case COPY:\n        copy = state.length;\n        if (copy) {\n          if (copy > have) { copy = have; }\n          if (copy > left) { copy = left; }\n          if (copy === 0) { break inf_leave; }\n          //--- zmemcpy(put, next, copy); ---\n          utils.arraySet(output, input, next, copy, put);\n          //---//\n          have -= copy;\n          next += copy;\n          left -= copy;\n          put += copy;\n          state.length -= copy;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       stored end\\n\"));\n        state.mode = TYPE;\n        break;\n      case TABLE:\n        //=== NEEDBITS(14); */\n        while (bits < 14) {\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n        }\n        //===//\n        state.nlen = (hold & 0x1f)/*BITS(5)*/ + 257;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ndist = (hold & 0x1f)/*BITS(5)*/ + 1;\n        //--- DROPBITS(5) ---//\n        hold >>>= 5;\n        bits -= 5;\n        //---//\n        state.ncode = (hold & 0x0f)/*BITS(4)*/ + 4;\n        //--- DROPBITS(4) ---//\n        hold >>>= 4;\n        bits -= 4;\n        //---//\n//#ifndef PKZIP_BUG_WORKAROUND\n        if (state.nlen > 286 || state.ndist > 30) {\n          strm.msg = 'too many length or distance symbols';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracev((stderr, \"inflate:       table sizes ok\\n\"));\n        state.have = 0;\n        state.mode = LENLENS;\n        /* falls through */\n      case LENLENS:\n        while (state.have < state.ncode) {\n          //=== NEEDBITS(3);\n          while (bits < 3) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.lens[order[state.have++]] = (hold & 0x07);//BITS(3);\n          //--- DROPBITS(3) ---//\n          hold >>>= 3;\n          bits -= 3;\n          //---//\n        }\n        while (state.have < 19) {\n          state.lens[order[state.have++]] = 0;\n        }\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        //state.next = state.codes;\n        //state.lencode = state.next;\n        // Switch to use dynamic table\n        state.lencode = state.lendyn;\n        state.lenbits = 7;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(CODES, state.lens, 0, 19, state.lencode, 0, state.work, opts);\n        state.lenbits = opts.bits;\n\n        if (ret) {\n          strm.msg = 'invalid code lengths set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, \"inflate:       code lengths ok\\n\"));\n        state.have = 0;\n        state.mode = CODELENS;\n        /* falls through */\n      case CODELENS:\n        while (state.have < state.nlen + state.ndist) {\n          for (;;) {\n            here = state.lencode[hold & ((1 << state.lenbits) - 1)];/*BITS(state.lenbits)*/\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          if (here_val < 16) {\n            //--- DROPBITS(here.bits) ---//\n            hold >>>= here_bits;\n            bits -= here_bits;\n            //---//\n            state.lens[state.have++] = here_val;\n          }\n          else {\n            if (here_val === 16) {\n              //=== NEEDBITS(here.bits + 2);\n              n = here_bits + 2;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              if (state.have === 0) {\n                strm.msg = 'invalid bit length repeat';\n                state.mode = BAD;\n                break;\n              }\n              len = state.lens[state.have - 1];\n              copy = 3 + (hold & 0x03);//BITS(2);\n              //--- DROPBITS(2) ---//\n              hold >>>= 2;\n              bits -= 2;\n              //---//\n            }\n            else if (here_val === 17) {\n              //=== NEEDBITS(here.bits + 3);\n              n = here_bits + 3;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 3 + (hold & 0x07);//BITS(3);\n              //--- DROPBITS(3) ---//\n              hold >>>= 3;\n              bits -= 3;\n              //---//\n            }\n            else {\n              //=== NEEDBITS(here.bits + 7);\n              n = here_bits + 7;\n              while (bits < n) {\n                if (have === 0) { break inf_leave; }\n                have--;\n                hold += input[next++] << bits;\n                bits += 8;\n              }\n              //===//\n              //--- DROPBITS(here.bits) ---//\n              hold >>>= here_bits;\n              bits -= here_bits;\n              //---//\n              len = 0;\n              copy = 11 + (hold & 0x7f);//BITS(7);\n              //--- DROPBITS(7) ---//\n              hold >>>= 7;\n              bits -= 7;\n              //---//\n            }\n            if (state.have + copy > state.nlen + state.ndist) {\n              strm.msg = 'invalid bit length repeat';\n              state.mode = BAD;\n              break;\n            }\n            while (copy--) {\n              state.lens[state.have++] = len;\n            }\n          }\n        }\n\n        /* handle error breaks in while */\n        if (state.mode === BAD) { break; }\n\n        /* check for end-of-block code (better have one) */\n        if (state.lens[256] === 0) {\n          strm.msg = 'invalid code -- missing end-of-block';\n          state.mode = BAD;\n          break;\n        }\n\n        /* build code tables -- note: do not change the lenbits or distbits\n           values here (9 and 6) without reading the comments in inftrees.h\n           concerning the ENOUGH constants, which depend on those values */\n        state.lenbits = 9;\n\n        opts = { bits: state.lenbits };\n        ret = inflate_table(LENS, state.lens, 0, state.nlen, state.lencode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.lenbits = opts.bits;\n        // state.lencode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid literal/lengths set';\n          state.mode = BAD;\n          break;\n        }\n\n        state.distbits = 6;\n        //state.distcode.copy(state.codes);\n        // Switch to use dynamic table\n        state.distcode = state.distdyn;\n        opts = { bits: state.distbits };\n        ret = inflate_table(DISTS, state.lens, state.nlen, state.ndist, state.distcode, 0, state.work, opts);\n        // We have separate tables & no pointers. 2 commented lines below not needed.\n        // state.next_index = opts.table_index;\n        state.distbits = opts.bits;\n        // state.distcode = state.next;\n\n        if (ret) {\n          strm.msg = 'invalid distances set';\n          state.mode = BAD;\n          break;\n        }\n        //Tracev((stderr, 'inflate:       codes ok\\n'));\n        state.mode = LEN_;\n        if (flush === Z_TREES) { break inf_leave; }\n        /* falls through */\n      case LEN_:\n        state.mode = LEN;\n        /* falls through */\n      case LEN:\n        if (have >= 6 && left >= 258) {\n          //--- RESTORE() ---\n          strm.next_out = put;\n          strm.avail_out = left;\n          strm.next_in = next;\n          strm.avail_in = have;\n          state.hold = hold;\n          state.bits = bits;\n          //---\n          inflate_fast(strm, _out);\n          //--- LOAD() ---\n          put = strm.next_out;\n          output = strm.output;\n          left = strm.avail_out;\n          next = strm.next_in;\n          input = strm.input;\n          have = strm.avail_in;\n          hold = state.hold;\n          bits = state.bits;\n          //---\n\n          if (state.mode === TYPE) {\n            state.back = -1;\n          }\n          break;\n        }\n        state.back = 0;\n        for (;;) {\n          here = state.lencode[hold & ((1 << state.lenbits) - 1)];  /*BITS(state.lenbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if (here_bits <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if (here_op && (here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.lencode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        state.length = here_val;\n        if (here_op === 0) {\n          //Tracevv((stderr, here.val >= 0x20 && here.val < 0x7f ?\n          //        \"inflate:         literal '%c'\\n\" :\n          //        \"inflate:         literal 0x%02x\\n\", here.val));\n          state.mode = LIT;\n          break;\n        }\n        if (here_op & 32) {\n          //Tracevv((stderr, \"inflate:         end of block\\n\"));\n          state.back = -1;\n          state.mode = TYPE;\n          break;\n        }\n        if (here_op & 64) {\n          strm.msg = 'invalid literal/length code';\n          state.mode = BAD;\n          break;\n        }\n        state.extra = here_op & 15;\n        state.mode = LENEXT;\n        /* falls through */\n      case LENEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.length += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n        //Tracevv((stderr, \"inflate:         length %u\\n\", state.length));\n        state.was = state.length;\n        state.mode = DIST;\n        /* falls through */\n      case DIST:\n        for (;;) {\n          here = state.distcode[hold & ((1 << state.distbits) - 1)];/*BITS(state.distbits)*/\n          here_bits = here >>> 24;\n          here_op = (here >>> 16) & 0xff;\n          here_val = here & 0xffff;\n\n          if ((here_bits) <= bits) { break; }\n          //--- PULLBYTE() ---//\n          if (have === 0) { break inf_leave; }\n          have--;\n          hold += input[next++] << bits;\n          bits += 8;\n          //---//\n        }\n        if ((here_op & 0xf0) === 0) {\n          last_bits = here_bits;\n          last_op = here_op;\n          last_val = here_val;\n          for (;;) {\n            here = state.distcode[last_val +\n                    ((hold & ((1 << (last_bits + last_op)) - 1))/*BITS(last.bits + last.op)*/ >> last_bits)];\n            here_bits = here >>> 24;\n            here_op = (here >>> 16) & 0xff;\n            here_val = here & 0xffff;\n\n            if ((last_bits + here_bits) <= bits) { break; }\n            //--- PULLBYTE() ---//\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n            //---//\n          }\n          //--- DROPBITS(last.bits) ---//\n          hold >>>= last_bits;\n          bits -= last_bits;\n          //---//\n          state.back += last_bits;\n        }\n        //--- DROPBITS(here.bits) ---//\n        hold >>>= here_bits;\n        bits -= here_bits;\n        //---//\n        state.back += here_bits;\n        if (here_op & 64) {\n          strm.msg = 'invalid distance code';\n          state.mode = BAD;\n          break;\n        }\n        state.offset = here_val;\n        state.extra = (here_op) & 15;\n        state.mode = DISTEXT;\n        /* falls through */\n      case DISTEXT:\n        if (state.extra) {\n          //=== NEEDBITS(state.extra);\n          n = state.extra;\n          while (bits < n) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          state.offset += hold & ((1 << state.extra) - 1)/*BITS(state.extra)*/;\n          //--- DROPBITS(state.extra) ---//\n          hold >>>= state.extra;\n          bits -= state.extra;\n          //---//\n          state.back += state.extra;\n        }\n//#ifdef INFLATE_STRICT\n        if (state.offset > state.dmax) {\n          strm.msg = 'invalid distance too far back';\n          state.mode = BAD;\n          break;\n        }\n//#endif\n        //Tracevv((stderr, \"inflate:         distance %u\\n\", state.offset));\n        state.mode = MATCH;\n        /* falls through */\n      case MATCH:\n        if (left === 0) { break inf_leave; }\n        copy = _out - left;\n        if (state.offset > copy) {         /* copy from window */\n          copy = state.offset - copy;\n          if (copy > state.whave) {\n            if (state.sane) {\n              strm.msg = 'invalid distance too far back';\n              state.mode = BAD;\n              break;\n            }\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n//#ifdef INFLATE_ALLOW_INVALID_DISTANCE_TOOFAR_ARRR\n//          Trace((stderr, \"inflate.c too far\\n\"));\n//          copy -= state.whave;\n//          if (copy > state.length) { copy = state.length; }\n//          if (copy > left) { copy = left; }\n//          left -= copy;\n//          state.length -= copy;\n//          do {\n//            output[put++] = 0;\n//          } while (--copy);\n//          if (state.length === 0) { state.mode = LEN; }\n//          break;\n//#endif\n          }\n          if (copy > state.wnext) {\n            copy -= state.wnext;\n            from = state.wsize - copy;\n          }\n          else {\n            from = state.wnext - copy;\n          }\n          if (copy > state.length) { copy = state.length; }\n          from_source = state.window;\n        }\n        else {                              /* copy from output */\n          from_source = output;\n          from = put - state.offset;\n          copy = state.length;\n        }\n        if (copy > left) { copy = left; }\n        left -= copy;\n        state.length -= copy;\n        do {\n          output[put++] = from_source[from++];\n        } while (--copy);\n        if (state.length === 0) { state.mode = LEN; }\n        break;\n      case LIT:\n        if (left === 0) { break inf_leave; }\n        output[put++] = state.length;\n        left--;\n        state.mode = LEN;\n        break;\n      case CHECK:\n        if (state.wrap) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            // Use '|' instead of '+' to make sure that result is signed\n            hold |= input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          _out -= left;\n          strm.total_out += _out;\n          state.total += _out;\n          if (_out) {\n            strm.adler = state.check =\n                /*UPDATE(state.check, put - _out, _out);*/\n                (state.flags ? crc32(state.check, output, _out, put - _out) : adler32(state.check, output, _out, put - _out));\n\n          }\n          _out = left;\n          // NB: crc32 stored as signed 32-bit int, zswap32 returns signed too\n          if ((state.flags ? hold : zswap32(hold)) !== state.check) {\n            strm.msg = 'incorrect data check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   check matches trailer\\n\"));\n        }\n        state.mode = LENGTH;\n        /* falls through */\n      case LENGTH:\n        if (state.wrap && state.flags) {\n          //=== NEEDBITS(32);\n          while (bits < 32) {\n            if (have === 0) { break inf_leave; }\n            have--;\n            hold += input[next++] << bits;\n            bits += 8;\n          }\n          //===//\n          if (hold !== (state.total & 0xffffffff)) {\n            strm.msg = 'incorrect length check';\n            state.mode = BAD;\n            break;\n          }\n          //=== INITBITS();\n          hold = 0;\n          bits = 0;\n          //===//\n          //Tracev((stderr, \"inflate:   length matches trailer\\n\"));\n        }\n        state.mode = DONE;\n        /* falls through */\n      case DONE:\n        ret = Z_STREAM_END;\n        break inf_leave;\n      case BAD:\n        ret = Z_DATA_ERROR;\n        break inf_leave;\n      case MEM:\n        return Z_MEM_ERROR;\n      case SYNC:\n        /* falls through */\n      default:\n        return Z_STREAM_ERROR;\n    }\n  }\n\n  // inf_leave <- here is real place for \"goto inf_leave\", emulated via \"break inf_leave\"\n\n  /*\n     Return from inflate(), updating the total counts and the check value.\n     If there was no progress during the inflate() call, return a buffer\n     error.  Call updatewindow() to create and/or update the window state.\n     Note: a memory error from inflate() is non-recoverable.\n   */\n\n  //--- RESTORE() ---\n  strm.next_out = put;\n  strm.avail_out = left;\n  strm.next_in = next;\n  strm.avail_in = have;\n  state.hold = hold;\n  state.bits = bits;\n  //---\n\n  if (state.wsize || (_out !== strm.avail_out && state.mode < BAD &&\n                      (state.mode < CHECK || flush !== Z_FINISH))) {\n    if (updatewindow(strm, strm.output, strm.next_out, _out - strm.avail_out)) {\n      state.mode = MEM;\n      return Z_MEM_ERROR;\n    }\n  }\n  _in -= strm.avail_in;\n  _out -= strm.avail_out;\n  strm.total_in += _in;\n  strm.total_out += _out;\n  state.total += _out;\n  if (state.wrap && _out) {\n    strm.adler = state.check = /*UPDATE(state.check, strm.next_out - _out, _out);*/\n      (state.flags ? crc32(state.check, output, _out, strm.next_out - _out) : adler32(state.check, output, _out, strm.next_out - _out));\n  }\n  strm.data_type = state.bits + (state.last ? 64 : 0) +\n                    (state.mode === TYPE ? 128 : 0) +\n                    (state.mode === LEN_ || state.mode === COPY_ ? 256 : 0);\n  if (((_in === 0 && _out === 0) || flush === Z_FINISH) && ret === Z_OK) {\n    ret = Z_BUF_ERROR;\n  }\n  return ret;\n}\n\nfunction inflateEnd(strm) {\n\n  if (!strm || !strm.state /*|| strm->zfree == (free_func)0*/) {\n    return Z_STREAM_ERROR;\n  }\n\n  var state = strm.state;\n  if (state.window) {\n    state.window = null;\n  }\n  strm.state = null;\n  return Z_OK;\n}\n\nfunction inflateGetHeader(strm, head) {\n  var state;\n\n  /* check state */\n  if (!strm || !strm.state) { return Z_STREAM_ERROR; }\n  state = strm.state;\n  if ((state.wrap & 2) === 0) { return Z_STREAM_ERROR; }\n\n  /* save header structure */\n  state.head = head;\n  head.done = false;\n  return Z_OK;\n}\n\nfunction inflateSetDictionary(strm, dictionary) {\n  var dictLength = dictionary.length;\n\n  var state;\n  var dictid;\n  var ret;\n\n  /* check state */\n  if (!strm /* == Z_NULL */ || !strm.state /* == Z_NULL */) { return Z_STREAM_ERROR; }\n  state = strm.state;\n\n  if (state.wrap !== 0 && state.mode !== DICT) {\n    return Z_STREAM_ERROR;\n  }\n\n  /* check for correct dictionary identifier */\n  if (state.mode === DICT) {\n    dictid = 1; /* adler32(0, null, 0)*/\n    /* dictid = adler32(dictid, dictionary, dictLength); */\n    dictid = adler32(dictid, dictionary, dictLength, 0);\n    if (dictid !== state.check) {\n      return Z_DATA_ERROR;\n    }\n  }\n  /* copy dictionary to window using updatewindow(), which will amend the\n   existing dictionary if appropriate */\n  ret = updatewindow(strm, dictionary, dictLength, dictLength);\n  if (ret) {\n    state.mode = MEM;\n    return Z_MEM_ERROR;\n  }\n  state.havedict = 1;\n  // Tracev((stderr, \"inflate:   dictionary set\\n\"));\n  return Z_OK;\n}\n\nexports.inflateReset = inflateReset;\nexports.inflateReset2 = inflateReset2;\nexports.inflateResetKeep = inflateResetKeep;\nexports.inflateInit = inflateInit;\nexports.inflateInit2 = inflateInit2;\nexports.inflate = inflate;\nexports.inflateEnd = inflateEnd;\nexports.inflateGetHeader = inflateGetHeader;\nexports.inflateSetDictionary = inflateSetDictionary;\nexports.inflateInfo = 'pako inflate (from Nodeca project)';\n\n/* Not implemented\nexports.inflateCopy = inflateCopy;\nexports.inflateGetDictionary = inflateGetDictionary;\nexports.inflateMark = inflateMark;\nexports.inflatePrime = inflatePrime;\nexports.inflateSync = inflateSync;\nexports.inflateSyncPoint = inflateSyncPoint;\nexports.inflateUndermine = inflateUndermine;\n*/\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/inftrees.js\":\n/*!************************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/inftrees.js ***!\n  \\************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\nvar MAXBITS = 15;\nvar ENOUGH_LENS = 852;\nvar ENOUGH_DISTS = 592;\n//var ENOUGH = (ENOUGH_LENS+ENOUGH_DISTS);\n\nvar CODES = 0;\nvar LENS = 1;\nvar DISTS = 2;\n\nvar lbase = [ /* Length codes 257..285 base */\n  3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 23, 27, 31,\n  35, 43, 51, 59, 67, 83, 99, 115, 131, 163, 195, 227, 258, 0, 0\n];\n\nvar lext = [ /* Length codes 257..285 extra */\n  16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 18, 18, 18, 18,\n  19, 19, 19, 19, 20, 20, 20, 20, 21, 21, 21, 21, 16, 72, 78\n];\n\nvar dbase = [ /* Distance codes 0..29 base */\n  1, 2, 3, 4, 5, 7, 9, 13, 17, 25, 33, 49, 65, 97, 129, 193,\n  257, 385, 513, 769, 1025, 1537, 2049, 3073, 4097, 6145,\n  8193, 12289, 16385, 24577, 0, 0\n];\n\nvar dext = [ /* Distance codes 0..29 extra */\n  16, 16, 16, 16, 17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22,\n  23, 23, 24, 24, 25, 25, 26, 26, 27, 27,\n  28, 28, 29, 29, 64, 64\n];\n\nmodule.exports = function inflate_table(type, lens, lens_index, codes, table, table_index, work, opts)\n{\n  var bits = opts.bits;\n      //here = opts.here; /* table entry for duplication */\n\n  var len = 0;               /* a code's length in bits */\n  var sym = 0;               /* index of code symbols */\n  var min = 0, max = 0;          /* minimum and maximum code lengths */\n  var root = 0;              /* number of index bits for root table */\n  var curr = 0;              /* number of index bits for current table */\n  var drop = 0;              /* code bits to drop for sub-table */\n  var left = 0;                   /* number of prefix codes available */\n  var used = 0;              /* code entries in table used */\n  var huff = 0;              /* Huffman code */\n  var incr;              /* for incrementing code, index */\n  var fill;              /* index for replicating entries */\n  var low;               /* low bits for current root entry */\n  var mask;              /* mask for low root bits */\n  var next;             /* next available space in table */\n  var base = null;     /* base value table to use */\n  var base_index = 0;\n//  var shoextra;    /* extra bits table to use */\n  var end;                    /* use base and extra for symbol > end */\n  var count = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];    /* number of codes of each length */\n  var offs = new utils.Buf16(MAXBITS + 1); //[MAXBITS+1];     /* offsets in table for each length */\n  var extra = null;\n  var extra_index = 0;\n\n  var here_bits, here_op, here_val;\n\n  /*\n   Process a set of code lengths to create a canonical Huffman code.  The\n   code lengths are lens[0..codes-1].  Each length corresponds to the\n   symbols 0..codes-1.  The Huffman code is generated by first sorting the\n   symbols by length from short to long, and retaining the symbol order\n   for codes with equal lengths.  Then the code starts with all zero bits\n   for the first code of the shortest length, and the codes are integer\n   increments for the same length, and zeros are appended as the length\n   increases.  For the deflate format, these bits are stored backwards\n   from their more natural integer increment ordering, and so when the\n   decoding tables are built in the large loop below, the integer codes\n   are incremented backwards.\n\n   This routine assumes, but does not check, that all of the entries in\n   lens[] are in the range 0..MAXBITS.  The caller must assure this.\n   1..MAXBITS is interpreted as that code length.  zero means that that\n   symbol does not occur in this code.\n\n   The codes are sorted by computing a count of codes for each length,\n   creating from that a table of starting indices for each length in the\n   sorted table, and then entering the symbols in order in the sorted\n   table.  The sorted table is work[], with that space being provided by\n   the caller.\n\n   The length counts are used for other purposes as well, i.e. finding\n   the minimum and maximum length codes, determining if there are any\n   codes at all, checking for a valid set of lengths, and looking ahead\n   at length counts to determine sub-table sizes when building the\n   decoding tables.\n   */\n\n  /* accumulate lengths for codes (assumes lens[] all in 0..MAXBITS) */\n  for (len = 0; len <= MAXBITS; len++) {\n    count[len] = 0;\n  }\n  for (sym = 0; sym < codes; sym++) {\n    count[lens[lens_index + sym]]++;\n  }\n\n  /* bound code lengths, force root to be within code lengths */\n  root = bits;\n  for (max = MAXBITS; max >= 1; max--) {\n    if (count[max] !== 0) { break; }\n  }\n  if (root > max) {\n    root = max;\n  }\n  if (max === 0) {                     /* no symbols to code at all */\n    //table.op[opts.table_index] = 64;  //here.op = (var char)64;    /* invalid code marker */\n    //table.bits[opts.table_index] = 1;   //here.bits = (var char)1;\n    //table.val[opts.table_index++] = 0;   //here.val = (var short)0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n\n    //table.op[opts.table_index] = 64;\n    //table.bits[opts.table_index] = 1;\n    //table.val[opts.table_index++] = 0;\n    table[table_index++] = (1 << 24) | (64 << 16) | 0;\n\n    opts.bits = 1;\n    return 0;     /* no symbols, but wait for decoding to report error */\n  }\n  for (min = 1; min < max; min++) {\n    if (count[min] !== 0) { break; }\n  }\n  if (root < min) {\n    root = min;\n  }\n\n  /* check for an over-subscribed or incomplete set of lengths */\n  left = 1;\n  for (len = 1; len <= MAXBITS; len++) {\n    left <<= 1;\n    left -= count[len];\n    if (left < 0) {\n      return -1;\n    }        /* over-subscribed */\n  }\n  if (left > 0 && (type === CODES || max !== 1)) {\n    return -1;                      /* incomplete set */\n  }\n\n  /* generate offsets into symbol table for each length for sorting */\n  offs[1] = 0;\n  for (len = 1; len < MAXBITS; len++) {\n    offs[len + 1] = offs[len] + count[len];\n  }\n\n  /* sort symbols by length, by symbol order within each length */\n  for (sym = 0; sym < codes; sym++) {\n    if (lens[lens_index + sym] !== 0) {\n      work[offs[lens[lens_index + sym]]++] = sym;\n    }\n  }\n\n  /*\n   Create and fill in decoding tables.  In this loop, the table being\n   filled is at next and has curr index bits.  The code being used is huff\n   with length len.  That code is converted to an index by dropping drop\n   bits off of the bottom.  For codes where len is less than drop + curr,\n   those top drop + curr - len bits are incremented through all values to\n   fill the table with replicated entries.\n\n   root is the number of index bits for the root table.  When len exceeds\n   root, sub-tables are created pointed to by the root entry with an index\n   of the low root bits of huff.  This is saved in low to check for when a\n   new sub-table should be started.  drop is zero when the root table is\n   being filled, and drop is root when sub-tables are being filled.\n\n   When a new sub-table is needed, it is necessary to look ahead in the\n   code lengths to determine what size sub-table is needed.  The length\n   counts are used for this, and so count[] is decremented as codes are\n   entered in the tables.\n\n   used keeps track of how many table entries have been allocated from the\n   provided *table space.  It is checked for LENS and DIST tables against\n   the constants ENOUGH_LENS and ENOUGH_DISTS to guard against changes in\n   the initial root table size constants.  See the comments in inftrees.h\n   for more information.\n\n   sym increments through all symbols, and the loop terminates when\n   all codes of length max, i.e. all codes, have been processed.  This\n   routine permits incomplete codes, so another loop after this one fills\n   in the rest of the decoding tables with invalid code markers.\n   */\n\n  /* set up for code type */\n  // poor man optimization - use if-else instead of switch,\n  // to avoid deopts in old v8\n  if (type === CODES) {\n    base = extra = work;    /* dummy value--not used */\n    end = 19;\n\n  } else if (type === LENS) {\n    base = lbase;\n    base_index -= 257;\n    extra = lext;\n    extra_index -= 257;\n    end = 256;\n\n  } else {                    /* DISTS */\n    base = dbase;\n    extra = dext;\n    end = -1;\n  }\n\n  /* initialize opts for loop */\n  huff = 0;                   /* starting code */\n  sym = 0;                    /* starting code symbol */\n  len = min;                  /* starting code length */\n  next = table_index;              /* current table to fill in */\n  curr = root;                /* current table index bits */\n  drop = 0;                   /* current bits to drop from code for index */\n  low = -1;                   /* trigger new sub-table when len > root */\n  used = 1 << root;          /* use root table entries */\n  mask = used - 1;            /* mask for comparing low */\n\n  /* check available table space */\n  if ((type === LENS && used > ENOUGH_LENS) ||\n    (type === DISTS && used > ENOUGH_DISTS)) {\n    return 1;\n  }\n\n  /* process all codes and make table entries */\n  for (;;) {\n    /* create table entry */\n    here_bits = len - drop;\n    if (work[sym] < end) {\n      here_op = 0;\n      here_val = work[sym];\n    }\n    else if (work[sym] > end) {\n      here_op = extra[extra_index + work[sym]];\n      here_val = base[base_index + work[sym]];\n    }\n    else {\n      here_op = 32 + 64;         /* end of block */\n      here_val = 0;\n    }\n\n    /* replicate for those indices with low len bits equal to huff */\n    incr = 1 << (len - drop);\n    fill = 1 << curr;\n    min = fill;                 /* save offset to next table */\n    do {\n      fill -= incr;\n      table[next + (huff >> drop) + fill] = (here_bits << 24) | (here_op << 16) | here_val |0;\n    } while (fill !== 0);\n\n    /* backwards increment the len-bit code huff */\n    incr = 1 << (len - 1);\n    while (huff & incr) {\n      incr >>= 1;\n    }\n    if (incr !== 0) {\n      huff &= incr - 1;\n      huff += incr;\n    } else {\n      huff = 0;\n    }\n\n    /* go to next symbol, update count, len */\n    sym++;\n    if (--count[len] === 0) {\n      if (len === max) { break; }\n      len = lens[lens_index + work[sym]];\n    }\n\n    /* create new sub-table if needed */\n    if (len > root && (huff & mask) !== low) {\n      /* if first time, transition to sub-tables */\n      if (drop === 0) {\n        drop = root;\n      }\n\n      /* increment past last table */\n      next += min;            /* here min is 1 << curr */\n\n      /* determine length of next table */\n      curr = len - drop;\n      left = 1 << curr;\n      while (curr + drop < max) {\n        left -= count[curr + drop];\n        if (left <= 0) { break; }\n        curr++;\n        left <<= 1;\n      }\n\n      /* check for enough space */\n      used += 1 << curr;\n      if ((type === LENS && used > ENOUGH_LENS) ||\n        (type === DISTS && used > ENOUGH_DISTS)) {\n        return 1;\n      }\n\n      /* point entry in root table to sub-table */\n      low = huff & mask;\n      /*table.op[low] = curr;\n      table.bits[low] = root;\n      table.val[low] = next - opts.table_index;*/\n      table[low] = (root << 24) | (curr << 16) | (next - table_index) |0;\n    }\n  }\n\n  /* fill in remaining table entry if code is incomplete (guaranteed to have\n   at most one remaining entry, since if the code is incomplete, the\n   maximum code length that was allowed to get this far is one bit) */\n  if (huff !== 0) {\n    //table.op[next + huff] = 64;            /* invalid code marker */\n    //table.bits[next + huff] = len - drop;\n    //table.val[next + huff] = 0;\n    table[next + huff] = ((len - drop) << 24) | (64 << 16) |0;\n  }\n\n  /* set return parameters */\n  //opts.table_index += used;\n  opts.bits = root;\n  return 0;\n};\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/messages.js\":\n/*!************************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/messages.js ***!\n  \\************************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nmodule.exports = {\n  2:      'need dictionary',     /* Z_NEED_DICT       2  */\n  1:      'stream end',          /* Z_STREAM_END      1  */\n  0:      '',                    /* Z_OK              0  */\n  '-1':   'file error',          /* Z_ERRNO         (-1) */\n  '-2':   'stream error',        /* Z_STREAM_ERROR  (-2) */\n  '-3':   'data error',          /* Z_DATA_ERROR    (-3) */\n  '-4':   'insufficient memory', /* Z_MEM_ERROR     (-4) */\n  '-5':   'buffer error',        /* Z_BUF_ERROR     (-5) */\n  '-6':   'incompatible version' /* Z_VERSION_ERROR (-6) */\n};\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/trees.js\":\n/*!*********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/trees.js ***!\n  \\*********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\n/* eslint-disable space-unary-ops */\n\nvar utils = __webpack_require__(/*! ../utils/common */ \"./node_modules/pako/lib/utils/common.js\");\n\n/* Public constants ==========================================================*/\n/* ===========================================================================*/\n\n\n//var Z_FILTERED          = 1;\n//var Z_HUFFMAN_ONLY      = 2;\n//var Z_RLE               = 3;\nvar Z_FIXED               = 4;\n//var Z_DEFAULT_STRATEGY  = 0;\n\n/* Possible values of the data_type field (though see inflate()) */\nvar Z_BINARY              = 0;\nvar Z_TEXT                = 1;\n//var Z_ASCII             = 1; // = Z_TEXT\nvar Z_UNKNOWN             = 2;\n\n/*============================================================================*/\n\n\nfunction zero(buf) { var len = buf.length; while (--len >= 0) { buf[len] = 0; } }\n\n// From zutil.h\n\nvar STORED_BLOCK = 0;\nvar STATIC_TREES = 1;\nvar DYN_TREES    = 2;\n/* The three kinds of block type */\n\nvar MIN_MATCH    = 3;\nvar MAX_MATCH    = 258;\n/* The minimum and maximum match lengths */\n\n// From deflate.h\n/* ===========================================================================\n * Internal compression state.\n */\n\nvar LENGTH_CODES  = 29;\n/* number of length codes, not counting the special END_BLOCK code */\n\nvar LITERALS      = 256;\n/* number of literal bytes 0..255 */\n\nvar L_CODES       = LITERALS + 1 + LENGTH_CODES;\n/* number of Literal or Length codes, including the END_BLOCK code */\n\nvar D_CODES       = 30;\n/* number of distance codes */\n\nvar BL_CODES      = 19;\n/* number of codes used to transfer the bit lengths */\n\nvar HEAP_SIZE     = 2 * L_CODES + 1;\n/* maximum heap size */\n\nvar MAX_BITS      = 15;\n/* All codes must not exceed MAX_BITS bits */\n\nvar Buf_size      = 16;\n/* size of bit buffer in bi_buf */\n\n\n/* ===========================================================================\n * Constants\n */\n\nvar MAX_BL_BITS = 7;\n/* Bit length codes must not exceed MAX_BL_BITS bits */\n\nvar END_BLOCK   = 256;\n/* end of block literal code */\n\nvar REP_3_6     = 16;\n/* repeat previous bit length 3-6 times (2 bits of repeat count) */\n\nvar REPZ_3_10   = 17;\n/* repeat a zero length 3-10 times  (3 bits of repeat count) */\n\nvar REPZ_11_138 = 18;\n/* repeat a zero length 11-138 times  (7 bits of repeat count) */\n\n/* eslint-disable comma-spacing,array-bracket-spacing */\nvar extra_lbits =   /* extra bits for each length code */\n  [0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0];\n\nvar extra_dbits =   /* extra bits for each distance code */\n  [0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13];\n\nvar extra_blbits =  /* extra bits for each bit length code */\n  [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,3,7];\n\nvar bl_order =\n  [16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15];\n/* eslint-enable comma-spacing,array-bracket-spacing */\n\n/* The lengths of the bit length codes are sent in order of decreasing\n * probability, to avoid transmitting the lengths for unused bit length codes.\n */\n\n/* ===========================================================================\n * Local data. These are initialized only once.\n */\n\n// We pre-fill arrays with 0 to avoid uninitialized gaps\n\nvar DIST_CODE_LEN = 512; /* see definition of array dist_code below */\n\n// !!!! Use flat array instead of structure, Freq = i*2, Len = i*2+1\nvar static_ltree  = new Array((L_CODES + 2) * 2);\nzero(static_ltree);\n/* The static literal tree. Since the bit lengths are imposed, there is no\n * need for the L_CODES extra codes used during heap construction. However\n * The codes 286 and 287 are needed to build a canonical tree (see _tr_init\n * below).\n */\n\nvar static_dtree  = new Array(D_CODES * 2);\nzero(static_dtree);\n/* The static distance tree. (Actually a trivial tree since all codes use\n * 5 bits.)\n */\n\nvar _dist_code    = new Array(DIST_CODE_LEN);\nzero(_dist_code);\n/* Distance codes. The first 256 values correspond to the distances\n * 3 .. 258, the last 256 values correspond to the top 8 bits of\n * the 15 bit distances.\n */\n\nvar _length_code  = new Array(MAX_MATCH - MIN_MATCH + 1);\nzero(_length_code);\n/* length code for each normalized match length (0 == MIN_MATCH) */\n\nvar base_length   = new Array(LENGTH_CODES);\nzero(base_length);\n/* First normalized length for each code (0 = MIN_MATCH) */\n\nvar base_dist     = new Array(D_CODES);\nzero(base_dist);\n/* First normalized distance for each code (0 = distance of 1) */\n\n\nfunction StaticTreeDesc(static_tree, extra_bits, extra_base, elems, max_length) {\n\n  this.static_tree  = static_tree;  /* static tree or NULL */\n  this.extra_bits   = extra_bits;   /* extra bits for each code or NULL */\n  this.extra_base   = extra_base;   /* base index for extra_bits */\n  this.elems        = elems;        /* max number of elements in the tree */\n  this.max_length   = max_length;   /* max bit length for the codes */\n\n  // show if `static_tree` has data or dummy - needed for monomorphic objects\n  this.has_stree    = static_tree && static_tree.length;\n}\n\n\nvar static_l_desc;\nvar static_d_desc;\nvar static_bl_desc;\n\n\nfunction TreeDesc(dyn_tree, stat_desc) {\n  this.dyn_tree = dyn_tree;     /* the dynamic tree */\n  this.max_code = 0;            /* largest code with non zero frequency */\n  this.stat_desc = stat_desc;   /* the corresponding static tree */\n}\n\n\n\nfunction d_code(dist) {\n  return dist < 256 ? _dist_code[dist] : _dist_code[256 + (dist >>> 7)];\n}\n\n\n/* ===========================================================================\n * Output a short LSB first on the stream.\n * IN assertion: there is enough room in pendingBuf.\n */\nfunction put_short(s, w) {\n//    put_byte(s, (uch)((w) & 0xff));\n//    put_byte(s, (uch)((ush)(w) >> 8));\n  s.pending_buf[s.pending++] = (w) & 0xff;\n  s.pending_buf[s.pending++] = (w >>> 8) & 0xff;\n}\n\n\n/* ===========================================================================\n * Send a value on a given number of bits.\n * IN assertion: length <= 16 and value fits in length bits.\n */\nfunction send_bits(s, value, length) {\n  if (s.bi_valid > (Buf_size - length)) {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    put_short(s, s.bi_buf);\n    s.bi_buf = value >> (Buf_size - s.bi_valid);\n    s.bi_valid += length - Buf_size;\n  } else {\n    s.bi_buf |= (value << s.bi_valid) & 0xffff;\n    s.bi_valid += length;\n  }\n}\n\n\nfunction send_code(s, c, tree) {\n  send_bits(s, tree[c * 2]/*.Code*/, tree[c * 2 + 1]/*.Len*/);\n}\n\n\n/* ===========================================================================\n * Reverse the first len bits of a code, using straightforward code (a faster\n * method would use a table)\n * IN assertion: 1 <= len <= 15\n */\nfunction bi_reverse(code, len) {\n  var res = 0;\n  do {\n    res |= code & 1;\n    code >>>= 1;\n    res <<= 1;\n  } while (--len > 0);\n  return res >>> 1;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer, keeping at most 7 bits in it.\n */\nfunction bi_flush(s) {\n  if (s.bi_valid === 16) {\n    put_short(s, s.bi_buf);\n    s.bi_buf = 0;\n    s.bi_valid = 0;\n\n  } else if (s.bi_valid >= 8) {\n    s.pending_buf[s.pending++] = s.bi_buf & 0xff;\n    s.bi_buf >>= 8;\n    s.bi_valid -= 8;\n  }\n}\n\n\n/* ===========================================================================\n * Compute the optimal bit lengths for a tree and update the total bit length\n * for the current block.\n * IN assertion: the fields freq and dad are set, heap[heap_max] and\n *    above are the tree nodes sorted by increasing frequency.\n * OUT assertions: the field len is set to the optimal bit length, the\n *     array bl_count contains the frequencies for each bit length.\n *     The length opt_len is updated; static_len is also updated if stree is\n *     not null.\n */\nfunction gen_bitlen(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc;    /* the tree descriptor */\n{\n  var tree            = desc.dyn_tree;\n  var max_code        = desc.max_code;\n  var stree           = desc.stat_desc.static_tree;\n  var has_stree       = desc.stat_desc.has_stree;\n  var extra           = desc.stat_desc.extra_bits;\n  var base            = desc.stat_desc.extra_base;\n  var max_length      = desc.stat_desc.max_length;\n  var h;              /* heap index */\n  var n, m;           /* iterate over the tree elements */\n  var bits;           /* bit length */\n  var xbits;          /* extra bits */\n  var f;              /* frequency */\n  var overflow = 0;   /* number of elements with bit length too large */\n\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    s.bl_count[bits] = 0;\n  }\n\n  /* In a first pass, compute the optimal bit lengths (which may\n   * overflow in the case of the bit length tree).\n   */\n  tree[s.heap[s.heap_max] * 2 + 1]/*.Len*/ = 0; /* root of the heap */\n\n  for (h = s.heap_max + 1; h < HEAP_SIZE; h++) {\n    n = s.heap[h];\n    bits = tree[tree[n * 2 + 1]/*.Dad*/ * 2 + 1]/*.Len*/ + 1;\n    if (bits > max_length) {\n      bits = max_length;\n      overflow++;\n    }\n    tree[n * 2 + 1]/*.Len*/ = bits;\n    /* We overwrite tree[n].Dad which is no longer needed */\n\n    if (n > max_code) { continue; } /* not a leaf node */\n\n    s.bl_count[bits]++;\n    xbits = 0;\n    if (n >= base) {\n      xbits = extra[n - base];\n    }\n    f = tree[n * 2]/*.Freq*/;\n    s.opt_len += f * (bits + xbits);\n    if (has_stree) {\n      s.static_len += f * (stree[n * 2 + 1]/*.Len*/ + xbits);\n    }\n  }\n  if (overflow === 0) { return; }\n\n  // Trace((stderr,\"\\nbit length overflow\\n\"));\n  /* This happens for example on obj2 and pic of the Calgary corpus */\n\n  /* Find the first bit length which could increase: */\n  do {\n    bits = max_length - 1;\n    while (s.bl_count[bits] === 0) { bits--; }\n    s.bl_count[bits]--;      /* move one leaf down the tree */\n    s.bl_count[bits + 1] += 2; /* move one overflow item as its brother */\n    s.bl_count[max_length]--;\n    /* The brother of the overflow item also moves one step up,\n     * but this does not affect bl_count[max_length]\n     */\n    overflow -= 2;\n  } while (overflow > 0);\n\n  /* Now recompute all bit lengths, scanning in increasing frequency.\n   * h is still equal to HEAP_SIZE. (It is simpler to reconstruct all\n   * lengths instead of fixing only the wrong ones. This idea is taken\n   * from 'ar' written by Haruhiko Okumura.)\n   */\n  for (bits = max_length; bits !== 0; bits--) {\n    n = s.bl_count[bits];\n    while (n !== 0) {\n      m = s.heap[--h];\n      if (m > max_code) { continue; }\n      if (tree[m * 2 + 1]/*.Len*/ !== bits) {\n        // Trace((stderr,\"code %d bits %d->%d\\n\", m, tree[m].Len, bits));\n        s.opt_len += (bits - tree[m * 2 + 1]/*.Len*/) * tree[m * 2]/*.Freq*/;\n        tree[m * 2 + 1]/*.Len*/ = bits;\n      }\n      n--;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Generate the codes for a given tree and bit counts (which need not be\n * optimal).\n * IN assertion: the array bl_count contains the bit length statistics for\n * the given tree and the field len is set for all tree elements.\n * OUT assertion: the field code is set for all tree elements of non\n *     zero code length.\n */\nfunction gen_codes(tree, max_code, bl_count)\n//    ct_data *tree;             /* the tree to decorate */\n//    int max_code;              /* largest code with non zero frequency */\n//    ushf *bl_count;            /* number of codes at each bit length */\n{\n  var next_code = new Array(MAX_BITS + 1); /* next code value for each bit length */\n  var code = 0;              /* running code value */\n  var bits;                  /* bit index */\n  var n;                     /* code index */\n\n  /* The distribution counts are first used to generate the code values\n   * without bit reversal.\n   */\n  for (bits = 1; bits <= MAX_BITS; bits++) {\n    next_code[bits] = code = (code + bl_count[bits - 1]) << 1;\n  }\n  /* Check that the bit counts in bl_count are consistent. The last code\n   * must be all ones.\n   */\n  //Assert (code + bl_count[MAX_BITS]-1 == (1<<MAX_BITS)-1,\n  //        \"inconsistent bit counts\");\n  //Tracev((stderr,\"\\ngen_codes: max_code %d \", max_code));\n\n  for (n = 0;  n <= max_code; n++) {\n    var len = tree[n * 2 + 1]/*.Len*/;\n    if (len === 0) { continue; }\n    /* Now reverse the bits */\n    tree[n * 2]/*.Code*/ = bi_reverse(next_code[len]++, len);\n\n    //Tracecv(tree != static_ltree, (stderr,\"\\nn %3d %c l %2d c %4x (%x) \",\n    //     n, (isgraph(n) ? n : ' '), len, tree[n].Code, next_code[len]-1));\n  }\n}\n\n\n/* ===========================================================================\n * Initialize the various 'constant' tables.\n */\nfunction tr_static_init() {\n  var n;        /* iterates over tree elements */\n  var bits;     /* bit counter */\n  var length;   /* length value */\n  var code;     /* code value */\n  var dist;     /* distance index */\n  var bl_count = new Array(MAX_BITS + 1);\n  /* number of codes at each bit length for an optimal tree */\n\n  // do check in _tr_init()\n  //if (static_init_done) return;\n\n  /* For some embedded targets, global variables are not initialized: */\n/*#ifdef NO_INIT_GLOBAL_POINTERS\n  static_l_desc.static_tree = static_ltree;\n  static_l_desc.extra_bits = extra_lbits;\n  static_d_desc.static_tree = static_dtree;\n  static_d_desc.extra_bits = extra_dbits;\n  static_bl_desc.extra_bits = extra_blbits;\n#endif*/\n\n  /* Initialize the mapping length (0..255) -> length code (0..28) */\n  length = 0;\n  for (code = 0; code < LENGTH_CODES - 1; code++) {\n    base_length[code] = length;\n    for (n = 0; n < (1 << extra_lbits[code]); n++) {\n      _length_code[length++] = code;\n    }\n  }\n  //Assert (length == 256, \"tr_static_init: length != 256\");\n  /* Note that the length 255 (match length 258) can be represented\n   * in two different ways: code 284 + 5 bits or code 285, so we\n   * overwrite length_code[255] to use the best encoding:\n   */\n  _length_code[length - 1] = code;\n\n  /* Initialize the mapping dist (0..32K) -> dist code (0..29) */\n  dist = 0;\n  for (code = 0; code < 16; code++) {\n    base_dist[code] = dist;\n    for (n = 0; n < (1 << extra_dbits[code]); n++) {\n      _dist_code[dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: dist != 256\");\n  dist >>= 7; /* from now on, all distances are divided by 128 */\n  for (; code < D_CODES; code++) {\n    base_dist[code] = dist << 7;\n    for (n = 0; n < (1 << (extra_dbits[code] - 7)); n++) {\n      _dist_code[256 + dist++] = code;\n    }\n  }\n  //Assert (dist == 256, \"tr_static_init: 256+dist != 512\");\n\n  /* Construct the codes of the static literal tree */\n  for (bits = 0; bits <= MAX_BITS; bits++) {\n    bl_count[bits] = 0;\n  }\n\n  n = 0;\n  while (n <= 143) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  while (n <= 255) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 9;\n    n++;\n    bl_count[9]++;\n  }\n  while (n <= 279) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 7;\n    n++;\n    bl_count[7]++;\n  }\n  while (n <= 287) {\n    static_ltree[n * 2 + 1]/*.Len*/ = 8;\n    n++;\n    bl_count[8]++;\n  }\n  /* Codes 286 and 287 do not exist, but we must include them in the\n   * tree construction to get a canonical Huffman tree (longest code\n   * all ones)\n   */\n  gen_codes(static_ltree, L_CODES + 1, bl_count);\n\n  /* The static distance tree is trivial: */\n  for (n = 0; n < D_CODES; n++) {\n    static_dtree[n * 2 + 1]/*.Len*/ = 5;\n    static_dtree[n * 2]/*.Code*/ = bi_reverse(n, 5);\n  }\n\n  // Now data ready and we can init static trees\n  static_l_desc = new StaticTreeDesc(static_ltree, extra_lbits, LITERALS + 1, L_CODES, MAX_BITS);\n  static_d_desc = new StaticTreeDesc(static_dtree, extra_dbits, 0,          D_CODES, MAX_BITS);\n  static_bl_desc = new StaticTreeDesc(new Array(0), extra_blbits, 0,         BL_CODES, MAX_BL_BITS);\n\n  //static_init_done = true;\n}\n\n\n/* ===========================================================================\n * Initialize a new block.\n */\nfunction init_block(s) {\n  var n; /* iterates over tree elements */\n\n  /* Initialize the trees. */\n  for (n = 0; n < L_CODES;  n++) { s.dyn_ltree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < D_CODES;  n++) { s.dyn_dtree[n * 2]/*.Freq*/ = 0; }\n  for (n = 0; n < BL_CODES; n++) { s.bl_tree[n * 2]/*.Freq*/ = 0; }\n\n  s.dyn_ltree[END_BLOCK * 2]/*.Freq*/ = 1;\n  s.opt_len = s.static_len = 0;\n  s.last_lit = s.matches = 0;\n}\n\n\n/* ===========================================================================\n * Flush the bit buffer and align the output on a byte boundary\n */\nfunction bi_windup(s)\n{\n  if (s.bi_valid > 8) {\n    put_short(s, s.bi_buf);\n  } else if (s.bi_valid > 0) {\n    //put_byte(s, (Byte)s->bi_buf);\n    s.pending_buf[s.pending++] = s.bi_buf;\n  }\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n}\n\n/* ===========================================================================\n * Copy a stored block, storing first the length and its\n * one's complement if requested.\n */\nfunction copy_block(s, buf, len, header)\n//DeflateState *s;\n//charf    *buf;    /* the input data */\n//unsigned len;     /* its length */\n//int      header;  /* true if block header must be written */\n{\n  bi_windup(s);        /* align on byte boundary */\n\n  if (header) {\n    put_short(s, len);\n    put_short(s, ~len);\n  }\n//  while (len--) {\n//    put_byte(s, *buf++);\n//  }\n  utils.arraySet(s.pending_buf, s.window, buf, len, s.pending);\n  s.pending += len;\n}\n\n/* ===========================================================================\n * Compares to subtrees, using the tree depth as tie breaker when\n * the subtrees have equal frequency. This minimizes the worst case length.\n */\nfunction smaller(tree, n, m, depth) {\n  var _n2 = n * 2;\n  var _m2 = m * 2;\n  return (tree[_n2]/*.Freq*/ < tree[_m2]/*.Freq*/ ||\n         (tree[_n2]/*.Freq*/ === tree[_m2]/*.Freq*/ && depth[n] <= depth[m]));\n}\n\n/* ===========================================================================\n * Restore the heap property by moving down the tree starting at node k,\n * exchanging a node with the smallest of its two sons if necessary, stopping\n * when the heap property is re-established (each father smaller than its\n * two sons).\n */\nfunction pqdownheap(s, tree, k)\n//    deflate_state *s;\n//    ct_data *tree;  /* the tree to restore */\n//    int k;               /* node to move down */\n{\n  var v = s.heap[k];\n  var j = k << 1;  /* left son of k */\n  while (j <= s.heap_len) {\n    /* Set j to the smallest of the two sons: */\n    if (j < s.heap_len &&\n      smaller(tree, s.heap[j + 1], s.heap[j], s.depth)) {\n      j++;\n    }\n    /* Exit if v is smaller than both sons */\n    if (smaller(tree, v, s.heap[j], s.depth)) { break; }\n\n    /* Exchange v with the smallest son */\n    s.heap[k] = s.heap[j];\n    k = j;\n\n    /* And continue down the tree, setting j to the left son of k */\n    j <<= 1;\n  }\n  s.heap[k] = v;\n}\n\n\n// inlined manually\n// var SMALLEST = 1;\n\n/* ===========================================================================\n * Send the block data compressed using the given Huffman trees\n */\nfunction compress_block(s, ltree, dtree)\n//    deflate_state *s;\n//    const ct_data *ltree; /* literal tree */\n//    const ct_data *dtree; /* distance tree */\n{\n  var dist;           /* distance of matched string */\n  var lc;             /* match length or unmatched char (if dist == 0) */\n  var lx = 0;         /* running index in l_buf */\n  var code;           /* the code to send */\n  var extra;          /* number of extra bits to send */\n\n  if (s.last_lit !== 0) {\n    do {\n      dist = (s.pending_buf[s.d_buf + lx * 2] << 8) | (s.pending_buf[s.d_buf + lx * 2 + 1]);\n      lc = s.pending_buf[s.l_buf + lx];\n      lx++;\n\n      if (dist === 0) {\n        send_code(s, lc, ltree); /* send a literal byte */\n        //Tracecv(isgraph(lc), (stderr,\" '%c' \", lc));\n      } else {\n        /* Here, lc is the match length - MIN_MATCH */\n        code = _length_code[lc];\n        send_code(s, code + LITERALS + 1, ltree); /* send the length code */\n        extra = extra_lbits[code];\n        if (extra !== 0) {\n          lc -= base_length[code];\n          send_bits(s, lc, extra);       /* send the extra length bits */\n        }\n        dist--; /* dist is now the match distance - 1 */\n        code = d_code(dist);\n        //Assert (code < D_CODES, \"bad d_code\");\n\n        send_code(s, code, dtree);       /* send the distance code */\n        extra = extra_dbits[code];\n        if (extra !== 0) {\n          dist -= base_dist[code];\n          send_bits(s, dist, extra);   /* send the extra distance bits */\n        }\n      } /* literal or match pair ? */\n\n      /* Check that the overlay between pending_buf and d_buf+l_buf is ok: */\n      //Assert((uInt)(s->pending) < s->lit_bufsize + 2*lx,\n      //       \"pendingBuf overflow\");\n\n    } while (lx < s.last_lit);\n  }\n\n  send_code(s, END_BLOCK, ltree);\n}\n\n\n/* ===========================================================================\n * Construct one Huffman tree and assigns the code bit strings and lengths.\n * Update the total bit length for the current block.\n * IN assertion: the field freq is set for all tree elements.\n * OUT assertions: the fields len and code are set to the optimal bit length\n *     and corresponding code. The length opt_len is updated; static_len is\n *     also updated if stree is not null. The field max_code is set.\n */\nfunction build_tree(s, desc)\n//    deflate_state *s;\n//    tree_desc *desc; /* the tree descriptor */\n{\n  var tree     = desc.dyn_tree;\n  var stree    = desc.stat_desc.static_tree;\n  var has_stree = desc.stat_desc.has_stree;\n  var elems    = desc.stat_desc.elems;\n  var n, m;          /* iterate over heap elements */\n  var max_code = -1; /* largest code with non zero frequency */\n  var node;          /* new node being created */\n\n  /* Construct the initial heap, with least frequent element in\n   * heap[SMALLEST]. The sons of heap[n] are heap[2*n] and heap[2*n+1].\n   * heap[0] is not used.\n   */\n  s.heap_len = 0;\n  s.heap_max = HEAP_SIZE;\n\n  for (n = 0; n < elems; n++) {\n    if (tree[n * 2]/*.Freq*/ !== 0) {\n      s.heap[++s.heap_len] = max_code = n;\n      s.depth[n] = 0;\n\n    } else {\n      tree[n * 2 + 1]/*.Len*/ = 0;\n    }\n  }\n\n  /* The pkzip format requires that at least one distance code exists,\n   * and that at least one bit should be sent even if there is only one\n   * possible code. So to avoid special checks later on we force at least\n   * two codes of non zero frequency.\n   */\n  while (s.heap_len < 2) {\n    node = s.heap[++s.heap_len] = (max_code < 2 ? ++max_code : 0);\n    tree[node * 2]/*.Freq*/ = 1;\n    s.depth[node] = 0;\n    s.opt_len--;\n\n    if (has_stree) {\n      s.static_len -= stree[node * 2 + 1]/*.Len*/;\n    }\n    /* node is 0 or 1 so it does not have extra bits */\n  }\n  desc.max_code = max_code;\n\n  /* The elements heap[heap_len/2+1 .. heap_len] are leaves of the tree,\n   * establish sub-heaps of increasing lengths:\n   */\n  for (n = (s.heap_len >> 1/*int /2*/); n >= 1; n--) { pqdownheap(s, tree, n); }\n\n  /* Construct the Huffman tree by repeatedly combining the least two\n   * frequent nodes.\n   */\n  node = elems;              /* next internal node of the tree */\n  do {\n    //pqremove(s, tree, n);  /* n = node of least frequency */\n    /*** pqremove ***/\n    n = s.heap[1/*SMALLEST*/];\n    s.heap[1/*SMALLEST*/] = s.heap[s.heap_len--];\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n    /***/\n\n    m = s.heap[1/*SMALLEST*/]; /* m = node of next least frequency */\n\n    s.heap[--s.heap_max] = n; /* keep the nodes sorted by frequency */\n    s.heap[--s.heap_max] = m;\n\n    /* Create a new node father of n and m */\n    tree[node * 2]/*.Freq*/ = tree[n * 2]/*.Freq*/ + tree[m * 2]/*.Freq*/;\n    s.depth[node] = (s.depth[n] >= s.depth[m] ? s.depth[n] : s.depth[m]) + 1;\n    tree[n * 2 + 1]/*.Dad*/ = tree[m * 2 + 1]/*.Dad*/ = node;\n\n    /* and insert the new node in the heap */\n    s.heap[1/*SMALLEST*/] = node++;\n    pqdownheap(s, tree, 1/*SMALLEST*/);\n\n  } while (s.heap_len >= 2);\n\n  s.heap[--s.heap_max] = s.heap[1/*SMALLEST*/];\n\n  /* At this point, the fields freq and dad are set. We can now\n   * generate the bit lengths.\n   */\n  gen_bitlen(s, desc);\n\n  /* The field len is now set, we can generate the bit codes */\n  gen_codes(tree, max_code, s.bl_count);\n}\n\n\n/* ===========================================================================\n * Scan a literal or distance tree to determine the frequencies of the codes\n * in the bit length tree.\n */\nfunction scan_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree;   /* the tree to be scanned */\n//    int max_code;    /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n  tree[(max_code + 1) * 2 + 1]/*.Len*/ = 0xffff; /* guard */\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      s.bl_tree[curlen * 2]/*.Freq*/ += count;\n\n    } else if (curlen !== 0) {\n\n      if (curlen !== prevlen) { s.bl_tree[curlen * 2]/*.Freq*/++; }\n      s.bl_tree[REP_3_6 * 2]/*.Freq*/++;\n\n    } else if (count <= 10) {\n      s.bl_tree[REPZ_3_10 * 2]/*.Freq*/++;\n\n    } else {\n      s.bl_tree[REPZ_11_138 * 2]/*.Freq*/++;\n    }\n\n    count = 0;\n    prevlen = curlen;\n\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Send a literal or distance tree in compressed form, using the codes in\n * bl_tree.\n */\nfunction send_tree(s, tree, max_code)\n//    deflate_state *s;\n//    ct_data *tree; /* the tree to be scanned */\n//    int max_code;       /* and its largest code of non zero frequency */\n{\n  var n;                     /* iterates over all tree elements */\n  var prevlen = -1;          /* last emitted length */\n  var curlen;                /* length of current code */\n\n  var nextlen = tree[0 * 2 + 1]/*.Len*/; /* length of next code */\n\n  var count = 0;             /* repeat count of the current code */\n  var max_count = 7;         /* max repeat count */\n  var min_count = 4;         /* min repeat count */\n\n  /* tree[max_code+1].Len = -1; */  /* guard already set */\n  if (nextlen === 0) {\n    max_count = 138;\n    min_count = 3;\n  }\n\n  for (n = 0; n <= max_code; n++) {\n    curlen = nextlen;\n    nextlen = tree[(n + 1) * 2 + 1]/*.Len*/;\n\n    if (++count < max_count && curlen === nextlen) {\n      continue;\n\n    } else if (count < min_count) {\n      do { send_code(s, curlen, s.bl_tree); } while (--count !== 0);\n\n    } else if (curlen !== 0) {\n      if (curlen !== prevlen) {\n        send_code(s, curlen, s.bl_tree);\n        count--;\n      }\n      //Assert(count >= 3 && count <= 6, \" 3_6?\");\n      send_code(s, REP_3_6, s.bl_tree);\n      send_bits(s, count - 3, 2);\n\n    } else if (count <= 10) {\n      send_code(s, REPZ_3_10, s.bl_tree);\n      send_bits(s, count - 3, 3);\n\n    } else {\n      send_code(s, REPZ_11_138, s.bl_tree);\n      send_bits(s, count - 11, 7);\n    }\n\n    count = 0;\n    prevlen = curlen;\n    if (nextlen === 0) {\n      max_count = 138;\n      min_count = 3;\n\n    } else if (curlen === nextlen) {\n      max_count = 6;\n      min_count = 3;\n\n    } else {\n      max_count = 7;\n      min_count = 4;\n    }\n  }\n}\n\n\n/* ===========================================================================\n * Construct the Huffman tree for the bit lengths and return the index in\n * bl_order of the last bit length code to send.\n */\nfunction build_bl_tree(s) {\n  var max_blindex;  /* index of last bit length code of non zero freq */\n\n  /* Determine the bit length frequencies for literal and distance trees */\n  scan_tree(s, s.dyn_ltree, s.l_desc.max_code);\n  scan_tree(s, s.dyn_dtree, s.d_desc.max_code);\n\n  /* Build the bit length tree: */\n  build_tree(s, s.bl_desc);\n  /* opt_len now includes the length of the tree representations, except\n   * the lengths of the bit lengths codes and the 5+5+4 bits for the counts.\n   */\n\n  /* Determine the number of bit length codes to send. The pkzip format\n   * requires that at least 4 bit length codes be sent. (appnote.txt says\n   * 3 but the actual value used is 4.)\n   */\n  for (max_blindex = BL_CODES - 1; max_blindex >= 3; max_blindex--) {\n    if (s.bl_tree[bl_order[max_blindex] * 2 + 1]/*.Len*/ !== 0) {\n      break;\n    }\n  }\n  /* Update opt_len to include the bit length tree and counts */\n  s.opt_len += 3 * (max_blindex + 1) + 5 + 5 + 4;\n  //Tracev((stderr, \"\\ndyn trees: dyn %ld, stat %ld\",\n  //        s->opt_len, s->static_len));\n\n  return max_blindex;\n}\n\n\n/* ===========================================================================\n * Send the header for a block using dynamic Huffman trees: the counts, the\n * lengths of the bit length codes, the literal tree and the distance tree.\n * IN assertion: lcodes >= 257, dcodes >= 1, blcodes >= 4.\n */\nfunction send_all_trees(s, lcodes, dcodes, blcodes)\n//    deflate_state *s;\n//    int lcodes, dcodes, blcodes; /* number of codes for each tree */\n{\n  var rank;                    /* index in bl_order */\n\n  //Assert (lcodes >= 257 && dcodes >= 1 && blcodes >= 4, \"not enough codes\");\n  //Assert (lcodes <= L_CODES && dcodes <= D_CODES && blcodes <= BL_CODES,\n  //        \"too many codes\");\n  //Tracev((stderr, \"\\nbl counts: \"));\n  send_bits(s, lcodes - 257, 5); /* not +255 as stated in appnote.txt */\n  send_bits(s, dcodes - 1,   5);\n  send_bits(s, blcodes - 4,  4); /* not -3 as stated in appnote.txt */\n  for (rank = 0; rank < blcodes; rank++) {\n    //Tracev((stderr, \"\\nbl code %2d \", bl_order[rank]));\n    send_bits(s, s.bl_tree[bl_order[rank] * 2 + 1]/*.Len*/, 3);\n  }\n  //Tracev((stderr, \"\\nbl tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_ltree, lcodes - 1); /* literal tree */\n  //Tracev((stderr, \"\\nlit tree: sent %ld\", s->bits_sent));\n\n  send_tree(s, s.dyn_dtree, dcodes - 1); /* distance tree */\n  //Tracev((stderr, \"\\ndist tree: sent %ld\", s->bits_sent));\n}\n\n\n/* ===========================================================================\n * Check if the data type is TEXT or BINARY, using the following algorithm:\n * - TEXT if the two conditions below are satisfied:\n *    a) There are no non-portable control characters belonging to the\n *       \"black list\" (0..6, 14..25, 28..31).\n *    b) There is at least one printable character belonging to the\n *       \"white list\" (9 {TAB}, 10 {LF}, 13 {CR}, 32..255).\n * - BINARY otherwise.\n * - The following partially-portable control characters form a\n *   \"gray list\" that is ignored in this detection algorithm:\n *   (7 {BEL}, 8 {BS}, 11 {VT}, 12 {FF}, 26 {SUB}, 27 {ESC}).\n * IN assertion: the fields Freq of dyn_ltree are set.\n */\nfunction detect_data_type(s) {\n  /* black_mask is the bit mask of black-listed bytes\n   * set bits 0..6, 14..25, and 28..31\n   * 0xf3ffc07f = binary 11110011111111111100000001111111\n   */\n  var black_mask = 0xf3ffc07f;\n  var n;\n\n  /* Check for non-textual (\"black-listed\") bytes. */\n  for (n = 0; n <= 31; n++, black_mask >>>= 1) {\n    if ((black_mask & 1) && (s.dyn_ltree[n * 2]/*.Freq*/ !== 0)) {\n      return Z_BINARY;\n    }\n  }\n\n  /* Check for textual (\"white-listed\") bytes. */\n  if (s.dyn_ltree[9 * 2]/*.Freq*/ !== 0 || s.dyn_ltree[10 * 2]/*.Freq*/ !== 0 ||\n      s.dyn_ltree[13 * 2]/*.Freq*/ !== 0) {\n    return Z_TEXT;\n  }\n  for (n = 32; n < LITERALS; n++) {\n    if (s.dyn_ltree[n * 2]/*.Freq*/ !== 0) {\n      return Z_TEXT;\n    }\n  }\n\n  /* There are no \"black-listed\" or \"white-listed\" bytes:\n   * this stream either is empty or has tolerated (\"gray-listed\") bytes only.\n   */\n  return Z_BINARY;\n}\n\n\nvar static_init_done = false;\n\n/* ===========================================================================\n * Initialize the tree data structures for a new zlib stream.\n */\nfunction _tr_init(s)\n{\n\n  if (!static_init_done) {\n    tr_static_init();\n    static_init_done = true;\n  }\n\n  s.l_desc  = new TreeDesc(s.dyn_ltree, static_l_desc);\n  s.d_desc  = new TreeDesc(s.dyn_dtree, static_d_desc);\n  s.bl_desc = new TreeDesc(s.bl_tree, static_bl_desc);\n\n  s.bi_buf = 0;\n  s.bi_valid = 0;\n\n  /* Initialize the first block of the first file: */\n  init_block(s);\n}\n\n\n/* ===========================================================================\n * Send a stored block\n */\nfunction _tr_stored_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  send_bits(s, (STORED_BLOCK << 1) + (last ? 1 : 0), 3);    /* send block type */\n  copy_block(s, buf, stored_len, true); /* with header */\n}\n\n\n/* ===========================================================================\n * Send one empty static block to give enough lookahead for inflate.\n * This takes 10 bits, of which 7 may remain in the bit buffer.\n */\nfunction _tr_align(s) {\n  send_bits(s, STATIC_TREES << 1, 3);\n  send_code(s, END_BLOCK, static_ltree);\n  bi_flush(s);\n}\n\n\n/* ===========================================================================\n * Determine the best encoding for the current block: dynamic trees, static\n * trees or store, and output the encoded block to the zip file.\n */\nfunction _tr_flush_block(s, buf, stored_len, last)\n//DeflateState *s;\n//charf *buf;       /* input block, or NULL if too old */\n//ulg stored_len;   /* length of input block */\n//int last;         /* one if this is the last block for a file */\n{\n  var opt_lenb, static_lenb;  /* opt_len and static_len in bytes */\n  var max_blindex = 0;        /* index of last bit length code of non zero freq */\n\n  /* Build the Huffman trees unless a stored block is forced */\n  if (s.level > 0) {\n\n    /* Check if the file is binary or text */\n    if (s.strm.data_type === Z_UNKNOWN) {\n      s.strm.data_type = detect_data_type(s);\n    }\n\n    /* Construct the literal and distance trees */\n    build_tree(s, s.l_desc);\n    // Tracev((stderr, \"\\nlit data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n\n    build_tree(s, s.d_desc);\n    // Tracev((stderr, \"\\ndist data: dyn %ld, stat %ld\", s->opt_len,\n    //        s->static_len));\n    /* At this point, opt_len and static_len are the total bit lengths of\n     * the compressed block data, excluding the tree representations.\n     */\n\n    /* Build the bit length tree for the above two trees, and get the index\n     * in bl_order of the last bit length code to send.\n     */\n    max_blindex = build_bl_tree(s);\n\n    /* Determine the best encoding. Compute the block lengths in bytes. */\n    opt_lenb = (s.opt_len + 3 + 7) >>> 3;\n    static_lenb = (s.static_len + 3 + 7) >>> 3;\n\n    // Tracev((stderr, \"\\nopt %lu(%lu) stat %lu(%lu) stored %lu lit %u \",\n    //        opt_lenb, s->opt_len, static_lenb, s->static_len, stored_len,\n    //        s->last_lit));\n\n    if (static_lenb <= opt_lenb) { opt_lenb = static_lenb; }\n\n  } else {\n    // Assert(buf != (char*)0, \"lost buf\");\n    opt_lenb = static_lenb = stored_len + 5; /* force a stored block */\n  }\n\n  if ((stored_len + 4 <= opt_lenb) && (buf !== -1)) {\n    /* 4: two words for the lengths */\n\n    /* The test buf != NULL is only necessary if LIT_BUFSIZE > WSIZE.\n     * Otherwise we can't have processed more than WSIZE input bytes since\n     * the last block flush, because compression would have been\n     * successful. If LIT_BUFSIZE <= WSIZE, it is never too late to\n     * transform a block into a stored block.\n     */\n    _tr_stored_block(s, buf, stored_len, last);\n\n  } else if (s.strategy === Z_FIXED || static_lenb === opt_lenb) {\n\n    send_bits(s, (STATIC_TREES << 1) + (last ? 1 : 0), 3);\n    compress_block(s, static_ltree, static_dtree);\n\n  } else {\n    send_bits(s, (DYN_TREES << 1) + (last ? 1 : 0), 3);\n    send_all_trees(s, s.l_desc.max_code + 1, s.d_desc.max_code + 1, max_blindex + 1);\n    compress_block(s, s.dyn_ltree, s.dyn_dtree);\n  }\n  // Assert (s->compressed_len == s->bits_sent, \"bad compressed size\");\n  /* The above check is made mod 2^32, for files larger than 512 MB\n   * and uLong implemented on 32 bits.\n   */\n  init_block(s);\n\n  if (last) {\n    bi_windup(s);\n  }\n  // Tracev((stderr,\"\\ncomprlen %lu(%lu) \", s->compressed_len>>3,\n  //       s->compressed_len-7*last));\n}\n\n/* ===========================================================================\n * Save the match info and tally the frequency counts. Return true if\n * the current block must be flushed.\n */\nfunction _tr_tally(s, dist, lc)\n//    deflate_state *s;\n//    unsigned dist;  /* distance of matched string */\n//    unsigned lc;    /* match length-MIN_MATCH or unmatched char (if dist==0) */\n{\n  //var out_length, in_length, dcode;\n\n  s.pending_buf[s.d_buf + s.last_lit * 2]     = (dist >>> 8) & 0xff;\n  s.pending_buf[s.d_buf + s.last_lit * 2 + 1] = dist & 0xff;\n\n  s.pending_buf[s.l_buf + s.last_lit] = lc & 0xff;\n  s.last_lit++;\n\n  if (dist === 0) {\n    /* lc is the unmatched char */\n    s.dyn_ltree[lc * 2]/*.Freq*/++;\n  } else {\n    s.matches++;\n    /* Here, lc is the match length - MIN_MATCH */\n    dist--;             /* dist = match distance - 1 */\n    //Assert((ush)dist < (ush)MAX_DIST(s) &&\n    //       (ush)lc <= (ush)(MAX_MATCH-MIN_MATCH) &&\n    //       (ush)d_code(dist) < (ush)D_CODES,  \"_tr_tally: bad match\");\n\n    s.dyn_ltree[(_length_code[lc] + LITERALS + 1) * 2]/*.Freq*/++;\n    s.dyn_dtree[d_code(dist) * 2]/*.Freq*/++;\n  }\n\n// (!) This block is disabled in zlib defaults,\n// don't enable it for binary compatibility\n\n//#ifdef TRUNCATE_BLOCK\n//  /* Try to guess if it is profitable to stop the current block here */\n//  if ((s.last_lit & 0x1fff) === 0 && s.level > 2) {\n//    /* Compute an upper bound for the compressed length */\n//    out_length = s.last_lit*8;\n//    in_length = s.strstart - s.block_start;\n//\n//    for (dcode = 0; dcode < D_CODES; dcode++) {\n//      out_length += s.dyn_dtree[dcode*2]/*.Freq*/ * (5 + extra_dbits[dcode]);\n//    }\n//    out_length >>>= 3;\n//    //Tracev((stderr,\"\\nlast_lit %u, in %ld, out ~%ld(%ld%%) \",\n//    //       s->last_lit, in_length, out_length,\n//    //       100L - out_length*100L/in_length));\n//    if (s.matches < (s.last_lit>>1)/*int /2*/ && out_length < (in_length>>1)/*int /2*/) {\n//      return true;\n//    }\n//  }\n//#endif\n\n  return (s.last_lit === s.lit_bufsize - 1);\n  /* We avoid equality with lit_bufsize because of wraparound at 64K\n   * on 16 bit machines and because stored blocks are restricted to\n   * 64K-1 bytes.\n   */\n}\n\nexports._tr_init  = _tr_init;\nexports._tr_stored_block = _tr_stored_block;\nexports._tr_flush_block  = _tr_flush_block;\nexports._tr_tally = _tr_tally;\nexports._tr_align = _tr_align;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pako/lib/zlib/zstream.js\":\n/*!***********************************************!*\\\n  !*** ./node_modules/pako/lib/zlib/zstream.js ***!\n  \\***********************************************/\n/*! no static exports found */\n/***/ (function(module, exports, __webpack_require__) {\n\n\"use strict\";\n\n\n// (C) 1995-2013 Jean-loup Gailly and Mark Adler\n// (C) 2014-2017 Vitaly Puzrin and Andrey Tupitsin\n//\n// This software is provided 'as-is', without any express or implied\n// warranty. In no event will the authors be held liable for any damages\n// arising from the use of this software.\n//\n// Permission is granted to anyone to use this software for any purpose,\n// including commercial applications, and to alter it and redistribute it\n// freely, subject to the following restrictions:\n//\n// 1. The origin of this software must not be misrepresented; you must not\n//   claim that you wrote the original software. If you use this software\n//   in a product, an acknowledgment in the product documentation would be\n//   appreciated but is not required.\n// 2. Altered source versions must be plainly marked as such, and must not be\n//   misrepresented as being the original software.\n// 3. This notice may not be removed or altered from any source distribution.\n\nfunction ZStream() {\n  /* next input byte */\n  this.input = null; // JS specific, because we have no pointers\n  this.next_in = 0;\n  /* number of bytes available at input */\n  this.avail_in = 0;\n  /* total number of input bytes read so far */\n  this.total_in = 0;\n  /* next output byte should be put there */\n  this.output = null; // JS specific, because we have no pointers\n  this.next_out = 0;\n  /* remaining free space at output */\n  this.avail_out = 0;\n  /* total number of bytes output so far */\n  this.total_out = 0;\n  /* last error message, NULL if no error */\n  this.msg = ''/*Z_NULL*/;\n  /* not visible by applications */\n  this.state = null;\n  /* best guess about the data type: binary or text */\n  this.data_type = 2/*Z_UNKNOWN*/;\n  /* adler32 value of the uncompressed data */\n  this.adler = 0;\n}\n\nmodule.exports = ZStream;\n\n\n/***/ }),\n\n/***/ \"./node_modules/pend/index.js\":\n/*!************************************!*\\\n  !*** ./node_modules/pend/index.js ***!\n  \\************************************/\n/*! no static exports found */\n/***/ (function(module, exports) {\n\nmodule.exports = Pend;\n\nfunction Pend() {\n  this.pending = 0;\n  this.max = Infinity;\n  this.listeners = [];\n  this.waiting = [];\n  this.error = null;\n}\n\nPend.prototype.go = function(fn) {\n  if (this.pending < this.max) {\n    pendGo(this, fn);\n  } else {\n    this.waiting.push(fn);\n  }\n};\n\nPend.prototype.wait = function(cb) {\n  if (this.pending === 0) {\n    cb(this.error);\n  } else {\n    this.listeners.push(cb);\n  }\n};\n\nPend.prototype.hold = function() {\n  return pendHold(this);\n};\n\nfunction pendHold(self) {\n  self.pending += 1;\n  var called = false;\n  return onCb;\n  function onCb(err) {\n    if (called) throw new Error(\"callback called twice\");\n    called = true;\n    self.error = self.error || err;\n    self.pending -= 1;\n    if (self.waiting.length > 0 && self.pending < self.max) {\n      pendGo(self, self.waiting.shift());\n    } else if (self.pending === 0) {\n      var listeners = self.listeners;\n      self.listeners = [];\n      listeners.forEach(cbListener);\n    }\n  }\n  function cbListener(listener) {\n    listener(self.error);\n  }\n}\n\nfunction pendGo(self, fn) {\n  fn(pendHold(self));\n}\n\n\n/***/ }),\n\n/***/ \"./node_modules/webpack/buildin/global.js\":\n/*!***********************************!*\\\n  !*** (webpack)/buildin/global.js ***!\n  \\***********************************/\n/*! no static exports found */\n/***/ (function(module, exports) {\n\nvar g;\n\n// This works in non-strict mode\ng = (function() {\n\treturn this;\n})();\n\ntry {\n\t// This works if eval is allowed (see CSP)\n\tg = g || new Function(\"return this\")();\n} catch (e) {\n\t// This works if the window reference is available\n\tif (typeof window === \"object\") g = window;\n}\n\n// g can still be undefined, but nothing to do about it...\n// We return undefined, instead of nothing here, so it's\n// easier to handle this case. if(!global) { ...}\n\nmodule.exports = g;\n\n\n/***/ }),\n\n/***/ \"./node_modules/webpack/buildin/module.js\":\n/*!***********************************!*\\\n  !*** (webpack)/buildin/module.js ***!\n  \\***********************************/\n/*! no static exports found */\n/***/ (function(module, exports) {\n\nmodule.exports = function(module) {\n\tif (!module.webpackPolyfill) {\n\t\tmodule.deprecate = function() {};\n\t\tmodule.paths = [];\n\t\t// module.parent = undefined by default\n\t\tif (!module.children) module.children = [];\n\t\tObject.defineProperty(module, \"loaded\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.l;\n\t\t\t}\n\t\t});\n\t\tObject.defineProperty(module, \"id\", {\n\t\t\tenumerable: true,\n\t\t\tget: function() {\n\t\t\t\treturn module.i;\n\t\t\t}\n\t\t});\n\t\tmodule.webpackPolyfill = 1;\n\t}\n\treturn module;\n};\n\n\n/***/ }),\n\n/***/ \"./src/compat.js\":\n/*!***********************!*\\\n  !*** ./src/compat.js ***!\n  \\***********************/\n/*! exports provided: getGlobal, isBrowser, isNodeJS, isIE11, launchFullscreen, exitFullscreen, inFullscreen, fullscreenElement, isFullscreenAvailable, getAndroidVersion, isTouchDevice, isIOSDevice, isAndroidDevice, isMobileDevice, isSafari, isFirefox, isChrome, isMac, isWindows, ObjectAssign, disableDocumentTouchSafari, enableDocumentTouchSafari, touchStartToClick */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* WEBPACK VAR INJECTION */(function(global) {/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getGlobal\", function() { return getGlobal; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isBrowser\", function() { return isBrowser; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isNodeJS\", function() { return isNodeJS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isIE11\", function() { return isIE11; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"launchFullscreen\", function() { return launchFullscreen; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"exitFullscreen\", function() { return exitFullscreen; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"inFullscreen\", function() { return inFullscreen; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"fullscreenElement\", function() { return fullscreenElement; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isFullscreenAvailable\", function() { return isFullscreenAvailable; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getAndroidVersion\", function() { return getAndroidVersion; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isTouchDevice\", function() { return isTouchDevice; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isIOSDevice\", function() { return isIOSDevice; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isAndroidDevice\", function() { return isAndroidDevice; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isMobileDevice\", function() { return isMobileDevice; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isSafari\", function() { return isSafari; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isFirefox\", function() { return isFirefox; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isChrome\", function() { return isChrome; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isMac\", function() { return isMac; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isWindows\", function() { return isWindows; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ObjectAssign\", function() { return ObjectAssign; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"disableDocumentTouchSafari\", function() { return disableDocumentTouchSafari; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enableDocumentTouchSafari\", function() { return enableDocumentTouchSafari; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"touchStartToClick\", function() { return touchStartToClick; });\n\nfunction getGlobal() {\n  return typeof window !== \"undefined\" && window !== null ?\n  window :\n  typeof self !== \"undefined\" && self !== null ?\n  self :\n  global;\n}\n\nvar _window = getGlobal();\nvar _document = _window && _window.document;\n\nvar isBrowser = typeof navigator !== \"undefined\";\n\nvar isNodeJS = function isNodeJS() {\n  return !isBrowser;\n};\n\nvar isIE11 = isBrowser && !!navigator.userAgent.match(/Edge|Trident\\/7\\./);\n\n// fix IE events\nif (typeof window !== \"undefined\" && isIE11) {\n  (function () {\n    function CustomEvent(event, params) {\n      params = params || { bubbles: false, cancelable: false, detail: undefined };\n      var evt = _document.createEvent('CustomEvent');\n      evt.initCustomEvent(event, params.bubbles, params.cancelable, params.detail);\n      return evt;\n    }\n\n    CustomEvent.prototype = _window.CustomEvent.prototype;\n\n    _window.CustomEvent = CustomEvent;\n  })();\n}\n\n// IE does not implement ArrayBuffer slice. Handy!\nif (!ArrayBuffer.prototype.slice) {\n  ArrayBuffer.prototype.slice = function (start, end) {\n    // Normalize start/end values\n    if (!end || end > this.byteLength) {\n      end = this.byteLength;\n    } else\n    if (end < 0) {\n      end = this.byteLength + end;\n      if (end < 0) end = 0;\n    }\n    if (start < 0) {\n      start = this.byteLength + start;\n      if (start < 0) start = 0;\n    }\n\n    if (end <= start) {\n      return new ArrayBuffer();\n    }\n\n    // Bytewise copy- this will not be fast, but what choice do we have?\n    var len = end - start;\n    var view = new Uint8Array(this, start, len);\n    var out = new Uint8Array(len);\n    for (var i = 0; i < len; i++) {\n      out[i] = view[i];\n    }\n    return out.buffer;\n  };\n}\n\n// IE doesn't implement Math.log2\n(function () {\n  Math.log2 = Math.log2 || function (x) {\n    return Math.log(x) / Math.LN2;\n  };\n})();\n\n//The BlobBuilder object\nif (typeof window !== \"undefined\")\n_window.BlobBuilder = _window.BlobBuilder || _window.WebKitBlobBuilder || _window.MozBlobBuilder || _window.MSBlobBuilder;\n\n\n// Launch full screen on the given element with the available method\nfunction launchFullscreen(element, options) {\n  if (element.requestFullscreen) {\n    element.requestFullscreen(options);\n  } else if (element.mozRequestFullScreen) {\n    element.mozRequestFullScreen(options);\n  } else if (element.webkitRequestFullscreen) {\n    element.webkitRequestFullscreen(options);\n  } else if (element.msRequestFullscreen) {\n    element.msRequestFullscreen(options);\n  }\n};\n\n// Exit full screen with the available method\nfunction exitFullscreen(_document) {\n  if (!inFullscreen(_document)) {\n    return;\n  }\n  if (_document.exitFullscreen) {\n    _document.exitFullscreen();\n  } else if (_document.mozCancelFullScreen) {\n    _document.mozCancelFullScreen();\n  } else if (_document.webkitExitFullscreen) {\n    _document.webkitExitFullscreen();\n  } else if (_document.msExitFullscreen) {\n    _document.msExitFullscreen();\n  }\n};\n\n// Determines if the browser is in full screen\nfunction inFullscreen(_document) {\n\n  // Special case for Ms-Edge that has webkitIsFullScreen with correct value\n  // and fullscreenEnabled with wrong value (thanks MS)\n\n  if (\"webkitIsFullScreen\" in _document) return !!_document.webkitIsFullScreen;\n  if (\"fullscreenElement\" in _document) return !!_document.fullscreenElement;\n  if (\"mozFullScreenElement\" in _document) return !!_document.mozFullScreenElement;\n  if (\"msFullscreenElement\" in _document) return !!_document.msFullscreenElement;\n\n  return !!_document.querySelector(\".viewer-fill-browser\"); // Fallback for iPad\n};\n\nfunction fullscreenElement(_document) {\n  return _document.fullscreenElement || _document.mozFullScreenElement || _document.webkitFullscreenElement || _document.msFullscreenElement;\n};\n\nfunction isFullscreenAvailable(element) {\n  return element.requestFullscreen || element.mozRequestFullScreen || element.webkitRequestFullscreen || element.msRequestFullscreen;\n};\n\n// Get the version of the android device through user agent.\n// Return the version string of android device, e.g. 4.4, 5.0...\nfunction getAndroidVersion(ua) {\n  ua = ua || navigator.userAgent;\n  var match = ua.match(/Android\\s([0-9\\.]*)/);\n  return match ? match[1] : false;\n};\n\n// Determine if this is a touch or notouch device.\nfunction isTouchDevice() {\n  /*\n                                 // Temporarily disable touch support through hammer on Android 5, to debug\n                                 // some specific gesture issue with Chromium WebView when loading viewer3D.js.\n                                 if (parseInt(getAndroidVersion()) == 5) {\n                                     return false;\n                                 }\n                                 */\n\n  return typeof window !== 'undefined' && ('ontouchstart' in window || navigator.maxTouchPoints > 0);\n};\n\n// Since iOS 13, the iPad identifies itself as a desktop, so the only way to reliably detect is to search for multitouch capabilities\n// (insofar as no other Apple device implements it)\nvar _isIOSDevice = isBrowser && (/ip(ad|hone|od)/.test(navigator.userAgent.toLowerCase()) || navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);\nfunction isIOSDevice() {\n  return _isIOSDevice;\n}\n\nvar _isAndroidDevice = isBrowser && navigator.userAgent.toLowerCase().indexOf('android') !== -1;\nfunction isAndroidDevice() {\n  return _isAndroidDevice;\n}\n\nfunction isMobileDevice() {\n  if (!isBrowser) return false;\n  return isIOSDevice() || isAndroidDevice();\n};\n\nfunction isSafari() {\n  if (!isBrowser) return false;\n  var _ua = navigator.userAgent.toLowerCase();\n  return _ua.indexOf(\"safari\") !== -1 && _ua.indexOf(\"chrome\") === -1;\n};\n\nfunction isFirefox() {\n  if (!isBrowser) return false;\n  var _ua = navigator.userAgent.toLowerCase();\n  return _ua.indexOf(\"firefox\") !== -1;\n};\n\nfunction isChrome() {\n  if (!isBrowser) return false;\n  var _ua = navigator.userAgent.toLowerCase();\n  return _ua.indexOf(\"chrome\") !== -1;\n};\n\nfunction isMac() {\n  if (!isBrowser) return false;\n  var _ua = navigator.userAgent.toLowerCase();\n  return _ua.indexOf(\"mac os\") !== -1;\n};\n\nfunction isWindows() {\n  if (!isBrowser) return false;\n  var _ua = navigator.userAgent.toLowerCase();\n  return _ua.indexOf(\"win32\") !== -1 || _ua.indexOf(\"windows\") !== -1;\n};\n\nfunction ObjectAssign(des, src) {\n  for (var key in src) {\n    if (src.hasOwnProperty(key))\n    des[key] = src[key];\n  }\n  return des;\n};\n\n\n// Hack to work around Safari's use of pinch and pan inside the viewer canvas.\nfunction disableTouchSafari(event) {\n  var xOff = _window.hasOwnProperty(\"pageXOffset\") ? _window.pageXOffset : _document.documentElement.scrollLeft;\n  var yOff = _window.hasOwnProperty(\"pageYOffset\") ? _window.pageYOffset : _document.documentElement.scrollTop;\n\n  // event.pageX and event.pageY returned undefined through Chrome console device mode\n  var pageX = typeof event.pageX === \"undefined\" ? event.changedTouches[0].pageX : event.pageX;\n  var pageY = typeof event.pageY === \"undefined\" ? event.changedTouches[0].pageY : event.pageY;\n\n  // If we aren't inside the canvas, then allow default propagation of the event\n  var element = _document.elementFromPoint(pageX - xOff, pageY - yOff);\n  if (!element || element.nodeName !== 'CANVAS')\n  return true;\n  // If it's a CANVAS, check that it's owned by us\n  if (element.getAttribute('data-viewer-canvas' !== 'true'))\n  return true;\n  // Inside the canvas, prevent the event from propagating to Safari'safely\n  // standard handlers, which will pan and zoom the page.\n  event.preventDefault();\n  return false;\n};\n\n// Hack to work around Safari's use of pinch and pan inside the viewer canvas.\nfunction disableDocumentTouchSafari() {\n  if (isMobileDevice() && isSafari()) {\n    // Safari mobile disable default touch handling inside viewer canvas\n    // Use capture to make sure Safari doesn't capture the touches and prevent\n    // us from disabling them.\n    _document.documentElement.addEventListener('touchstart', disableTouchSafari, true);\n    _document.documentElement.addEventListener('touchmove', disableTouchSafari, true);\n    _document.documentElement.addEventListener('touchcanceled', disableTouchSafari, true);\n    _document.documentElement.addEventListener('touchend', disableTouchSafari, true);\n  }\n};\n\n// Hack to work around Safari's use of pinch and pan inside the viewer canvas.\n// This method is not being invoked explicitly.\nfunction enableDocumentTouchSafari() {\n  if (isMobileDevice() && isSafari()) {\n    // Safari mobile disable default touch handling inside viewer canvas\n    // Use capture to make sure Safari doesn't capture the touches and prevent\n    // us from disabling them.\n    _document.documentElement.removeEventListener('touchstart', disableTouchSafari, true);\n    _document.documentElement.removeEventListener('touchmove', disableTouchSafari, true);\n    _document.documentElement.removeEventListener('touchcanceled', disableTouchSafari, true);\n    _document.documentElement.removeEventListener('touchend', disableTouchSafari, true);\n  }\n};\n\n\n// Convert touchstart event to click to remove the delay between the touch and\n// the click event which is sent after touchstart with about 300ms deley.\n// Should be used in UI elements on touch devices.\nfunction touchStartToClick(e) {\n  // Buttons that activate fullscreen are a special case. The HTML5 fullscreen spec\n  // requires the original user gesture signal to avoid a security issue.  See LMV-2396 and LMV-2326\n  if (e.target.className.indexOf(\"fullscreen\") > -1 || e.target.className.indexOf(\"webvr\") > -1)\n  return;\n  e.preventDefault(); // Stops the firing of delayed click event.\n  e.stopPropagation();\n  e.target.click(); // Maps to immediate click.\n};\n\n//Safari doesn't have the Performance object\n//We only need the now() function, so that's easy to emulate.\n(function () {\n  var global = getGlobal();\n  if (!global.performance)\n  global.performance = Date;\n})();\n\n// Polyfill for IE and Safari\n// https://developer.mozilla.org/de/docs/Web/JavaScript/Reference/Global_Objects/Number/isInteger\nNumber.isInteger = Number.isInteger || function (value) {\n  return typeof value === \"number\" &&\n  isFinite(value) &&\n  Math.floor(value) === value;\n};\n\n// Polyfill for IE\nString.prototype.repeat = String.prototype.repeat || function (count) {\n  if (count < 1) return '';\n  var result = '',pattern = this.valueOf();\n  while (count > 1) {\n    if (count & 1) result += pattern;\n    count >>= 1, pattern += pattern;\n  }\n  return result + pattern;\n};\n\n// Polyfill for IE\n// It doesn't support negative values for start and end; it complicates the code using this function.\nif (!Array.prototype.fill) {\n  Object.defineProperty(Array.prototype, \"fill\", {\n    enumerable: false,\n    value: function value(_value, start, end) {\n      start = start === undefined ? 0 : start;\n      end = end === undefined ? this.length : end;\n      for (var i = start; i < end; ++i) {\n        this[i] = _value;}\n    } });\n\n}\n// Polyfill for IE\nInt32Array.prototype.lastIndexOf = Int32Array.prototype.lastIndexOf || function (searchElement, fromIndex) {\n  return Array.prototype.lastIndexOf.call(this, searchElement, fromIndex);\n};\n\n// Polyfill for IE\n// It doesn't support negative values for start and end; it complicates the code using this function.\nif (!Array.prototype.find) {\n  Object.defineProperty(Array.prototype, \"find\", {\n    enumerable: false,\n    value: function value(callback, _this) {\n      var len = this.length;\n      for (var i = 0; i < len; ++i) {\n        var item = this[i];\n        if (callback.call(_this, item, i, this))\n        return item;\n      }\n      return undefined;\n    } });\n\n}\n\n// Polyfill for IE\nif (typeof Object.assign != 'function') {\n  // Must be writable: true, enumerable: false, configurable: true\n  Object.defineProperty(Object, \"assign\", {\n    value: function assign(target, varArgs) {// .length of function is 2\n      'use strict';\n      if (target == null) {// TypeError if undefined or null\n        throw new TypeError('Cannot convert undefined or null to object');\n      }\n\n      var to = Object(target);\n\n      for (var index = 1; index < arguments.length; index++) {\n        var nextSource = arguments[index];\n\n        if (nextSource != null) {// Skip over if undefined or null\n          for (var nextKey in nextSource) {\n            // Avoid bugs when hasOwnProperty is shadowed\n            if (Object.prototype.hasOwnProperty.call(nextSource, nextKey)) {\n              to[nextKey] = nextSource[nextKey];\n            }\n          }\n        }\n      }\n      return to;\n    },\n    writable: true,\n    configurable: true });\n\n}\n\n// Polyfill for IE and iOS devices\nif (typeof window !== \"undefined\" && (isIE11 || isIOSDevice()) && !HTMLCanvasElement.prototype.toBlob) {\n  Object.defineProperty(HTMLCanvasElement.prototype, 'toBlob', {\n    value: function value(callback, type, quality) {\n      var canvas = this;\n      setTimeout(function () {\n\n        var binStr = atob(canvas.toDataURL(type, quality).split(',')[1]),\n        len = binStr.length,\n        arr = new Uint8Array(len);\n\n        for (var i = 0; i < len; i++) {\n          arr[i] = binStr.charCodeAt(i);\n        }\n\n        callback(new Blob([arr], { type: type || 'image/png' }));\n\n      });\n    } });\n\n}\n\n// Polyfill for IE (LMV-3823)\nif (!Uint8Array.prototype.slice) {\n\n  // This will work for genuine arrays, array-like objects, \n  // NamedNodeMap (attributes, entities, notations),\n  // NodeList (e.g., getElementsByTagName), HTMLCollection (e.g., childNodes),\n  // and will not fail on other DOM objects (as do DOM elements in IE < 9)\n  Uint8Array.prototype.slice = function (begin, end) {\n    // IE < 9 gets unhappy with an undefined end argument\n    end = typeof end !== 'undefined' ? end : this.length;\n\n    // For native Array objects, we use the native slice function\n    if (Object.prototype.toString.call(this) === '[object Array]') {\n      return _slice.call(this, begin, end);\n    }\n\n    // For array like object we handle it ourselves.\n    var i,cloned = [],\n    size,len = this.length;\n\n    // Handle negative value for \"begin\"\n    var start = begin || 0;\n    start = start >= 0 ? start : Math.max(0, len + start);\n\n    // Handle negative value for \"end\"\n    var upTo = typeof end == 'number' ? Math.min(end, len) : len;\n    if (end < 0) {\n      upTo = len + end;\n    }\n\n    // Actual expected size of the slice\n    size = upTo - start;\n\n    if (size > 0) {\n      cloned = new Array(size);\n      if (this.charAt) {\n        for (i = 0; i < size; i++) {\n          cloned[i] = this.charAt(start + i);\n        }\n      } else {\n        for (i = 0; i < size; i++) {\n          cloned[i] = this[start + i];\n        }\n      }\n    }\n\n    return cloned;\n  };\n}\n/* WEBPACK VAR INJECTION */}.call(this, __webpack_require__(/*! ./../node_modules/webpack/buildin/global.js */ \"./node_modules/webpack/buildin/global.js\")))\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/common/InputStream.js\":\n/*!******************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/common/InputStream.js ***!\n  \\******************************************************/\n/*! exports provided: InputStream */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"InputStream\", function() { return InputStream; });\n/* harmony import */ var _StringUtils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./StringUtils */ \"./src/file-loaders/lmvtk/common/StringUtils.js\");\n\n\n\"use strict\";\n\n//We will use these shared memory arrays to\n//convert from bytes to the desired data type.\nvar convBuf = new ArrayBuffer(8);\nvar convUint8 = new Uint8Array(convBuf);\nvar convUint16 = new Uint16Array(convBuf);\nvar convInt32 = new Int32Array(convBuf);\nvar convUint32 = new Uint32Array(convBuf);\nvar convFloat32 = new Float32Array(convBuf);\nvar convFloat64 = new Float64Array(convBuf);\n\n\n/** @constructor */\nfunction InputStream(buf) {\n  this.buffer = buf;\n  this.offset = 0;\n  this.byteLength = buf.length;\n}\n\n\nInputStream.prototype.seek = function (off) {\n  this.offset = off;\n};\n\nInputStream.prototype.getBytes = function (len) {\n  var ret = new Uint8Array(this.buffer.buffer, this.offset, len);\n  this.offset += len;\n  return ret;\n};\n\nInputStream.prototype.getVarints = function () {\n  var b;\n  var value = 0;\n  var shiftBy = 0;\n  do {\n    b = this.buffer[this.offset++];\n    value |= (b & 0x7f) << shiftBy;\n    shiftBy += 7;\n  } while (b & 0x80);\n  return value;\n};\n\nInputStream.prototype.getUint8 = function () {\n  return this.buffer[this.offset++];\n};\n\nInputStream.prototype.getUint16 = function () {\n  convUint8[0] = this.buffer[this.offset++];\n  convUint8[1] = this.buffer[this.offset++];\n  return convUint16[0];\n};\n\nInputStream.prototype.getInt16 = function () {\n  var tmp = this.getUint16();\n  //make negative integer if the ushort is negative\n  if (tmp > 0x7fff)\n  tmp = tmp | 0xffff0000;\n  return tmp;\n};\n\nInputStream.prototype.getInt32 = function () {\n  var src = this.buffer;\n  var dst = convUint8;\n  var off = this.offset;\n  dst[0] = src[off];\n  dst[1] = src[off + 1];\n  dst[2] = src[off + 2];\n  dst[3] = src[off + 3];\n  this.offset += 4;\n  return convInt32[0];\n};\n\nInputStream.prototype.getUint32 = function () {\n  var src = this.buffer;\n  var dst = convUint8;\n  var off = this.offset;\n  dst[0] = src[off];\n  dst[1] = src[off + 1];\n  dst[2] = src[off + 2];\n  dst[3] = src[off + 3];\n  this.offset += 4;\n  return convUint32[0];\n};\n\nInputStream.prototype.getFloat32 = function () {\n  var src = this.buffer;\n  var dst = convUint8;\n  var off = this.offset;\n  dst[0] = src[off];\n  dst[1] = src[off + 1];\n  dst[2] = src[off + 2];\n  dst[3] = src[off + 3];\n  this.offset += 4;\n  return convFloat32[0];\n};\n\n//Specialized copy which copies 4 byte integers into 2-byte target.\n//Used for downcasting OCTM int32 index buffers to int16 index buffers,\n//in cases we know we don't need more (LMVTK guarantees 2 byte indices).\nInputStream.prototype.getIndicesArray = function (buffer, offset, numItems) {\n\n  var src = this.buffer;\n  var dst = new Uint8Array(buffer, offset, numItems * 2);\n  var off = this.offset;\n\n  for (var i = 0, iEnd = numItems * 2; i < iEnd; i += 2) {\n    dst[i] = src[off];\n    dst[i + 1] = src[off + 1];\n    off += 4;\n  }\n\n  this.offset = off;\n};\n\nInputStream.prototype.getVector3Array = function (arr, numItems, startOffset, stride) {\n  var src = this.buffer;\n  var off = this.offset;\n\n  //We cannot use Float32Array copying here because the\n  //source stream is out of alignment\n  var dst = new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\n\n  if (stride === 3 && startOffset === 0) {\n    var len = numItems * 12;\n    dst.set(src.subarray(off, off + len));\n    this.offset += len;\n  } else {\n\n    stride *= 4;\n    var aoff = startOffset * 4;\n    for (var i = 0; i < numItems; i++) {\n      for (var j = 0; j < 12; j++) {\n        dst[aoff + j] = src[off++];\n      }\n      aoff += stride;\n    }\n\n    this.offset = off;\n  }\n};\n\nInputStream.prototype.getVector2Array = function (arr, numItems, startOffset, stride) {\n  var src = this.buffer;\n  var dst = new Uint8Array(arr.buffer, arr.byteOffset, arr.byteLength);\n  var off = this.offset;\n\n  stride *= 4;\n  var aoff = startOffset * 4;\n  for (var i = 0; i < numItems; i++) {\n    for (var j = 0; j < 8; j++) {\n      dst[aoff + j] = src[off++];\n    }\n    aoff += stride;\n  }\n\n  this.offset = off;\n};\n\nInputStream.prototype.getVector4 = function (arr, offset) {\n  var src = this.buffer;\n  var dst = convUint8;\n  var off = this.offset;\n  var conv = convFloat32;\n\n  for (var j = 0; j < 4; j++) {\n    dst[0] = src[off];\n    dst[1] = src[off + 1];\n    dst[2] = src[off + 2];\n    dst[3] = src[off + 3];\n    arr[offset + j] = conv[0];\n    off += 4;\n  }\n\n  this.offset = off;\n};\n\nInputStream.prototype.getFloat64 = function () {\n  var src = this.buffer;\n  var dst = convUint8;\n  var off = this.offset;\n  for (var i = 0; i < 8; i++) {\n    dst[i] = src[off + i];}\n  this.offset += 8;\n  return convFloat64[0];\n};\n\n\n\nInputStream.prototype.getString = function (len) {\n  var res = Object(_StringUtils__WEBPACK_IMPORTED_MODULE_0__[\"utf8ArrayToString\"])(this.buffer, this.offset, len);\n  this.offset += len;\n  return res;\n};\n\nInputStream.prototype.reset = function (buf) {\n  this.buffer = buf;\n  this.offset = 0;\n  this.byteLength = buf.length;\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/common/StringUtils.js\":\n/*!******************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/common/StringUtils.js ***!\n  \\******************************************************/\n/*! exports provided: utf8BlobToStr, safeUtf8BlobToStr, utf16to8, utf8ArrayToString, blobToJson, subBlobToJson, subBlobToJsonInt, parseIntArray, findValueOffsets */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"utf8BlobToStr\", function() { return utf8BlobToStr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"safeUtf8BlobToStr\", function() { return safeUtf8BlobToStr; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"utf16to8\", function() { return utf16to8; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"utf8ArrayToString\", function() { return utf8ArrayToString; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"blobToJson\", function() { return blobToJson; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"subBlobToJson\", function() { return subBlobToJson; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"subBlobToJsonInt\", function() { return subBlobToJsonInt; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"parseIntArray\", function() { return parseIntArray; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"findValueOffsets\", function() { return findValueOffsets; });\n\n\n// http://www.onicos.com/staff/iz/amuse/javascript/expert/utf.txt\n/* utf.js - UTF-8 <=> UTF-16 convertion\n *\n * Copyright (C) 1999 Masanao Izumo <iz@onicos.co.jp>\n * Version: 1.0\n * LastModified: Dec 25 1999\n * This library is free.  You can redistribute it and/or modify it.\n */\nfunction utf8BlobToStr(array, start, length) {\n  var out, i, len, c;\n  var char2, char3;\n\n  out = '';\n  len = length;\n  i = 0;\n  while (i < len) {\n    c = array[start + i++];\n    switch (c >> 4) {\n\n      case 0:case 1:case 2:case 3:case 4:case 5:case 6:case 7:\n        // 0xxxxxxx\n        out += String.fromCharCode(c);\n        break;\n      case 12:case 13:\n        // 110x xxxx   10xx xxxx\n        char2 = array[start + i++];\n        out += String.fromCharCode((c & 0x1F) << 6 | char2 & 0x3F);\n        break;\n      case 14:\n        // 1110 xxxx  10xx xxxx  10xx xxxx\n        char2 = array[start + i++];\n        char3 = array[start + i++];\n        out += String.fromCharCode((c & 0x0F) << 12 |\n        (char2 & 0x3F) << 6 |\n        (char3 & 0x3F) << 0);\n        break;}\n\n  }\n\n  return out;\n}\n\n/**\n   * Safe version of utf8BlobToStr(), where Arrays are used to concatenate chars via join().\n   * This function exists because string::operator += crashes on Chrome with large inputs.\n   */\nfunction safeUtf8BlobToStr(array, start, length) {\n  var out, i, len, c, outArray, count;\n  var char2, char3;\n\n  var STR_CVT_LIMIT = 32 * 1024;\n  out = '';\n  outArray = [];\n  len = length;\n  count = 0;\n  i = 0;\n  while (i < len) {\n    c = array[start + i++];\n    switch (c >> 4) {\n\n      case 0:case 1:case 2:case 3:case 4:case 5:case 6:case 7:\n        // 0xxxxxxx\n        outArray.push(String.fromCharCode(c));\n        break;\n      case 12:case 13:\n        // 110x xxxx   10xx xxxx\n        char2 = array[start + i++];\n        outArray.push(String.fromCharCode((c & 0x1F) << 6 | char2 & 0x3F));\n        break;\n      case 14:\n        // 1110 xxxx  10xx xxxx  10xx xxxx\n        char2 = array[start + i++];\n        char3 = array[start + i++];\n        outArray.push(String.fromCharCode((c & 0x0F) << 12 |\n        (char2 & 0x3F) << 6 |\n        (char3 & 0x3F) << 0));\n        break;}\n\n    if (++count >= STR_CVT_LIMIT || i >= len) {\n      out += outArray.join(\"\");\n      outArray.length = 0;\n      count = 0;\n    }\n  }\n\n  return out;\n}\n\n\nfunction utf16to8(str, array, start) {\n  var i, len, c;\n\n  var j = start || 0;\n  len = str.length;\n\n  if (array) {\n    for (i = 0; i < len; i++) {\n      c = str.charCodeAt(i);\n      if (c >= 0x0001 && c <= 0x007F) {\n        array[j++] = c;\n      } else if (c > 0x07FF) {\n        array[j++] = 0xE0 | c >> 12 & 0x0F;\n        array[j++] = 0x80 | c >> 6 & 0x3F;\n        array[j++] = 0x80 | c >> 0 & 0x3F;\n      } else {\n        array[j++] = 0xC0 | c >> 6 & 0x1F;\n        array[j++] = 0x80 | c >> 0 & 0x3F;\n      }\n    }\n  } else {\n    //If no output buffer is passed in, estimate the required\n    //buffer size and return that.\n    for (i = 0; i < len; i++) {\n      c = str.charCodeAt(i);\n      if (c >= 0x0001 && c <= 0x007F) {\n        j++;\n      } else if (c > 0x07FF) {\n        j += 3;\n      } else {\n        j += 2;\n      }\n    }\n  }\n\n  return j - (start || 0);\n}\n\n\nvar USE_MANUAL_UTF8 = true;\nvar SAFE_UTF_LENGTH = 1024 * 1024;\n\nfunction utf8ArrayToString(array, start, length) {\n\n  if (start === undefined)\n  start = 0;\n  if (length === undefined)\n  length = array.length;\n\n  if (USE_MANUAL_UTF8) {\n    if (length > SAFE_UTF_LENGTH) {\n      return safeUtf8BlobToStr(array, start, length);\n    }\n    return utf8BlobToStr(array, start, length);\n  } else {\n    var encodedString = \"\";\n    for (var i = start, iEnd = start + length; i < iEnd; i++) {\n      encodedString += String.fromCharCode(array[i]);}\n\n    return decodeURIComponent(escape(encodedString));\n  }\n};\n\nfunction blobToJson(blob) {\n\n  var decodedString = utf8ArrayToString(blob, 0, blob.length);\n\n  return JSON.parse(decodedString);\n};\n\n//parses a piece of json from a given blob (representing an array of json values)\n//up to the next comma+newline combo (i.e. array delimiter).\nfunction subBlobToJson(blob, startIndex) {\n  if (startIndex === undefined) {\n    return '';\n  }\n\n  var i = startIndex;\n\n  while (i < blob.length - 1) {\n    var c = blob[i];\n    if (c == 44 && (blob[i + 1] == 10 || blob[i + 1] == 13)) //comma followed by newline?\n      break;\n    if (c == 10 || c == 13) //detect newline or line feed\n      break;\n    i++;\n  }\n\n  var decodedString = utf8ArrayToString(blob, startIndex, i - startIndex);\n  try {\n    return JSON.parse(decodedString);\n  } catch (e) {\n    console.error(\"Error parsing property blob to JSON : \" + decodedString);\n    return decodedString;\n  }\n};\n\nfunction subBlobToJsonInt(blob, startIndex) {\n  var val = 0;\n  var i = startIndex;\n\n  //Check for integers that were serialized as strings.\n  //This should not happen, ever, but hey, it does.\n  if (blob[i] == 34)\n  i++;\n\n  while (i < blob.length - 1) {\n    var c = blob[i];\n    if (c == 44 && (blob[i + 1] == 10 || blob[i + 1] == 13))\n    break;\n    if (c == 10 || c == 13 || c == 34)\n    break;\n    if (c >= 48 && c <= 57)\n    val = val * 10 + (c - 48);\n\n    i++;\n  }\n\n  return val;\n};\n\n//Simple integer array parse -- expects the array in property database\n//format, where the array is packed with possibly newline separator,\n//but no other white space. Does not do extensive error checking\nfunction parseIntArray(blob, wantSentinel) {\n\n  //find out how many items we have\n  var count = 0;\n  for (var i = 0, iEnd = blob.length; i < iEnd; i++) {\n    if (blob[i] == 44) //44 = ','\n      count++;}\n\n  count++; //last item has no comma after it\n\n  var items = new Uint32Array(count + (wantSentinel ? 1 : 0));\n\n  i = 0;\n  var end = blob.length;\n\n  while (blob[i] != 91 && i < end) {//91 = '['\n    i++;}\n\n  if (i == blob.length)\n  return null;\n\n  i++;\n\n  var seenDigit = false;\n  count = 0;\n  var curInt = 0;\n  while (i < end) {\n    var c = blob[i];\n    if (c >= 48 && c <= 57) {//digit\n      curInt = 10 * curInt + (c - 48);\n      seenDigit = true;\n    } else\n    if (c == 44 || c == 93) {//',' or ']'\n      if (seenDigit) {\n        items[count++] = curInt;\n        seenDigit = false;\n        curInt = 0;\n      }\n    } else {\n      seenDigit = false; //most likely a newline (the only other thing we have in our arrays\n      curInt = 0;\n    }\n    i++;\n  }\n\n  return items;\n};\n\n//Scans an array of json values (strings, integers, doubles) and finds the\n//offset of each value in the array, so that we can later pick off that\n//specific value, without parsing the whole (potentially huge) json array up front.\n//This expects the input blob to be in the form serialized by the property database\n//C++ component -- one value per line. A more sophisticated parser would be needed\n//in case the format changes and this assumption is not true anymore.\nfunction findValueOffsets(blob) {\n\n  //first, count how many items we have\n  var count = 0;\n  var end = blob.length - 1;\n\n  for (var i = 0; i < end; i++) {\n    if (blob[i] == 44 && (blob[i + 1] == 10 || blob[i + 1] == 13)) // ',' + newline is the item delimiter\n      count++;\n  }\n\n  if (!count)\n  return null;\n\n  count++; //one for the last item\n\n  var items = new Uint32Array(count);\n\n  i = 0;\n  count = 0;\n\n  //find opening [\n  while (blob[i] != 91 && i < end) {//91 = '['\n    i++;}\n\n  i++;\n\n  items[count++] = i;\n  var seenEol = false;\n  while (i < end) {\n    if (blob[i] == 10 || blob[i] == 13)\n    seenEol = true;else\n    if (seenEol) {\n      seenEol = false;\n      items[count++] = i;\n    }\n\n    i++;\n  }\n\n  return items;\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/common/SvfPlacementUtils.js\":\n/*!************************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/common/SvfPlacementUtils.js ***!\n  \\************************************************************/\n/*! exports provided: derivePlacementTransform, calculatePlacementWithOffset, initPlacement, transformAnimations */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"derivePlacementTransform\", function() { return derivePlacementTransform; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"calculatePlacementWithOffset\", function() { return calculatePlacementWithOffset; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"initPlacement\", function() { return initPlacement; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"transformAnimations\", function() { return transformAnimations; });\n/* harmony import */ var _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../wgs/scene/LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/* harmony import */ var _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../wgs/scene/LmvBox3 */ \"./src/wgs/scene/LmvBox3.js\");\n/* harmony import */ var _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../wgs/scene/LmvMatrix4 */ \"./src/wgs/scene/LmvMatrix4.js\");\nfunction _typeof(obj) {if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {_typeof = function _typeof(obj) {return typeof obj;};} else {_typeof = function _typeof(obj) {return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;};}return _typeof(obj);}\n\n\n\n\nfunction getUnitScale(unit) {\n  //Why are translators not using standard strings for those?!?!?!?\n  switch (unit) {\n    case 'meter':\n    case 'meters':\n    case 'm':return 1.0;\n    case 'feet and inches':\n    case 'foot':\n    case 'feet':\n    case 'ft':return 0.3048;\n    case 'inch':\n    case 'inches':\n    case 'in':return 0.0254;\n    case 'centimeter':\n    case 'centimeters':\n    case 'cm':return 0.01;\n    case 'millimeter':\n    case 'millimeters':\n    case 'mm':return 0.001;\n    default:return 1.0;}\n\n}\n\n\nfunction isIdentity(mtx) {\n  var e = mtx.elements;\n  for (var i = 0; i < 4; i++) {\n    for (var j = 0; j < 4; j++) {\n      if (i === j) {\n        if (e[i * 4 + j] !== 1)\n        return false;\n      } else {\n        if (e[i * 4 + j] !== 0)\n        return false;\n      }\n    }\n  }\n\n  return true;\n}\n\n\nfunction derivePlacementTransform(svf, loadContext) {\n\n  // We now will apply overall model transforms, following the following logic:\n  //    1) placementTransform = options.placementTransform);\n  //    2) placementTransform = placementTransform.multiply(scalingTransform);\n  //    3) placementTransform = placementTransform.multiply(refPointTransform);\n  // This is for aggregation scenarios, where multiple models are loaded into the scene\n  // In such scenarios the client will most probably manually override the model units\n\n\n  //First, take the input placement transform as is (could be null).\n  svf.placementTransform = loadContext.placementTransform;\n\n  // If requested in the load options, apply scaling from optional 'from' to 'to' units.\n  // If unpecified, then units will be read from the models metadata.\n  // * usage overloads\n  //      options.appyScaling: { from: 'ft', to: 'm' }\n  //      options.appyScaling: 'm'   ( equivalent to { to: 'm' })\n  // * this is aimed at multiple 3D model situations where models potentialy have different units, but\n  //   one  doesn't up-front know what these units are.It also allows overriding of such units.\n  // * Model methods: getUnitString , getUnitScale &  getDisplayUnit will be automatically return corrected values\n  //   as long as there are no additional options.placementTransform scalings applied.\n  if (loadContext.applyScaling) {\n\n    // default 'from' & 'to'  units are from metadata, or 'm' not present\n    var scalingFromUnit = 'm';\n    if (svf.metadata[\"distance unit\"]) {\n      scalingFromUnit = svf.metadata[\"distance unit\"][\"value\"];\n    }\n    svf.scalingUnit = scalingFromUnit;\n\n    if ('object' === _typeof(loadContext.applyScaling)) {\n      if (loadContext.applyScaling.from) {\n        scalingFromUnit = loadContext.applyScaling.from;\n      }\n      if (loadContext.applyScaling.to) {\n        svf.scalingUnit = loadContext.applyScaling.to;\n      }\n    } else {\n      svf.scalingUnit = loadContext.applyScaling;\n    }\n\n\n    // Work out overall desired scaling factor.\n    var scalingFactor = getUnitScale(scalingFromUnit) / getUnitScale(svf.scalingUnit);\n\n    if (1 != scalingFactor) {\n\n      var placementS = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n\n      var scalingTransform = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n      scalingTransform.elements[0] = scalingFactor;\n      scalingTransform.elements[5] = scalingFactor;\n      scalingTransform.elements[10] = scalingFactor;\n\n      if (loadContext.placementTransform) {\n        // There may well already be a placementTransform from previous options/operations.\n        placementS.copy(loadContext.placementTransform);\n\n      }\n\n      svf.placementTransform = loadContext.placementTransform = placementS.multiply(scalingTransform);\n    }\n  }\n\n\n  var custom_values = svf.metadata[\"custom values\"];\n\n  if (custom_values && custom_values.refPointTransform) {\n\n    svf.refPointTransform = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n    var e = svf.refPointTransform.elements;\n    var src = custom_values.refPointTransform;\n\n    e[0] = src[0];\n    e[1] = src[1];\n    e[2] = src[2];\n\n    e[4] = src[3];\n    e[5] = src[4];\n    e[6] = src[5];\n\n    e[8] = src[6];\n    e[9] = src[7];\n    e[10] = src[8];\n\n    e[12] = src[9];\n    e[13] = src[10];\n    e[14] = src[11];\n\n  } else {\n    //Is there an extra offset specified in the georeference?\n    //This is important when aggregating Revit models from the same Revit\n    //project into the same scene, because Revit SVFs use RVT internal coordinates, which\n    //need extra offset to get into the world space.\n    var georeference = svf.metadata[\"georeference\"];\n    var refPointLMV = georeference && georeference[\"refPointLMV\"];\n\n    var angle = 0;\n    if (custom_values && custom_values.hasOwnProperty(\"angleToTrueNorth\")) {\n      angle = Math.PI / 180.0 * custom_values[\"angleToTrueNorth\"];\n    }\n\n    if (refPointLMV || angle) {\n\n      var rotation = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n      var m = rotation.elements;\n      m[0] = m[5] = Math.cos(angle);\n      m[1] = -Math.sin(angle);\n      m[4] = Math.sin(angle);\n\n      //refPointLMV is given in model local coordinates, hence the negation needed\n      //to make the translation go from local to shared coordinates.\n      var offset = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n      m = offset.elements;\n      if (refPointLMV) {\n        m[12] = -refPointLMV[0];\n        m[13] = -refPointLMV[1];\n        m[14] = -refPointLMV[2];\n      }\n\n      //Compose the rotation and offset.\n      svf.refPointTransform = rotation.multiply(offset);\n    }\n  }\n\n  //If request in the load options, apply the reference point transform when loading the model\n  if (loadContext.applyRefPoint && svf.refPointTransform) {\n\n    var placement = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n\n    //Normally we expect the input placement transform to come in as identity in case\n    //we have it specified in the georef here, but, whatever, let's be thorough for once.\n    if (loadContext.placementTransform)\n    placement.copy(loadContext.placementTransform);\n\n    placement.multiply(svf.refPointTransform);\n\n    svf.placementTransform = loadContext.placementTransform = placement;\n\n  } else if (!loadContext.applyRefPoint && loadContext.placementTransform) {\n\n    //In case we are given a placement transform that overrides the icoming refPointTransform\n\n    svf.placementTransform = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true).copy(loadContext.placementTransform);\n\n  }\n\n  if (svf.placementTransform && isIdentity(svf.placementTransform))\n  svf.placementTransform = null;\n\n  return svf.placementTransform;\n}\n\nfunction calculatePlacementWithOffset(svf, pt) {\n  var go = svf.globalOffset;\n  if (go.x || go.y || go.z) {\n    if (!pt) {\n      pt = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n      pt.makeTranslation(-go.x, -go.y, -go.z);\n    } else {\n      var pt2 = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"](true);\n      pt2.copy(pt);\n      pt = pt2;\n      pt.elements[12] -= go.x;\n      pt.elements[13] -= go.y;\n      pt.elements[14] -= go.z;\n    }\n\n    svf.placementWithOffset = pt;\n  } else {\n    svf.placementWithOffset = pt;\n  }\n}\n\nfunction initPlacement(svf, loadContext) {\n\n  if (!svf.metadata)\n  return;\n\n  //Retrieve world bounding box\n  var bbox = svf.metadata[\"world bounding box\"];\n  var min = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](bbox.minXYZ[0], bbox.minXYZ[1], bbox.minXYZ[2]);\n  var max = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](bbox.maxXYZ[0], bbox.maxXYZ[1], bbox.maxXYZ[2]);\n  svf.bbox = new _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_1__[\"LmvBox3\"](min, max);\n\n  var pt = derivePlacementTransform(svf, loadContext);\n  if (pt && !svf.bbox.empty()) {\n    svf.bbox.applyMatrix4(pt);\n  }\n\n  //Global offset is used to avoid floating point precision issues for models\n  //located enormous distances from the origin. The default is to move the model to the origin\n  //but it can be overridden in case of model aggregation scenarios, where multiple\n  //models are loaded into the scene and a common offset is needed for all.\n  if (loadContext.globalOffset) {\n    // Apply user-defined globalOffset\n    svf.globalOffset = loadContext.globalOffset;\n  } else {\n    // Choose global offset automatically at the center of the placmenent transformed model. \n    svf.globalOffset = svf.bbox.center();\n  }\n\n  calculatePlacementWithOffset(svf, pt);\n\n  // The model boundingBox must finally be in viewer-coords, just like everything else. I.e. with subtracted offset.\n  // Therefore, we have to subtract the globaloffset from bbox as well.\n  if (!svf.bbox.empty()) {\n    svf.bbox.min.sub(svf.globalOffset);\n    svf.bbox.max.sub(svf.globalOffset);\n  }\n\n  if (svf.metadata.hasOwnProperty(\"double sided geometry\") &&\n  svf.metadata[\"double sided geometry\"][\"value\"]) //TODO: do we want to check the global flag or drop that and rely on material only?\n    {\n      svf.doubleSided = true;\n    }\n\n}\n\nfunction applyOffset(a, offset) {\n  a[0] -= offset.x;\n  a[1] -= offset.y;\n  a[2] -= offset.z;\n}\n\n\nfunction transformAnimations(svf) {\n\n  if (!svf.animations)\n  return;\n\n  // apply global offset to animations\n  var animations = svf.animations[\"animations\"];\n  if (animations) {\n    var globalOffset = svf.globalOffset;\n    var t = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"]().makeTranslation(globalOffset.x, globalOffset.y, globalOffset.z);\n    var tinv = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"]().makeTranslation(-globalOffset.x, -globalOffset.y, -globalOffset.z);\n    var r = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"]();\n    var m = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_2__[\"LmvMatrix4\"]();\n    for (var a = 0; a < animations.length; a++) {\n      var anim = animations[a];\n      if (anim.hierarchy) {\n        for (var h = 0; h < anim.hierarchy.length; h++) {\n          var keys = anim.hierarchy[h].keys;\n          if (keys) {\n            for (var k = 0; k < keys.length; k++) {\n              var pos = keys[k].pos;\n              if (pos) {\n                var offset = globalOffset;\n                var rot = keys[k].rot;\n                if (rot) {\n                  r.makeRotationFromQuaternion({ x: rot[0], y: rot[1], z: rot[2], w: rot[3] });\n                  m.multiplyMatrices(t, r).multiply(tinv);\n                  offset = { x: m.elements[12], y: m.elements[13], z: m.elements[14] };\n                }\n                applyOffset(pos, offset);\n              }\n              var target = keys[k].target;\n              if (target) {\n                applyOffset(target, globalOffset);\n              }\n              var points = keys[k].points;\n              if (points) {\n                for (var p = 0; p < points.length; p++) {\n                  applyOffset(points[p], globalOffset);\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/common/VbUtils.js\":\n/*!**************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/common/VbUtils.js ***!\n  \\**************************************************/\n/*! exports provided: VBUtils */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VBUtils\", function() { return VBUtils; });\n\n\n\nvar VBUtils = {\n\n\n  deduceUVRepetition: function deduceUVRepetition(mesh) {\n\n    for (var p in mesh.vblayout) {\n\n      if (p.indexOf(\"uv\") != 0 || p.indexOf(\"uvw\") == 0)\n      continue;\n\n      var baseOffset = mesh.vblayout[p].offset;\n      var floatStride = mesh.vbstride;\n      var vbf = mesh.vb;\n      var vcount = mesh.vb.length / floatStride;\n\n      for (var i = 0, offset = baseOffset; i < vcount; i++, offset += floatStride)\n      {\n        var u = vbf[offset];\n        var v = vbf[offset + 1];\n        if (u > 2 || u < 0 || v > 2 || v < 0) {\n          mesh.vblayout[p].isPattern = true;\n          break;\n        }\n      }\n    }\n  },\n\n\n  //Calculate the 3D bounding box and bounding sphere\n  //of a mesh containing an interleaved vertex buffer\n  computeBounds3D: function computeBounds3D(mesh) {\n\n    var minx = Infinity,miny = Infinity,minz = Infinity;\n    var maxx = -Infinity,maxy = -Infinity,maxz = -Infinity;\n    var i, offset, x, y, z;\n\n    var floatStride = mesh.vbstride;\n    var baseOffset = mesh.vblayout.position.offset;\n    var vbf = mesh.vb;\n    var vcount = mesh.vb.length / floatStride;\n\n    for (i = 0, offset = baseOffset; i < vcount; i++, offset += floatStride)\n    {\n      x = vbf[offset];\n      y = vbf[offset + 1];\n      z = vbf[offset + 2];\n\n      if (minx > x) minx = x;\n      if (miny > y) miny = y;\n      if (minz > z) minz = z;\n\n      if (maxx < x) maxx = x;\n      if (maxy < y) maxy = y;\n      if (maxz < z) maxz = z;\n    }\n\n    var bb = mesh.boundingBox = {\n      min: { x: minx, y: miny, z: minz },\n      max: { x: maxx, y: maxy, z: maxz } };\n\n\n    var cx = 0.5 * (minx + maxx),cy = 0.5 * (miny + maxy),cz = 0.5 * (minz + maxz);\n\n    var bs = mesh.boundingSphere = {};\n    bs.center = { x: cx, y: cy, z: cz };\n\n    var maxRadiusSq = 0;\n    for (i = 0, offset = baseOffset; i < vcount; i++, offset += floatStride) {\n\n      x = vbf[offset];\n      y = vbf[offset + 1];\n      z = vbf[offset + 2];\n\n      var dx = x - cx;\n      var dy = y - cy;\n      var dz = z - cz;\n      var distsq = dx * dx + dy * dy + dz * dz;\n      if (distsq > maxRadiusSq)\n      maxRadiusSq = distsq;\n    }\n\n    bs.radius = Math.sqrt(maxRadiusSq);\n\n  },\n\n  bboxUnion: function bboxUnion(bdst, bsrc) {\n    if (bsrc.min.x < bdst.min.x)\n    bdst.min.x = bsrc.min.x;\n    if (bsrc.min.y < bdst.min.y)\n    bdst.min.y = bsrc.min.y;\n    if (bsrc.min.z < bdst.min.z)\n    bdst.min.z = bsrc.min.z;\n\n    if (bsrc.max.x > bdst.max.x)\n    bdst.max.x = bsrc.max.x;\n    if (bsrc.max.y > bdst.max.y)\n    bdst.max.y = bsrc.max.y;\n    if (bsrc.max.z > bdst.max.z)\n    bdst.max.z = bsrc.max.z;\n  } };\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/gltf/Gltf.js\":\n/*!*********************************************!*\\\n  !*** ./src/file-loaders/lmvtk/gltf/Gltf.js ***!\n  \\*********************************************/\n/*! exports provided: GltfPackage */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"GltfPackage\", function() { return GltfPackage; });\n/* harmony import */ var _common_VbUtils__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/VbUtils */ \"./src/file-loaders/lmvtk/common/VbUtils.js\");\n/* harmony import */ var _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../wgs/scene/LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/* harmony import */ var _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../wgs/scene/LmvBox3 */ \"./src/wgs/scene/LmvBox3.js\");\n/* harmony import */ var _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../wgs/scene/LmvMatrix4 */ \"./src/wgs/scene/LmvMatrix4.js\");\n/* harmony import */ var _net_Xhr__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\nfunction _typeof(obj) {if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {_typeof = function _typeof(obj) {return typeof obj;};} else {_typeof = function _typeof(obj) {return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;};}return _typeof(obj);}\n\n\n\n\n\n/*\n                                                 * base64-arraybuffer\n                                                 * https://github.com/niklasvh/base64-arraybuffer\n                                                 *\n                                                 * Copyright (c) 2012 Niklas von Hertzen\n                                                 * Licensed under the MIT license.\n                                                 */\n\nvar chars = \"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/\";\n\n// Use a lookup table to find the index.\nvar lookup = new Uint8Array(256);\nfor (var i = 0; i < chars.length; i++) {\n  lookup[chars.charCodeAt(i)] = i;\n}\n\n// currently base64_encode is not used.\n/*\nvar base64_encode = function(arraybuffer) {\n  var bytes = new Uint8Array(arraybuffer),\n  i, len = bytes.length, base64 = \"\";\n   for (i = 0; i < len; i+=3) {\n    base64 += chars[bytes[i] >> 2];\n    base64 += chars[((bytes[i] & 3) << 4) | (bytes[i + 1] >> 4)];\n    base64 += chars[((bytes[i + 1] & 15) << 2) | (bytes[i + 2] >> 6)];\n    base64 += chars[bytes[i + 2] & 63];\n  }\n   if ((len % 3) === 2) {\n    base64 = base64.substring(0, base64.length - 1) + \"=\";\n  } else if (len % 3 === 1) {\n    base64 = base64.substring(0, base64.length - 2) + \"==\";\n  }\n   return base64;\n};\n*/\n\n\n\n\nvar base64_decode = function base64_decode(base64) {\n  var bufferLength = base64.length * 0.75,\n  len = base64.length,i,p = 0,\n  encoded1,encoded2,encoded3,encoded4;\n\n  if (base64[base64.length - 1] === \"=\") {\n    bufferLength--;\n    if (base64[base64.length - 2] === \"=\") {\n      bufferLength--;\n    }\n  }\n\n  var arraybuffer = new ArrayBuffer(bufferLength),\n  bytes = new Uint8Array(arraybuffer);\n\n  for (i = 0; i < len; i += 4) {\n    encoded1 = lookup[base64.charCodeAt(i)];\n    encoded2 = lookup[base64.charCodeAt(i + 1)];\n    encoded3 = lookup[base64.charCodeAt(i + 2)];\n    encoded4 = lookup[base64.charCodeAt(i + 3)];\n\n    bytes[p++] = encoded1 << 2 | encoded2 >> 4;\n    bytes[p++] = (encoded2 & 15) << 4 | encoded3 >> 2;\n    bytes[p++] = (encoded3 & 3) << 6 | encoded4 & 63;\n  }\n\n  return arraybuffer;\n};\n\n\nfunction blobToJson(blob) {\n\n  var decodedString;\n\n  if ((typeof TextDecoder === \"undefined\" ? \"undefined\" : _typeof(TextDecoder)) !== undefined) {\n    decodedString = new TextDecoder(\"utf-8\").decode(blob);\n  } else\n  {\n    var encodedString = \"\";\n    for (var i = 0; i < blob.length; i++) {\n      encodedString += String.fromCharCode(blob[i]);}\n\n    decodedString = decodeURIComponent(escape(encodedString));\n  }\n\n  return JSON.parse(decodedString);\n}\n\n\nfunction GltfPackage(gltfJson) {\n\n  this.loadedBuffers = {};\n\n  //Check for binary glTF (glb)\n  if (gltfJson instanceof Uint8Array) {\n    var header = new Int32Array(gltfJson.buffer, 0, 20);\n    if (header[0] !== 0x46546C67) //['g', 'l', 'T', 'F'] in little endian\n      debug(\"glb header \" + header[0]);\n    var sceneLength = header[3];\n\n    var sceneBlob = new Uint8Array(gltfJson.buffer, 20, sceneLength);\n\n    //TODO: this is a bit lame, copies a large part of the ArrayBuffer,\n    //but the geometry parsing logic is made much easier this way, without\n    //having to keep track of a base offset to add when creating buffer views.\n    var binary_glTF = gltfJson.buffer.slice(20 + sceneLength);\n\n    gltfJson = blobToJson(sceneBlob);\n\n    this.loadedBuffers[\"binary_glTF\"] = binary_glTF;\n  }\n\n  this.gltf = gltfJson;\n  //NOTE: We will map the GltfPackage contents to a structure similar\n  //to an SVF package so that the rendering engine and viewer can work with it.\n\n  this.manifest = null;\n\n  this.metadata = this.gltf.asset || {}; //metadata json\n  this.metadata.gltf = this.metadata.version || 1;\n\n  this.materials = this.gltfMaterials = {\n    name: \"GLTF Materials\",\n    version: \"1.0\",\n    scene: {\n      \"SceneUnit\": \"m\" },\n\n    materials: {} };\n  //The materials jsons from the GLTF, reindexed\n\n  this.materialToIndex = {};\n  this.materialList = [];\n\n  this.geomToIndex = {};\n  this.geomList = [];\n  this.geomsLoaded = 0;\n\n  this.fragments = {\n    length: 0,\n    numLoaded: 0,\n    boxes: null,\n    transforms: null,\n    materials: null,\n\n    fragId2dbId: null,\n    entityIndexes: null,\n    mesh2frag: {} };\n\n\n  this.geompacks = [];\n\n  this.instances = [];\n\n  this.cameras = [];\n  this.lights = [];\n\n  this.bbox = null; //Overall scene bounds\n\n  this.animations = null; // animations json\n\n  this.pendingRequests = 0;\n\n  this.globalOffset = { x: 0, y: 0, z: 0 };\n  this.bbox = new _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_2__[\"LmvBox3\"]();\n\n  this.nodeToDbId = {};\n  this.nextDbId = 1;\n  this.nextFragId = 0;\n\n}\n\n\nvar BASE64_PREFIX = \"data:application/octet-stream;base64,\";\n\n//Lists all dependent files, so that their paths can be converted\n//to e.g. signed links by the manifest interceptor before they are loaded.\nGltfPackage.prototype.loadManifest = function (loadContext) {\n\n  var manifestTemplate = {\n    \"name\": \"LMV Manifest\",\n    \"toolkitversion\": \"LMVTK 2.6.4\",\n    \"manifestversion\": 2,\n    \"adskID\": {\n      \"sourceSystem\": \"\",\n      \"type\": \"\",\n      \"id\": \"\",\n      \"version\": \"\" },\n\n    \"assets\": [],\n    \"typesets\": [] };\n\n\n  this.manifest = manifestTemplate;\n\n  var buffers = this.gltf.buffers;\n\n  for (var bid in buffers) {\n\n    //Is it the embedded glb buffer? Skip it, it needs no URI remapping.\n    if (bid === \"binary_glTF\")\n    continue;\n\n    var buffer = buffers[bid];\n\n    //Base64 embedded buffers, decode\n    //and store in loaded buffers array.\n    if (buffer.uri.indexOf(BASE64_PREFIX) === 0) {\n      this.loadedBuffers[bid] = base64_decode(buffer.uri.slice(BASE64_PREFIX.length));\n      buffer.uri = \"embed://\" + bid;\n      continue;\n    }\n\n    var asset = {\n      id: bid,\n      URI: buffer.uri,\n      uri: buffer.uri,\n      usize: buffer.byteLength,\n      type: buffer.type };\n\n\n    this.manifest.assets.push(asset);\n  }\n\n  var images = this.gltf.images;\n\n  for (var iid in images) {\n\n    var image = images[iid];\n\n    var _asset = {\n      id: iid,\n      URI: image.uri,\n      uri: image.uri,\n      name: image.name,\n      type: \"image\" //just so we can differentiate it from the geom buffers\n    };\n\n    this.manifest.assets.push(_asset);\n  }\n\n  //TODO: Process any other externally referenced assets that we want to support\n\n};\n\n\nGltfPackage.prototype.loadRemainingSvf = function (loadContext) {\n\n  //In case it was modified by the path interceptor\n  if (loadContext.manifest)\n  this.manifest = loadContext.manifest;\n\n  //It's more convenient to find assets by their ids\n  //when dealing with gltf.\n  this.manifest.assetMap = {};\n  for (var i = 0; i < this.manifest.assets.length; i++) {\n    var a = this.manifest.assets[i];\n    this.manifest.assetMap[a.id] = a;\n  }\n\n  this.processMeshesList();\n  this.processMaterialsList();\n\n  this.deriveInstanceTree();\n\n  loadContext.loadDoneCB(\"svf\");\n\n  //Call the callback for any buffers that were embedded in the gltf,\n  //before loading the external ones.\n  for (var b in this.loadedBuffers) {\n    this.loadGeometry(loadContext, b);\n  }\n\n  this.loadBuffers(loadContext);\n\n};\n\nGltfPackage.prototype.loadBuffers = function (loadContext) {\n\n  //Launch an XHR to load the data from external file\n  var svf = this;\n\n  var bufList = [];\n  var assets = this.manifest.assets;\n  for (var i = 0; i < assets.length; i++) {\n    if (assets[i].type !== \"image\")\n    bufList.push(assets[i]);\n  }\n\n  var currentRequest = -1;\n\n  function xhrCB(responseData) {\n\n    if (currentRequest < bufList.length - 1) {\n      var nextBuf = bufList[currentRequest + 1];\n\n      var options = {\n        responseType: nextBuf.type || 'arraybuffer' };\n\n\n      _net_Xhr__WEBPACK_IMPORTED_MODULE_4__[\"ViewingService\"].getItem(\n      loadContext,\n      loadContext.basePath + nextBuf.URI,\n      xhrCB,\n      loadContext.onFailureCallback,\n      options);\n\n    }\n\n    if (responseData) {\n      var curBuf = bufList[currentRequest];\n      svf.loadedBuffers[curBuf.id] = responseData.buffer; //Get the ArrayBuffer out of the Uint8Array returned by the ViewingService.getItem\n      svf.loadGeometry(loadContext, curBuf.id);\n    }\n\n    currentRequest++;\n\n  }\n\n  xhrCB(null);\n\n};\n\nvar COMPONENT_TO_BYTES = {\n  \"5120\": 1, //BYTE\n  \"5121\": 1, //UNSIGNED_BYTE\n  \"5122\": 2, //SHORT\n  \"5123\": 2, //UNSIGNED_SHORT\n  \"5124\": 4, //INT\n  \"5125\": 4, //UNSIGNED_INT\n  \"5126\": 4 //FLOAT\n};\n\nvar TYPE_TO_SIZE = {\n  \"SCALAR\": 1,\n  \"VEC2\": 2,\n  \"VEC3\": 3,\n  \"VEC4\": 4 };\n\n\n\nvar _tmpfbuf = new Float32Array(1);\nvar _tmpbbuf = new Uint8Array(_tmpfbuf.buffer);\n\nfunction extractFloat(bbuf, offset) {\n  _tmpbbuf[0] = bbuf[offset];\n  _tmpbbuf[1] = bbuf[offset + 1];\n  _tmpbbuf[2] = bbuf[offset + 2];\n  _tmpbbuf[3] = bbuf[offset + 3];\n  return _tmpfbuf[0];\n}\n\n//Constructs all meshes that use the buffer\n//that was just loaded\n//NOTE: This loader pulls out all attributes for a mesh from a possibly\n//large shared buffer and interleaves them into a per-mesh vertex buffer\n//for each mesh. This fits better with the architecture of the LMV renderer\n//right now. But, in the future, things could be refactored so that the GL\n//buffers are managed separately from the meshes, and the meshes are pointing\n//into larger shared buffers.\nGltfPackage.prototype.loadGeometry = function (loadContext, bufferId) {\n\n  var buffer = this.gltf.buffers[bufferId];\n  var meshIds = buffer.meshes;\n  var scope = this;\n\n  function checkIfBufferAvailable(accessorId) {\n    var accessor = scope.gltf.accessors[accessorId];\n    var bvId = accessor.bufferView;\n    if (bvId) {\n      var bufferId = scope.gltf.bufferViews[bvId].buffer;\n      if (bufferId) {\n        return !!scope.loadedBuffers[bufferId];\n      }\n    }\n    return false;\n  }\n\n  for (var meshIdx = 0; meshIdx < meshIds.length; meshIdx++) {\n\n    var mesh = this.gltf.meshes[meshIds[meshIdx]];\n    var prims = mesh.primitives;\n\n    var usePackedNormals = typeof loadContext.packNormals !== \"undefined\" ? loadContext.packNormals : true;\n\n    for (var primIdx = 0; primIdx < prims.length; primIdx++) {\n\n      var prim = prims[primIdx];\n\n      var mesh = {\n        vblayout: {},\n        vbstride: 0,\n        packedNormals: usePackedNormals };\n\n\n      var canLoad = true;\n      if (prim.indices) {\n        canLoad = canLoad && checkIfBufferAvailable(prim.indices);\n        if (canLoad) {\n          var inds = scope.gltf.accessors[prim.indices];\n          mesh.triangleCount = inds.count / 3;\n          var stride = inds.byteStride;\n          var componentSize = 2;\n\n          var bv = scope.gltf.bufferViews[inds.bufferView];\n          var byteOffset = inds.byteOffset + bv.byteOffset;\n          var buffer = scope.loadedBuffers[bv.buffer];\n          var src, dst;\n\n          if (inds.componentType === 5123) {\n            dst = mesh.indices = new Uint16Array(inds.count);\n            componentSize = 2;\n            src = new Uint16Array(buffer);\n          } else\n          if (inds.componentType === 5125) {\n            dst = mesh.indices = new Uint32Array(inds.count);\n            componentSize = 4;\n            src = new Uint32Array(buffer);\n          } else\n            // other unimplemented types\n            debug(\"Unimplemented component type for index buffer\");\n\n          var srcOffset = byteOffset / componentSize;\n\n          if (stride === 0)\n          stride = 1;else\n\n          stride /= componentSize;\n\n          for (var i = 0; i < inds.count; i++) {\n            dst[i] = src[srcOffset + i * stride];\n          }\n        }\n      }\n\n      var offset = 0;\n      for (var a in prim.attributes) {\n        canLoad = canLoad && checkIfBufferAvailable(prim.attributes[a]);\n        var attr = scope.gltf.accessors[prim.attributes[a]];\n\n        if (canLoad) {\n          if (a === \"NORMAL\") {\n            mesh.vbstride += usePackedNormals ? 1 : 3;\n\n            mesh.vblayout['normal'] = { offset: offset,\n              itemSize: usePackedNormals ? 2 : 3,\n              bytesPerItem: usePackedNormals ? 2 : 4,\n              normalize: usePackedNormals };\n\n            offset += usePackedNormals ? 1 : 3;\n\n          } else\n          {\n            var attrName = a;\n\n            if (a === \"POSITION\") {\n              attrName = \"position\";\n              mesh.vertexCount = attr.count;\n            } else if (a.indexOf(\"TEXCOORD\") === 0) {\n              var uvIdx = parseInt(a.split(\"_\")[1]);\n              attrName = \"uv\" + (uvIdx || \"\");\n            } else if (a.indexOf(\"COLOR\") === 0) {\n              attrName = \"color\";\n            }\n\n            var byteSize = COMPONENT_TO_BYTES[attr.componentType] * TYPE_TO_SIZE[attr.type];\n            mesh.vbstride += byteSize / 4;\n\n            mesh.vblayout[attrName] = { offset: offset,\n              itemSize: TYPE_TO_SIZE[attr.type],\n              bytesPerItem: COMPONENT_TO_BYTES[attr.componentType],\n              normalize: false };\n\n\n            offset += byteSize / 4;\n          }\n        }\n\n      }\n\n      //Now that we know how big of a vertex buffer we need, make one, and\n      //go over the attributes again to copy their data from the glTF buffer\n      //into the mesh vertex buffer\n      if (canLoad) {\n        var vbf = mesh.vb = new Float32Array(mesh.vertexCount * mesh.vbstride);\n        //See if we want to pack the normals into two shorts\n        var vbi;\n        if (usePackedNormals)\n        vbi = new Uint16Array(mesh.vb.buffer);\n\n        for (var a in prim.attributes) {\n          var attr = scope.gltf.accessors[prim.attributes[a]];\n          var bv = scope.gltf.bufferViews[attr.bufferView];\n          var byteOffset = attr.byteOffset + bv.byteOffset;\n          var rawbuffer = new Uint8Array(scope.loadedBuffers[bv.buffer]);\n\n          if (a === \"NORMAL\") {\n            var lmvAttr = mesh.vblayout[\"normal\"];\n\n            if (attr.count != mesh.vertexCount)\n            debug(\"Normals count does not equal vertex count\");\n\n            //TODO: assumption that they're all floats...\n            var stride = attr.byteStride !== 0 ? attr.byteStride : bytesPerItem * TYPE_TO_SIZE[attr.type];\n            var srcIdx = byteOffset;\n            var offset = lmvAttr.offset;\n\n            for (var i = 0; i < mesh.vertexCount; i++, offset += mesh.vbstride) {\n              var nx = extractFloat(rawbuffer, srcIdx);\n              var ny = extractFloat(rawbuffer, srcIdx + 4);\n              var nz = extractFloat(rawbuffer, srcIdx + 8);\n\n              if (vbi) {\n                var pnx = (Math.atan2(ny, nx) / Math.PI + 1.0) * 0.5;\n                var pny = (nz + 1.0) * 0.5;\n\n                vbi[offset * 2] = pnx * 65535 | 0;\n                vbi[offset * 2 + 1] = pny * 65535 | 0;\n              } else {\n                vbf[offset] = nx;\n                vbf[offset + 1] = ny;\n                vbf[offset + 2] = nz;\n              }\n\n              srcIdx += stride;\n            }\n          } else\n          {\n            var attrName = a;\n\n            //Map common attribute names to ones used by LMV\n            if (a === \"POSITION\") {\n              attrName = \"position\";\n              mesh.vertexCount = attr.count;\n            } else if (a.indexOf(\"TEXCOORD\") === 0) {\n              var uvIdx = parseInt(a.split(\"_\")[1]);\n              attrName = \"uv\" + (uvIdx || \"\");\n            } else if (a.indexOf(\"COLOR\") === 0) {\n              attrName = \"color\";\n            }\n\n            var lmvAttr = mesh.vblayout[attrName];\n\n            var bytesPerItem = COMPONENT_TO_BYTES[attr.componentType];\n            var stride = attr.byteStride !== 0 ? attr.byteStride : bytesPerItem * TYPE_TO_SIZE[attr.type];\n            var src = new Uint8Array(rawbuffer);\n            var dst = new Uint8Array(vbf.buffer, lmvAttr.offset * 4);\n            var srcIdx = byteOffset;\n            var offset = 0;\n            for (var i = 0; i < mesh.vertexCount; i++) {\n\n              for (var j = 0; j < lmvAttr.itemSize * bytesPerItem; j++) {\n                dst[offset + j] = src[srcIdx + j];\n              }\n\n              offset += mesh.vbstride * bytesPerItem;\n              srcIdx += stride;\n            }\n          }\n\n          //If all meshes using this buffer are successfully loaded,\n          //free its array buffer from memory.\n          var gltfBuffer = scope.gltf.buffers[bv.buffer];\n          gltfBuffer.refCount--;\n          if (gltfBuffer.refCount === 0) {\n            delete scope.loadedBuffers[bv.buffer];\n          }\n        }\n\n        //Mesh is complete.\n        scope.geomsLoaded++;\n\n        _common_VbUtils__WEBPACK_IMPORTED_MODULE_0__[\"VBUtils\"].computeBounds3D(mesh);\n\n        loadContext.loadDoneCB(\"mesh\", { mesh: mesh,\n\n          //Set these so that when SvfLoader adds them together\n          //it comes up with the IDs we use in the meshToFrag map.\n          packId: meshIds[meshIdx],\n          meshIndex: primIdx,\n\n          progress: scope.geomsLoaded / scope.geomList.length });\n      }\n    }\n\n  }\n\n  buffer.meshes = null;\n\n};\n\n//Converts materials to indexed list, for use in\n//the fragment list material indices array\nGltfPackage.prototype.processMaterialsList = function () {\n\n  var mats = this.gltf.materials;\n\n  for (var m in mats) {\n    var idx = this.materialList.length;\n    this.materialToIndex[m] = idx;\n    this.gltfMaterials.materials[idx] = mats[m];\n    this.materialList.push(m);\n  }\n\n};\n\nGltfPackage.prototype.processMeshesList = function () {\n\n  var meshes = this.gltf.meshes;\n  var scope = this;\n\n  function processAccessor(accessorId) {\n    var accessor = scope.gltf.accessors[accessorId];\n    var bvId = accessor.bufferView;\n    if (bvId) {\n      var bufferId = scope.gltf.bufferViews[bvId].buffer;\n      if (bufferId) {\n        var buffer = scope.gltf.buffers[bufferId];\n\n        //Keep track of how many buffer views are using this buffer.\n        //Once we load all of them, we will free it from memory\n        if (!buffer.refCount)\n        buffer.refCount = 1;else\n\n        buffer.refCount++;\n\n        //Keep track of meshes using a buffer. We will load those\n        //in a batch once a buffer file is loaded.\n        if (!buffer.meshes)\n        buffer.meshes = [];\n\n        if (!addedToBuffer) {\n          buffer.meshes.push(m);\n          addedToBuffer = true;\n        }\n      }\n    }\n  }\n\n  for (var m in meshes) {\n    var mesh = meshes[m];\n    var addedToBuffer = false;\n    for (var k = 0; k < mesh.primitives.length; k++) {\n      var entityId = m + \":\" + k;\n      this.geomToIndex[entityId] = this.geomList.length;\n      this.geomList.push(entityId);\n\n      var prim = mesh.primitives[k];\n\n      if (prim.indices) {\n        processAccessor(prim.indices);\n      }\n\n      for (var a in prim.attributes) {\n        processAccessor(prim.attributes[a]);\n      }\n    }\n  }\n\n  this.numGeoms = this.geomList.length;\n};\n\n\n//Pre-traversal of the node hierarchy to count how many fragments we will\n//need in the LMV fragment list\nGltfPackage.prototype.countFragments = function () {\n\n  var sceneName = this.gltf.scene;\n  var gltfRoot = this.gltf.scenes[sceneName];\n  var gltfNodes = this.gltf.nodes;\n\n  var numFrags = 0;\n\n  var scope = this;\n\n  function traverseNodes(gltfNode) {\n\n    var meshes = gltfNode.meshes;\n    if (gltfNode.meshes) {\n      for (var j = 0; j < meshes.length; j++) {\n        var prims = scope.gltf.meshes[meshes[j]].primitives;\n        for (var k = 0; k < prims.length; k++) {\n          numFrags++;\n        }\n      }\n    }\n\n    var children = gltfNode.children || gltfNode.nodes; //the root scene uses \"nodes\" instead of \"children\"\n    if (children) {\n      for (var i = 0; i < children.length; i++) {\n        var gltfChild = gltfNodes[children[i]];\n        traverseNodes(gltfChild);\n      }\n    }\n  }\n\n  traverseNodes(gltfRoot);\n\n  this.fragments.length = numFrags;\n  this.fragments.boxes = new Float32Array(6 * numFrags);\n  this.fragments.transforms = new Float32Array(12 * numFrags);\n  this.fragments.materials = new Int32Array(numFrags);\n  this.fragments.entityIndexes = new Int32Array(numFrags);\n  this.fragments.fragId2dbId = new Int32Array(numFrags);\n  this.fragments.packIds = new Int32Array(numFrags); //TODO: not used for gltf\n\n};\n\n//Create an instance tree similar to the one\n//that SVF gets from the property db\nGltfPackage.prototype.deriveInstanceTree = function () {\n\n  this.countFragments();\n\n  var sceneName = this.gltf.scene;\n  var gltfRoot = this.gltf.scenes[sceneName];\n  var gltfNodes = this.gltf.nodes;\n\n  this.instanceTree = {\n    name: sceneName,\n    dbId: this.nextDbId++,\n    children: [] };\n\n  this.nodeToDbId[sceneName] = this.instanceTree.dbId;\n\n  var nodeBoxes = [];\n  var maxDepth = 1;\n\n  var scope = this;\n  var fragments = this.fragments;\n  var tmpBox = new _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_2__[\"LmvBox3\"]();\n\n  function traverseNodes(svfNode, gltfNode, worldTransform, depth) {\n\n    if (depth > maxDepth)\n    maxDepth = depth;\n\n    var currentTransform = worldTransform.clone();\n    // nodes can have a matrix transform, or a TRS type transform\n    if (gltfNode.matrix) {\n      var mtx = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_3__[\"LmvMatrix4\"](true);\n      mtx.fromArray(gltfNode.matrix);\n      currentTransform.multiply(mtx);\n    } else\n    {\n      var t = gltfNode.translation;\n      var r = gltfNode.rotation;\n      var s = gltfNode.scale;\n\n      // if none are defined, don't bother making the matrix -\n      // this may be a non-matrix-oriented node\n      if (t !== undefined || r !== undefined || s !== undefined) {\n\n        // Rotations are stored as quaternions in glTF. Here is a quick and dirty quaternion class.\n        // It's purely for storing the incoming data. We need this below to call the matrix.compose function.\n        // Feel free to make a whole separate LmvQuaternion.js file if you're doing serious quaternion work.\n        var Quat = function Quat(x, y, z, w) {\n\n          this.x = x || 0;\n          this.y = y || 0;\n          this.z = z || 0;\n          this.w = w || 0;\n\n        };\n\n        var position = t ? new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"](t[0], t[1], t[2]) :\n        new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n        var rotation = r ? new Quat(r[0], r[1], r[2], r[3]) :\n        new Quat();\n        var scale = s ? new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"](s[0], s[1], s[2]) :\n        new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"](1, 1, 1);\n\n        var mtx = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_3__[\"LmvMatrix4\"](true);\n        mtx.compose(position, rotation, scale);\n        currentTransform.multiply(mtx);\n      }\n    }\n\n    var nodeBox = new _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_2__[\"LmvBox3\"]();\n\n    var meshes = gltfNode.meshes;\n    if (gltfNode.meshes) {\n      svfNode.fragIds = [];\n      for (var j = 0; j < meshes.length; j++) {\n        var prims = scope.gltf.meshes[meshes[j]].primitives;\n        for (var k = 0; k < prims.length; k++) {\n\n          var entityId = meshes[j] + \":\" + k;\n          var fragId = scope.nextFragId++;\n\n          svfNode.fragIds.push(fragId);\n\n          fragments.fragId2dbId[fragId] = svfNode.dbId;\n\n          fragments.entityIndexes[fragId] = scope.geomToIndex[entityId];\n\n          if (!fragments.mesh2frag[entityId])\n          fragments.mesh2frag[entityId] = [fragId];else\n\n          fragments.mesh2frag[entityId].push(fragId);\n\n          fragments.materials[fragId] = scope.materialToIndex[prims[k].material];\n\n          // Copy the transform to the fraglist array\n          var off = fragId * 12;\n          var cur = currentTransform.elements;\n          var orig = fragments.transforms;\n          orig[off] = cur[0];\n          orig[off + 1] = cur[1];\n          orig[off + 2] = cur[2];\n          orig[off + 3] = cur[4];\n          orig[off + 4] = cur[5];\n          orig[off + 5] = cur[6];\n          orig[off + 6] = cur[8];\n          orig[off + 7] = cur[9];\n          orig[off + 8] = cur[10];\n          orig[off + 9] = cur[12];\n          orig[off + 10] = cur[13];\n          orig[off + 11] = cur[14];\n\n          var posAccessorId = prims[k].attributes[\"POSITION\"];\n          if (posAccessorId) {\n            var accessor = scope.gltf.accessors[posAccessorId];\n            if (accessor.min && accessor.max) {\n              tmpBox.min.x = accessor.min[0];\n              tmpBox.min.y = accessor.min[1];\n              tmpBox.min.z = accessor.min[2];\n              tmpBox.max.x = accessor.max[0];\n              tmpBox.max.y = accessor.max[1];\n              tmpBox.max.z = accessor.max[2];\n\n            } else {\n\n              tmpBox.min.x = -0.5;\n              tmpBox.min.y = -0.5;\n              tmpBox.min.z = -0.5;\n              tmpBox.max.x = 0.5;\n              tmpBox.max.y = 0.5;\n              tmpBox.max.z = 0.5;\n\n              debug(\"unknown bbox for mesh, using unit box\", meshes[j]);\n            }\n\n            tmpBox.applyMatrix4(currentTransform);\n\n            off = fragId * 6;\n            var dst = fragments.boxes;\n            dst[off] = tmpBox.min.x;\n            dst[off + 1] = tmpBox.min.y;\n            dst[off + 2] = tmpBox.min.z;\n\n            dst[off + 3] = tmpBox.max.x;\n            dst[off + 4] = tmpBox.max.y;\n            dst[off + 5] = tmpBox.max.z;\n\n            nodeBox.union(tmpBox);\n          }\n        }\n      }\n    }\n\n    var children = gltfNode.children || gltfNode.nodes; //the root scene uses \"nodes\" instead of \"children\"\n    if (children) {\n      svfNode.children = [];\n      for (var i = 0; i < children.length; i++) {\n        var gltfChild = gltfNodes[children[i]];\n\n        var svfChild = {\n          name: gltfChild.name || children[i],\n          dbId: scope.nextDbId++ };\n\n\n        scope.nodeToDbId[children[i]] = svfChild.dbId;\n\n        svfNode.children.push(svfChild);\n\n        var childBox = traverseNodes(svfChild, gltfChild, currentTransform, depth + 1);\n        nodeBox.union(childBox);\n      }\n    }\n\n    var boxOffset = svfNode.dbId * 6;\n    var dst = nodeBoxes;\n    dst[boxOffset] = nodeBox.min.x;\n    dst[boxOffset + 1] = nodeBox.min.y;\n    dst[boxOffset + 2] = nodeBox.min.z;\n    dst[boxOffset + 3] = nodeBox.max.x;\n    dst[boxOffset + 4] = nodeBox.max.y;\n    dst[boxOffset + 5] = nodeBox.max.z;\n\n    return nodeBox;\n  }\n\n  var rootBox = traverseNodes(this.instanceTree, gltfRoot, new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_3__[\"LmvMatrix4\"](true), 1);\n  scope.bbox.union(rootBox);\n\n  //convert boxes to typed array now that we know the needed size\n  this.instanceBoxes = new Float32Array(nodeBoxes.length);\n  this.instanceBoxes.set(nodeBoxes);\n  this.objectCount = this.nextDbId;\n  this.maxTreeDepth = maxDepth;\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Cameras.js\":\n/*!***********************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Cameras.js ***!\n  \\***********************************************/\n/*! exports provided: readCameraDefinition */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readCameraDefinition\", function() { return readCameraDefinition; });\n\n\nfunction readCameraDefinition(pfr, inst) {\n  var entry = inst.definition;\n  var tse = pfr.seekToEntry(entry);\n  if (!tse)\n  return null;\n  if (tse.version > 2 /*Constants::CameraDefinitionVersion*/)\n    return null;\n\n  var s = pfr.stream;\n  var cam = {\n    isPerspective: !s.getUint8(), /* 0 = perspective, 1 = ortho */\n    position: pfr.readVector3f(),\n    target: pfr.readVector3f(),\n    up: pfr.readVector3f(),\n    aspect: s.getFloat32(),\n    fov: s.getFloat32() * (180 / Math.PI) };\n\n  if (tse.version < 2) {\n    // Skip the clip planes for old files.\n    s.getFloat32();\n    s.getFloat32();\n  }\n\n  cam.orthoScale = s.getFloat32();\n\n  return cam;\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Fragments.js\":\n/*!*************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Fragments.js ***!\n  \\*************************************************/\n/*! exports provided: FragList, readGeometryMetadataIntoFragments, readGeometryMetadata, readFragments, filterFragments */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FragList\", function() { return FragList; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readGeometryMetadataIntoFragments\", function() { return readGeometryMetadataIntoFragments; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readGeometryMetadata\", function() { return readGeometryMetadata; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readFragments\", function() { return readFragments; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"filterFragments\", function() { return filterFragments; });\n/* harmony import */ var _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../wgs/scene/LmvBox3 */ \"./src/wgs/scene/LmvBox3.js\");\n/* harmony import */ var _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../wgs/scene/LmvMatrix4 */ \"./src/wgs/scene/LmvMatrix4.js\");\n/* harmony import */ var _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../wgs/scene/LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../../compat */ \"./src/compat.js\");\n/* harmony import */ var _wgs_scene_MeshFlags__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../../wgs/scene/MeshFlags */ \"./src/wgs/scene/MeshFlags.js\");\n\n\n\n\n\n\n//FragList represents an array of fragments, stored in Structure of Arrays form\n//which allows us to free some parts easily and transfer the fragment information in large chunks.\nvar NUM_FRAGMENT_LIMITS = Object(_compat__WEBPACK_IMPORTED_MODULE_3__[\"isMobileDevice\"])() ? null : null;\nvar MAX_BBOX_RATIO = 100;\n\n/** @constructor */\n// note: update transferable var list in SvfWorker.ts if you add a new field\nfunction FragList() {\n  this.length = 0;\n  this.numLoaded = 0;\n\n  this.boxes = null;\n  this.transforms = null;\n  this.materials = null;\n\n  this.packIds = null;\n  this.entityIndexes = null;\n\n  this.fragId2dbId = null;\n\n  this.topoIndexes = null;\n\n  this.visibilityFlags = null;\n}\n\nfunction readGeometryMetadataIntoFragments(pfr, fragments) {\n  var length = fragments.geomDataIndexes.length;\n  var stream = pfr.stream;\n  var primsCount = 0;\n\n  // Read from cache if the same entry has been reading from stream.\n  var entryCache = {};\n  var mesh2frag = fragments.mesh2frag = {};\n  fragments.polygonCounts = fragments.geomDataIndexes;\n  for (var g = 0; g < length; g++) {\n    var entry = fragments.geomDataIndexes[g];\n\n    if (entryCache[entry]) {\n      var i = entryCache[entry];\n      fragments.polygonCounts[g] = fragments.polygonCounts[i];\n      fragments.packIds[g] = fragments.packIds[i];\n      fragments.entityIndexes[g] = fragments.entityIndexes[i];\n      primsCount += fragments.polygonCounts[g];\n    } else\n    {\n      var tse = pfr.seekToEntry(entry);\n      if (!tse)\n      return;\n\n      // Frag type, seems no use any more.\n      stream.getUint8();\n      //skip past object space bbox -- we don't use that\n      stream.seek(stream.offset + 24);\n\n      fragments.polygonCounts[g] = stream.getUint16();\n      fragments.packIds[g] = parseInt(pfr.readString());\n      fragments.entityIndexes[g] = pfr.readU32V();\n      primsCount += fragments.polygonCounts[g];\n\n      entryCache[entry] = g;\n    }\n\n    // Construct mesh2frag here directly\n    var meshid = fragments.packIds[g] + \":\" + fragments.entityIndexes[g];\n    var meshRefs = mesh2frag[meshid];\n    if (meshRefs === undefined) {\n      //If it's the first fragments for this mesh,\n      //store the index directly -- most common case.\n      mesh2frag[meshid] = g;\n    } else\n    if (!Array.isArray(meshRefs)) {\n      //otherwise put the fragments that\n      //reference the mesh into an array\n      mesh2frag[meshid] = [meshRefs, g];\n    } else\n    {\n      //already is an array\n      meshRefs.push(g);\n    }\n\n  }\n  fragments.geomDataIndexes = null;\n  entryCache = null;\n\n  return primsCount;\n}\n\nfunction readGeometryMetadata(pfr, geoms)\n{\n  var numGeoms = pfr.getEntryCounts();\n  var stream = pfr.stream;\n\n  geoms.length = numGeoms;\n  var fragTypes = geoms.fragTypes = new Uint8Array(numGeoms);\n  var primCounts = geoms.primCounts = new Uint16Array(numGeoms);\n  var packIds = geoms.packIds = new Int32Array(numGeoms);\n  var entityIndexes = geoms.entityIndexes = new Int32Array(numGeoms);\n  // Holds the indexes to the topology data.\n  var topoIndexes;\n\n  for (var g = 0, gEnd = numGeoms; g < gEnd; g++) {\n    var tse = pfr.seekToEntry(g);\n    if (!tse)\n    return;\n\n    fragTypes[g] = stream.getUint8();\n    //skip past object space bbox -- we don't use that\n    stream.seek(stream.offset + 24);\n    primCounts[g] = stream.getUint16();\n    packIds[g] = parseInt(pfr.readString());\n    entityIndexes[g] = pfr.readU32V();\n\n    if (tse.version > 2) {\n      var topoIndex = stream.getInt32();\n      if (topoIndex != -1 && topoIndexes === undefined) {\n        topoIndexes = geoms.topoIndexes = new Int32Array(numGeoms);\n        // Fill in the first entries to indicate\n        for (var i = 0; i < g; i++) {\n          topoIndexes[i] = -1;}\n      }\n\n      if (topoIndexes != undefined)\n      topoIndexes[g] = topoIndex;\n    }\n\n  }\n}\n\n// Convert a list of object id (dbid) to a list of integers where each integer is an index of the fragment\n// in fragment list that associated with the object id.\nfunction objectIds2FragmentIndices(pfr, ids) {\n  var ret = [];\n\n  if (!ids) {\n    return ret;\n  }\n\n  var counts = pfr.getEntryCounts();\n  var stream = pfr.stream;\n  for (var entry = 0; entry < counts; entry++) {\n    var tse = pfr.seekToEntry(entry);\n    if (!tse)\n    return;\n    if (tse.version > 5)\n    return;\n\n    // Keep reading fragment fields as usual, but does not store anything as we only\n    // interested in the data base id / object id field at the very end.\n    if (tse.version > 4) {\n      // Flag byte.\n      pfr.readU8();\n    }\n    // Material index\n    pfr.readU32V();\n    if (tse.version > 2) {\n      // Geometry metadata reference\n      pfr.readU32V();\n    } else {\n      // Pack file reference\n      pfr.readString();\n      pfr.readU32V();\n    }\n\n    // Transform\n    pfr.readTransform(entry, null, 12 * entry);\n\n    // Bounding box\n    for (var i = 0; i < 6; i++) {\n      stream.getFloat32();\n    }\n\n    if (tse.version > 1) {\n      var dbid = pfr.readU32V();\n      if (ids.indexOf(dbid) >= 0) {\n        ret.push(entry);\n      }\n    }\n  }\n\n  return ret;\n}\n\n// globalOffset:        GlobalOffset as specified by loadOptions (may be undefined)\n// defaultGlobalOffset: GlobalOffset as initially chosen by SvfPlacementUtil.initPlacement\nfunction readFragments(pfr, frags, globalOffset, placementTransform, fragmentTransformsDouble, ids, bbox, defaultGlobalOffset) {\n  var filteredIndices = objectIds2FragmentIndices(pfr, ids);\n\n  //Initialize all the fragments structures\n  //once we know how many fragments we have.\n  var numFrags = filteredIndices.length ? filteredIndices.length : pfr.getEntryCounts();\n  var stream = pfr.stream;\n\n  if (NUM_FRAGMENT_LIMITS && numFrags > NUM_FRAGMENT_LIMITS) {\n    numFrags = NUM_FRAGMENT_LIMITS;\n  }\n\n  // Recored the total length of the fragments\n  frags.totalLength = pfr.getEntryCounts();\n  frags.length = numFrags;\n  frags.numLoaded = 0;\n\n  //Allocate flat array per fragment property\n  var fragBoxes = frags.boxes = fragmentTransformsDouble ? new Float64Array(6 * numFrags) : new Float32Array(6 * numFrags);\n  var transforms = frags.transforms = fragmentTransformsDouble ? new Float64Array(12 * numFrags) : new Float32Array(12 * numFrags);\n  var materials = frags.materials = new Int32Array(numFrags);\n  var packIds = frags.packIds = new Int32Array(numFrags);\n  var entityIndexes = frags.entityIndexes = new Int32Array(numFrags);\n  var geomDataIndexes = frags.geomDataIndexes = new Int32Array(numFrags);\n  var fragId2dbId = frags.fragId2dbId = new Int32Array(numFrags); //NOTE: this potentially truncates IDs bigger than 4 billion -- can be converted to array if needed.\n  var visibilityFlags = frags.visibilityFlags = new Uint16Array(numFrags);\n\n  var tmpBox;\n  var tmpMat;\n  var boxTranslation = [0, 0, 0];\n  if (placementTransform) {\n    tmpBox = new _wgs_scene_LmvBox3__WEBPACK_IMPORTED_MODULE_0__[\"LmvBox3\"]();\n    tmpMat = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__[\"LmvMatrix4\"](true).fromArray(placementTransform.elements);\n  }\n\n  var calculateOffset = !globalOffset && bbox;\n  var dpTranslations = transforms;\n  // Normally the translations component of transforms is 12 entries for each\n  // transform and then offset by 9 in the transform.\n  var translationSize = 12;\n  var translationOff = 9;\n  if (calculateOffset) {\n    // A global offset wasn't specified in the load context, so we will calculate one\n    // here. We normally use the center of the bbox, but if the bbox is signficantly\n    // larger than the objects in the model, then we make the global offset the\n    // average of the centers of the fragment bounding boxes, which will push\n    // offset toward places where there are more fragments.\n    if (!fragmentTransformsDouble) {\n      // We need to keep bboxes and transform translations in double precision\n      // to guarantee precision in large bbox cases\n      fragBoxes = new Float64Array(6 * numFrags);\n      dpTranslations = new Float64Array(3 * numFrags);\n      // In this case the translations are 3 entries offset by 0\n      translationSize = 3;\n      translationOff = 0;\n    }\n  }\n\n  //Helper functions used by the main fragment read loop.\n\n  function applyPlacement(index) {\n    if (placementTransform) {\n      var offset = index * 6;\n      tmpBox.setFromArray(fragBoxes, offset);\n      tmpBox.applyMatrix4(tmpMat);\n      tmpBox.copyToArray(fragBoxes, offset);\n    }\n  }\n\n  function readBoundingBox(entry) {\n    var offset = entry * 6;\n    for (var i = 0; i < 6; i++) {\n      fragBoxes[offset++] = stream.getFloat32();}\n  }\n\n  function readBoundingBoxOffset(entry, boxTranslation) {\n    var offset = entry * 6;\n    for (var i = 0; i < 6; i++) {\n      fragBoxes[offset++] = stream.getFloat32() + boxTranslation[i % 3];}\n  }\n\n  //Spin through all the fragments now\n  for (var entry = 0, eEnd = frags.length; entry < eEnd; entry++) {\n    var tse = filteredIndices.length ? pfr.seekToEntry(filteredIndices[entry]) : pfr.seekToEntry(entry);\n\n    if (!tse)\n    return;\n    if (tse.version > 5)\n    return;\n\n    var isVisible = true;\n    if (tse.version > 4) {\n      // Fragments v5+ include a flag byte, the LSB of which denotes\n      // visibility\n      var flags = pfr.readU8();\n      isVisible = (flags & 0x01) != 0;\n    }\n    visibilityFlags[entry] = isVisible ? _wgs_scene_MeshFlags__WEBPACK_IMPORTED_MODULE_4__[\"MeshFlags\"].MESH_VISIBLE : 0;\n\n    materials[entry] = pfr.readU32V();\n\n    if (tse.version > 2) {\n      //In case it's new style fragment that\n      //points to a geometry metadata entry\n      geomDataIndexes[entry] = pfr.readU32V();\n    } else\n    {\n      //Old style fragment, pack reference is directly\n      //encoded in the fragment entry\n      packIds[entry] = parseInt(pfr.readString());\n      entityIndexes[entry] = pfr.readU32V();\n    }\n\n    pfr.readTransform(entry, transforms, 12 * entry, placementTransform, globalOffset, boxTranslation);\n    if (calculateOffset && dpTranslations !== transforms) {\n      dpTranslations.set(boxTranslation, entry * translationSize + translationOff);\n    }\n\n    if (tse.version > 3) {\n      // With this version the transform's (double precision) translation is subtracted from the BB,\n      // so we have to add it back\n      readBoundingBoxOffset(entry, boxTranslation);\n    } else\n    {\n      readBoundingBox(entry);\n    }\n\n    //Apply the placement transform to the world space bbox\n    applyPlacement(entry);\n\n    //Apply any global offset to the world space bbox\n    if (globalOffset) {\n      var offset = entry * 6;\n      fragBoxes[offset++] -= globalOffset.x;\n      fragBoxes[offset++] -= globalOffset.y;\n      fragBoxes[offset++] -= globalOffset.z;\n      fragBoxes[offset++] -= globalOffset.x;\n      fragBoxes[offset++] -= globalOffset.y;\n      fragBoxes[offset++] -= globalOffset.z;\n    }\n\n    if (tse.version > 1) {\n      fragId2dbId[entry] = pfr.readU32V();\n    }\n    // Skip reading path ID which is not in use now.\n    // pfr.readPathID();\n  }\n\n  if (calculateOffset) {\n    // We compare the size of the bbox against the size of the largest\n    // max size of the bounding boxes in the model to see decide\n    // what to use as the globalOffset.\n\n    // First calculate the max of object box sizes\n    var maxX = -1,maxY = -1,maxZ = -1;\n    var boxEnd = fragBoxes.length;\n    // Effectively this calculates the average of the centers of the fragment bboxes\n    for (var i = 0; i < boxEnd; i += 6) {\n      maxX = Math.max(maxX, fragBoxes[i + 3] - fragBoxes[i]);\n      maxY = Math.max(maxY, fragBoxes[i + 4] - fragBoxes[i + 1]);\n      maxZ = Math.max(maxZ, fragBoxes[i + 5] - fragBoxes[i + 2]);\n    }\n\n    var size = bbox.size();\n    if (size.x > maxX * MAX_BBOX_RATIO || size.y > maxY * MAX_BBOX_RATIO || size.z > maxZ * MAX_BBOX_RATIO) {\n      // Now calculate the weighted offset. The weighted globalOffset is\n      // weighted to be close to places with more fragments.\n      var offsetX = 0,offsetY = 0,offsetZ = 0;\n      // Effectively this calculates the average of the centers of the fragment bboxes\n      for (var i = 0; i < boxEnd; i += 3) {\n        offsetX += fragBoxes[i];\n        offsetY += fragBoxes[i + 1];\n        offsetZ += fragBoxes[i + 2];\n      }\n      globalOffset = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__[\"LmvVector3\"](offsetX * 3 / boxEnd, offsetY * 3 / boxEnd, offsetZ * 3 / boxEnd);\n    } else {\n      globalOffset = defaultGlobalOffset;\n    }\n\n    // Need to addjust the bounding boxes, using the globalOffset\n    var outBoxes = frags.boxes;\n    for (i = 0; i < boxEnd; i += 3) {\n      outBoxes[i] = fragBoxes[i] - globalOffset.x;\n      outBoxes[i + 1] = fragBoxes[i + 1] - globalOffset.y;\n      outBoxes[i + 2] = fragBoxes[i + 2] - globalOffset.z;\n    }\n\n    if (placementTransform && dpTranslations !== transforms) {\n      var tmpVec = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__[\"LmvVector3\"]();\n      // And adjust the transforms, too\n      for (entry = 0; entry < eEnd; ++entry) {\n        var _from = entry * translationSize + translationOff;\n        tmpVec.fromArray(dpTranslations, _from).applyMatrix4(tmpMat).toArray(dpTranslations, _from);\n      }\n    }\n\n    // And adjust the transforms, too\n    for (entry = 0; entry < eEnd; ++entry) {\n      var to = entry * 12 + 9;\n      var from = entry * translationSize + translationOff;\n      transforms[to] = dpTranslations[from] - globalOffset.x;\n      transforms[to + 1] = dpTranslations[from + 1] - globalOffset.y;\n      transforms[to + 2] = dpTranslations[from + 2] - globalOffset.z;\n    }\n  }\n\n  frags.finishLoading = true;\n\n  return globalOffset;\n}\n\n// Filter fragments based on specified object id list, by picking\n// up fragment whose id is in the specified id list, and dropping others.\n// This is used to produce a list of fragments that matches a search hit.\nfunction filterFragments(frags, ids) {\n  frags.length = ids.length;\n  frags.numLoaded = 0;\n  var numFrags = frags.length;\n  var bb = [Infinity, Infinity, Infinity, -Infinity, -Infinity, -Infinity];\n\n  var fragBoxes = new Float32Array(6 * numFrags);\n  var transforms = new Float32Array(12 * numFrags);\n  var materials = new Int32Array(numFrags);\n  var packIds = new Int32Array(numFrags);\n  var entityIndexes = new Int32Array(numFrags);\n  var visibilityFlags = new Uint16Array(numFrags);\n  var mesh2frag = {};\n\n  for (var i = 0; i < ids.length; ++i) {\n    var index = ids[i];\n\n    var idxOld = index * 6;\n    var idxNew = i * 6;\n    for (var j = 0; j < 6; ++j) {\n      fragBoxes[idxNew++] = frags.boxes[idxOld++];}\n\n    idxOld = index * 12;\n    idxNew = i * 12;\n    for (var j = 0; j < 12; ++j) {\n      transforms[idxNew++] = frags.transforms[idxOld++];}\n\n    materials[i] = frags.materials[index];\n    packIds[i] = frags.packIds[index];\n    entityIndexes[i] = frags.entityIndexes[index];\n    visibilityFlags[i] = frags.visibilityFlags[index];\n\n    // TODO: consolidate this with addToMeshMap.\n    var meshID = frags.packIds[index] + \":\" + frags.entityIndexes[index];\n    var meshRefs = mesh2frag[meshID];\n    if (meshRefs == undefined) {\n      mesh2frag[meshID] = i;\n    } else\n    if (!Array.isArray(meshRefs)) {\n      mesh2frag[meshID] = [meshRefs, i];\n    } else\n    {\n      meshRefs.push(i);\n    }\n\n    var bbIndex = i * 6;\n    for (var j = 0; j < 3; ++j) {\n      if (fragBoxes[bbIndex + j] < bb[j])\n      bb[j] = fragBoxes[bbIndex + j];}\n    for (var j = 3; j < 6; ++j) {\n      if (fragBoxes[bbIndex + j] > bb[j])\n      bb[j] = fragBoxes[bbIndex + j];}\n  }\n\n  frags.boxes = fragBoxes;\n  frags.transforms = transforms;\n  frags.materials = materials;\n  frags.packIds = packIds;\n  frags.entityIndexes = entityIndexes;\n  frags.mesh2frag = mesh2frag;\n  frags.visibilityFlags = visibilityFlags;\n\n  return bb;\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Geoms.js\":\n/*!*********************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Geoms.js ***!\n  \\*********************************************/\n/*! exports provided: readGeometry */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readGeometry\", function() { return readGeometry; });\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../compat */ \"./src/compat.js\");\n/* harmony import */ var _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../common/VbUtils */ \"./src/file-loaders/lmvtk/common/VbUtils.js\");\n\n\n//import { readOpenCTM_MG2 } from './OctmMG2';\n\n\"use strict\";\n\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n\nvar ntmp = new Float32Array(3);\n\nvar INV_PI = 1.0 / Math.PI;\n\nvar atan2 = Math.atan2;\nif (!Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isNodeJS\"])()) {\n  //Faster approximation to atan2\n  //http://math.stackexchange.com/questions/1098487/atan2-faster-approximation\n  //The algorithm does not deal with special cases such as x=0,y=0x=0,y=0,\n  //nor does it consider special IEEE-754 floating-point operands such as infinities and NaN.\n  atan2 = function atan2(y, x) {\n    var ax = Math.abs(x);\n    var ay = Math.abs(y);\n    //var a = (ax > ay) ? ay / ax : ax / ay;\n    var a = Math.min(ax, ay) / Math.max(ax, ay);\n    var s = a * a;\n    var r = ((-0.0464964749 * s + 0.15931422) * s - 0.327622764) * s * a + a;\n    if (ay > ax)\n    r = 1.57079637 - r;\n    if (x < 0)\n    r = 3.14159274 - r;\n    if (y < 0)\n    r = -r;\n    return r;\n  };\n}\n\nfunction readOpenCTM_RAW(stream, mesh, dstBuffer, startOffset, estimateSizeOnly) {\n\n  var readOpenCTMString = function readOpenCTMString() {\n    return stream.getString(stream.getInt32());\n  };\n\n  //Now do the data reads\n  var name = stream.getString(4);\n  if (name != \"INDX\") return null;\n\n  var vcount = mesh.vertexCount;\n  var tcount = mesh.triangleCount;\n  var stride = mesh.vbstride;\n\n  //We will create a single ArrayBuffer to back both the vertex and index buffers\n  //The indices will be places after the vertex information, because we need alignment\n  //of 4 bytes\n  var vbSizeFloat = vcount * stride;\n  var totalSizeInFloats = vbSizeFloat + (tcount * 3 * 2 + 3) / 4 | 0;\n\n  mesh.sharedBufferBytes = totalSizeInFloats * 4;\n\n  if (estimateSizeOnly) {\n    return;\n  }\n\n  var vbf;\n  if (!dstBuffer) {\n    dstBuffer = new ArrayBuffer(totalSizeInFloats * 4);\n    startOffset = 0;\n  }\n\n  vbf = mesh.vb = new Float32Array(dstBuffer, startOffset, vbSizeFloat);\n  mesh.indices = new Uint16Array(dstBuffer, startOffset + vbSizeFloat * 4, tcount * 3);\n  stream.getIndicesArray(vbf.buffer, startOffset + vbSizeFloat * 4, tcount * 3);\n\n  name = stream.getString(4);\n  if (name != \"VERT\") return null;\n\n  var vbi;\n  //See if we want to pack the normals into two shorts\n  if (mesh.vblayout.normal && mesh.vblayout.normal.itemSize === 2)\n  vbi = new Uint16Array(vbf.buffer, vbf.byteOffset, vbf.byteLength / 2);\n\n  //Read positions\n  stream.getVector3Array(vbf, vcount, mesh.vblayout['position'].offset, stride);\n\n  //Read normals\n  var i, t, offset;\n  if (mesh.flags & 1) {\n    name = stream.getString(4);\n    if (name != \"NORM\") return null;\n\n    if (vbi) {\n      if (ntmp.length < vcount * 3)\n      ntmp = new Float32Array(vcount * 3);\n      stream.getVector3Array(ntmp, vcount, 0, 3);\n\n      for (i = 0, offset = mesh.vblayout['normal'].offset;\n      i < vcount;\n      i++, offset += stride)\n      {\n        var pnx = (atan2(ntmp[i * 3 + 1], ntmp[i * 3]) * INV_PI + 1.0) * 0.5;\n        var pny = (ntmp[i * 3 + 2] + 1.0) * 0.5;\n\n        vbi[offset * 2] = pnx * 65535 | 0;\n        vbi[offset * 2 + 1] = pny * 65535 | 0;\n      }\n    } else {\n      stream.getVector3Array(vbf, vcount, mesh.vblayout['normal'].offset, stride);\n    }\n\n  }\n\n  //Read uv layers\n  for (t = 0; t < mesh.texMapCount; t++) {\n    name = stream.getString(4);\n    if (name != \"TEXC\") return null;\n\n    var uv = {\n      name: readOpenCTMString(),\n      file: readOpenCTMString() };\n\n    mesh.uvs.push(uv);\n\n    var uvname = \"uv\";\n    if (t)\n    uvname += (t + 1).toString();\n\n    stream.getVector2Array(vbf, vcount, mesh.vblayout[uvname].offset, stride);\n  }\n\n  var attributeOffset = stride - (mesh.attribMapCount || 0) * 3;\n\n  //Read vertex colors and uvw (and skip any other attributes that we don't know)\n  for (t = 0; t < mesh.attribMapCount; t++) {\n    name = stream.getString(4);\n    if (name != \"ATTR\") return null;\n\n    var attr = {\n      name: readOpenCTMString() };\n\n\n    // console.log(\"attribute\", attr.name);\n\n    var attrname;\n    if (attr.name.indexOf(\"Color\") != -1) //Special case of vertex colors\n      attrname = 'color';else\n    if (attr.name.indexOf(\"UVW\") != -1) //Only used by prism 3d wood.\n      attrname = 'uvw';else\n    {\n      //Other attributes, though we don't know what to do with those\n      mesh.attrs.push(attr);\n      stream.getBytes(vcount * 16); //skip past\n      continue;\n    }\n\n    mesh.vblayout[attrname] = { offset: attributeOffset, itemSize: 3 };\n\n    var v4 = [0, 0, 0, 0];\n    for (i = 0, offset = attributeOffset;\n    i < vcount;\n    i++, offset += stride) {\n      stream.getVector4(v4, 0);\n      vbf[offset] = v4[0];\n      vbf[offset + 1] = v4[1];\n      vbf[offset + 2] = v4[2];\n      //Ignoring the alpha term. For color attribute, we can actually pack it in a 4-byte attribute,\n      //but we do not know in advance (when we allocate the target buffer) if the OCTM attribute is UVW or color\n    }\n    attributeOffset += 3;\n  }\n\n}\n\n// Helper function for calculating new vertex for wide lines\nvar getLineSplitVertex = function getLineSplitVertex(stride, vbf, neighbourhoods, a, b) {\n  // New vertex position\n  var pos = {\n    x: vbf[stride * a],\n    y: vbf[stride * a + 1],\n    z: vbf[stride * a + 2] };\n\n  // Direction to the next vertex for segment (must be valid always)\n  var next = {\n    x: pos.x - vbf[stride * b],\n    y: pos.y - vbf[stride * b + 1],\n    z: pos.z - vbf[stride * b + 2] };\n\n\n  // Index of previous point\n  var prev_ind = neighbourhoods[a].next == b ? neighbourhoods[a].prev : neighbourhoods[a].next;\n\n  // Direction to previous point\n  var prev;\n  // If does not exist\n  if (prev_ind < 0) {\n    // mirror next direction\n    prev = {\n      x: next.x,\n      y: next.y,\n      z: next.z };\n\n  } else {\n    // else - set directly\n    prev = {\n      x: vbf[stride * prev_ind] - pos.x,\n      y: vbf[stride * prev_ind + 1] - pos.y,\n      z: vbf[stride * prev_ind + 2] - pos.z };\n\n  }\n\n  return {\n    pos: pos,\n    next: next,\n    prev: prev };\n\n};\n\n// convert a line mesh into specially organised triangles, which will be drawn\n// as lines with a specific width\nvar convertToWideLines = function convertToWideLines(mesh, stride, vbf, indexPairs, offset) {\n\n  var numCoords = 3;\n\n  // add some extra vertex data to the mesh\n  // prev & next are directions specific vertex positions, which are used to specify\n  // the offset direction in the shader\n  // side is the directed line width used for the magnitude of the offset in the shader\n  offset = mesh.vbstride;\n  mesh.vblayout['prev'] = { offset: offset, itemSize: numCoords };\n  offset += numCoords;\n  mesh.vblayout['next'] = { offset: offset, itemSize: numCoords };\n  offset += numCoords;\n  mesh.vblayout['side'] = { offset: offset, itemSize: 1 };\n\n  mesh.vbstride += 7;\n\n  // Count of shared vertexes\n  var connections = 0;\n\n  // Build neighbourhoods of each vertex\n  var neighbourhoods = new Array(mesh.vertexCount);\n  var i, j, n, a, b;\n  for (i = 0; i < mesh.vertexCount; ++i) {\n    neighbourhoods[i] = {\n      prev: -1, // index of previous vertex\n      next: -1, // index of next vertex\n      prev_seg: -1 // index of previous segment\n    };\n  }\n\n  for (j = 0; j < indexPairs; ++j) {\n    n = j * 2;\n    a = mesh.indices[n];\n    b = mesh.indices[n + 1];\n    neighbourhoods[a].next = b;\n    if (neighbourhoods[a].prev >= 0) {\n      ++connections;\n    }\n\n    neighbourhoods[b].prev = a;\n    neighbourhoods[b].prev_seg = j;\n    if (neighbourhoods[b].next >= 0) {\n      ++connections;\n    }\n  }\n\n  // Each segment will have its own vertexes\n  var newBaseVertexCount = indexPairs * 2;\n  var newBaseVertexies = new Array(newBaseVertexCount);\n\n  // Indexes contains line segments and additional connection for shared vertexes\n  var newIndices = new Uint16Array(2 * numCoords * (indexPairs + connections));\n  var meshIndex = 0;\n\n  // Split all vertexes and build indexes of all triangles\n  for (j = 0; j < indexPairs; ++j) {\n    n = j * 2;\n    a = mesh.indices[n];\n    b = mesh.indices[n + 1];\n    // New vertexes with calculated next and previous points\n    newBaseVertexies[n] = getLineSplitVertex(stride, vbf, neighbourhoods, a, b);\n    newBaseVertexies[n + 1] = getLineSplitVertex(stride, vbf, neighbourhoods, b, a);\n\n    // Segment triangles\n    a = n;\n    b = n + 1;\n    // First two coordinates form line segment are used in ray casting\n    newIndices[meshIndex++] = 2 * a + 1;\n    newIndices[meshIndex++] = 2 * b;\n    newIndices[meshIndex++] = 2 * a;\n    newIndices[meshIndex++] = 2 * b;\n    newIndices[meshIndex++] = 2 * b + 1;\n    newIndices[meshIndex++] = 2 * a;\n\n    // Connection triangles for shared vertexes, if exist\n    a = mesh.indices[n];\n    if (neighbourhoods[a].prev >= 0) {\n      b = neighbourhoods[a].prev_seg * 2 + 1;\n      a = n;\n\n      newIndices[meshIndex++] = 2 * b;\n      newIndices[meshIndex++] = 2 * a;\n      newIndices[meshIndex++] = 2 * b + 1;\n      newIndices[meshIndex++] = 2 * a + 1;\n      newIndices[meshIndex++] = 2 * a;\n      newIndices[meshIndex++] = 2 * b;\n    }\n  }\n  mesh.indices = newIndices;\n\n  // Finally, fill vertex buffer with new data\n  var newVertexCount = newBaseVertexCount * 2;\n  mesh.vb = new Float32Array(newVertexCount * mesh.vbstride);\n\n  offset = mesh.vblayout['position'].offset;\n  for (var c = 0; c < newBaseVertexCount; ++c) {\n    // Duplicate every vertex for each side\n    for (var side = 0; side < 2; ++side) {\n      // Vertex position\n      mesh.vb[offset] = newBaseVertexies[c].pos.x;\n      mesh.vb[offset + 1] = newBaseVertexies[c].pos.y;\n      mesh.vb[offset + 2] = newBaseVertexies[c].pos.z;\n      offset += stride;\n\n      // Previous vertex direction\n      mesh.vb[offset] = newBaseVertexies[c].prev.x;\n      mesh.vb[offset + 1] = newBaseVertexies[c].prev.y;\n      mesh.vb[offset + 2] = newBaseVertexies[c].prev.z;\n      offset += numCoords;\n\n      // Next vertex direction\n      mesh.vb[offset] = newBaseVertexies[c].next.x;\n      mesh.vb[offset + 1] = newBaseVertexies[c].next.y;\n      mesh.vb[offset + 2] = newBaseVertexies[c].next.z;\n      offset += numCoords;\n\n      // Side (offset direction)\n      mesh.vb[offset] = side ? -1 : 1;\n      offset += 1;\n    }\n  }\n\n  mesh.vertexCount = newVertexCount;\n\n  // flag to mark this mesh as special\n  mesh.isWideLines = true;\n};\n\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n//=====================================================================\n\n\nvar readOpenCTM = function readOpenCTM(stream, dstBuffer, startOffset, estimateSizeOnly, packNormals) {\n\n  var readOpenCTMString = function readOpenCTMString() {\n    return stream.getString(stream.getInt32());\n  };\n\n  var fourcc = stream.getString(4);\n  if (fourcc != \"OCTM\") return null;\n\n  var version = stream.getInt32();\n  if (version != 5) return null;\n\n  var method = stream.getString(3);\n  stream.getUint8(); //read the last 0 char of the RAW or MG2 fourCC.\n\n  var mesh = {\n    stream: null,\n    vertices: null,\n    indices: null,\n    normals: null,\n    colors: null,\n    uvs: [],\n    attrs: [] };\n\n\n  mesh.vertexCount = stream.getInt32();\n  mesh.triangleCount = stream.getInt32();\n  mesh.texMapCount = stream.getInt32();\n  mesh.attribMapCount = stream.getInt32();\n  mesh.flags = stream.getInt32();\n  mesh.comment = readOpenCTMString();\n\n  var usePackedNormals = packNormals;\n\n\n  //Calculate stride of the interleaved buffer we need\n  mesh.vbstride = 3; //position is always there\n  if (mesh.flags & 1)\n  mesh.vbstride += usePackedNormals ? 1 : 3; //normal\n  mesh.vbstride += 2 * (mesh.texMapCount || 0); //texture coords\n  mesh.vbstride += 3 * (mesh.attribMapCount || 0); //we now support color and uvw. Both of them use three floats.\n\n  mesh.vblayout = {};\n  var offset = 0;\n\n  mesh.vblayout['position'] = { offset: offset, itemSize: 3 };\n\n  offset += 3;\n  if (mesh.flags & 1) {\n    mesh.vblayout['normal'] = { offset: offset,\n      itemSize: usePackedNormals ? 2 : 3,\n      bytesPerItem: usePackedNormals ? 2 : 4,\n      normalize: usePackedNormals };\n\n    offset += usePackedNormals ? 1 : 3; //offset is counted in units of 4 bytes\n  }\n  if (mesh.texMapCount) {\n    for (var i = 0; i < mesh.texMapCount; i++) {\n      var uvname = \"uv\";\n      if (i)\n      uvname += (i + 1).toString();\n\n      mesh.vblayout[uvname] = { offset: offset, itemSize: 2 };\n      offset += 2;\n    }\n  }\n\n  //Now read and populate the mesh data\n  if (method == \"RAW\") {\n    readOpenCTM_RAW(stream, mesh, dstBuffer, startOffset, estimateSizeOnly);\n    if (!estimateSizeOnly) {\n      _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__[\"VBUtils\"].deduceUVRepetition(mesh);\n      _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__[\"VBUtils\"].computeBounds3D(mesh);\n    }\n    return mesh;\n  } else\n  if (method == \"MG2\") {\n    //This code path is never used, since MG2 compression is disabled at the LMVTK C++ level\n    debug(\"readOpenCTM_MG2(stream, mesh, dstBuffer, startOffset, estimateSizeOnly) not supported\");\n    if (!estimateSizeOnly) {\n      _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__[\"VBUtils\"].deduceUVRepetition(mesh);\n      _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__[\"VBUtils\"].computeBounds3D(mesh);\n    }\n    return mesh;\n  } else\n\n  return null;\n};\n\n\nvar readLinesOrPoints = function readLinesOrPoints(pfr, tse, estimateSizeOnly, lines) {\n\n  //TODO: Line geometry does not go into shared buffers yet\n  if (estimateSizeOnly)\n  return null;\n\n  // Initialize mesh\n  var mesh = {\n    vertices: null,\n    indices: null,\n    colors: null,\n    normals: null,\n    uvs: [],\n    attrs: [],\n    lineWidth: 1.0 };\n\n\n  // Read vertex count, index count, polyline bound count\n  var indexCount;\n  if (lines) {\n    // Read vertex count, index count, polyline bound count\n    var polyLineBoundCount;\n    if (tse.version > 1) {\n      mesh.vertexCount = pfr.readU16();\n      indexCount = pfr.readU16();\n      polyLineBoundCount = pfr.readU16();\n\n      if (tse.version > 2) {\n        mesh.lineWidth = pfr.readF32();\n      }\n    } else {\n      mesh.vertexCount = pfr.readU32V();\n      indexCount = pfr.readU32V();\n      polyLineBoundCount = pfr.readU32V();\n    }\n    mesh.isLines = true;\n  } else {\n    // Read vertex count, index count, point size\n    mesh.vertexCount = pfr.readU16();\n    indexCount = pfr.readU16();\n    mesh.pointSize = pfr.readF32();\n    mesh.isPoints = true;\n  }\n\n  // Determine if color is defined\n  var hasColor = pfr.stream.getUint8() != 0;\n\n\n  //Calculate stride of the interleaved buffer we need\n  mesh.vbstride = 3; //position is always there\n  if (hasColor)\n  mesh.vbstride += 3; //we only interleave the color attribute, and we reduce that to RGB from ARGB.\n\n  mesh.vblayout = {};\n  var offset = 0;\n\n  mesh.vblayout['position'] = { offset: offset, itemSize: 3 };\n\n  offset += 3;\n  if (hasColor) {\n    mesh.vblayout['color'] = { offset: offset, itemSize: 3 };\n  }\n\n  mesh.vb = new Float32Array(mesh.vertexCount * mesh.vbstride);\n\n\n  // Read vertices\n  var vbf = mesh.vb;\n  var stride = mesh.vbstride;\n  var stream = pfr.stream;\n\n  stream.getVector3Array(vbf, mesh.vertexCount, mesh.vblayout['position'].offset, stride);\n\n  // Determine color if specified\n  var c, cEnd;\n  if (hasColor) {\n    for (c = 0, offset = mesh.vblayout['color'].offset, cEnd = mesh.vertexCount;\n    c < cEnd;\n    c++, offset += stride)\n    {\n      vbf[offset] = stream.getFloat32();\n      vbf[offset + 1] = stream.getFloat32();\n      vbf[offset + 2] = stream.getFloat32();\n      stream.getFloat32(); //skip alpha -- TODO: convert color to ARGB 32 bit integer in the vertex layout and shader\n    }\n  }\n\n  // Copies bytes from buffer\n  var forceCopy = function forceCopy(b) {\n    return b.buffer.slice(b.byteOffset, b.byteOffset + b.length);\n  };\n\n  // Read indices and polyline bound buffer\n  if (lines) {\n    var indices;\n    var polyLineBoundBuffer;\n    if (tse.version > 1) {\n      // 16 bit format\n      indices = new Uint16Array(forceCopy(stream.getBytes(indexCount * 2)));\n      polyLineBoundBuffer = new Uint16Array(forceCopy(stream.getBytes(polyLineBoundCount * 2)));\n    } else\n    {\n      // 32 bit format\n      indices = new Int32Array(forceCopy(stream.getBytes(indexCount * 4)));\n      polyLineBoundBuffer = new Int32Array(forceCopy(stream.getBytes(polyLineBoundCount * 4)));\n    }\n\n    // three.js uses GL-style index pairs in its index buffer. We need one pair\n    // per segment in each polyline\n    var indexPairs = polyLineBoundBuffer[polyLineBoundCount - 1] - polyLineBoundCount + 1;\n\n    mesh.indices = new Uint16Array(2 * indexPairs);\n\n    // Extract the individual line segment index pairs\n    var meshIndex = 0;\n    for (var i = 0; i + 1 < polyLineBoundCount; i++) {\n      for (var j = polyLineBoundBuffer[i]; j + 1 < polyLineBoundBuffer[i + 1]; j++) {\n        mesh.indices[meshIndex++] = indices[j];\n        mesh.indices[meshIndex++] = indices[j + 1];\n      }\n    }\n  } else {\n    mesh.indices = new Uint16Array(forceCopy(stream.getBytes(indexCount * 2)));\n  }\n\n  if (mesh.lineWidth != 1.0) {\n    convertToWideLines(mesh, stride, vbf, indexPairs, offset);\n  }\n\n  _common_VbUtils__WEBPACK_IMPORTED_MODULE_1__[\"VBUtils\"].computeBounds3D(mesh);\n\n  return mesh;\n};\n\nvar readLines = function readLines(pfr, tse, estimateSizeOnly) {\n  return readLinesOrPoints(pfr, tse, estimateSizeOnly, true);\n};\n\nvar readPoints = function readPoints(pfr, tse, estimateSizeOnly) {\n  return readLinesOrPoints(pfr, tse, estimateSizeOnly, false);\n};\n\nfunction readGeometry(pfr, entry, options) {\n  var tse = pfr.seekToEntry(entry);\n  if (!tse)\n  return null;\n\n  if (tse.entryType == \"Autodesk.CloudPlatform.OpenCTM\") {\n    return readOpenCTM(pfr.stream, options.dstBuffer, options.startOffset, options.estimateSizeOnly, options.packNormals);\n  } else\n  if (tse.entryType == \"Autodesk.CloudPlatform.Lines\") {\n    return readLines(pfr, tse, options.estimateSizeOnly);\n  } else\n  if (tse.entryType == \"Autodesk.CloudPlatform.Points\") {\n    return readPoints(pfr, tse, options.estimateSizeOnly);\n  }\n\n  return null;\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Instances.js\":\n/*!*************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Instances.js ***!\n  \\*************************************************/\n/*! exports provided: readInstance, readInstanceTree */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readInstance\", function() { return readInstance; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readInstanceTree\", function() { return readInstanceTree; });\n\n\nfunction readInstance(pfr, entry, placementTransform, globalOffset) {\n  var tse = pfr.seekToEntry(entry);\n  if (!tse)\n  return null;\n  if (tse.version > 2 /*Constants::InstanceVersion*/)\n    return null;\n\n  var isVisible = true;\n  if (tse.version > 1) {\n    // Instances v2+ include a flag byte, the LSB of which denotes visibility\n    var flags = pfr.readU8();\n    isVisible = (flags & 0x01) != 0;\n  }\n\n  return {\n    definition: pfr.stream.getUint32(),\n    transform: pfr.readTransform(undefined, undefined, undefined, placementTransform, globalOffset),\n    instanceNodePath: pfr.readPathID() };\n\n}\n\n\n\nvar NodeType = {\n  NT_Inner: 0,\n  NT_Geometry: 1,\n  NT_Camera: 2,\n  NT_Light: 3 };\n\n\nfunction readInstanceTree(pfr, version) {\n\n  var transforms = [];\n  var dbIds = [];\n  var fragIds = [];\n  var childCounts = [];\n  var nodeIndex = 0;\n  var s = pfr.stream;\n\n  while (s.offset < s.byteLength - 8 - 1) {\n\n    pfr.readTransform(nodeIndex, transforms, nodeIndex * 12, undefined, undefined, undefined);\n\n    // Version 1-4 had optional \"shared nodes\" that were never used in practice. If found, consume and ignore.\n    if (version < 5) {\n      var hasSharedNode = s.getUint8();\n      if (hasSharedNode) {\n        s.getUint32();\n      }\n    }\n\n    var nodeType = s.getUint8();\n\n    // Version 5 introduced a flags byte and the visibility flag.\n    if (version >= 5) {\n      var flags = s.getUint8();\n      var visible = !!(flags & 1);\n    }\n\n    // Version 3 introduced the database ID\n    if (version >= 3) {\n      dbIds[nodeIndex] = s.getVarints();\n    }\n\n    if (nodeIndex) {\n      // Not a root, behavior depends on type\n      // Leaf, instantiate and add fragment references before returning\n      switch (nodeType) {\n\n        case NodeType.NT_Inner:\n          break;\n        case NodeType.NT_Geometry:{\n            if (version < 2) {\n              var fragCount = s.getUint16();\n              if (fragCount === 1) {\n                fragIds[nodeIndex] = s.getUint32();\n              } else if (fragCount > 0) {\n                var flist = [];\n                for (var i = 0; i < fragCount; i++) {\n                  flist.push(s.getUint32());}\n                fragIds[nodeIndex] = flist;\n              }\n            } else {\n              var fragCount = s.getVarints();\n              if (fragCount === 1) {\n                fragIds[nodeIndex] = s.getVarints();\n              } else if (fragCount > 0) {\n                var flist = [];\n                for (var i = 0; i < fragCount; i++) {\n                  flist.push(s.getVarints());}\n                fragIds[nodeIndex] = flist;\n              }\n            }\n          }\n          break;\n        case NodeType.NT_Camera:\n        case NodeType.NT_Light:{\n            var hasInstanceEntryId = s.getUint8();\n            if (hasInstanceEntryId) {\n              s.getUint32();\n            }\n          }\n          break;\n        default:\n          debug(\"Unrecognized instance tree node type.\");\n          break;}\n\n    }\n\n    var childCount = 0;\n    if (nodeType === NodeType.NT_Inner) {\n      if (version < 2) {\n        childCount = s.getUint16();\n      } else {\n        childCount = s.getVarints();\n      }\n    }\n    childCounts[nodeIndex] = childCount;\n\n    nodeIndex++;\n  }\n\n  var dbIdBuffer = new Uint32Array(dbIds.length);\n  dbIdBuffer.set(dbIds);\n\n  var xformBuffer = new Float32Array(transforms.length);\n  xformBuffer.set(transforms);\n\n  var childCountsBuffer = new Uint32Array(childCounts.length);\n  childCountsBuffer.set(childCounts);\n\n  return { dbIds: dbIdBuffer, fragIds: fragIds, transforms: xformBuffer, childCounts: childCountsBuffer };\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Lights.js\":\n/*!**********************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Lights.js ***!\n  \\**********************************************/\n/*! exports provided: readLightDefinition */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"readLightDefinition\", function() { return readLightDefinition; });\n\n\n\nfunction readLightDefinition(pfr, entry) {\n  var tse = pfr.seekToEntry(entry);\n  if (!tse)\n  return null;\n  if (tse.version > 1 /*Constants::LightDefinitionVersion*/)\n    return null;\n\n  var s = pfr.stream;\n\n  var light = {\n    position: pfr.readVector3f(),\n    dir: pfr.readVector3f(),\n    r: s.getFloat32(),\n    g: s.getFloat32(),\n    b: s.getFloat32(),\n    intensity: s.getFloat32(),\n    spotAngle: s.getFloat32(),\n    size: s.getFloat32(),\n    type: s.getUint8() };\n\n\n  return light;\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/PackReader.js\":\n/*!**************************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/PackReader.js ***!\n  \\**************************************************/\n/*! exports provided: PackFileReader */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"PackFileReader\", function() { return PackFileReader; });\n/* harmony import */ var _common_InputStream__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../common/InputStream */ \"./src/file-loaders/lmvtk/common/InputStream.js\");\n/* harmony import */ var _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../wgs/scene/LmvMatrix4 */ \"./src/wgs/scene/LmvMatrix4.js\");\n\n\n\n\n\"use strict\";\n\nvar warnedGzip = false;\n\n/** @constructor */\nfunction PackFileReader(data)\n{\n  var stream = this.stream = new _common_InputStream__WEBPACK_IMPORTED_MODULE_0__[\"InputStream\"](data);\n\n  var len = stream.getInt32();\n  this.type = stream.getString(len);\n  this.version = stream.getInt32();\n\n  this.types = null;\n  this.entryOffsets = [];\n\n  //read the table of contents\n  {\n    var offset = stream.offset;\n\n    // Jump to file footer.\n    stream.seek(stream.byteLength - 8);\n\n    // Jump to toc.\n    var tocOffset = stream.getUint32();\n    this.typesOffset = stream.getUint32();\n\n    // Populate type sets.\n    stream.seek(this.typesOffset);\n    var typesCount = this.readU32V();\n    this.types = [];\n    for (var i = 0; i < typesCount; ++i) {\n      this.types.push({\n        \"entryClass\": this.readString(),\n        \"entryType\": this.readString(),\n        \"version\": this.readU32V() });}\n\n\n    // Populate data offset list.\n    stream.seek(tocOffset);\n    var entryCount = this.readU32V();\n    var dso = this.entryOffsets;\n    for (var i = 0; i < entryCount; ++i) {\n      dso.push(stream.getUint32());}\n\n    // Restore sanity of the world.\n    stream.seek(offset);\n  }\n};\n\nPackFileReader.prototype.readVarint = function () {\n  var b;\n  var value = 0;\n  var shiftBy = 0;\n  do {\n    b = this.stream.getUint8();\n    value |= (b & 0x7f) << shiftBy;\n    shiftBy += 7;\n  } while (b & 0x80);\n  return value;\n};\nPackFileReader.prototype.readU32V = PackFileReader.prototype.readVarint;\n\nPackFileReader.prototype.readU16 = function () {\n  return this.stream.getUint16();\n};\n\nPackFileReader.prototype.readU8 = function () {\n  return this.stream.getUint8();\n};\n\nPackFileReader.prototype.readString = function () {\n  return this.stream.getString(this.readU32V());\n};\n\nPackFileReader.prototype.readVector3f = function () {\n  var s = this.stream;\n  return { x: s.getFloat32(), y: s.getFloat32(), z: s.getFloat32() };\n};\n\nPackFileReader.prototype.readF32 = function () {\n  return this.stream.getFloat32();\n};\n\nPackFileReader.prototype.readVector3d = function () {\n\n  var t = { x: 0, y: 0, z: 0 };\n\n  return function () {\n    var s = this.stream;\n    t.x = s.getFloat64();\n    t.y = s.getFloat64();\n    t.z = s.getFloat64();\n\n    return t;\n  };\n}();\n\nPackFileReader.prototype.readQuaternionf = function () {\n\n  var q = { x: 0, y: 0, z: 0, w: 0 };\n\n  return function () {\n    var s = this.stream;\n    q.x = s.getFloat32();\n    q.y = s.getFloat32();\n    q.z = s.getFloat32();\n    q.w = s.getFloat32();\n\n    return q;\n  };\n\n}();\n\nPackFileReader.prototype.readMatrix3f = function () {\n\n  var _m = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__[\"LmvMatrix4\"]();\n\n  return function (dst) {\n    if (!dst) dst = _m;\n\n    var s = this.stream;\n    dst.identity();\n    for (var i = 0; i < 3; ++i) {\n      for (var j = 0; j < 3; ++j) {\n        dst.elements[4 * i + j] = s.getFloat32();}}\n\n    return dst;\n  };\n\n}();\n\n\n\nPackFileReader.prototype.readTransform = function () {\n\n  var s = { x: 1, y: 1, z: 1 };\n  var m = new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__[\"LmvMatrix4\"](true);\n\n  return function (entityIndex, buffer, offset, placementTransform, globalOffset, originalTranslation)\n  {\n    var stream = this.stream;\n    var t, q;\n\n    var transformType = stream.getUint8();\n\n    switch (transformType) {\n\n      case 4 /*TransformType.Identity*/:{\n          m.identity();\n        }break;\n      case 0 /*TransformType.Translation*/:{\n          t = this.readVector3d();\n          m.makeTranslation(t.x, t.y, t.z);\n        }break;\n      case 1 /*TransformType.RotationTranslation*/:{\n          q = this.readQuaternionf();\n          t = this.readVector3d();\n          s.x = 1;s.y = 1;s.z = 1;\n          m.compose(t, q, s);\n        }break;\n      case 2 /*TransformType.UniformScaleRotationTranslation*/:{\n          var scale = stream.getFloat32();\n          q = this.readQuaternionf();\n          t = this.readVector3d();\n          s.x = scale;s.y = scale;s.z = scale;\n          m.compose(t, q, s);\n        }break;\n      case 3 /*TransformType.AffineMatrix*/:{\n          this.readMatrix3f(m);\n          t = this.readVector3d();\n          m.setPosition(t);\n        }break;\n      default:\n        break; //ERROR\n    }\n\n    //Report the original translation term to the caller, if they need it.\n    //This is only required when reading fragment bounding boxes, where the translation\n    //term of this matrix is subtracted from the bbox terms.\n    if (originalTranslation) {\n      originalTranslation[0] = m.elements[12];\n      originalTranslation[1] = m.elements[13];\n      originalTranslation[2] = m.elements[14];\n    }\n\n    //Apply any placement transform\n    if (placementTransform) {\n      m.multiplyMatrices(placementTransform, m);\n    }\n\n    //Apply global double precision offset on top\n    if (globalOffset) {\n      m.elements[12] -= globalOffset.x;\n      m.elements[13] -= globalOffset.y;\n      m.elements[14] -= globalOffset.z;\n    }\n\n    //Store result back into single precision matrix or array\n    if (entityIndex !== undefined) {\n      var src = m.elements;\n      // Sometimes we don't want to keep this data (e.g. when we are probing the fragment list\n      // to find the data base id to fragment index mappings used for fragment filtering) so we\n      // pass a null buffer and if that is the case, bail out here.\n      if (!buffer) return;\n      buffer[offset + 0] = src[0];buffer[offset + 1] = src[1];buffer[offset + 2] = src[2];\n      buffer[offset + 3] = src[4];buffer[offset + 4] = src[5];buffer[offset + 5] = src[6];\n      buffer[offset + 6] = src[8];buffer[offset + 7] = src[9];buffer[offset + 8] = src[10];\n      buffer[offset + 9] = src[12];buffer[offset + 10] = src[13];buffer[offset + 11] = src[14];\n    } else\n    {\n      return new _wgs_scene_LmvMatrix4__WEBPACK_IMPORTED_MODULE_1__[\"LmvMatrix4\"]().copy(m);\n    }\n  };\n\n}();\n\nPackFileReader.prototype.getEntryCounts = function () {\n  return this.entryOffsets.length;\n};\n\nPackFileReader.prototype.seekToEntry = function (entryIndex) {\n  var count = this.getEntryCounts();\n  if (entryIndex >= count)\n  return null;\n\n  // Read the type index and populate the entry data\n  this.stream.seek(this.entryOffsets[entryIndex]);\n  var typeIndex = this.stream.getUint32();\n  if (typeIndex >= this.types.length)\n  return null;\n\n  return this.types[typeIndex];\n};\n\n\nPackFileReader.prototype.readPathID = function () {\n  var s = this.stream;\n\n  //Construct a /-delimited string as the path to a node\n  //TODO: in case we need a split representation (e.g. to follow paths), then\n  //an array of numbers might be better to return from here.\n  if (this.version < 2) {\n    var pathLength = s.getUint16();\n    if (!pathLength)\n    return null;\n\n    //The first number in a path ID is always zero (root)\n    //so we skip adding it to the path string here.\n    //Remove this section if that is not the case in the future.\n    s.getUint16();\n    if (pathLength == 1)\n    return \"\";\n\n    var path = s.getUint16();\n    for (var i = 2; i < pathLength; ++i) {\n      path += \"/\" + s.getUint16();\n    }\n  } else\n  {\n    var pathLength = this.readU32V();\n    if (!pathLength)\n    return null;\n\n    //The first number in a path ID is always zero (root)\n    //so we skip adding it to the path string here.\n    //Remove this section if that is not the case in the future.\n    this.readU32V();\n    if (pathLength == 1)\n    return \"\";\n\n    var path = this.readU32V();\n    for (var i = 2; i < pathLength; ++i) {\n      path += \"/\" + this.readU32V();\n    }\n  }\n  return path;\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/lmvtk/svf/Package.js\":\n/*!***********************************************!*\\\n  !*** ./src/file-loaders/lmvtk/svf/Package.js ***!\n  \\***********************************************/\n/*! exports provided: Package */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Package\", function() { return Package; });\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../../compat */ \"./src/compat.js\");\n/* harmony import */ var _wgs_scene_BVHBuilder__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../../wgs/scene/BVHBuilder */ \"./src/wgs/scene/BVHBuilder.js\");\n/* harmony import */ var _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../../../wgs/scene/LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/* harmony import */ var _net_Xhr__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../../net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\n/* harmony import */ var _common_InputStream__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../common/InputStream */ \"./src/file-loaders/lmvtk/common/InputStream.js\");\n/* harmony import */ var _PackReader__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./PackReader */ \"./src/file-loaders/lmvtk/svf/PackReader.js\");\n/* harmony import */ var _Fragments__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./Fragments */ \"./src/file-loaders/lmvtk/svf/Fragments.js\");\n/* harmony import */ var _Instances__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./Instances */ \"./src/file-loaders/lmvtk/svf/Instances.js\");\n/* harmony import */ var _common_SvfPlacementUtils__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ../common/SvfPlacementUtils */ \"./src/file-loaders/lmvtk/common/SvfPlacementUtils.js\");\n/* harmony import */ var _Cameras__WEBPACK_IMPORTED_MODULE_9__ = __webpack_require__(/*! ./Cameras */ \"./src/file-loaders/lmvtk/svf/Cameras.js\");\n/* harmony import */ var _Lights__WEBPACK_IMPORTED_MODULE_10__ = __webpack_require__(/*! ./Lights */ \"./src/file-loaders/lmvtk/svf/Lights.js\");\n\n\n\n\n\n\n\n\n\n\n\n\n\nvar Zlib = __webpack_require__(/*! ../../../../thirdparty/zlib/unzip.min.js */ \"./thirdparty/zlib/unzip.min.js\").Zlib;\n\n\n/** @constructor */\nfunction Package(zipPack) {\n\n  this.unzip = new Zlib.Unzip(zipPack);\n\n  this.manifest = null;\n\n  this.materials = null; //The materials json as it came from the SVF\n\n  this.metadata = null; //metadata json\n\n  this.fragments = null; //will be a FragList\n\n  this.geompacks = [];\n\n  //TODO:\n  //Those will not be parsed immediately\n  //but we will remember the raw arrays\n  //and fire off async workers to parse\n  //them later, once we are loading geometry packs\n  this.instances = [];\n\n  this.cameras = [];\n  this.lights = [];\n\n  this.propertydb = {\n    attrs: [],\n    avs: [],\n    ids: [],\n    values: [],\n    offsets: [] };\n\n\n  this.bbox = null; //Overall scene bounds\n\n  this.animations = null; // animations json\n\n  this.pendingRequests = 0;\n\n  this.globalOffset = { x: 0, y: 0, z: 0 };\n\n  this.topologyPath = null; // string path to the topology file\n\n}\n\n\n\nPackage.prototype.loadAsyncResource = function (loadContext, resourcePath, contents, callback) {\n\n  //Data is immediately available from the SVF zip\n  if (contents) {\n    callback(contents);\n    return;\n  }\n\n  //Launch an XHR to load the data from external file\n  var svf = this;\n\n  this.pendingRequests++;\n\n  function xhrCB(responseData) {\n    svf.pendingRequests--;\n\n    callback(responseData);\n\n    if (svf.pendingRequests == 0)\n    svf.postLoad(loadContext);\n  }\n\n  _net_Xhr__WEBPACK_IMPORTED_MODULE_3__[\"ViewingService\"].getItem(loadContext, loadContext.basePath + resourcePath,\n  xhrCB,\n  loadContext.onFailureCallback);\n\n\n};\n\nPackage.prototype.loadManifest = function (loadContext) {\n  // TODO: zlib.js throws exceptions on failure;\n  // it doesn't return null as this code seems to assume.\n  // yes, LoadContext is passed in, but is not used.\n  var manifestJson = this.unzip.decompress(\"manifest.json\");\n  if (!manifestJson)\n  return false;\n\n  var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](manifestJson);\n  this.manifest = JSON.parse(jdr.getString(manifestJson.byteLength));\n};\n\n// Replace default globalOffset from SvfPlacementOffset by a recomputed one computed based on Fragment bboxes.\nPackage.prototype.applyLargeBoxOffset = function (offset) {\n  if (offset && (\n  offset.x !== this.globalOffset.x ||\n  offset.y !== this.globalOffset.y ||\n  offset.z !== this.globalOffset.z))\n  {\n    // So far, bbox was in viewer-coords, assuming the default globalOffset. Since we modified the offset,\n    // we have to adjust the bbox now.\n    if (!this.bbox.empty()) {\n      this.bbox.translate({\n        x: this.globalOffset.x - offset.x,\n        y: this.globalOffset.y - offset.y,\n        z: this.globalOffset.z - offset.z });\n\n    }\n\n    // self.globalOffset may not be an LMVVector3, but in that case\n    // offset should be self.GlobalOffset, so this should be OK\n    this.verylargebbox = true;\n    this.globalOffset.copy(offset);\n    Object(_common_SvfPlacementUtils__WEBPACK_IMPORTED_MODULE_8__[\"calculatePlacementWithOffset\"])(this, this.placementTransform);\n  }\n};\n\nPackage.prototype.parseFragmentList = function (asset, loadContext, path, contents) {\n\n  var self = this;\n  this.loadAsyncResource(loadContext, path, contents, function (data) {\n    var pfr = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n\n    //Use a single large blocks to store all fragment elements\n    //TODO: perhaps have a FragList per pack file to keep block size down?\n    var frags = self.fragments = new _Fragments__WEBPACK_IMPORTED_MODULE_6__[\"FragList\"]();\n    var offset = Object(_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"readFragments\"])(pfr, frags, loadContext.globalOffset, loadContext.placementTransform,\n    loadContext.fragmentTransformsDouble, undefined, self.bbox, self.globalOffset);\n    pfr = null;\n\n    self.applyLargeBoxOffset(offset);\n  });\n};\n\nPackage.prototype.parseGeometryMetadata = function (asset, loadContext, path, contents) {\n  var self = this;\n  this.loadAsyncResource(loadContext, path, contents, function (data) {\n    var pfr = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n\n    self.geomMetadata = {};\n    Object(_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"readGeometryMetadata\"])(pfr, self.geomMetadata);\n    self.numGeoms = self.geomMetadata.primCounts.length;\n  });\n};\n\n\nPackage.prototype.parseInstanceTree = function (loadContext, path, contents, version) {\n\n  var that = this;\n\n  this.loadAsyncResource(loadContext, path, contents, function (data) {\n    var pfr = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n    that.instanceTransforms = Object(_Instances__WEBPACK_IMPORTED_MODULE_7__[\"readInstanceTree\"])(pfr, version);\n  });\n\n};\n\n\nPackage.prototype.loadRemainingSvf = function (loadContext) {\n  var svf = this;\n\n  var unzip = this.unzip;\n\n  //var filenames = unzip.getFilenames();\n  this.manifest = loadContext.manifest;\n  var manifest = this.manifest;\n\n  var assets = manifest[\"assets\"];\n\n  var metadataJson = unzip.decompress(\"metadata.json\");\n  var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](metadataJson);\n\n  // Test to see if this is json (not a binary header)\n  // Done by verifying that there is no 0 (Hence ASCII)\n  if (metadataJson.byteLength > 3 && metadataJson[3] !== 0) {\n    this.metadata = JSON.parse(jdr.getString(metadataJson.byteLength)).metadata;\n\n    Object(_common_SvfPlacementUtils__WEBPACK_IMPORTED_MODULE_8__[\"initPlacement\"])(this, loadContext);\n  }\n\n  //Version strings seem to be variable at the moment.\n  //var manifestVersion = manifest[\"manifestversion\"];\n  //if (   manifest[\"name\"] != \"LMV Manifest\"\n  //    || manifest[\"manifestversion\"] != 1)\n  //    return false;\n\n  this.packFileTotalSize = 0;\n  this.primitiveCount = 0;\n\n  var typesetsList = manifest[\"typesets\"];\n  var typesets = {};\n  for (var i = 0; i < typesetsList.length; i++) {\n    var ts = typesetsList[i];\n    typesets[ts['id']] = ts['types'];\n  }\n\n  //Loop through the assets, and schedule non-embedded\n  //ones for later loading.\n  //TODO: currently only geometry pack files are stored for later\n  //load and other assets will be loaded by this worker thread before\n  //we return to the SvfLoader in the main thread.\n\n  for (var i = 0; i < assets.length; i++)\n  {\n    var asset = assets[i];\n    if (Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isMobileDevice\"])() && asset.id === \"Set.bin\")\n    continue;\n    var type = asset[\"type\"];\n    if (type.indexOf(\"Autodesk.CloudPlatform.\") == 0)\n    type = type.substr(23);\n    var uri = asset[\"URI\"];\n    var typeset = asset[\"typeset\"] ? typesets[asset[\"typeset\"]] : null;\n    var usize = asset[\"usize\"] || 0;\n    var megaBytes = Math.round(usize / 1048576 * 100000) / 100000 | 0;\n\n    //If the asset is a geometry pack or property pack\n    //just remember it for later demand loading\n    if (uri.indexOf(\"embed:/\") != 0) {\n      if (type == \"PackFile\") {\n        var typeclass = typeset ? typeset[0][\"class\"] : null;\n\n        if (typeclass == \"Autodesk.CloudPlatform.Geometry\") {\n\n          this.packFileTotalSize += usize;\n\n          this.geompacks.push({ id: asset[\"id\"], uri: uri, usize: usize });\n        }\n      } else\n      if (type == \"PropertyAttributes\") {\n        this.propertydb.attrs.push({ path: uri });\n      } else\n      if (type == \"PropertyAVs\") {\n        this.propertydb.avs.push({ path: uri });\n      } else\n      if (type == \"PropertyIDs\") {\n        this.propertydb.ids.push({ path: uri });\n      } else\n      if (type == \"PropertyOffsets\") {\n        this.propertydb.offsets.push({ path: uri });\n      } else\n      if (type == \"PropertyValues\") {\n        this.propertydb.values.push({ path: uri });\n      }\n    }\n\n    //parse assets which we will need immediately when\n    // setting up the scene (whether embedded or not)\n    var path = asset[\"URI\"];\n    var contents = null; //if the data was in the zip, this will contain it\n    if (path.indexOf(\"embed:/\") == 0) {\n      path = path.substr(7);\n      contents = unzip.decompress(path);\n    }\n\n    if (type == \"ProteinMaterials\") {\n      //For simple materials, we want the file named \"Materials.json\" and not \"ProteinMaterials.json\"\n      if (path.indexOf(\"Protein\") == -1) {\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](data);\n          var byteLength = data.byteLength;\n          if (0 < byteLength) {\n            svf.materials = JSON.parse(jdr.getString(byteLength));\n          } else {\n            svf.materials = null;\n          }\n        });\n      } else {\n        //Also parse the Protein materials -- at the moment this helps\n        //With some Prism materials that have properties we can handle, but\n        //are not in the Simple variant.\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](data);\n          var byteLength = data.byteLength;\n          if (0 < byteLength) {\n            try {\n              svf.proteinMaterials = JSON.parse(jdr.getString(byteLength));\n            } catch (e) {\n              //TS: This is dumb, but what can we do... Revit extractor had (has?) a bug where\n              //materials are written as ANSI instead of UTF8 encoded. So we have this fallback attempt\n              var ansi = \"\";\n              for (var i = 0; i < data.length; i++) {\n                ansi += String.fromCharCode(data[i]);}\n\n              try {\n                svf.proteinMaterials = JSON.parse(ansi);\n              } catch (e) {\n                console.error(\"Failed to parse Protein materials file either as UTF8 or ANSI\");\n              }\n            }\n          } else {\n            svf.proteinMaterials = null;\n          }\n        });\n      }\n    } else\n    if (type == \"StandardMaterials\") {\n\n      this.loadAsyncResource(loadContext, path, contents, function (data) {\n        var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](data);\n        var byteLength = data.byteLength;\n        if (0 < byteLength) {\n          var strContent = jdr.getString(byteLength);\n          svf.stdSurfMats = JSON.parse(strContent);\n        } else {\n          svf.stdSurfMats = null;\n        }\n      });\n    } else\n    if (type == \"FragmentList\") {\n\n      this.parseFragmentList(asset, loadContext, path, contents);\n\n    } else\n    if (type == \"GeometryMetadataList\") {\n\n      this.parseGeometryMetadata(asset, loadContext, path, contents);\n\n    } else\n    if (type == \"PackFile\") {\n\n      if (path.indexOf(\"CameraDefinitions.bin\") != -1) {\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          svf.camDefPack = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n        });\n      } else\n\n      if (path.indexOf(\"CameraList.bin\") != -1) {\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          svf.camInstPack = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n        });\n      } else\n\n      if (path.indexOf(\"LightDefinitions.bin\") != -1) {\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          svf.lightDefPack = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n        });\n      } else\n\n      if (path.indexOf(\"LightList.bin\") != -1) {\n        this.loadAsyncResource(loadContext, path, contents, function (data) {\n          svf.lightInstPack = new _PackReader__WEBPACK_IMPORTED_MODULE_5__[\"PackFileReader\"](data);\n        });\n      }\n    } else\n    if (type == \"Animations\") {\n      this.loadAsyncResource(loadContext, path, contents, function (data) {\n        var jdr = new _common_InputStream__WEBPACK_IMPORTED_MODULE_4__[\"InputStream\"](data);\n        var byteLength = data.byteLength;\n        if (0 < byteLength) {\n          svf.animations = JSON.parse(jdr.getString(byteLength));\n        } else {\n          svf.animations = null;\n        }\n      });\n    } else\n    if (type == \"Topology\") {\n\n      // save the path for later download.\n      svf.topologyPath = loadContext.basePath + path;\n      svf.topologySizeMB = megaBytes;\n\n    } else\n    if (loadContext.loadInstanceTree && (\n    type == \"InstanceTree\" || type == \"InstanceTreeTree\")) {//Yes, the typo does occur in some older files\n\n      //Instance tree node serialization version is stored in the type set\n      var version = typeset ? typeset[0][\"version\"] : 1;\n\n      this.parseInstanceTree(loadContext, path, contents, version);\n    }\n  }\n\n\n  if (this.pendingRequests == 0)\n  this.postLoad(loadContext);\n\n  delete this.unzip;\n};\n\nPackage.prototype.addTransparencyFlagsToMaterials = function (mats) {\n  for (var id in mats) {\n    var mat = mats[id];\n    var userAssets = mat[\"userassets\"];\n    var innerMats = mat[\"materials\"];\n    var innerMat = innerMats[userAssets[0]];\n    mat.transparent = innerMat[\"transparent\"];\n  }\n};\n\nPackage.prototype.postLoadOfCam = function (loadContext) {\n\n  //Combine camera instances and camera definitions -- we need\n  //both to be loaded to get the camera list\n  if (this.camDefPack && this.camInstPack) {\n    for (var k = 0, kEnd = this.camInstPack.getEntryCounts(); k < kEnd; k++) {\n      var inst = Object(_Instances__WEBPACK_IMPORTED_MODULE_7__[\"readInstance\"])(this.camInstPack, k, this.placementTransform, this.globalOffset);\n      var cam = Object(_Cameras__WEBPACK_IMPORTED_MODULE_9__[\"readCameraDefinition\"])(this.camDefPack, inst);\n\n      //Apply any instance transform to get the camera to world space.\n      if (inst.transform) {\n        // Apply any transformations associated with the camera\n        // to put it into world space\n        inst.transform.transformPoint(cam.position);\n        inst.transform.transformPoint(cam.target);\n        inst.transform.transformDirection(cam.up);\n      }\n\n      // Fix camera's target if it is not inside the scene's bounding box.\n      var bbox = this.bbox;\n      if (bbox && !bbox.containsPoint(cam.target)) {\n        var distanceFromCenter = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__[\"LmvVector3\"]().copy(bbox.center()).distanceTo(cam.position);\n        var direction = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__[\"LmvVector3\"]().copy(cam.target).sub(cam.position).normalize().multiplyScalar(distanceFromCenter);\n        cam.target = new _wgs_scene_LmvVector3__WEBPACK_IMPORTED_MODULE_2__[\"LmvVector3\"]().copy(cam.position).add(direction);\n      }\n\n      this.cameras.push(cam);\n    }\n\n    delete this.camDefPack;\n    delete this.camInstPack;\n  }\n\n};\n\nPackage.prototype.postLoadOfLight = function (loadContext) {\n\n  //Lights need the same thing as the cameras\n  if (this.lightDefPack && this.lightInstPack) {\n    for (var k = 0, kEnd = this.lightInstPack.getEntryCounts(); k < kEnd; k++) {\n      var inst = Object(_Instances__WEBPACK_IMPORTED_MODULE_7__[\"readInstance\"])(this.lightInstPack, k, this.placementTransform, this.globalOffset);\n      this.lights.push(Object(_Lights__WEBPACK_IMPORTED_MODULE_10__[\"readLightDefinition\"])(this.lightDefPack, inst.definition));\n    }\n\n    delete this.lightInstPack;\n    delete this.lightDefPack;\n  }\n\n};\n\nPackage.prototype.postLoadOfFragments = function (loadContext) {\n\n  //Post processing step -- splice geometry metadata information\n  //into the fragments list, in case it was given separately\n  //TODO: consider keeping the geom metadata as is instead of splicing\n  //into the fragments, as it would be more efficient --\n  //but that would require special handling on the viewer side,\n  //changing the fragment filter code, etc.\n  var frags = this.fragments;\n\n  if (this.geomMetadata) {\n\n    //reusing the geomDataIndexes array to store\n    //polygon counts, now that we don't need the geomIndexes\n    //after this loop.\n    frags.polygonCounts = frags.geomDataIndexes;\n\n    var gm = this.geomMetadata;\n\n    // Holds the indexes to the topology data.\n    if (gm.topoIndexes != undefined) {\n      frags.topoIndexes = new Int32Array(frags.length);\n    }\n\n    for (var i = 0, iEnd = frags.length; i < iEnd; i++) {\n      var geomIndex = frags.geomDataIndexes[i];\n      frags.entityIndexes[i] = gm.entityIndexes[geomIndex];\n      frags.packIds[i] = gm.packIds[geomIndex];\n\n      frags.polygonCounts[i] = gm.primCounts[geomIndex];\n      this.primitiveCount += gm.primCounts[geomIndex];\n\n      // Fills in the indexes to the topology data.\n      if (gm.topoIndexes != undefined) {\n        frags.topoIndexes[i] = gm.topoIndexes[geomIndex];\n      }\n    }\n\n    frags.geomDataIndexes = null;\n\n    this.geomMetadata = null;\n  }\n\n  //Build a map from mesh to its referencing fragment(s)\n  //So that we can quickly find them once meshes begin loading\n  //incrementally. This requires the packIds and entityIndexes\n  //to be known per fragment, so it happens after geometry metadata\n  //is resolved above\n  this.calculateMesh2Frag(frags);\n};\n\nPackage.prototype.calculateMesh2Frag = function (frags) {\n  var mesh2frag = frags.mesh2frag = {};\n  var packIds = frags.packIds;\n  var entityIndexes = frags.entityIndexes;\n\n  for (var i = 0, iEnd = frags.length; i < iEnd; i++) {\n    var meshid = packIds[i] + \":\" + entityIndexes[i];\n\n    var meshRefs = mesh2frag[meshid];\n    if (meshRefs === undefined) {\n      //If it's the first fragments for this mesh,\n      //store the index directly -- most common case.\n      mesh2frag[meshid] = i;\n    } else\n    if (!Array.isArray(meshRefs)) {\n      //otherwise put the fragments that\n      //reference the mesh into an array\n      mesh2frag[meshid] = [meshRefs, i];\n    } else\n    {\n      //already is an array\n      meshRefs.push(i);\n    }\n  }\n};\n\nPackage.prototype.postLoadOfBBox = function (loadContext) {\n\n  //if we don't know the overall scene bounds, compute them from the\n  //fragment boxes\n  if (!this.bbox || loadContext.placementTransform) {\n\n    var totalbox = [Infinity, Infinity, Infinity, -Infinity, -Infinity, -Infinity];\n    var frags = this.fragments;\n    var fragBoxes = frags.boxes;\n\n    for (var f = 0, fEnd = frags.length; f < fEnd; f++) {\n      var bboff = f * 6;\n      var i;\n      for (i = 0; i < 3; i++) {\n        if (fragBoxes[bboff + i] < totalbox[i])\n        totalbox[i] = fragBoxes[bboff + i];}\n\n      for (i = 3; i < 6; i++) {\n        if (fragBoxes[bboff + i] > totalbox[i])\n        totalbox[i] = fragBoxes[bboff + i];}\n    }\n\n    this.bbox = {\n      min: { x: totalbox[0], y: totalbox[1], z: totalbox[2] },\n      max: { x: totalbox[3], y: totalbox[4], z: totalbox[5] } };\n\n  }\n\n\n};\n\nPackage.prototype.postLoadOfObjectIds = function (loadContext) {\n\n  // If object ids are specified, clean up pack file list by only keeping the packs that's\n  // we intended to load.\n  var ids = loadContext.objectIds;\n  if (ids != null) {\n    var packIds = [];\n    var fragIndexes = [];\n    // Pick out pack ids that referenced by fragments with specified db ids.\n    for (var i = 0; i < ids.length; ++i) {\n      for (var j = 0; j < this.fragments.length; ++j) {\n        if (this.fragments.fragId2dbId[j] == ids[i]) {\n          packIds.push(this.fragments.packIds[j]);\n          fragIndexes.push(j);\n        }\n      }\n    }\n\n    // Two fragments could reference same pack file, so packIds may contain duplicates.\n    // Remove any duplicates here.\n    var end = 1,n = packIds.length; // end is the length of reduced array.\n    for (var i = 1; i < n;) {\n      while (i < n && packIds[i] == packIds[i - 1]) {\n        ++i;}\n      if (n == i)\n      break;\n      packIds[end++] = packIds[i++];\n    }\n    packIds.splice(end - 1, n - end);\n\n    // Reduce pack files based on selected pack ids.\n    var packs = [];\n    for (var i = 0; i < this.geompacks.length; ++i) {\n      for (var j = 0; j < packIds.length; ++j) {\n        // LMVTK pre-2.0 release uses integers for pack file id.\n        // LMVTK 2.0 release uses integer + .pf as id.\n        // We just drop the suffix here as we did in SVFLoader.\n        // More info: https://git.autodesk.com/A360/LMVTK/commit/68b8c07a643a7ac39ecd5651d031d170e3a325be\n        if (parseInt(this.geompacks[i].id) == packIds[j])\n        packs.push(this.geompacks[i]);\n      }\n    }\n    this.geompacks = packs;\n\n    var bb = Object(_Fragments__WEBPACK_IMPORTED_MODULE_6__[\"filterFragments\"])(this.fragments, fragIndexes);\n    this.bbox = {\n      min: { x: bb[0], y: bb[1], z: bb[2] },\n      max: { x: bb[3], y: bb[4], z: bb[5] } };\n\n  }\n\n};\n\nPackage.prototype.postLoadComplete = function (loadContext) {\n\n  loadContext.loadDoneCB(\"svf\");\n\n  if (this.fragments.polygonCounts) {\n    //Build the R-Tree\n    var t0 = performance.now();\n    var mats = this.materials ? this.materials[\"materials\"] : null;\n    if (mats)\n    this.addTransparencyFlagsToMaterials(mats);\n    this.bvh = new _wgs_scene_BVHBuilder__WEBPACK_IMPORTED_MODULE_1__[\"BVHBuilder\"](this.fragments, mats);\n    this.bvh.build(loadContext.bvhOptions);\n    var t1 = performance.now();\n    loadContext.worker.debug(\"BVH build time (worker thread):\" + (t1 - t0));\n\n    // In normal mode, just post back BVH as svf is already posted back earlier.\n    loadContext.loadDoneCB(\"bvh\");\n  }\n\n  loadContext.loadDoneCB(\"done\");\n};\n\nPackage.prototype.postLoad = function (loadContext) {\n\n  Object(_common_SvfPlacementUtils__WEBPACK_IMPORTED_MODULE_8__[\"transformAnimations\"])(this);\n\n  this.postLoadOfCam(loadContext);\n\n  this.postLoadOfLight(loadContext);\n\n  this.postLoadOfFragments(loadContext);\n\n  this.postLoadOfBBox(loadContext);\n\n  this.postLoadOfObjectIds(loadContext);\n\n  this.postLoadComplete(loadContext);\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/net/ErrorCodes.js\":\n/*!********************************************!*\\\n  !*** ./src/file-loaders/net/ErrorCodes.js ***!\n  \\********************************************/\n/*! exports provided: ErrorCodes, errorCodeString, getErrorCode */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ErrorCodes\", function() { return ErrorCodes; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"errorCodeString\", function() { return errorCodeString; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getErrorCode\", function() { return getErrorCode; });\n\n/**\n * Error code constants\n * These constants will be used in {@link Callbacks#onGenericError} functions.\n *\n * @namespace Autodesk.Viewing.ErrorCodes\n */\nvar ErrorCodes = {\n  /** \n                           * An unknown failure has occurred. \n                           * @constant\n                           * @memberof Autodesk.Viewing.ErrorCodes\n                           * @default\n                           */\n  UNKNOWN_FAILURE: 1,\n\n  /** \n                       * Bad data (corrupted or malformed) was encountered. \n                       * @constant\n                       * @memberof Autodesk.Viewing.ErrorCodes\n                       * @default\n                       */\n  BAD_DATA: 2,\n\n  /** \n                * A network failure was encountered. \n                * @constant\n                * @memberof Autodesk.Viewing.ErrorCodes\n                * @default\n                */\n  NETWORK_FAILURE: 3,\n\n  /** \n                       * Access was denied to a network resource (HTTP 403)\n                       * @constant\n                       * @memberof Autodesk.Viewing.ErrorCodes\n                       * @default\n                       */\n  NETWORK_ACCESS_DENIED: 4,\n\n  /** \n                             * A network resource could not be found (HTTP 404)\n                             * @constant\n                             * @memberof Autodesk.Viewing.ErrorCodes\n                             * @default\n                             */\n  NETWORK_FILE_NOT_FOUND: 5,\n\n  /** \n                              * A server error was returned when accessing a network resource (HTTP 5xx)\n                              * @constant\n                              * @memberof Autodesk.Viewing.ErrorCodes\n                              * @default\n                              */\n  NETWORK_SERVER_ERROR: 6,\n\n  /** \n                            * An unhandled response code was returned when accessing a network resource (HTTP 'everything else')\n                            * @constant\n                            * @memberof Autodesk.Viewing.ErrorCodes\n                            * @default\n                            */\n  NETWORK_UNHANDLED_RESPONSE_CODE: 7,\n\n  /** \n                                       * Browser error = webGL is not supported by the current browser\n                                       * @constant\n                                       * @memberof Autodesk.Viewing.ErrorCodes\n                                       * @default\n                                       */\n  BROWSER_WEBGL_NOT_SUPPORTED: 8,\n\n  /** \n                                   * There is nothing viewable in the fetched document \n                                   * @constant\n                                   * @memberof Autodesk.Viewing.ErrorCodes\n                                   * @default\n                                   */\n  BAD_DATA_NO_VIEWABLE_CONTENT: 9,\n\n  /** \n                                    * Browser error = webGL is supported, but not enabled \n                                    * @constant\n                                    * @memberof Autodesk.Viewing.ErrorCodes\n                                    * @default\n                                    */\n  BROWSER_WEBGL_DISABLED: 10,\n\n  /**\n                               * There is no geometry in loaded model\n                               * @constant\n                               * @memberof Autodesk.Viewing.ErrorCodes\n                               * @default\n                               */\n  BAD_DATA_MODEL_IS_EMPTY: 11,\n\n  /** \n                                * Collaboration server error\n                                * @constant\n                                * @memberof Autodesk.Viewing.ErrorCodes\n                                * @default\n                                */\n  RTC_ERROR: 12,\n\n  /** \n                  * The extension of the loaded file is not supported \n                  * @constant\n                  * @memberof Autodesk.Viewing.ErrorCodes\n                  * @default\n                  */\n  UNSUPORTED_FILE_EXTENSION: 13,\n\n  /** \n                                  * Viewer error: wrong or forbidden usage of the viewer\n                                  * @constant\n                                  * @memberof Autodesk.Viewing.ErrorCodes\n                                  * @default\n                                  */\n  VIEWER_INTERNAL_ERROR: 14,\n\n  /** \n                              * WebGL error while loading a model, typically due to IE11 limitations\n                              * @constant\n                              * @memberof Autodesk.Viewing.ErrorCodes \n                              * @default\n                              */\n  WEBGL_LOST_CONTEXT: 15 };\n\n\n\nfunction errorCodeString(errorCode) {\n  return \"ErrorCode:\" + errorCode + \".\";\n}\n\nfunction getErrorCode(networkStatus)\n{\n  if (networkStatus === 403 || networkStatus === 401)\n  {\n    return ErrorCodes.NETWORK_ACCESS_DENIED;\n  } else\n  if (networkStatus === 404)\n  {\n    return ErrorCodes.NETWORK_FILE_NOT_FOUND;\n  } else\n  if (networkStatus >= 500)\n  {\n    return ErrorCodes.NETWORK_SERVER_ERROR;\n  }\n  return ErrorCodes.NETWORK_UNHANDLED_RESPONSE_CODE;\n}\n\n/***/ }),\n\n/***/ \"./src/file-loaders/net/Xhr.js\":\n/*!*************************************!*\\\n  !*** ./src/file-loaders/net/Xhr.js ***!\n  \\*************************************/\n/*! exports provided: ViewingService, pathToURL, textToArrayBuffer */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"ViewingService\", function() { return ViewingService; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"pathToURL\", function() { return pathToURL; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"textToArrayBuffer\", function() { return textToArrayBuffer; });\n/* harmony import */ var _logger_Logger__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../logger/Logger */ \"./src/logger/Logger.js\");\n/* harmony import */ var _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./ErrorCodes */ \"./src/file-loaders/net/ErrorCodes.js\");\n/* harmony import */ var _lmvtk_common_StringUtils__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lmvtk/common/StringUtils */ \"./src/file-loaders/lmvtk/common/StringUtils.js\");\n/* harmony import */ var _endpoints__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./endpoints */ \"./src/file-loaders/net/endpoints.js\");\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../compat */ \"./src/compat.js\");\n\n\n\n\n\nvar pako = __webpack_require__(/*! pako */ \"./node_modules/pako/index.js\");\n\nvar ViewingService = {};\n\nvar warnedGzip = false;\n\n// Simplify Unix style file path. For example, turn '/a/./b/../../c/' into \"/c\".\n// Required to deal with OSS crappy URNs where there are embedded '..'.\nfunction simplifyPath(path) {\n\n  var elements = path.split('/');\n  if (elements.length == 0)\n  return path;\n\n  var stack = [];\n  for (var index = 0; index < elements.length; ++index) {\n    var c = elements[index];\n    if (c === '.') {\n      continue;\n    }if (c === '..' && stack.length) {\n      stack.pop();\n    } else {\n      stack.push(c);\n    }\n  }\n\n  // Great, the path commits suicide.\n  if (stack.length == 0)\n  return '';\n\n  return stack.join(\"/\");\n}\n\n//Maps a relative resource path (like a pack file or texture)\n//to an absolute URL. If absoluteBasePath is specified, it is\n//used to construct the absolute URL, otherwise the window location\n//is used.\nfunction pathToURL(path, absoluteBasePath) {\n\n  if (path.indexOf(\"://\") !== -1 ||\n  path.indexOf(\"urn:\") === 0) {\n    return path;\n  }\n\n  if (absoluteBasePath) {\n    return absoluteBasePath + path;\n  }\n\n  if (typeof window === \"undefined\")\n  return path;\n\n  var _window = Object(_compat__WEBPACK_IMPORTED_MODULE_4__[\"getGlobal\"])();\n  var rootRelPath = _window.location.pathname;\n  //chop off the index.html part\n  var lastSlash = rootRelPath.lastIndexOf(\"/\");\n  rootRelPath = rootRelPath.substr(0, lastSlash + 1);\n  var absPath = _window.location.protocol + \"//\" + _window.location.host + rootRelPath + path;\n  return absPath;\n}\n\n\nViewingService.simplifyPath = simplifyPath;\n\nfunction textToArrayBuffer(textBuffer, startOffset) {\n  var len = textBuffer.length - startOffset;\n  var arrayBuffer = new ArrayBuffer(len);\n  var ui8a = new Uint8Array(arrayBuffer, 0);\n  for (var i = 0, j = startOffset; i < len; i++, j++) {\n    ui8a[i] = textBuffer.charCodeAt(j) & 0xff;}\n  return ui8a;\n}\n\n\nViewingService.OSS_PREFIX = \"urn:adsk.objects:os.object:\";\n\n/**\n                                                            * Construct full URL given a potentially partial viewing service \"urn:\" prefixed resource\n                                                            * @returns {string}\n                                                            */\nViewingService.generateUrl = function (baseUrl, api, path) {\n\n  path = path || \"\";\n\n  //NODE\n  if (Object(_compat__WEBPACK_IMPORTED_MODULE_4__[\"isNodeJS\"])() && !isRemotePath(baseUrl, path)) {\n    return path;\n  }\n\n  path = simplifyPath(path);\n\n  //V2 only accepts URL encoded paths\n  var urnidx = path.indexOf(\"urn:\");\n  var qidx = path.indexOf(\"?\");\n  if (urnidx != -1) {\n    if (qidx !== -1) {\n      //TODO: not sure this will happen, queryParams are normally\n      //passed in separately in the options object\n      path = path.slice(0, urnidx) + encodeURIComponent(path.slice(urnidx, qidx)) + path.slice(qidx);\n    } else {\n      path = path.slice(0, urnidx) + encodeURIComponent(path.slice(urnidx));\n    }\n  } else {\n    path = encodeURI(path);\n  }\n\n  //Check if it's a viewing service item path\n  //Public/static content will not have the urn: prefix.\n  //So URL construction is a no-op\n  if (!api || decodeURIComponent(path).indexOf('urn:') !== 0) {\n    if (isRemotePath(null, path))\n    return path;else\n\n    return baseUrl + path;\n  }\n\n  //Remove \"urn:\" prefix when getting URN-based stuff (manifests and thumbnails)\n  if (api !== 'items') {\n    path = path.substr(6);\n  }\n\n  switch (api) {\n    case \"items\":return _endpoints__WEBPACK_IMPORTED_MODULE_3__[\"endpoint\"].getItemApi(baseUrl, path);\n    case \"bubbles\":return _endpoints__WEBPACK_IMPORTED_MODULE_3__[\"endpoint\"].getManifestApi(baseUrl, path);\n    case \"thumbnails\":return _endpoints__WEBPACK_IMPORTED_MODULE_3__[\"endpoint\"].getThumbnailApi(baseUrl, path);}\n\n};\n\nfunction isRemotePath(baseUrl, path) {\n  if (path.indexOf(\"file://\") !== -1)\n  return false;\n  if (path.indexOf(\"://\") !== -1)\n  return true;\n  if (baseUrl)\n  return true;\n}\n\n\n//Conditional GET request implementation for node vs. browser\nif (Object(_compat__WEBPACK_IMPORTED_MODULE_4__[\"isNodeJS\"])()) {\n\n  (function () {\n\n    var fs = __webpack_require__(/*! fs */ \"./node_modules/node-libs-browser/mock/empty.js\");\n    var zlib = __webpack_require__(/*! zlib */ \"./node_modules/node-libs-browser/mock/empty.js\");\n    var https = __webpack_require__(/*! https */ \"./node_modules/node-libs-browser/mock/empty.js\");\n    var http = __webpack_require__(/*! http */ \"./node_modules/node-libs-browser/mock/empty.js\");\n    var urllib = __webpack_require__(/*! url */ \"./node_modules/node-libs-browser/mock/empty.js\");\n\n    var httpsAgent = new https.Agent({\n      keepAlive: true,\n      keepAliveMsecs: 100,\n      maxSockets: 10 });\n\n    var httpAgent = new http.Agent({\n      keepAlive: true,\n      keepAliveMsecs: 100,\n      maxSockets: 10 });\n\n\n\n    var forgeAgent = new https.Agent({ maxSockets: 10 });\n\n    function loadLocalFile(url, onSuccess, onFailure, options) {\n\n      if (url.indexOf(\"file://\") === 0)\n      url = url.substr(7);\n\n      function postProcess(data) {\n        if (options.responseType === \"json\") {\n          try {\n            return JSON.parse(data.toString(\"utf8\"));\n          } catch (e) {\n            onFailure(e);\n          }\n        }\n        return data;\n      }\n\n      //Always use async on Node\n      fs.readFile(url, function (error, data) {\n        if (error) {\n          onFailure(0, 0, { httpStatusText: error, url: url });\n        } else {\n          if (data[0] === 31 && data[1] === 139) {\n            zlib.gunzip(data, null, function (error, data) {\n              if (error)\n              onFailure(0, 0, { httpStatusText: error, url: url });else\n              {\n                data = postProcess(data);\n                if (options.ondata)\n                options.ondata(data);\n                onSuccess(data);\n              }\n            });\n          } else {\n            data = postProcess(data);\n            if (options.ondata)\n            options.ondata(data);\n            onSuccess(data);\n          }\n        }\n      });\n    }\n\n    function needsGunzip(res, pathname) {\n\n      if (res.headers['content-encoding'] === 'gzip')\n      return true;\n\n      //These SVF related files come pre-gzipped\n      //regardless of content-encoding header\n\n      if (pathname.endsWith(\".json.gz\"))\n      return true;\n\n      if (pathname.endsWith(\"FragmentList.pack\"))\n      return true;\n\n      if (pathname.endsWith(\"LightList.bin\"))\n      return true;\n\n      if (pathname.endsWith(\"CameraList.bin\"))\n      return true;\n\n      if (pathname.endsWith(\"CameraDefinitions.bin\"))\n      return true;\n\n      if (pathname.endsWith(\"LightDefinitions.bin\"))\n      return true;\n\n      return false;\n    }\n\n\n    /**\n       *  Performs a GET/HEAD request to Viewing Service. (Node.js specific implementation)\n       *\n       * @param {string} viewingServiceBaseUrl - The base url for the viewing service.\n       * @param {string} api - The api to call in the viewing service.\n       *  @param {string} url - The url for the request.\n       *  @param {function} onSuccess - A function that takes a single parameter that represents the response\n       *                                returned if the request is successful.\n       *  @param {function} onFailure - A function that takes an integer status code, and a string status, which together represent\n       *                                the response returned if the request is unsuccessful, and a third data argument, which\n       *                                has more information about the failure.  The data is a dictionary that minimally includes\n       *                                the url, and an exception if one was raised.\n       *  @param {Object=} [options] - A dictionary of options that can include:\n       *                               headers - A dictionary representing the additional headers to add.\n       *                               queryParams - A string representing the query parameters\n       *                               responseType - A string representing the response type for this request.\n       *                               {boolean} [encodeUrn] - when true, encodes the document urn if found.\n       *                               {boolean} [noBody] - when true, will perform a HEAD request\n       */\n    ViewingService.rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {\n\n      options = options || {};\n\n      url = ViewingService.generateUrl(viewingServiceBaseUrl, api, url);\n\n      if (!isRemotePath(viewingServiceBaseUrl, url)) {\n        loadLocalFile(url, onSuccess, onFailure, options);\n        return;\n      }\n\n      if (options.queryParams) {\n        var concatSymbol = url.indexOf('?') === -1 ? '?' : '&';\n        url = url + concatSymbol + options.queryParams;\n      }\n\n      var parsed = urllib.parse(url);\n\n      var req = {\n        host: parsed.hostname,\n        port: parsed.port,\n        method: options.method || \"GET\",\n        path: parsed.path,\n        headers: {},\n        retryCount: 0,\n        agent: parsed.protocol === \"https:\" ? httpsAgent : httpAgent };\n\n\n      //Don't overload derivative service with requests\n      if (req.host.endsWith(\".api.autodesk.com\") && (\n      req.path.startsWith(\"/derivativeservice\") || req.path.startsWith(\"/modelderivative\"))) {\n        req.agent = forgeAgent;\n      }\n\n      if (options.headers) {\n        for (var p in options.headers) {\n          req.headers[p] = options.headers[p];\n        }\n      }\n\n      if (!req.headers['accept-encoding']) {\n        req.headers['accept-encoding'] = 'gzip, deflate';\n      }\n\n      if (options.range) {\n        req.headers[\"Range\"] = \"bytes=\" + options.range.min + \"-\" + options.range.max;\n      }\n\n      //Undo hack used to make streaming receive work on browser XHR -- the hack\n      //involves processing the response as text, so responseType is set to \"\".\n      if (options.ondata || options.onprogress) {\n        options.responseType = \"arraybuffer\";\n      }\n\n      var request = (parsed.protocol === \"https:\" ? https : http).request(req, function (res) {\n\n        var hasError = !(res.statusCode >= 200 && res.statusCode < 400);\n\n        //Pipe through gunzip if needed\n        var stream = res;\n        if (!hasError && needsGunzip(res, parsed.pathname) && !options.skipDecompress) {\n          stream = res.pipe(zlib.createGunzip());\n        }\n\n        //Decode as UTF8 string if needed\n        if (options.responseType === \"json\" || options.responseType === \"text\" || !options.responseType)\n        stream.setEncoding('utf8');\n\n        var chunks = [];\n        var receiveBuffer = Buffer.allocUnsafe(65536);\n        var receivedLen = 0;\n        stream.on('data', function (chunk) {\n\n          //The onprogress callback is special in that it\n          //want us to accumulate the data as we receive it, and it only looks at it.\n          if (options.onprogress) {\n\n            if (chunk.length + receivedLen > receiveBuffer.length) {\n              var nb = Buffer.allocUnsafe(0 | Math.ceil(receiveBuffer.length * 1.5));\n              receiveBuffer.copy(nb, 0, 0, receivedLen);\n              receiveBuffer = nb;\n            }\n\n            chunk.copy(receiveBuffer, receivedLen, 0, chunk.length);\n            receivedLen += chunk.length;\n            var abort = options.onprogress(receiveBuffer, receivedLen);\n            if (abort)\n            request.abort();\n            return;\n          } else {\n            chunks.push(chunk);\n          }\n\n          if (options.ondata) {\n            options.ondata(chunk);\n          }\n\n        });\n\n        stream.on('end', function () {\n\n          if (res.statusCode >= 200 && res.statusCode < 400) {\n\n            if (options.responseType === \"json\") {\n              var jsobj = JSON.parse(chunks.join(''));\n              onSuccess(jsobj);\n              return;\n            }\n\n            if (options.responseType === \"text\" || options.responseType === \"\") {\n              var str = chunks.join('');\n              onSuccess(str);\n              return;\n            }\n\n            var buf = options.onprogress ? receiveBuffer : Buffer.concat(chunks);\n\n            if (!options.skipDecompress && buf[0] === 31 && buf[1] === 139) {\n\n              _logger_Logger__WEBPACK_IMPORTED_MODULE_0__[\"logger\"].warn(\"An LMV resource (\" + url + \") was double compressed, or Content-Encoding header missing\");\n\n              try {\n                buf = zlib.gunzipSync(buf);\n                receivedLen = buf.length;\n              } catch (err) {\n                onFailure(_ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].BAD_DATA,\n                \"Malformed data received when requesting file\",\n                { \"url\": url, \"exception\": err.toString(), \"stack\": err.stack });\n              }\n            }\n\n            if (request.status === 200 && options.range) {\n              //If we requested a range, but the entire content was returned,\n              //make sure to give back just the requested subset to the caller\n              buf = new Uint8Array(buf, options.range.min, options.range.max - options.range.min);\n            }\n\n            onSuccess(buf, receivedLen);\n\n          } else {\n\n            if (onFailure)\n            onFailure(res.statusCode, res.statusMessage, { url: url });\n\n          }\n        });\n\n      });\n\n      request.on(\"error\", function (error) {\n        if (onFailure)\n        onFailure(error.code, error.message, { url: url });\n      });\n\n      if (options.postData) {\n        request.write(options.postData);\n      }\n\n      request.end();\n\n    };\n\n  })();\n\n} else {\n\n  var Pend = __webpack_require__(/*! pend */ \"./node_modules/pend/index.js\");\n  var xhrThrottle = new Pend();\n  xhrThrottle.max = 25;\n\n  ViewingService.rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {\n    xhrThrottle.go(function (pendCB) {\n      var onFailureWrapped = function onFailureWrapped() {\n        pendCB();for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {args[_key] = arguments[_key];}\n        onFailure && onFailure.apply(onFailure, args);\n      };\n\n      var onSuccessWrapped = function onSuccessWrapped() {\n        pendCB();for (var _len2 = arguments.length, args = new Array(_len2), _key2 = 0; _key2 < _len2; _key2++) {args[_key2] = arguments[_key2];}\n        onSuccess && onSuccess.apply(onSuccess, args);\n      };\n\n      ViewingService._rawGet(viewingServiceBaseUrl, api, url, onSuccessWrapped, onFailureWrapped, options);\n    });\n  };\n\n  /**\n      *  Performs a GET/HEAD request to Viewing Service.\n      *\n      * @param {string} viewingServiceBaseUrl - The base url for the viewing service.\n      * @param {string} api - The api to call in the viewing service.\n      *  @param {string} url - The url for the request.\n      *  @param {function} onSuccess - A function that takes a single parameter that represents the response\n      *                                returned if the request is successful.\n      *  @param {function} onFailure - A function that takes an integer status code, and a string status, which together represent\n      *                                the response returned if the request is unsuccessful, and a third data argument, which\n      *                                has more information about the failure.  The data is a dictionary that minimally includes\n      *                                the url, and an exception if one was raised.\n      *  @param {Object=} [options] - A dictionary of options that can include:\n      *                               headers - A dictionary representing the additional headers to add.\n      *                               queryParams - A string representing the query parameters\n      *                               responseType - A string representing the response type for this request.\n      *                               {boolean} [encodeUrn] - when true, encodes the document urn if found.\n      *                               {boolean} [noBody] - when true, will perform a HEAD request\n      */\n  ViewingService._rawGet = function (viewingServiceBaseUrl, api, url, onSuccess, onFailure, options) {\n\n    options = options || {};\n\n    url = ViewingService.generateUrl(viewingServiceBaseUrl, api, url);\n\n    if (options.queryParams) {\n      var concatSymbol = url.indexOf('?') === -1 ? '?' : '&';\n      url = url + concatSymbol + options.queryParams;\n    }\n\n    var request = new XMLHttpRequest();\n\n    function onError(e) {\n      if (onFailure)\n      onFailure(request.status, request.statusText, { url: url });\n    }\n\n    function fixJsonResponse(response) {\n      if (options.responseType === \"json\") {\n        try {\n          if (response instanceof Uint8Array) {\n            //This should only happen in the node.js case so we can do toString\n            //instead of using the LMV utf8 converter.\n            return Object(_lmvtk_common_StringUtils__WEBPACK_IMPORTED_MODULE_2__[\"blobToJson\"])(response);\n          } else if (typeof response === \"string\") {\n            return JSON.parse(response);\n          }\n        } catch (e) {}\n      }\n      return response;\n    }\n\n    function onLoad(e) {\n      if (request.status === 200 || request.status === 206) {\n\n        if (request.response &&\n        request.response instanceof ArrayBuffer) {\n\n          var rawbuf;\n          if (request.status === 200 && options.range) {\n            //If we requested a range, but the entire content was returned,\n            //make sure to give back just the requested subset to the caller\n            rawbuf = new Uint8Array(request.response, options.range.min, options.range.max - options.range.min);\n          } else {\n            rawbuf = new Uint8Array(request.response);\n          }\n\n          // It's possible that if the Content-Encoding header is set,\n          // the browser unzips the file by itself, so let's check if it did.\n          // Return raw buffer if skip decompress is true\n          if (!options.skipDecompress && rawbuf[0] === 31 && rawbuf[1] === 139) {\n            if (!warnedGzip) {\n              warnedGzip = true;\n              _logger_Logger__WEBPACK_IMPORTED_MODULE_0__[\"logger\"].warn(\"An LMV resource (\" + url + \") was not uncompressed by the browser. This hurts performance. Check the Content-Encoding header returned by the server and check whether you're getting double-compressed streams. The warning prints only once but it's likely the problem affects multiple resources.\");\n            }\n            try {\n              rawbuf = pako.ungzip(rawbuf);\n            } catch (err) {\n              onFailure(_ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].BAD_DATA,\n              \"Malformed data received when requesting file\",\n              { \"url\": url, \"exception\": err.toString(), \"stack\": err.stack });\n            }\n          }\n\n          onSuccess && onSuccess(fixJsonResponse(rawbuf));\n        } else\n        {\n          var res = request.response;\n          if (!res && (!options.responseType || options.responseType === \"text\"))\n          res = request.responseText;\n\n          onSuccess && onSuccess(fixJsonResponse(res));\n        }\n      } else\n      {\n        onError(e);\n      }\n    }\n\n    try {\n\n      var isAsync = options.hasOwnProperty('asynchronous') ? options.asynchronous : true;\n      request.open(options.method || (options.noBody ? 'HEAD' : 'GET'), url, isAsync);\n\n      if (options.hasOwnProperty('responseType')) {\n        request.responseType = options.responseType;\n      }\n\n      request.withCredentials = true;\n      if (options.hasOwnProperty(\"withCredentials\"))\n      request.withCredentials = options.withCredentials;\n\n      if (options.range) {\n        request.setRequestHeader(\"Range\", \"bytes=\" + options.range.min + \"-\" + options.range.max);\n      }\n\n      if (options.headers) {\n        for (var header in options.headers) {\n          request.setRequestHeader(header, options.headers[header]);\n\n          // Disable withCredentials if header is Authorization type\n          // NOTE: using withCredentials attaches cookie data to request\n          if (header.toLocaleLowerCase() === \"authorization\") {\n            request.withCredentials = false;\n          }\n        }\n      }\n\n      if (isAsync) {\n        request.onload = onLoad;\n        request.onerror = onError;\n        request.ontimeout = onError;\n\n        if (options.ondata || options.onprogress) {\n\n          //Set up incremental progress notification\n          //if needed. We have to do some magic in order\n          //to get the received data progressively.\n          //https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest\n          request.overrideMimeType('text/plain; charset=x-user-defined');\n          options._dlProgress = {\n            streamOffset: 0 };\n\n\n          request.onreadystatechange = function () {\n\n            if (request.readyState > 2 && request.status === 200) {\n\n              if (options.ondata) {\n\n                var textBuffer = request.responseText;\n\n                // No new data coming in.\n                if (options._dlProgress.streamOffset >= textBuffer.length)\n                return;\n\n                var arrayBuffer = textToArrayBuffer(textBuffer, options._dlProgress.streamOffset);\n\n                options._dlProgress.streamOffset = textBuffer.length;\n\n                options.ondata(arrayBuffer);\n\n              } else if (options.onprogress) {\n\n                var abort = options.onprogress(request.responseText);\n                if (abort)\n                request.abort();\n              }\n            }\n          };\n        }\n      }\n\n      request.send(options.postData);\n\n      if (!isAsync) {\n        onLoad();\n      }\n    }\n    catch (e) {\n      onFailure(request.status, request.statusText, { url: url, exception: e });\n    }\n  };\n\n} //rawGet conditionsl implementation\n\n// Create the default failure callback.\n//\nViewingService.defaultFailureCallback = function (httpStatus, httpStatusText, data) {\n  if (httpStatus == 403) {\n    this.raiseError(\n    _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].NETWORK_ACCESS_DENIED,\n    \"Access denied to remote resource\",\n    { \"url\": data.url, \"httpStatus\": httpStatus, \"httpStatusText\": httpStatusText });\n  } else\n  if (httpStatus == 404) {\n    this.raiseError(\n    _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].NETWORK_FILE_NOT_FOUND,\n    \"Remote resource not found\",\n    { \"url\": data.url, \"httpStatus\": httpStatus, \"httpStatusText\": httpStatusText });\n  } else\n  if (httpStatus >= 500 && httpStatus < 600) {\n    this.raiseError(\n    _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].NETWORK_SERVER_ERROR,\n    \"Server error when accessing resource\",\n    { \"url\": data.url, \"httpStatus\": httpStatus, \"httpStatusText\": httpStatusText });\n  } else\n  if (data.exception) {\n    this.raiseError(\n    _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].NETWORK_FAILURE,\n    \"Network failure\",\n    { \"url\": data.url, \"exception\": data.exception.toString(), \"stack\": data.exception.stack });\n  } else\n  {\n    this.raiseError(\n    _ErrorCodes__WEBPACK_IMPORTED_MODULE_1__[\"ErrorCodes\"].NETWORK_UNHANDLED_RESPONSE_CODE,\n    \"Unhandled response code from server\",\n    { \"url\": data.url, \"httpStatus\": httpStatus, \"httpStatusText\": httpStatusText, data: data });\n  }\n};\n\n\n\nfunction copyOptions(loadContext, options) {\n\n  //Those are the usual defaults when called from the LMV worker\n\n  if (!options.hasOwnProperty(\"responseType\"))\n  options.responseType = \"arraybuffer\";\n\n  //Add options junk we got from the main thread context\n\n  if (!options.hasOwnProperty(\"withCredentials\"))\n  options.withCredentials = !!loadContext.auth;\n\n  options.headers = loadContext.headers;\n  options.queryParams = loadContext.queryParams;\n  options.endpoint = loadContext.endpoint;\n}\n\n//Utility function called from the web worker to set up the options for a get request,\n//then calling ViewingService.get internally\nViewingService.getItem = function (loadContext, url, onSuccess, onFailure, options) {\n\n  options = options || {};\n\n  copyOptions(loadContext, options);\n\n  //If the endpoint does not support range requests (Apigee), then convert\n  //the range to start/end URL parameters.\n  if (options.range && !loadContext.supportsRangeRequests) {\n\n    var rangeParam = \"start=\" + options.range.min + \"&end=\" + options.range.max;\n    if (options.queryParams) {\n      options.queryParams += \"&\" + rangeParam;\n    } else {\n      options.queryParams = rangeParam;\n    }\n\n    options.range = undefined;\n  }\n\n  ViewingService.rawGet(loadContext.endpoint, 'items', url, onSuccess, onFailure, options);\n\n};\n\n//Utility function called from the web worker to set up the options for a get request,\n//then calling ViewingService.get internally\nViewingService.getManifest = function (loadContext, url, onSuccess, onFailure, options) {\n\n  options = options || {};\n\n  if (!options.hasOwnProperty(\"responseType\"))\n  options.responseType = \"json\";\n\n  copyOptions(loadContext, options);\n\n  ViewingService.rawGet(loadContext.endpoint, 'bubbles', url, onSuccess, onFailure, options);\n\n};\n\n//Utility function called from the web worker to set up the options for a get request,\n//then calling ViewingService.get internally\nViewingService.getThumbnail = function (loadContext, url, onSuccess, onFailure, options) {\n\n  options = options || {};\n\n  copyOptions(loadContext, options);\n\n  var queryParams = options.queryParams || '';\n  var missingElements = [];\n  if (queryParams.indexOf('guid=') === -1) {\n    missingElements.push(\"guid=\" + encodeURIComponent(options.guid));\n  }\n  if (queryParams.indexOf('role=') === -1) {\n    var role = options.role || \"rendered\";\n    missingElements.push(\"role=\" + role);\n  }\n  if (queryParams.indexOf('width=') === -1) {\n    var sz = options.size || 400;\n    missingElements.push(\"width=\" + sz);\n  }\n  if (queryParams.indexOf('height=') === -1) {\n    var sz = options.size || 400;\n    missingElements.push(\"height=\" + sz);\n  }\n  if (queryParams.indexOf('acmsession=') === -1 && options.acmsession) {\n    missingElements.push(\"acmsession=\" + options.acmsession);\n  }\n  var thumbQueryParams = missingElements.join('&');\n\n  if (options.queryParams) {\n    options.queryParams = options.queryParams + '&' + thumbQueryParams;\n  } else {\n    options.queryParams = thumbQueryParams;\n  }\n\n  ViewingService.rawGet(loadContext.endpoint, 'thumbnails', url, onSuccess, onFailure, options);\n};\n\n\nViewingService.getACMSession = function (endpoint, acmProperties, onSuccess, onFailure) {\n\n  var acmHeaders = {};\n  var token;\n\n  for (var key in acmProperties) {\n\n    if (key === \"oauth2AccessToken\")\n    token = acmProperties[key];else\n\n    if (key.indexOf(\"x-ads-acm\") !== -1)\n    acmHeaders[key] = acmProperties[key];\n  }\n\n  // The value of this can be anything. Required for some arcane reasons.\n  acmHeaders.application = \"autodesk\";\n\n  var xhr = new XMLHttpRequest();\n  xhr.open(\"POST\", endpoint + '/oss-ext/v2/acmsessions', true);\n  xhr.setRequestHeader(\"Content-Type\", \"application/json\");\n  xhr.setRequestHeader(\"Authorization\", \"Bearer \" + token);\n  xhr.responseType = \"json\";\n\n  xhr.onload = function () {\n    if (xhr.status === 200 && xhr.response) {\n      // If the response is a string (e.g. from IE), need to parse it to an object first\n      var response = typeof xhr.response === 'string' ? JSON.parse(xhr.response) : xhr.response;\n\n      if (response && response.acmsession) {\n        onSuccess(response.acmsession);\n      } else\n      {\n        onFailure(xhr.status, \"Can't get acm session from response.\");\n      }\n\n    } else {\n      onFailure(xhr.status);\n    }\n  };\n\n  xhr.onerror = onFailure;\n  xhr.ontimeout = onFailure;\n  xhr.send(JSON.stringify(acmHeaders));\n\n  // \"application\" header is only required for OSS end point, and should not be passed\n  // with normal requests because this header is not in allowed header sets of APIGEE.\n  delete acmHeaders.application;\n\n};\n\n/***/ }),\n\n/***/ \"./src/file-loaders/net/endpoints.js\":\n/*!*******************************************!*\\\n  !*** ./src/file-loaders/net/endpoints.js ***!\n  \\*******************************************/\n/*! exports provided: getEnv, setEnv, isOffline, setOffline, setOfflineResourcePrefix, getOfflineResourcePrefix, endpoint, initLoadContext */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getEnv\", function() { return getEnv; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setEnv\", function() { return setEnv; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isOffline\", function() { return isOffline; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setOffline\", function() { return setOffline; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setOfflineResourcePrefix\", function() { return setOfflineResourcePrefix; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getOfflineResourcePrefix\", function() { return getOfflineResourcePrefix; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"endpoint\", function() { return endpoint; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"initLoadContext\", function() { return initLoadContext; });\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../../compat */ \"./src/compat.js\");\n/* harmony import */ var _globals__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../../globals */ \"./src/globals.js\");\n\n\n\n\nvar _window = Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"getGlobal\"])();\n\nvar endp = {};\n\nvar CDN_ROOT = null;\nendp.ENDPOINT_API_DERIVATIVE_SERVICE_V2 = 'derivativeV2';\nendp.ENDPOINT_API_MODEL_DERIVATIVE_V2 = 'modelDerivativeV2'; // Forge\nendp.ENDPOINT_API_FLUENT = 'fluent';\n\nvar _apis_data = {\n  derivativeV2: {\n    baseURL: '/derivativeservice/v2',\n    itemURL: '/derivativeservice/v2/derivatives/:derivativeurn',\n    manifestURL: '/derivativeservice/v2/manifest/:urn',\n    thumbnailsURL: '/derivativeservice/v2/thumbnails/:urn' },\n\n  derivativeV2_EU: {\n    baseURL: '/derivativeservice/v2/regions/eu',\n    itemURL: '/derivativeservice/v2/regions/eu/derivatives/:derivativeurn',\n    manifestURL: '/derivativeservice/v2/regions/eu/manifest/:urn',\n    thumbnailsURL: '/derivativeservice/v2/regions/eu/thumbnails/:urn' },\n\n  modelDerivativeV2: {\n    baseURL: '/modelderivative/v2/',\n    itemURL: '/modelderivative/v2/designdata/:urn/manifest/:derivativeurn',\n    manifestURL: '/modelderivative/v2/designdata/:urn/manifest',\n    thumbnailsURL: '/modelderivative/v2/designdata/:urn/thumbnail' },\n\n  fluent: {\n    baseURL: '/modeldata',\n    itemURL: '/modeldata/file/:derivativeurn',\n    manifestURL: '/modeldata/manifest/:urn',\n    thumbnailsURL: '/derivativeservice/v2/thumbnails/:urn',\n    cdnURL: '/cdn',\n    cdnWS: '/cdnws'\n    //cdnRedirectURL: '/cdnurl', //There is no separate CDN endpoint currently\n  } };\n\n\nvar _endpoint = '';\nvar _api = endp.ENDPOINT_API_DERIVATIVE_SERVICE_V2;\nvar _useCredentials = false;\nvar _useCookie = false;\nvar _acmSession = '';\n\nendp.HTTP_REQUEST_HEADERS = {};\nendp.queryParams = {};\n\n/**\r\n                        * Sets the endpoint and api to be used to create REST API request strings.\r\n                        * @param {string} endpoint\r\n                        * @param {string} [api] - Possible values are derivativeV2, modelDerivativeV2\r\n                        */\nendp.setEndpointAndApi = function (endpoint, api) {\n  _endpoint = endpoint;\n  if (api) {\n    _api = api;\n  }\n};\n\n/**\r\n    * Returns the endpoint plus the api used to create REST API request strings.\r\n    * Example: \"developer.api.autodesk.com/modelderivative/v2\"\r\n    * @returns {string}\r\n    */\nendp.getEndpointAndApi = function () {\n  return _endpoint + _apis_data[_api].baseURL;\n};\n\n/**\r\n    * Returns the endpoint used to create REST API request strings.\r\n    * Examples: \"developer.api.autodesk.com\"\r\n    * @returns {string}\r\n    */\nendp.getApiEndpoint = function () {\n  return _endpoint;\n};\n\n/**\r\n    * @private\r\n    * @returns {string}\r\n    */\nendp.getApiFlavor = function () {\n  return _api;\n};\n\n/**\r\n    * Returns the default shared resource CDN location.\r\n    * For best performance (and to not overload our servers), this should\r\n    * be replaced by a direct CloudFront url during initialization, by\r\n    * calling the cdnRedirectUrl and looking at the result.\r\n    */\nendp.getCdnUrl = function () {\n  return CDN_ROOT || (_endpoint ? _endpoint + _apis_data[_api].cdnURL : undefined);\n};\n\nendp.getCdnWebSocketEndpoint = function () {\n  return _endpoint + (_apis_data[_api].cdnWS || '');\n};\n\nendp.setCdnUrl = function (url) {\n  CDN_ROOT = url;\n};\n\nendp.getCdnRedirectUrl = function () {\n  var redirect = _apis_data[_api].cdnRedirectURL;\n  if (!redirect)\n  return null;\n  return _endpoint + redirect;\n};\n\nendp.setAcmSession = function (value) {\n  _acmSession = value;\n};\n\nendp.getAcmSession = function () {\n  return _acmSession;\n};\n\n/**\r\n    * Returns a REST API request strings to be used to get the manifest of the provided urn.\r\n    * Example: \"developer.api.autodesk.com/modelderivative/v2/designdata/:urn/manifest\"\r\n    * @param {string | null} endpoint - When provided is used instead of the globally set endpoint.\r\n    * @param {string} urn\r\n    * @param {string} api - When provided is used instead of the globally set API flavor\r\n    * @returns {string}\r\n    */\nendp.getManifestApi = function (endpoint, urn, api) {\n  var url = endpoint || _endpoint;\n  api = api || _api;\n  url += _apis_data[api].manifestURL;\n  // If urn is not provided we return same string that before for backward compatibility.\n  urn = urn || '';\n  url = url.replace(':urn', urn);\n  return url;\n};\n\n/**\r\n    * Returns a REST API request strings to be used to get a derivative urn.\r\n    * Example: \"developer.api.autodesk.com/modelderivative/v2/designdata/:urn/manifest/:derivativeUrn\"\r\n    * @param {string | null} endpoint - When provided is used instead of the globally set API endpoint.\r\n    * @param {string} derivativeUrn\r\n    * @param {string} api - When provided is used instead of the globally set API flavor\r\n    * @returns {string}\r\n    */\nendp.getItemApi = function (endpoint, derivativeUrn, api) {\n  var theApi = api || _api;\n  var itemApi = (endpoint || _endpoint) + _apis_data[theApi].itemURL;\n  // If urn is not provided we return same string that before for backward compatibility.\n  derivativeUrn = derivativeUrn || '';\n  var decodedUrn = decodeURIComponent(derivativeUrn);\n\n  // Extract svf urn from item urn, needed when using model derivative.\n  if (itemApi.indexOf(':urn') !== -1) {\n    var parts = decodedUrn.split('/');\n    var urn = parts[0] || '';\n    urn = urn.split(':');\n    urn = urn[urn.length - 1] || '';\n\n    itemApi = itemApi.replace(':urn', urn);\n  }\n\n  if (theApi === endp.ENDPOINT_API_MODEL_DERIVATIVE_V2) {\n    derivativeUrn = encodeURIComponent(decodedUrn);\n  }\n\n  itemApi = itemApi.replace(':derivativeurn', derivativeUrn);\n\n  return itemApi;\n};\n\n/**\r\n    * Returns a REST API request strings to be used to get the thumbnail for a specific urn.\r\n    * Example: \"developer.api.autodesk.com/modelderivative/v2/designdata/:urn/thumbnail\"\r\n    * @param {string | null} endpoint - When provided is used instead of the globally set endpoint.\r\n    * @param {string} urn\r\n    * @param {string} api - When provided is used instead of the globally set API flavor\r\n    * @returns {string}\r\n    */\nendp.getThumbnailApi = function (endpoint, urn, api) {\n  var thumbnailApi = (endpoint || _endpoint) + _apis_data[api || _api].thumbnailsURL;\n  return thumbnailApi.replace(':urn', urn || '');\n};\n\nendp.getUseCredentials = function () {\n  return _useCredentials;\n};\n\nendp.getDomainParam = function () {\n  console.warn(\"getDomainParam is deprecated, switch to getQueryParams instead.\");\n  return this.getUseCredentials() && !Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isNodeJS\"])() ? \"domain=\" + encodeURIComponent(_window.location.origin) : \"\";\n};\n\n/**\r\n    * Adds a URL parameter that will be used in all data load requests.\r\n    * @param {string} param - The name of the parameter\r\n    * @param {string} value - The value of the parameter. It will be URI encoded when constructing the final URL.\r\n    */\nendp.addQueryParam = function (param, value) {\n  this.queryParams[param] = value;\n};\n\n/**\r\n    * Deletes a previously specified URL parameter.\r\n    * @param {string} param - The name of the parameter to delete\r\n    */\nendp.deleteQueryParam = function (param) {\n  delete this.queryParams[param];\n};\n\nendp.getQueryParams = function (inputObj) {\n\n  var qParam = this.getUseCredentials() && !Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isNodeJS\"])() ? \"domain=\" + encodeURIComponent(_window.location.origin) : \"\";\n\n  var bypassDs = Object(_globals__WEBPACK_IMPORTED_MODULE_1__[\"getParameterByName\"])(\"bypassds\");\n  if (bypassDs) {\n    qParam = qParam ? qParam + \"&bypassds=1\" : \"bypassds=1\";\n  }\n\n  var addedParams = [];\n  for (var p in this.queryParams) {\n    addedParams.push(encodeURIComponent(p) + \"=\" + encodeURIComponent(this.queryParams[p]));\n  }\n\n  if (addedParams.length) {\n    if (qParam)\n    qParam += \"&\" + addedParams.join(\"&\");else\n\n    qParam = addedParams.join(\"&\");\n  }\n\n  if (qParam && inputObj) {\n    if (inputObj.queryParams) {\n      inputObj.queryParams += \"&\" + qParam;\n    } else {\n      inputObj.queryParams = qParam;\n    }\n  }\n\n  return qParam;\n};\n\nendp.setUseCredentials = function (useCredentials) {\n  _useCredentials = useCredentials;\n};\n\nendp.setUseCookie = function (useCookie) {\n  _useCookie = useCookie;\n};\n\nendp.getUseCookie = function () {\n  return _useCookie;\n};\n\nendp.initLoadContext = function (inputObj) {\n\n  inputObj = inputObj || {};\n\n  inputObj.auth = this.getUseCredentials();\n\n  if (!inputObj.endpoint)\n  inputObj.endpoint = this.getApiEndpoint();\n\n  if (!inputObj.api)\n  inputObj.api = this.getApiFlavor();\n\n  if (!inputObj.headers)\n  inputObj.headers = {};\n\n  for (var p in this.HTTP_REQUEST_HEADERS) {\n    inputObj.headers[p] = this.HTTP_REQUEST_HEADERS[p];\n  }\n\n  if (inputObj.api === this.ENDPOINT_API_FLUENT) {\n    inputObj.supportsRangeRequests = true;\n  }\n\n  //This is done to avoid CORS errors on content served from proxy or browser cache\n  //The cache will respond with a previously received response, but the Access-Control-Allow-Origin\n  //response header might not match the current Origin header (e.g. localhost vs. developer.api.autodesk.com)\n  //which will cause a CORS error on the second request for the same resource.\n  this.getQueryParams(inputObj);\n\n  //shared geometry/material storage\n  inputObj.otg_cdn = CDN_ROOT || this.getCdnUrl();\n  inputObj.otg_ws = this.getCdnWebSocketEndpoint();\n\n  return inputObj;\n};\n\n//TODO: Globals that need a better place\nvar _env; //formerly avp.env\nfunction getEnv() {\n  return _env;\n}\nfunction setEnv(env) {\n  _env = env;\n}\n\n// Set viewer in offline mode if set to true. In offline mode, viewer would ignore all URNs in bubble JSON\n// and assume the viewables are laid out in local file system path relative to the bubble.json.\nvar _offline = false;\nfunction isOffline() {\n  return _offline;\n}\nfunction setOffline(offline) {\n  _offline = offline;\n}\n\n// Offline resource prefix specified by viewer consumer (e.g. IOS web view). Used as prefix to concatenate with\n// each resource relative path to form the absolute path of each resource.\nvar _offlineResourcePrefix = \"\";\nfunction setOfflineResourcePrefix(prefix) {\n  _offlineResourcePrefix = prefix;\n}\nfunction getOfflineResourcePrefix() {\n  return _offlineResourcePrefix;\n}\n\nvar endpoint = endp;\n\n//For backwards compatibility until all code is converted to use\n//the function from the endpoint instance.\nvar initLoadContext = endp.initLoadContext.bind(endp);\n\n/***/ }),\n\n/***/ \"./src/file-loaders/workers/GeomWorker.js\":\n/*!************************************************!*\\\n  !*** ./src/file-loaders/workers/GeomWorker.js ***!\n  \\************************************************/\n/*! exports provided: register */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"register\", function() { return register; });\n/* harmony import */ var _lmvtk_svf_PackReader__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lmvtk/svf/PackReader */ \"./src/file-loaders/lmvtk/svf/PackReader.js\");\n/* harmony import */ var _lmvtk_svf_Geoms__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lmvtk/svf/Geoms */ \"./src/file-loaders/lmvtk/svf/Geoms.js\");\n/* harmony import */ var _net_ErrorCodes__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../net/ErrorCodes */ \"./src/file-loaders/net/ErrorCodes.js\");\n/* harmony import */ var _net_Xhr__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../net/Xhr */ \"./src/file-loaders/net/Xhr.js\");\n/* harmony import */ var _wgs_scene_DeriveTopology__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ../../wgs/scene/DeriveTopology */ \"./src/wgs/scene/DeriveTopology.js\");\n\n\n\n\n\n\nfunction guardFunction(loadContext, f) {\n  try {\n    f();\n  }\n  catch (exc) {\n    loadContext.raiseError(\n    _net_ErrorCodes__WEBPACK_IMPORTED_MODULE_2__[\"ErrorCodes\"].BAD_DATA, \"Unhandled exception while reading pack file\",\n    { \"url\": loadContext.url, \"exception\": exc.toString(), \"stack\": exc.stack });\n  }\n}\n\nfunction doGeomLoad(loadContext) {\n\n  var _this = loadContext.worker;\n\n  //Make a blocking request -- it's ok, because\n  //we are in a worker thread.\n\n  function onSuccess(arrayBuffer) {\n    _this.postMessage({\n      url: loadContext.url,\n      workerId: loadContext.workerId,\n      progress: 0.5 });\n    //rough progress reporting -- can do better\n\n    guardFunction(loadContext, function () {\n\n      var pfr = new _lmvtk_svf_PackReader__WEBPACK_IMPORTED_MODULE_0__[\"PackFileReader\"](arrayBuffer);\n\n      var raisedError = false;\n\n      var options = {\n        estimateSizeOnly: true,\n        packNormals: typeof loadContext.packNormals !== \"undefined\" ? loadContext.packNormals : true };\n\n\n      var i,iEnd = pfr.getEntryCounts(),mesh;\n      var skip = loadContext.inMemory || [];\n      var estLength = 0;\n      var shouldReadNext = function shouldReadNext(i) {\n        var v = skip[i >> 5];\n        return !v || !(v & 1 << (i & 31));\n      };\n\n      for (i = 0; i < iEnd; i++)\n      {\n        if (shouldReadNext(i)) {\n          mesh = Object(_lmvtk_svf_Geoms__WEBPACK_IMPORTED_MODULE_1__[\"readGeometry\"])(pfr, i, options);\n          estLength += mesh && mesh.sharedBufferBytes || 0;\n        }\n      }\n\n      var sharedBuffer = estLength ? new ArrayBuffer(estLength) : null;\n      var currentOffset = 0;\n\n      var msg = { \"packId\": loadContext.packId,\n        \"workerId\": loadContext.workerId,\n        \"progress\": 1,\n        \"meshes\": [],\n        \"sharedBuffer\": sharedBuffer };\n\n\n      var transferList = sharedBuffer ? [sharedBuffer] : [];\n\n      options = {\n        dstBuffer: sharedBuffer,\n        startOffset: 0,\n        estimateSizeOnly: false,\n        packNormals: typeof loadContext.packNormals !== \"undefined\" ? loadContext.packNormals : true };\n\n\n      for (i = 0; i < iEnd; i++)\n      {\n        options.startOffset = currentOffset;\n\n        if (shouldReadNext(i)) {\n          mesh = Object(_lmvtk_svf_Geoms__WEBPACK_IMPORTED_MODULE_1__[\"readGeometry\"])(pfr, i, options);\n\n          if (mesh) {\n            currentOffset += mesh.sharedBufferBytes || 0;\n            msg.meshes[i] = mesh;\n\n            if (loadContext.createWireframe) {\n              Object(_wgs_scene_DeriveTopology__WEBPACK_IMPORTED_MODULE_4__[\"createWireframe\"])(mesh);\n\n              //TODO: optimize the storage of the lines index buffer to use\n              //a single shared buffer for all meshes in the pack\n              if (mesh.iblines)\n              transferList.push(mesh.iblines.buffer);\n            }\n          } else {\n            // it doesn't make much sense to raise an error for each entry that can't\n            // be read, because chances are they will all be unreadable after the\n            // first bad one.\n            if (!raisedError) {\n              _this.raiseError(\n              _net_ErrorCodes__WEBPACK_IMPORTED_MODULE_2__[\"ErrorCodes\"].BAD_DATA, \"Unable to load geometry\",\n              { \"url\": loadContext.url });\n              raisedError = true;\n            }\n\n            // in this case, we still post the full message instead of just null;\n            // the mesh itself will be null, of course.\n            _this.postMessage(msg);\n          }\n        }\n      }\n\n      _this.postMessage(msg, transferList);\n    });\n\n  }\n\n  // With this option to control whether want to record assets request.\n  var options = {\n    skipAssetCallback: loadContext.skipAssetCallback };\n\n  _net_Xhr__WEBPACK_IMPORTED_MODULE_3__[\"ViewingService\"].getItem(loadContext, loadContext.url, onSuccess, loadContext.onFailureCallback, options);\n\n}\n\nfunction register(workerMain) {\n  workerMain.register(\"LOAD_GEOMETRY\", { doOperation: doGeomLoad });\n}\n\n/***/ }),\n\n/***/ \"./src/globals.js\":\n/*!************************!*\\\n  !*** ./src/globals.js ***!\n  \\************************/\n/*! exports provided: getScript, injectCSS, getHtmlTemplate, isExperimentalFlagEnabled, getResourceUrl, getParameterByName, getParameterByNameFromPath, stringToDOM */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getScript\", function() { return getScript; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"injectCSS\", function() { return injectCSS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getHtmlTemplate\", function() { return getHtmlTemplate; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"isExperimentalFlagEnabled\", function() { return isExperimentalFlagEnabled; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getResourceUrl\", function() { return getResourceUrl; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getParameterByName\", function() { return getParameterByName; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getParameterByNameFromPath\", function() { return getParameterByNameFromPath; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"stringToDOM\", function() { return stringToDOM; });\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./compat */ \"./src/compat.js\");\n\n\n\nvar g = Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"getGlobal\"])();\nvar _window = g;\nvar _document = _window && _window.document;\n\ng.LOCALIZATION_REL_PATH = \"\";\n\n/**\n                               * Contains the Viewer's version.\n                               * @type {string}\n                               * @global\n                               */\ng.LMV_VIEWER_VERSION = \"7.11.0\";\n\ng.LMV_BUILD_TYPE = \"Production\";\ng.LMV_RESOURCE_ROOT = \"\";\n\n/**\n                           * When true, requests to Forge are authenticated with a cookie. \n                           * When false, requests to Forge are authenticated with an Authentication header.\n                           * When undefined, the viewer will first try authentication via cookie, if \n                           * that doesn't work it will fallback to using an Authentication header.\n                           * @type {boolean|undefined}\n                           * @global\n                           * @default undefined\n                           */\ng.LMV_THIRD_PARTY_COOKIE = Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isNodeJS\"])() ? false : undefined;\n\nif (g.LMV_VIEWER_VERSION.charAt(0) === 'v') {\n  // remove prefixed 'v'\n  // Required due to TeamCity build pipeline (LMV-1361)\n  g.LMV_VIEWER_VERSION = g.LMV_VIEWER_VERSION.substr(1);\n}\n\n\n/**\n   * When true, the viewer will favor loading the PDF file over the Leaflet derivative, \n   * ignoring the manifest value for `totalRasterPixels`. A true value will take precedence over {@link LMV_RASTER_PDF}.\n   * @type {boolean}\n   * @default \n   * @global\n   */\ng.LMV_VECTOR_PDF = false;\n\n/**\n                           * When true, the viewer will favor loading the Leaflet derivative over the PDF file,\n                           * ignoring the manifest value for `totalRasterPixels`. When {@link LMV_RASTER_PDF} is true, this value is ignored. \n                           * @type {boolean}\n                           * @default \n                           * @global\n                           */\ng.LMV_RASTER_PDF = true;\n\n\n// TODO:  This is here for now, until we find a better place for it.\n//\n/**\n * Returns the first source url found containing the given script name.\n * @private\n * @param {string} scriptName - Script name.\n * @returns {HTMLScriptElement} The script element whose source location matches the input parameter.\n */\nfunction getScript(scriptName) {\n  scriptName = scriptName.toLowerCase();\n  var scripts = _document.getElementsByTagName('SCRIPT');\n  if (scripts && scripts.length > 0) {\n    for (var i = 0; i < scripts.length; ++i) {\n      if (scripts[i].src && scripts[i].src.toLowerCase().indexOf(scriptName) !== -1) {\n        return scripts[i];\n      }\n    }\n  }\n  return null;\n}\n\n/**\n   * Inject a css file into the page.\n   * There's a callback if you need to know when it gets downloaded (rare).\n   * Accepts both relative and absolute URLs.\n   * @private\n   */\nfunction injectCSS(cssUrl, callback, onError) {\n  var href = cssUrl.indexOf('://') > 0 ? cssUrl : getResourceUrl(cssUrl);\n\n  // Verify that we haven't downloaded it already\n  var results = _document.getElementsByTagName('link');\n  for (var i = 0, len = results.length; i < len; i++) {\n    if (results[i].href === href) {\n      // Already downloaded\n      callback && callback();\n      return;\n    }\n  }\n\n  // else, download it\n  var s = _document.createElement(\"link\");\n  s.setAttribute('rel', \"stylesheet\");\n  s.setAttribute('type', \"text/css\");\n  s.setAttribute('href', href);\n  if (callback) {\n    s.onload = callback;\n  }\n  if (onError) {\n    s.onerror = onError;\n  }\n  _document.head.appendChild(s);\n}\n\n/**\n   * Download an HTML template.\n   * If successful, will invoke callback(null, templateString)\n   * If failure, will invoke callback(\"some error\", null)\n   * @private\n   * @deprecated\n   */\nfunction getHtmlTemplate(templateUrl, callback) {\n  var href = templateUrl.indexOf('://') > 0 ? templateUrl : getResourceUrl(templateUrl);\n  var request = new XMLHttpRequest();\n  request.onload = requestLoad;\n  request.onerror = requestError;\n  request.ontimeout = requestError;\n  request.open('GET', href, true);\n  request.send();\n\n  function requestError(err) {\n    callback(err, null);\n  }\n  function requestLoad(event) {\n    var content = event.currentTarget.responseText;\n    callback(null, content);\n  }\n\n}\n\n/**\n   * Checks whether an experimental flag has been set into the viewer's' `config`\n   * object, which happens to be the same as the extension's `options` object.\n   * @private\n   */\nfunction isExperimentalFlagEnabled(flagName, config3d) {\n  if (!config3d || !Array.isArray(config3d.experimental))\n  return false;\n  return config3d.experimental.indexOf(flagName) !== -1;\n}\n\n\n/**\n   * Returns the full url of a resource with version.\n   * The version will be determined from the LMV_VIEWER_VERSION variable.\n   * @private\n   * @param {string} resourceRelativePath - The path of the resource relative to LMV_RESOURCE_ROOT.\n   * @returns {string} The full resource path.\n   */\nfunction getResourceUrl(resourceRelativePath) {\n  return g.LMV_RESOURCE_ROOT + resourceRelativePath;\n}\n\n\n// Returns the query parameter value from window url\nfunction getParameterByName(name) {\n  if (typeof window === \"undefined\") {\n    return \"\";\n  }\n  return getParameterByNameFromPath(name, _window.location.href);\n}\n\n// return value of parameter from a url\nfunction getParameterByNameFromPath(name, url) {\n  name = name.replace(/[\\[]/, \"\\\\\\[\").replace(/[\\]]/, \"\\\\\\]\");\n  var regexS = \"[\\\\?&]\" + name + \"=([^&#]*)\";\n  var regex = new RegExp(regexS);\n  var results = regex.exec(url);\n  if (results == null)\n  return \"\";else\n\n  return decodeURIComponent(results[1].replace(/\\+/g, \" \"));\n}\n\n\nfunction stringToDOM(str) {\n  var d = _document.createElement(\"div\");\n  d.innerHTML = str;\n  return d.firstChild;\n}\n\n/***/ }),\n\n/***/ \"./src/logger/Logger.js\":\n/*!******************************!*\\\n  !*** ./src/logger/Logger.js ***!\n  \\******************************/\n/*! exports provided: LogLevels, Logger, logger, setLogger */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LogLevels\", function() { return LogLevels; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"Logger\", function() { return Logger; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"logger\", function() { return logger; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"setLogger\", function() { return setLogger; });\n/* harmony import */ var _compat__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../compat */ \"./src/compat.js\");\n/* harmony import */ var _file_loaders_net_endpoints__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../file-loaders/net/endpoints */ \"./src/file-loaders/net/endpoints.js\");\n\n\n\n\nvar global = Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"getGlobal\"])();\nvar _window = global;\n\n/**\n                       * Logging levels. Higher number means more verbose logs,\n                       * for example, with level 3, `info`, `warn`, or `error`\n                       * logs will show up in the console but `debug` and `log` won't.\n                       *\n                       * Semantics of specific levels:\n                       *  - debug: low-level debugging logs\n                       *  - log: common, higher-level debugging logs\n                       *  - info: helpful runtime information (even for stag/prod environments)\n                       *  - warn: potentially problematic situations; handled exceptions\n                       *  - error: definitely problematic situations; unhandled exceptions\n                       * @readonly\n                       * @enum {number}\n                       */\nvar LogLevels = {\n  DEBUG: 5,\n  LOG: 4,\n  INFO: 3,\n  WARNING: 2,\n  ERROR: 1,\n  NONE: 0 };\n\n\n\n/**\n              * Logger class. \n              * Depending on options.logLevel setting in initilize function, corresponding functions would be activated.\n              */\nfunction Logger() {\n  this.runtimeStats = {};\n  this.level = -1;\n  this.setLevel(LogLevels.ERROR);\n  this._reportError = this._reportError.bind(this);\n}\n\n/**\n   * Initialize Logger object with options. \n   * \n   * @param {object}   [options] - Options object to configure the Logger.\n   * @param {function} [options.eventCallback] - An optional callback used for processing the log entry with properties like \"category\", \"timestamp\", etc. \n                                                 It can be used as for analytics tracking by filtering and listening to specific category users are interested. \n                                                 The expected argument is the user supplied entry object instrumented with \"timestamp\" and \"sessionId\" properties. \n   * @param {string}   [options.sessionId] - An optional id for each browser session. Default gets generated based on current time stamp if not specified. \n   * @param {number}   [options.logLevel] - An optional level to define the log level. Default is LogLevels.ERROR if not specified.\n   *\n   */\n\nLogger.prototype.initialize = function (options) {\n\n  if (options.eventCallback)\n  this.callback = options.eventCallback;\n\n  this.sessionId = options.sessionId;\n  if (!this.sessionId) {\n    var now = Date.now() + \"\";\n    this.sessionId = parseFloat((Math.random() * 10000 | 0) + \"\" + now.substring(4));\n  }\n\n  // Initialize log level is passed in\n  if (typeof options.logLevel === 'number') {\n    this.setLevel(options.logLevel);\n  }\n\n  this.environmentInfo = {\n    touch: Object(_compat__WEBPACK_IMPORTED_MODULE_0__[\"isTouchDevice\"])(),\n    env: Object(_file_loaders_net_endpoints__WEBPACK_IMPORTED_MODULE_1__[\"getEnv\"])(),\n    referer: getReferer(),\n    version: global.LMV_VIEWER_VERSION,\n    build_type: global.LMV_BUILD_TYPE };\n\n\n  //Kick off with a viewer start event\n  var startEvent = {\n    category: \"viewer_start\",\n    touch: this.environmentInfo.touch,\n    env: this.environmentInfo.env,\n    referer: this.environmentInfo.referer,\n    version: this.environmentInfo.version,\n    build_type: this.environmentInfo.build_type };\n\n  this.track(startEvent);\n\n  var _this = this;\n  this.interval = setInterval(function () {\n    _this.reportRuntimeStats();\n  }, 60000);\n};\n\n/**\n    * Stop the runtime stats reporting every min.\n    */\nLogger.prototype.shutdown = function () {\n  clearInterval(this.interval);\n  this.interval = undefined;\n};\n\n\n/**\n    * Track the user inputted entry by appending additional info \"timestamp\", \"sessionId\"\n    * @param {object} [entry] - User object to define the track object, \n           e.g. {\n               category : \"load_document\",\n               urn: \"xyz\"\n           }   \n    */\nLogger.prototype.track = function (entry) {\n\n  this.updateRuntimeStats(entry);\n\n  if (Object(_file_loaders_net_endpoints__WEBPACK_IMPORTED_MODULE_1__[\"isOffline\"])() || !this.sessionId) {\n    return;\n  }\n\n  if (this.callback) {\n\n    entry.timestamp = Date.now();\n    entry.sessionId = this.sessionId;\n\n    this.callback(entry);\n  }\n};\n\nLogger.prototype.updateRuntimeStats = function (entry) {\n  if (entry.hasOwnProperty('aggregate')) {\n    switch (entry.aggregate) {\n      case 'count':\n        if (this.runtimeStats[entry.name] > 0) {\n          this.runtimeStats[entry.name]++;\n        } else {\n          this.runtimeStats[entry.name] = 1;\n        }\n        this.runtimeStats._nonempty = true;\n        break;\n      case 'last':\n        this.runtimeStats[entry.name] = entry.value;\n        this.runtimeStats._nonempty = true;\n        break;\n      default:\n        this.warn('unknown log aggregate type');}\n\n  }\n};\n\nLogger.prototype.reportRuntimeStats = function () {\n  if (this.runtimeStats._nonempty) {\n    delete this.runtimeStats._nonempty;\n\n    this.runtimeStats.category = 'misc_stats';\n    this.track(this.runtimeStats);\n    this.runtimeStats = {};\n  }\n};\n\nLogger.prototype.setLevel = function (level) {\n  if (this.level === level)\n  return;\n\n  this.level = level;\n\n  // Bind to console\n  this.debug = level >= LogLevels.DEBUG ? console.log : consoleNothing;\n  this.log = level >= LogLevels.LOG ? console.log : consoleNothing;\n  this.info = level >= LogLevels.INFO ? console.info : consoleNothing;\n  this.warn = level >= LogLevels.WARNING ? console.warn : consoleNothing;\n  this.error = level >= LogLevels.ERROR ? this._reportError : consoleNothing;\n};\n\n\n/**\n    * Reports an error to the browser console and to the logger's callback.\n    * Invoked by developers when method `logger.error()` is used. \n    * Forwards the arguments directly into `console.error()`. \n    * @private\n    */\nLogger.prototype._reportError = function () {\n  if (this.callback) {\n    var msg = Array.prototype.slice.call(arguments).join(' ');\n    this.callback({ category: 'error', message: msg });\n  }\n  console.error.apply(console, arguments);\n};\n\n/**\n    * @private\n    */\nfunction getReferer() {\n  // Wrapping href retrieval due to Fortify complains\n  if (typeof window !== 'undefined') {\n    return encodeURI(_window.location.href);\n  }\n  return '';\n}\n\n\n\n/**\n   * Swallows log/debug/info/warn/error calls when the logLevel disallows it.\n   * @private\n   */\nfunction consoleNothing() {\n\n}\n\n\nvar logger = new Logger();\n\nfunction setLogger(l) {\n  logger = l;\n}\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/BVHBuilder.js\":\n/*!*************************************!*\\\n  !*** ./src/wgs/scene/BVHBuilder.js ***!\n  \\*************************************/\n/*! exports provided: NodeArray, BVHBuilder */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"NodeArray\", function() { return NodeArray; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"BVHBuilder\", function() { return BVHBuilder; });\n/**\n * BVH definitions:\n *\n * BVH Node: if this was C (the only real programming language), it would go something like this,\n * but with better alignment.\n *\n * This is definition for \"fat\" nodes (for rasterization),\n * i.e. when inner nodes also contain primitives.\n * struct Node {                                                            byte/short/int offset\n *      float worldBox[6]; //world box of the node node                         0/0/0\n *      int leftChildIndex; //pointer to left child node (right is left+1)     24/12/6\n *      ushort primCount; //how many fragments are at this node                28/14/7\n *      ushort flags; //bitfield of good stuff                                 30/15/7.5\n *\n *      int primStart; //start of node's own primitives (fragments) list       32/16/8\n * };\n * => sizeof(Node) = 36 bytes\n\n * Definition for lean nodes (for ray casting): when a node is either inner node (just children, no primitives)\n * or leaf (just primitives, no children).\n * struct Node {\n *      float worldBox[6]; //world box of the node\n *      union {\n *          int leftChildIndex; //pointer to left child node (right is left+1)\n *          int primStart; //start of node's own primitives (fragments) list\n *      };\n *      ushort primCount; //how many fragments are at this node\n *      ushort flags; //bitfield of good stuff\n * };\n * => sizeof(Node) = 32 bytes\n *\n * The class below encapsulates an array of such nodes using ArrayBuffer as backing store.\n *\n * @param {ArrayBuffer|number} initialData  Initial content of the NodeArray, or initial allocation of empty nodes\n * @param {boolean} useLeanNode Use minimal node structure size. Currently this parameter must be set to false.\n * @constructor\n */\nfunction NodeArray(initialData, useLeanNode) {\n  'use strict';\n\n  if (useLeanNode) {\n    this.bytes_per_node = 32;\n  } else {\n    this.bytes_per_node = 36;\n  }\n\n  var initialCount;\n  var initialBuffer;\n\n  if (initialData instanceof ArrayBuffer) {\n    initialCount = initialData.byteLength / this.bytes_per_node;\n    initialBuffer = initialData;\n    this.nodeCount = initialCount;\n  } else\n  {\n    initialCount = initialData | 0;\n    initialBuffer = new ArrayBuffer(this.bytes_per_node * initialCount);\n    this.nodeCount = 0;\n  }\n\n  this.nodeCapacity = initialCount;\n  this.nodesRaw = initialBuffer;\n\n  this.is_lean_node = useLeanNode;\n  this.node_stride = this.bytes_per_node / 4;\n  this.node_stride_short = this.bytes_per_node / 2;\n\n  //Allocate memory buffer for all tree nodes\n  this.nodesF = new Float32Array(this.nodesRaw);\n  this.nodesI = new Int32Array(this.nodesRaw);\n  this.nodesS = new Uint16Array(this.nodesRaw);\n}\n\nNodeArray.prototype.setLeftChild = function (nodeidx, childidx) {\n  this.nodesI[nodeidx * this.node_stride + 6] = childidx;\n};\nNodeArray.prototype.getLeftChild = function (nodeidx) {\n  return this.nodesI[nodeidx * this.node_stride + 6];\n};\n\nNodeArray.prototype.setPrimStart = function (nodeidx, start) {\n  if (this.is_lean_node)\n  this.nodesI[nodeidx * this.node_stride + 6] = start;else\n\n  this.nodesI[nodeidx * this.node_stride + 8] = start;\n};\nNodeArray.prototype.getPrimStart = function (nodeidx) {\n  if (this.is_lean_node)\n  return this.nodesI[nodeidx * this.node_stride + 6];else\n\n  return this.nodesI[nodeidx * this.node_stride + 8];\n};\n\nNodeArray.prototype.setPrimCount = function (nodeidx, count) {\n  this.nodesS[nodeidx * this.node_stride_short + 14] = count;\n};\nNodeArray.prototype.getPrimCount = function (nodeidx) {\n  return this.nodesS[nodeidx * this.node_stride_short + 14];\n};\n\nNodeArray.prototype.setFlags = function (nodeidx, axis, isFirst, isTransparent) {\n  this.nodesS[nodeidx * this.node_stride_short + 15] = isTransparent << 3 | isFirst << 2 | axis & 0x3;\n};\nNodeArray.prototype.getFlags = function (nodeidx) {\n  return this.nodesS[nodeidx * this.node_stride_short + 15];\n};\n\nNodeArray.prototype.setBox0 = function (nodeidx, src) {\n  var off = nodeidx * this.node_stride;\n  var dst = this.nodesF;\n  dst[off] = src[0];\n  dst[off + 1] = src[1];\n  dst[off + 2] = src[2];\n  dst[off + 3] = src[3];\n  dst[off + 4] = src[4];\n  dst[off + 5] = src[5];\n};\nNodeArray.prototype.getBoxThree = function (nodeidx, dst) {\n  var off = nodeidx * this.node_stride;\n  var src = this.nodesF;\n  dst.min.x = src[off];\n  dst.min.y = src[off + 1];\n  dst.min.z = src[off + 2];\n  dst.max.x = src[off + 3];\n  dst.max.y = src[off + 4];\n  dst.max.z = src[off + 5];\n};\nNodeArray.prototype.getBoxArray = function (nodeidx, dst, offset) {\n  var off = nodeidx * this.node_stride;\n  var src = this.nodesF;\n  offset = offset || 0;\n  dst[0 + offset] = src[off];\n  dst[1 + offset] = src[off + 1];\n  dst[2 + offset] = src[off + 2];\n  dst[3 + offset] = src[off + 3];\n  dst[4 + offset] = src[off + 4];\n  dst[5 + offset] = src[off + 5];\n};\nNodeArray.prototype.setBoxThree = function (nodeidx, src) {\n  var off = nodeidx * this.node_stride;\n  var dst = this.nodesF;\n  dst[off] = src.min.x;\n  dst[off + 1] = src.min.y;\n  dst[off + 2] = src.min.z;\n  dst[off + 3] = src.max.x;\n  dst[off + 4] = src.max.y;\n  dst[off + 5] = src.max.z;\n};\n\n\n\n\nNodeArray.prototype.makeEmpty = function (nodeidx) {\n\n  var off = nodeidx * this.node_stride;\n  var dst = this.nodesI;\n\n  //No point to makeEmpty here, because the box gets set\n  //directly when the node is initialized in bvh_subdivide.\n  //box_make_empty(this.nodesF, off);\n\n  //_this.setLeftChild(nodeidx,-1);\n  dst[off + 6] = -1;\n\n  //both prim count and flags to 0\n  dst[off + 7] = 0;\n\n  //_this.setPrimStart(nodeidx, -1);\n  if (!this.is_lean_node)\n  dst[off + 8] = -1;\n\n};\n\nNodeArray.prototype.realloc = function (extraSize) {\n  if (this.nodeCount + extraSize > this.nodeCapacity) {\n    var nsz = 0 | this.nodeCapacity * 3 / 2;\n    if (nsz < this.nodeCount + extraSize)\n    nsz = this.nodeCount + extraSize;\n\n    var nnodes = new ArrayBuffer(nsz * this.bytes_per_node);\n    var nnodesI = new Int32Array(nnodes);\n    nnodesI.set(this.nodesI);\n\n    this.nodeCapacity = nsz;\n    this.nodesRaw = nnodes;\n    this.nodesF = new Float32Array(nnodes);\n    this.nodesI = nnodesI;\n    this.nodesS = new Uint16Array(nnodes);\n  }\n};\n\nNodeArray.prototype.nextNodes = function (howMany) {\n\n  this.realloc(howMany);\n\n  var res = this.nodeCount;\n  this.nodeCount += howMany;\n\n  for (var i = 0; i < howMany; i++) {\n    this.makeEmpty(res + i);\n  }\n\n  return res;\n};\n\nNodeArray.prototype.getRawData = function () {\n  return this.nodesRaw.slice(0, this.nodeCount * this.bytes_per_node);\n};\n\nvar POINT_STRIDE = 3;\nvar BOX_EPSILON = 1e-5;\nvar BOX_SCALE_EPSILON = 1e-5;\nvar MAX_DEPTH = 15; /* max tree depth */\nvar MAX_BINS = 16;\n\n/**\n                   * Bounding Volume Hierarchy build algorithm.\n                   * Uses top down binning -- see \"On fast Construction of SAH-based Bounding Volume Hierarchies\" by I.Wald\n                   * Ported from the C version here: https://git.autodesk.com/stanevt/t-ray/blob/master/render3d/t-ray/t-core/t-bvh.c\n                   * Optimized for JavaScript.\n                   */\nvar BVHModule = function () {\n  //There be dragons in this closure.\n\n  \"use strict\";\n\n\n  /**\n                 * Utilities for manipulating bounding boxes stored\n                 * in external array (as sextuplets of float32)\n                 */\n\n\n  function box_get_centroid(dst, dst_off, src, src_off) {\n    dst[dst_off] = 0.5 * (src[src_off] + src[src_off + 3]);\n    dst[dst_off + 1] = 0.5 * (src[src_off + 1] + src[src_off + 4]);\n    dst[dst_off + 2] = 0.5 * (src[src_off + 2] + src[src_off + 5]);\n  }\n\n  function box_add_point_0(dst, src, src_off) {\n\n    if (dst[0] > src[src_off]) dst[0] = src[src_off];\n    if (dst[3] < src[src_off]) dst[3] = src[src_off];\n\n    if (dst[1] > src[src_off + 1]) dst[1] = src[src_off + 1];\n    if (dst[4] < src[src_off + 1]) dst[4] = src[src_off + 1];\n\n    if (dst[2] > src[src_off + 2]) dst[2] = src[src_off + 2];\n    if (dst[5] < src[src_off + 2]) dst[5] = src[src_off + 2];\n\n  }\n\n  function box_add_box_0(dst, src, src_off) {\n\n    if (dst[0] > src[src_off]) dst[0] = src[src_off];\n    if (dst[1] > src[src_off + 1]) dst[1] = src[src_off + 1];\n    if (dst[2] > src[src_off + 2]) dst[2] = src[src_off + 2];\n\n    if (dst[3] < src[src_off + 3]) dst[3] = src[src_off + 3];\n    if (dst[4] < src[src_off + 4]) dst[4] = src[src_off + 4];\n    if (dst[5] < src[src_off + 5]) dst[5] = src[src_off + 5];\n  }\n\n  function box_add_box_00(dst, src) {\n    if (dst[0] > src[0]) dst[0] = src[0];\n    if (dst[1] > src[1]) dst[1] = src[1];\n    if (dst[2] > src[2]) dst[2] = src[2];\n\n    if (dst[3] < src[3]) dst[3] = src[3];\n    if (dst[4] < src[4]) dst[4] = src[4];\n    if (dst[5] < src[5]) dst[5] = src[5];\n  }\n\n  function box_get_size(dst, dst_off, src, src_off) {\n    for (var i = 0; i < 3; i++) {\n      dst[dst_off + i] = src[src_off + 3 + i] - src[src_off + i];\n    }\n  }\n\n  //function box_copy(dst, dst_off, src, src_off) {\n  //    for (var i=0; i<6; i++) {\n  //        dst[dst_off+i] = src[src_off+i];\n  //    }\n  //}\n\n  // unwound version of box_copy\n  function box_copy_00(dst, src) {\n    dst[0] = src[0];\n    dst[1] = src[1];\n    dst[2] = src[2];\n    dst[3] = src[3];\n    dst[4] = src[4];\n    dst[5] = src[5];\n  }\n\n  var dbl_max = Infinity;\n\n  //function box_make_empty(dst, dst_off) {\n  //        dst[dst_off]   =  dbl_max;\n  //        dst[dst_off+1] =  dbl_max;\n  //        dst[dst_off+2] =  dbl_max;\n  //        dst[dst_off+3] = -dbl_max;\n  //        dst[dst_off+4] = -dbl_max;\n  //        dst[dst_off+5] = -dbl_max;\n  //}\n\n  function box_make_empty_0(dst) {\n    dst[0] = dbl_max;\n    dst[1] = dbl_max;\n    dst[2] = dbl_max;\n    dst[3] = -dbl_max;\n    dst[4] = -dbl_max;\n    dst[5] = -dbl_max;\n  }\n\n  function box_area(src, src_off) {\n\n    var dx = src[src_off + 3] - src[src_off];\n    var dy = src[src_off + 4] - src[src_off + 1];\n    var dz = src[src_off + 5] - src[src_off + 2];\n\n    if (dx < 0 || dy < 0 || dz < 0)\n    return 0;\n\n    return 2.0 * (dx * dy + dy * dz + dz * dx);\n  }\n\n  function box_area_0(src) {\n\n    var dx = src[3] - src[0];\n    var dy = src[4] - src[1];\n    var dz = src[5] - src[2];\n\n    if (dx < 0 || dy < 0 || dz < 0)\n    return 0;\n\n    return 2.0 * (dx * dy + dy * dz + dz * dx);\n  }\n\n\n\n\n\n  function bvh_split_info() {\n    this.vb_left = new Float32Array(6);\n    this.vb_right = new Float32Array(6);\n    this.cb_left = new Float32Array(6);\n    this.cb_right = new Float32Array(6);\n    this.num_left = 0;\n    this.best_split = -1;\n    this.best_cost = -1;\n    this.num_bins = -1;\n  }\n\n  bvh_split_info.prototype.reset = function () {\n    this.num_left = 0;\n    this.best_split = -1;\n    this.best_cost = -1;\n    this.num_bins = -1;\n  };\n\n\n  function bvh_bin() {\n    this.box_bbox = new Float32Array(6); // bbox of all primitive bboxes\n    this.box_centroid = new Float32Array(6); // bbox of all primitive centroids\n    this.num_prims = 0; // number of primitives in the bin\n  }\n\n  bvh_bin.prototype.reset = function () {\n    this.num_prims = 0; // number of primitives in the bin\n    box_make_empty_0(this.box_bbox);\n    box_make_empty_0(this.box_centroid);\n  };\n\n  function accum_bin_info() {\n    this.BL = new Float32Array(6);\n    this.CL = new Float32Array(6);\n    this.NL = 0;\n    this.AL = 0;\n  }\n\n  accum_bin_info.prototype.reset = function () {\n    this.NL = 0;\n    this.AL = 0;\n\n    box_make_empty_0(this.BL);\n    box_make_empty_0(this.CL);\n  };\n\n\n  //Scratch variables used by bvh_bin_axis\n  //TODO: can be replaced by a flat ArrayBuffer\n  var bins = [];\n  var i;\n  for (i = 0; i < MAX_BINS; i++) {\n    bins.push(new bvh_bin());\n  }\n\n  //TODO: can be replaced by a flat ArrayBuffer\n  var ai = [];\n  for (i = 0; i < MAX_BINS - 1; i++) {\n    ai.push(new accum_bin_info());}\n\n  var BR = new Float32Array(6);\n  var CR = new Float32Array(6);\n\n\n  function assign_bins(bvh, start, end, axis, cb, cbdiag, num_bins) {\n\n    var centroids = bvh.centroids;\n    var primitives = bvh.primitives;\n    var boxes = bvh.finfo.boxes;\n    var boxStride = bvh.finfo.boxStride;\n\n    /* bin assignment */\n    var k1 = num_bins * (1.0 - BOX_SCALE_EPSILON) / cbdiag[axis];\n    var cbaxis = cb[axis];\n    var sp = bvh.sort_prims;\n\n    for (var j = start; j <= end; j++)\n    {\n      /* map array index to primitive index -- since primitive index array gets reordered by the BVH build*/\n      /* while the primitive info array is not reordered */\n      var iprim = primitives[j] | 0;\n\n      var fpbin = k1 * (centroids[iprim * 3 /*POINT_STRIDE*/ + axis] - cbaxis);\n      var binid = fpbin | 0; //Truncate to int is algorithmic -> not an optimization thing!\n\n      /* possible floating point problems */\n      if (binid < 0)\n      {\n        binid = 0;\n        //debug(\"Bin index out of range \" + fpbin);\n      } else\n      if (binid >= num_bins)\n      {\n        binid = num_bins - 1;\n        //debug(\"Bin index out of range. \" + fpbin);\n      }\n\n      /* Store the bin index for the partitioning step, so we don't recompute it there */\n      sp[j] = binid;\n\n      /* update other bin data with the new primitive */\n      //var bin = bins[binid];\n      bins[binid].num_prims++;\n\n      box_add_box_0(bins[binid].box_bbox, boxes, iprim * boxStride);\n      box_add_point_0(bins[binid].box_centroid, centroids, iprim * 3 /*POINT_STRIDE*/);\n    }\n    /* at this point all primitves are assigned to a bin */\n  }\n\n\n  function bvh_bin_axis(bvh, start, end, axis, cb, cbdiag, split_info) {\n\n    /* if size is near 0 on this axis, cost of split is infinite */\n    if (cbdiag[axis] < bvh.scene_epsilon)\n    {\n      split_info.best_cost = Infinity;\n      return;\n    }\n\n    var num_bins = MAX_BINS;\n    if (num_bins > end - start + 1)\n    num_bins = end - start + 1;\n\n    var i;\n    for (i = 0; i < num_bins; i++) {\n      bins[i].reset();}\n\n    for (i = 0; i < num_bins - 1; i++) {\n      ai[i].reset();}\n\n    split_info.num_bins = num_bins;\n\n    assign_bins(bvh, start, end, axis, cb, cbdiag, num_bins);\n\n\n    /* now do the accumulation sweep from left to right */\n    box_copy_00(ai[0].BL, bins[0].box_bbox);\n    box_copy_00(ai[0].CL, bins[0].box_centroid);\n    ai[0].AL = box_area_0(ai[0].BL);\n    ai[0].NL = bins[0].num_prims;\n    var bin;\n    for (i = 1; i < num_bins - 1; i++)\n    {\n      bin = bins[i];\n      var aii = ai[i];\n      box_copy_00(aii.BL, ai[i - 1].BL);\n      box_add_box_00(aii.BL, bin.box_bbox);\n      aii.AL = box_area_0(aii.BL);\n\n      box_copy_00(aii.CL, ai[i - 1].CL);\n      box_add_box_00(aii.CL, bin.box_centroid);\n\n      aii.NL = ai[i - 1].NL + bin.num_prims;\n    }\n\n    /* sweep from right to left, keeping track of lowest cost and split */\n    i = num_bins - 1;\n    box_copy_00(BR, bins[i].box_bbox);\n    box_copy_00(CR, bins[i].box_centroid);\n    var AR = box_area_0(BR);\n    var NR = bins[i].num_prims;\n\n    var best_split = i;\n    var best_cost = AR * NR + ai[i - 1].AL * ai[i - 1].NL;\n    box_copy_00(split_info.vb_right, BR);\n    box_copy_00(split_info.cb_right, bins[i].box_centroid);\n    box_copy_00(split_info.vb_left, ai[i - 1].BL);\n    box_copy_00(split_info.cb_left, ai[i - 1].CL);\n    split_info.num_left = ai[i - 1].NL;\n\n    for (i = i - 1; i >= 1; i--)\n    {\n      bin = bins[i];\n      box_add_box_00(BR, bin.box_bbox);\n      box_add_box_00(CR, bin.box_centroid);\n      AR = box_area_0(BR);\n      NR += bin.num_prims;\n\n      var cur_cost = AR * NR + ai[i - 1].AL * ai[i - 1].NL;\n\n      if (cur_cost <= best_cost)\n      {\n        best_cost = cur_cost;\n        best_split = i;\n\n        box_copy_00(split_info.vb_right, BR);\n        box_copy_00(split_info.cb_right, CR);\n        box_copy_00(split_info.vb_left, ai[i - 1].BL);\n        box_copy_00(split_info.cb_left, ai[i - 1].CL);\n        split_info.num_left = ai[i - 1].NL;\n      }\n    }\n\n    split_info.best_split = best_split;\n    split_info.best_cost = best_cost;\n  }\n\n  function bvh_partition(bvh, start, end, axis, cb, cbdiag, split_info) {\n\n    //At this point, the original algorithm does an in-place NON-STABLE partition\n    //to move primitives to the left and right sides of the split plane\n    //into contiguous location of the primitives list for use by\n    //the child nodes. But, we want to preserve the ordering by size\n    //without having to do another sort, so we have to use\n    //a temporary storage location to copy into. We place right-side primitives\n    //in temporary storage, then copy back into the original storage in the right order.\n    //Left-side primitives are still put directly into the destination location.\n    var primitives = bvh.primitives;\n    //var centroids = bvh.centroids;\n    var i, j;\n\n    //sort_prims contains bin indices computed during the split step.\n    //Here we read those and also use sort_prims as temporary holding\n    //of primitive indices. Hopefully the read happens before the write. :)\n    //In C it was cheap enough to compute this again...\n    //var k1 = split_info.num_bins * (1.0 - BOX_SCALE_EPSILON) / cbdiag[axis];\n    //var cbaxis = cb[axis];\n    var sp = bvh.sort_prims;\n\n    var right = 0;\n    var left = start | 0;\n    var best_split = split_info.best_split | 0;\n\n    for (i = start; i <= end; i++) {\n      var iprim = primitives[i] | 0;\n      //var fpbin = (k1 * (centroids[3/*POINT_STRIDE*/ * iprim + axis] - cbaxis));\n      var binid = sp[i]; /* fpbin|0; */\n\n      if (binid < best_split) {\n        primitives[left++] = iprim;\n      } else {\n        sp[right++] = iprim;\n      }\n    }\n\n    //if ((left-start) != split_info.num_left)\n    //    debug(\"Mismatch between binning and partitioning.\");\n\n    //Copy back the right-side primitives into main primitives array, while\n    //maintaining order\n    for (j = 0; j < right; j++) {\n      primitives[left + j] = sp[j];\n    }\n    /* at this point the binning is complete and we have computed a split */\n  }\n\n\n  function bvh_fatten_inner_node(bvh, nodes, nodeidx, start, end, cb, cbdiag, poly_cut_off) {\n\n    var primitives = bvh.primitives;\n    var centroids = bvh.centroids;\n\n    //Take the first few items to place into the inner node,\n    //but do not go over the max item or polygon count.\n    var prim_count = end - start + 1;\n\n    if (prim_count > bvh.frags_per_inner_node)\n    prim_count = bvh.frags_per_inner_node;\n\n    if (prim_count > poly_cut_off)\n    prim_count = poly_cut_off;\n\n\n    nodes.setPrimStart(nodeidx, start);\n    nodes.setPrimCount(nodeidx, prim_count);\n    start += prim_count;\n\n    //Because we take some primitives off the input, we have to recompute\n    //the bounding box used for computing the node split.\n    box_make_empty_0(cb);\n    for (var i = start; i <= end; i++) {\n      box_add_point_0(cb, centroids, 3 /*POINT_STRIDE*/ * primitives[i]);\n    }\n\n    //Also update the split axis -- it could possibly change too.\n    box_get_size(cbdiag, 0, cb, 0);\n    //Decide which axis to split on. Done purely by longest.\n    var axis = 0;\n    if (cbdiag[1] > cbdiag[0])\n    axis = 1;\n    if (cbdiag[2] > cbdiag[axis])\n    axis = 2;\n\n    return axis;\n  }\n\n\n  var cbdiag = new Float32Array(3); //scratch variable used in bvh_subdivide\n\n  function bvh_subdivide(bvh,\n  nodeidx, /* current parent node to consider splitting */\n  start, end, /* primitive sub-range to be considered at this recursion step */\n  vb, /* bounding volume of the primitives' bounds in the sub-range */\n  cb, /* bounding box of primitive centroids in this range */\n  transparent, /* does the node contain opaque or transparent objects */\n  depth /* recursion depth */)\n\n  {\n    box_get_size(cbdiag, 0, cb, 0);\n    var nodes = bvh.nodes;\n    var frags_per_leaf = transparent ? bvh.frags_per_leaf_node_transparent : bvh.frags_per_leaf_node;\n    var frags_per_inner = transparent ? bvh.frags_per_inner_node_transparent : bvh.frags_per_inner_node;\n    var polys_per_node = bvh.max_polys_per_node;\n\n    //Decide which axis to split on.\n    var axis = 0;\n    if (cbdiag[1] > cbdiag[0])\n    axis = 1;\n    if (cbdiag[2] > cbdiag[axis])\n    axis = 2;\n\n    //Whether the node gets split or not, it gets\n    //the same overall bounding box.\n    nodes.setBox0(nodeidx, vb);\n\n    //Check the expected polygon count of the node. This figures out the maximum number of fragments\n    // we can put at the node as determined by polys_per_node\n    var poly_count = 0;\n    var poly_cut_off = 0;\n    var prim_count = end - start + 1;\n\n    // If we have the number of triangles in each mesh, limit the number of primitives in an inner node.\n    if (bvh.finfo.hasPolygonCounts && bvh.frags_per_inner_node) {\n      // Walk through primitives, add up the counts until we reach polys_per_node (10000), or run through\n      // frags_per_inner_node (usually 32).\n      // We know that later on we'll limit the number to frags_per_inner_node, so also do it here.\n      var shorten_end = prim_count <= bvh.frags_per_inner_node ? end : start + bvh.frags_per_inner_node - 1;\n      for (var i = start; i <= shorten_end; i++) {\n        poly_count += bvh.finfo.getPolygonCount(bvh.primitives[i]);\n        poly_cut_off++;\n        if (poly_count > polys_per_node)\n        break;\n      }\n    }\n\n    var isSmall = prim_count <= frags_per_leaf && poly_count < polys_per_node ||\n    prim_count === 1;\n\n    //Decide whether to terminate recursion\n    if (isSmall ||\n    depth > MAX_DEPTH || //max recursion depth\n    cbdiag[axis] < bvh.scene_epsilon) //node would be way too tiny for math to make sense (a point)\n      {\n        nodes.setLeftChild(nodeidx, -1);\n        nodes.setPrimStart(nodeidx, start);\n        nodes.setPrimCount(nodeidx, end - start + 1);\n        nodes.setFlags(nodeidx, 0, 0, transparent ? 1 : 0);\n        return;\n      }\n\n    //Pick the largest (first) primitives to live in this node\n    //NOTE: this assumes primitives are sorted by size.\n    //NOTE: This step is an optional departure from the original, and we also do a check for it above\n    // to compute poly_cut_off.\n    if (frags_per_inner) {\n      axis = bvh_fatten_inner_node(bvh, nodes, nodeidx, start, end, cb, cbdiag, poly_cut_off);\n      start = start + nodes.getPrimCount(nodeidx);\n    }\n\n    var split_info = new bvh_split_info();\n\n    //Do the binning of the remaining primitives to go into child nodes\n    bvh_bin_axis(bvh, start, end, axis, cb, cbdiag, split_info);\n\n    if (split_info.num_bins < 0) {\n      //Split was too costly, so add all objects to the current node and bail\n      nodes.setPrimCount(nodeidx, nodes.getPrimCount(nodeidx) + end - start + 1);\n      return;\n    }\n\n    bvh_partition(bvh, start, end, axis, cb, cbdiag, split_info);\n\n    var child_idx = nodes.nextNodes(2);\n\n    /* set info about split into the node */\n    var cleft = (split_info.vb_left[3 + axis] + split_info.vb_left[axis]) * 0.5;\n    var cright = (split_info.vb_right[3 + axis] + split_info.vb_right[axis]) * 0.5;\n\n    nodes.setFlags(nodeidx, axis, cleft < cright ? 0 : 1, transparent ? 1 : 0);\n    nodes.setLeftChild(nodeidx, child_idx);\n\n\n    /* validate split */\n    /*\n                         if (true) {\n                             for (var i=start; i< start+num_left; i++)\n                             {\n                                 //int binid = (int)(k1 * (info->prim_info[info->bvh->iprims[i]].centroid.v[axis] - cb->min.v[axis]));\n                                 var cen = primitives[i] * POINT_STRIDE;\n                                 if (   centroids[cen] < split_info.cb_left[0]\n                                     || centroids[cen] > split_info.cb_left[3]\n                                     || centroids[cen+1] < split_info.cb_left[1]\n                                     || centroids[cen+1] > split_info.cb_left[4]\n                                     || centroids[cen+2] < split_info.cb_left[2]\n                                     || centroids[cen+2] > split_info.cb_left[5])\n                                 {\n                                     debug (\"wrong centroid box\");\n                                 }\n                             }\n                              for (i=start+num_left; i<=end; i++)\n                             {\n                                 //int binid = (int)(k1 * (info->prim_info[info->bvh->iprims[i]].centroid.v[axis] - cb->min.v[axis]));\n                                 var cen = primitives[i] * POINT_STRIDE;\n                                 if (   centroids[cen] < split_info.cb_right[0]\n                                     || centroids[cen] > split_info.cb_right[3]\n                                     || centroids[cen+1] < split_info.cb_right[1]\n                                     || centroids[cen+1] > split_info.cb_right[4]\n                                     || centroids[cen+2] < split_info.cb_right[2]\n                                     || centroids[cen+2] > split_info.cb_right[5])\n                                 {\n                                     debug (\"wrong centroid box\");\n                                 }\n                             }\n                         }\n                         */\n\n\n    /* recurse */\n    //bvh_subdivide(bvh, child_idx, start, start + split_info.num_left - 1, split_info.vb_left, split_info.cb_left, transparent, depth+1);\n    //bvh_subdivide(bvh, child_idx + 1, start + split_info.num_left, end, split_info.vb_right, split_info.cb_right, transparent, depth+1);\n\n    //Iterative stack-based recursion for easier profiling\n    bvh.recursion_stack.push([bvh, child_idx + 1, start + split_info.num_left, end, split_info.vb_right, split_info.cb_right, transparent, depth + 1]);\n    bvh.recursion_stack.push([bvh, child_idx, start, start + split_info.num_left - 1, split_info.vb_left, split_info.cb_left, transparent, depth + 1]);\n\n  }\n\n\n  function compute_boxes(bvh) {\n\n    var boxv_o = bvh.boxv_o;\n    var boxc_o = bvh.boxc_o;\n    var boxv_t = bvh.boxv_t;\n    var boxc_t = bvh.boxc_t;\n\n    box_make_empty_0(boxv_o);\n    box_make_empty_0(boxc_o);\n    box_make_empty_0(boxv_t);\n    box_make_empty_0(boxc_t);\n\n    var c = bvh.centroids;\n    var b = bvh.finfo.boxes;\n    var boxStride = bvh.finfo.boxStride;\n\n    for (var i = 0, iEnd = bvh.prim_count; i < iEnd; i++) {\n\n      // find which primitive in the sorted list to use next\n      var p = bvh.primitives[i];\n      box_get_centroid(c, 3 /*POINT_STRIDE*/ * p, b, boxStride * p);\n\n      if (i >= bvh.first_transparent) {\n\n        box_add_point_0(boxc_t, c, 3 /*POINT_STRIDE*/ * p);\n        box_add_box_0(boxv_t, b, boxStride * p);\n\n      } else {\n\n        box_add_point_0(boxc_o, c, 3 /*POINT_STRIDE*/ * p);\n        box_add_box_0(boxv_o, b, boxStride * p);\n\n      }\n    }\n\n    box_get_size(cbdiag, 0, bvh.boxv_o, 0);\n    var maxsz = Math.max(cbdiag[0], cbdiag[1], cbdiag[2]);\n    bvh.scene_epsilon = BOX_EPSILON * maxsz;\n  }\n\n\n\n\n  //Module exports\n  return {\n    bvh_subdivide: bvh_subdivide,\n    compute_boxes: compute_boxes,\n    box_area: box_area };\n\n\n}();\n\n\nfunction FragInfo(fragments, materialDefs) {\n  //Invariants\n  this.boxes = fragments.boxes; //Array of Float32, each bbox is a sextuplet\n  this.polygonCounts = fragments.polygonCounts;\n  this.hasPolygonCounts = !!this.polygonCounts;\n  this.materials = fragments.materials; //material indices (we need to know which fragments are transparent)\n  this.materialDefs = materialDefs;\n  this.count = fragments.length;\n  this.boxStride = 6;\n  this.wantSort = true;\n}\n\nFragInfo.prototype.getCount = function () {\n  return this.count;\n};\n\nFragInfo.prototype.isTransparent = function (i) {\n  return this.materialDefs && this.materialDefs[this.materials[i]] ? this.materialDefs[this.materials[i]].transparent : false;\n};\n\nFragInfo.prototype.getPolygonCount = function (i) {\n  return this.polygonCounts[i];\n};\n\n/**\n    * Given a list of LMV fragments, builds a spatial index for view-dependent traversal and hit testing.\n    * @constructor\n    */\nfunction BVHBuilder(fragments, materialDefs, finfo) {\n\n  //Initialize the inputs (bboxes, transparent flags, polygon counts)\n  this.finfo = finfo || new FragInfo(fragments, materialDefs);\n\n  this.prim_count = this.finfo.getCount();\n\n  //To be initialized by build() function based on build options\n  this.frags_per_leaf_node = -1;\n  this.frags_per_inner_node = -1;\n  this.nodes = null;\n\n  this.work_buf = new ArrayBuffer(this.prim_count * 4);\n  this.sort_prims = new Int32Array(this.work_buf);\n\n  //Allocate memory buffer for re-ordered fragment primitive indices,\n  //which will be sorted by node ownership and point to the index\n  //of the fragment data.\n  this.primitives = new Int32Array(this.prim_count);\n\n  //The BVH split algorithm works based on centroids of the bboxes.\n  this.centroids = new Float32Array(POINT_STRIDE * this.prim_count);\n\n  //BBoxes and centroid bboxes for opaque and transparent primitive sets\n  this.boxv_o = new Float32Array(6);\n  this.boxc_o = new Float32Array(6);\n  this.boxv_t = new Float32Array(6);\n  this.boxc_t = new Float32Array(6);\n\n\n  this.recursion_stack = [];\n}\n\nBVHBuilder.prototype.sortPrimitives = function (wantSort) {\n\n  var prim_sizes = new Float32Array(this.work_buf);\n  var primitives = this.primitives;\n  var numTransparent = 0;\n\n  //Sort the input objects by size\n  //We assume all LMV SVF files come\n  //sorted by draw priority already, so in theory we can skip this step.\n  //This turns out to not be the case - some fragments are badly sorted.\n  //Part of the reason may be that the surface area of the geometry itself,\n  //not its bounding box, is used to sort by physical size in LMVTK.\n  //In any case, the transparent objects do not always come last (bug in LMVTK?),\n  //so we still have to pull them out to the end of the list, so some sorting\n  //takes place no matter how this value is set.\n  // Turning this option on will mean that the BVH building process as a whole\n  // will be 45% to 75% longer, for large models - full sorting takes awhile.\n  // In absolute terms this is an increase of a maximum of 1.15 seconds for a\n  // very large model (one with over 1 million fragments, i.e., mesh instances).\n  // This cost may be acceptable. For smaller models - \"only\" 70K instances -\n  // the cost is 0.05 seconds. For 130k instances, 0.1 seconds. The rise is\n  // slightly more than linear, but not excessively slow. I think it's acceptable,\n  // given that the cost is still much less than loading even a small part of the\n  // model.\n  var doSort = wantSort;\n\n  // console.log(\"BVH sort is \" + WANT_SORT);\n\n  var i, iEnd;\n  for (i = 0, iEnd = this.prim_count; i < iEnd; i++) {\n\n    //Start with trivial 1:1 order of the indices array\n    primitives[i] = i;\n\n    var transparent = this.finfo.isTransparent(i);\n\n    if (transparent)\n    numTransparent++;\n\n    if (doSort) {\n      prim_sizes[i] = BVHModule.box_area(this.finfo.boxes, this.finfo.boxStride * i);\n\n      //In order to make transparent objects appear last,\n      //we give them a negative size, so that they are naturally\n      //sorted last in the sort by size.\n      if (transparent)\n      prim_sizes[i] = -prim_sizes[i];\n    } else {\n      //We still need the transparency flag for the loop below\n      //where we find the last opaque item, but we can\n      //short-cut the size computation.\n      prim_sizes[i] = transparent ? -1 : 1;\n    }\n  }\n\n\n  if (doSort) {\n    Array.prototype.sort.call(this.primitives, function (a, b) {\n      return prim_sizes[b] - prim_sizes[a];\n    });\n  } else {\n    if (numTransparent && numTransparent < this.prim_count) {\n\n      var tmpTransparent = new Int32Array(numTransparent);\n      var oidx = 0,tidx = 0;\n\n      for (i = 0, iEnd = this.prim_count; i < iEnd; i++) {\n        if (prim_sizes[i] >= 0)\n        primitives[oidx++] = primitives[i];else\n\n        tmpTransparent[tidx++] = primitives[i];\n      }\n\n      primitives.set(tmpTransparent, this.prim_count - numTransparent);\n    }\n  }\n\n  this.first_transparent = this.prim_count - numTransparent;\n};\n\n\nBVHBuilder.prototype.build = function (options) {\n  //Kick off the BVH build.\n\n  var useSlimNodes = options && !!options.useSlimNodes;\n\n  var self = this;\n  function assign_option(name, defaultVal) {\n    if (options.hasOwnProperty(name))\n    self[name] = options[name];else\n\n    self[name] = defaultVal;\n  }\n\n  // note: frags_per_leaf_node does *not* make an upper limit for the number of frags per node.\n\n  //options for build optimized for rasterization renderer scenes\n  if (useSlimNodes) {\n    assign_option(\"frags_per_leaf_node\", 1);\n    assign_option(\"frags_per_inner_node\", 0);\n    assign_option(\"frags_per_leaf_node_transparent\", 1);\n    assign_option(\"frags_per_inner_node_transparent\", 0);\n    assign_option(\"max_polys_per_node\", Infinity);\n  } else {\n    var multiplier = options.isWeakDevice ? 0.5 : 1.0;\n\n    //TODO: tune these constants\n    assign_option(\"frags_per_leaf_node\", 0 | 256 * multiplier);\n    //Placing fragments at inner nodes places more emphasis on bigger objects during tree traversal\n    //but it can only be done for opaque objects. Transparent objects have to be strictly back to front\n    //traversal regardless of size, unless a unified traversal\n    assign_option(\"frags_per_inner_node\", 0 | this.frags_per_leaf_node);\n    assign_option(\"frags_per_leaf_node_transparent\", this.frags_per_leaf_node);\n    assign_option(\"frags_per_inner_node_transparent\", 0);\n    assign_option(\"max_polys_per_node\", 0 | 20000 * multiplier);\n  }\n\n  //Reuse existing node array if there\n  if (this.nodes && this.nodes.is_lean_node == useSlimNodes)\n  this.nodes.nodeCount = 0;else\n  {\n    var est_nodes = this.prim_count / this.frags_per_leaf_node;\n    var num_nodes = 1;\n    while (num_nodes < est_nodes) {\n      num_nodes *= 2;}\n\n    this.nodes = new NodeArray(num_nodes, options ? options.useSlimNodes : false);\n  }\n\n  this.sortPrimitives(this.finfo.wantSort);\n\n  BVHModule.compute_boxes(this);\n\n  //Init the root nodes at 0 for opaque\n  //and 1 for transparent objects\n  var root = this.nodes.nextNodes(2);\n\n  //Now kick off the recursive tree build\n\n  //Opaque\n  BVHModule.bvh_subdivide(this, root, 0, this.first_transparent - 1, this.boxv_o, this.boxc_o, false, 0);\n\n  var a;\n  while (this.recursion_stack.length) {\n    a = this.recursion_stack.pop();\n    BVHModule.bvh_subdivide(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);\n  }\n\n  //Transparent\n  BVHModule.bvh_subdivide(this, root + 1, this.first_transparent, this.prim_count - 1, this.boxv_t, this.boxc_t, true, 0);\n\n  while (this.recursion_stack.length) {\n    a = this.recursion_stack.pop();\n    BVHModule.bvh_subdivide(a[0], a[1], a[2], a[3], a[4], a[5], a[6], a[7]);\n  }\n};\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/DeriveTopology.js\":\n/*!*****************************************!*\\\n  !*** ./src/wgs/scene/DeriveTopology.js ***!\n  \\*****************************************/\n/*! exports provided: createWireframe */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"createWireframe\", function() { return createWireframe; });\n/* harmony import */ var _VertexEnumerator__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./VertexEnumerator */ \"./src/wgs/scene/VertexEnumerator.js\");\n/* harmony import */ var _LmvVector3__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/* harmony import */ var _LmvBox3__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./LmvBox3 */ \"./src/wgs/scene/LmvBox3.js\");\n\n\n\n\nfunction remapVertices(geom, boundingBox) {\n  //de-duplicate vertices based on position only (ignoring normals)\n\n  var remap = [];\n  var uniqueV = {};\n\n  var boxScale = 1.0;\n  if (geom.boundingBox || boundingBox) {\n    var bbox = new _LmvBox3__WEBPACK_IMPORTED_MODULE_2__[\"LmvBox3\"]().copy(geom.boundingBox || boundingBox);\n    var sz = bbox.size();\n    boxScale = Math.max(sz.x, Math.max(sz.y, sz.z));\n  }\n\n  var SCALE = (1 << 16) / boxScale; //snap scale, assuming unit mesh\n\n  function getVertexIndex(v, i) {\n    var x = 0 | v.x * SCALE;\n    var y = 0 | v.y * SCALE;\n    var z = 0 | v.z * SCALE;\n\n    var mx = uniqueV[x];\n    if (!mx) {\n      uniqueV[x] = mx = {};\n    }\n\n    var my = mx[y];\n    if (!my) {\n      mx[y] = my = {};\n    }\n\n    var mz = my[z];\n    if (mz === undefined) {\n      my[z] = mz = i;\n    }\n\n    return mz;\n  }\n\n  function remapcb(v, n, uv, i) {\n    var vidx = getVertexIndex(v, i);\n    remap[i] = vidx;\n  }\n\n  Object(_VertexEnumerator__WEBPACK_IMPORTED_MODULE_0__[\"enumMeshVertices\"])(geom, remapcb);\n\n  return remap;\n}\n\n\nfunction transformVertices(geom, toWorld) {\n\n  var vbuf = new Float32Array(3 * Object(_VertexEnumerator__WEBPACK_IMPORTED_MODULE_0__[\"getVertexCount\"])(geom));\n\n  function cb(v, n, uv, i) {\n    vbuf[3 * i] = v.x;\n    vbuf[3 * i + 1] = v.y;\n    vbuf[3 * i + 2] = v.z;\n  }\n\n  Object(_VertexEnumerator__WEBPACK_IMPORTED_MODULE_0__[\"enumMeshVertices\"])(geom, cb, toWorld);\n\n  return vbuf;\n}\n\nfunction createWireframe(geom, toWorld, boundingBox, wantAllTriangleEdges) {\n\n  if (geom.isLines)\n  return;\n\n  if (geom.iblines)\n  return;\n\n  //find unique vertices\n  var remap = remapVertices(geom, boundingBox);\n\n  //get vertices in world space -- we need this for\n  //correct angle calculations\n  var worldVerts = transformVertices(geom, toWorld);\n\n  //loop over all triangles, keeping track of\n  //edges that seem important\n  var seenEdges = {};\n\n  var edgeIB = [];\n\n  var _v1 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n  var _v2 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n  var _v3 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n  var _n1 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n  var _n2 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_1__[\"LmvVector3\"]();\n\n  function getV(i, v) {\n    v.x = worldVerts[3 * i];\n    v.y = worldVerts[3 * i + 1];\n    v.z = worldVerts[3 * i + 2];\n  }\n\n  function getNormal(i1, i2, i3, n) {\n    getV(i1, _v1);\n    getV(i2, _v2);\n    getV(i3, _v3);\n\n    _v2.sub(_v1);\n    _v3.sub(_v1);\n    _v2.cross(_v3);\n\n    n.copy(_v2).normalize();\n  }\n\n  function doOneEdge(i1orig, i2orig, opp1orig) {\n\n    var i1 = remap[i1orig];\n    var i2 = remap[i2orig];\n    var opp1 = remap[opp1orig];\n\n    //Ignore degenerates\n    if (i1 === i2 || i1 === opp1 || i2 === opp1)\n    return;\n\n    var reversed = false;\n    if (i1 > i2) {\n      var tmp = i1;\n      i1 = i2;\n      i2 = tmp;\n      reversed = true;\n    }\n\n    var e1 = seenEdges[i1];\n    if (e1) {\n      var opp2orig = e1[i2];\n      if (opp2orig === undefined) {\n        e1[i2] = reversed ? -opp1orig - 1 : opp1orig;\n      } else {\n        //We now know two triangles that share this edge,\n        //we can check if it's important\n\n        if (!wantAllTriangleEdges) {\n          //Use original indices, so that we\n          //can do the math with the correct winding order\n          getNormal(i1orig, i2orig, opp1orig, _n1);\n\n          if (opp2orig < 0) {\n            getNormal(i2, i1, remap[-opp2orig - 1], _n2);\n          } else {\n            getNormal(i1, i2, remap[opp2orig], _n2);\n          }\n\n          var dot = _n1.dot(_n2);\n\n          if (Math.abs(dot) < 0.25) {\n            edgeIB.push(i1orig);\n            edgeIB.push(i2orig);\n          }\n        } else {\n          edgeIB.push(i1orig);\n          edgeIB.push(i2orig);\n        }\n\n        delete e1[i2];\n      }\n    } else {\n      seenEdges[i1] = {};\n      seenEdges[i1][i2] = opp1orig;\n    }\n  }\n\n  function tricb(vA, vB, vC, iA, iB, iC) {\n    doOneEdge(iA, iB, iC);\n    doOneEdge(iB, iC, iA);\n    doOneEdge(iC, iA, iB);\n  }\n\n  //find edges that have neighboring triangles at sharp angle\n  Object(_VertexEnumerator__WEBPACK_IMPORTED_MODULE_0__[\"enumMeshTriangles\"])(geom, tricb);\n\n  //process remaining edges (outer edges that only have one triangle)\n\n  for (var i1 in seenEdges) {\n    for (var i2 in seenEdges[i1]) {\n      edgeIB.push(parseInt(i1));\n      edgeIB.push(parseInt(i2));\n    }\n  }\n\n\n  if (edgeIB.length > 1) {\n    geom.iblines = new Uint16Array(edgeIB.length);\n    geom.iblines.set(edgeIB);\n  }\n\n  /*\n        for (var i=0; i<geom.ib.length; i++) {\n            geom.ib[i] = remap[geom.ib[i]];\n        }\n        */\n}\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/FrustumIntersector.js\":\n/*!*********************************************!*\\\n  !*** ./src/wgs/scene/FrustumIntersector.js ***!\n  \\*********************************************/\n/*! exports provided: FrustumIntersector, OUTSIDE, INTERSECTS, CONTAINS, CONTAINMENT_UNKNOWN */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"FrustumIntersector\", function() { return FrustumIntersector; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"OUTSIDE\", function() { return OUTSIDE; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"INTERSECTS\", function() { return INTERSECTS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CONTAINS\", function() { return CONTAINS; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"CONTAINMENT_UNKNOWN\", function() { return CONTAINMENT_UNKNOWN; });\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! three */ \"./extensions/MemoryLimited/thirdparty/three.js/three-worker.js\");\n/* harmony import */ var three__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(three__WEBPACK_IMPORTED_MODULE_0__);\n\n\n// Rearranged logically, base 3. X is 1's digit, Y is 10's digit, Z is 100's digit.\n// low/medium/high value is 0/1/2. So the center of the 3x3x3 space is == 111 base 3 == 13.\n// old 64-position code, which is what the comment indices are based on\n// var pos = ((this.eye.x < box.min.x) ?  1 : 0)   // 1 = left\n//         + ((this.eye.x > box.max.x) ?  2 : 0)   // 2 = right\n//         + ((this.eye.y < box.min.y) ?  4 : 0)   // 4 = bottom\n//         + ((this.eye.y > box.max.y) ?  8 : 0)   // 8 = top\n//         + ((this.eye.z < box.min.z) ? 16 : 0)   // 16 = front\n//         + ((this.eye.z > box.max.z) ? 32 : 0);  // 32 = back\nvar _boxIndexList = // [27][7]\n[\n[1, 5, 4, 7, 3, 2, 6], //21 front, bottom, left\n[0, 3, 2, 1, 5, 4, 6], //20 front, bottom\n[0, 3, 2, 6, 5, 4, 6], //22 front, bottom, right\n[0, 4, 7, 3, 2, 1, 6], //17 front, left\n[0, 3, 2, 1, -1, -1, 4], //16 front\n[0, 3, 2, 6, 5, 1, 6], //18 front, right\n[0, 4, 7, 6, 2, 1, 6], //25 front, top, left\n[0, 3, 7, 6, 2, 1, 6], //24 front, top\n[0, 3, 7, 6, 5, 1, 6], //26 front, top, right\n[0, 1, 5, 4, 7, 3, 6], // 5 bottom, left\n[0, 1, 5, 4, -1, -1, 4], // 4 bottom\n[0, 1, 2, 6, 5, 4, 6], // 6 bottom, right\n[0, 4, 7, 3, -1, -1, 4], // 1 left\n[-1, -1, -1, -1, -1, -1, 0], // 0 inside\n[1, 2, 6, 5, -1, -1, 4], // 2 right\n[0, 4, 7, 6, 2, 3, 6], // 9 top, left \n[2, 3, 7, 6, -1, -1, 4], // 8 top\n[1, 2, 3, 7, 6, 5, 6], //10 top, right\n[0, 1, 5, 6, 7, 3, 6], //37 back, bottom, left\n[0, 1, 5, 6, 7, 4, 6], //36 back, bottom\n[0, 1, 2, 6, 7, 4, 6], //38 back, bottom, right\n[0, 4, 5, 6, 7, 3, 6], //33 back, left\n[4, 5, 6, 7, -1, -1, 4], //32 back\n[1, 2, 6, 7, 4, 5, 6], //34 back, right\n[0, 4, 5, 6, 2, 3, 6], //41 back, top, left\n[2, 3, 7, 4, 5, 6, 6], //40 back, top\n[1, 2, 3, 7, 4, 5, 6] //42 back, top, right\n];\n\n//Encapsulates frustum-box intersection logic\nfunction FrustumIntersector() {\n  this.frustum = new three__WEBPACK_IMPORTED_MODULE_0__[\"Frustum\"]();\n  this.viewProj = new three__WEBPACK_IMPORTED_MODULE_0__[\"Matrix4\"]();\n  this.viewDir = [0, 0, 1];\n  this.ar = 1.0;\n  this.viewport = new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](1, 1, 1);\n  this.areaConv = 1;\n  this.areaCullThreshold = 1; // The pixel size of the object projected on screen, will be culled if less than this value.\n  this.eye = new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]();\n  this.perspective = false; // assume orthographic camera to match viewProj\n}\n\nvar OUTSIDE = 0;\nvar INTERSECTS = 1;\nvar CONTAINS = 2;\nvar CONTAINMENT_UNKNOWN = -1;\nFrustumIntersector.OUTSIDE = OUTSIDE;\nFrustumIntersector.INTERSECTS = INTERSECTS;\nFrustumIntersector.CONTAINS = CONTAINS;\nFrustumIntersector.CONTAINMENT_UNKNOWN = CONTAINMENT_UNKNOWN;\n\n// @param {THREE.Vector4[]} [cutPlanes]\nFrustumIntersector.prototype.reset = function (camera, cutPlanes) {\n  this.viewProj.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);\n  this.perspective = camera.isPerspective;\n  this.frustum.setFromMatrix(this.viewProj);\n  var vm = camera.matrixWorldInverse.elements;\n  this.ar = camera.aspect;\n  this.viewDir[0] = -vm[2];\n  this.viewDir[1] = -vm[6];\n  this.viewDir[2] = -vm[10];\n  this.eye.x = camera.position.x;\n  this.eye.y = camera.position.y;\n  this.eye.z = camera.position.z;\n  this.areaConv = camera.clientWidth * camera.clientHeight / 4;\n  this.cutPlanes = cutPlanes;\n};\n\nFrustumIntersector.prototype.projectedArea = function () {\n\n  var points = [\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"](),\n  new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]()];\n\n  var tmpBox = new three__WEBPACK_IMPORTED_MODULE_0__[\"Box2\"]();\n\n  function applyProjection(p, m) {\n\n    var x = p.x,y = p.y,z = p.z;\n    var e = m.elements;\n\n    var w = e[3] * x + e[7] * y + e[11] * z + e[15];\n\n    //This is the difference between this function and\n    //the normal THREE.Vector3.applyProjection. We avoid\n    //inverting the positions of points behind the camera,\n    //otherwise our screen area computation can result in\n    //boxes getting clipped out when they are in fact partially visible.\n    if (w < 0)\n    w = -w;\n\n    var d = 1.0 / w;\n\n    p.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;\n    p.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;\n\n    //We also don't need the Z\n    //p.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * d;\n  }\n\n  return function (box) {\n\n    if (box.empty())\n    return 0;\n\n    var matrix = this.viewProj;\n\n    // NOTE: I am using a binary pattern to specify all 2^3 combinations below\n    points[0].set(box.min.x, box.min.y, box.min.z); // 000\n    points[1].set(box.min.x, box.min.y, box.max.z); // 001\n    points[2].set(box.min.x, box.max.y, box.min.z); // 010\n    points[3].set(box.min.x, box.max.y, box.max.z); // 011\n    points[4].set(box.max.x, box.min.y, box.min.z); // 100\n    points[5].set(box.max.x, box.min.y, box.max.z); // 101\n    points[6].set(box.max.x, box.max.y, box.min.z); // 110\n    points[7].set(box.max.x, box.max.y, box.max.z); // 111\n\n    for (var i = 0; i < 8; i++) {\n      applyProjection(points[i], matrix);}\n\n    tmpBox.makeEmpty();\n    tmpBox.setFromPoints(points);\n\n    // Clamp both min and max value between [-1.0, 1.0]\n    if (tmpBox.min.x < -1.0)\n    tmpBox.min.x = -1.0;\n    if (tmpBox.min.x > 1.0)\n    tmpBox.min.x = 1.0;\n    if (tmpBox.min.y < -1.0)\n    tmpBox.min.y = -1.0;\n    if (tmpBox.min.y > 1.0)\n    tmpBox.min.y = 1.0;\n\n    if (tmpBox.max.x > 1.0)\n    tmpBox.max.x = 1.0;\n    if (tmpBox.max.x < -1.0)\n    tmpBox.max.x = -1.0;\n    if (tmpBox.max.y > 1.0)\n    tmpBox.max.y = 1.0;\n    if (tmpBox.max.y < -1.0)\n    tmpBox.max.y = -1.0;\n\n    return (tmpBox.max.x - tmpBox.min.x) * (tmpBox.max.y - tmpBox.min.y);\n  };\n\n}();\n\n// A more precise estimator, based on https://github.com/erich666/jgt-code/blob/master/Volume_04/Number_2/Schmalstieg1999/bboxarea.cxx\n// Schmalstieg, Dieter, and Robert F. Tobler, \"Fast Projected Area Computation for Three-Dimensional Bounding Boxes,\" journal of graphics tools, 4(2):37-43, 1999.\n// Note: this code assumes that the silhouette corners will all project to be in front of the viewer. We do Take\n// corrective action if this is not the case, but it's of a \"well, negate the value\" nature, not a true clip fix.\n// It is assumed that frustum culling has already been applied, so that such cases should be rare.\n// So, for example, a long terrain tile below the viewer may get the corners behind the viewer transformed to be some\n// semi-arbitrary corner locations in front. ProjectedArea has the same problem. Since this method is used just to get\n// a rough idea of the importance of a fragment, we don't spend a lot of time on fixing this. If a corner is detected\n// as behind the eye, we could instead return an area of 4, i.e., it fills the screen.\nFrustumIntersector.prototype.projectedBoxArea = function () {\n\n  var sizeClippedPolygon;\n\n  // maximum of 6 points in silhouette, plus 4 points, one for each clip edge\n  var points = [];\n  var pointsSwap = [];\n  for (var i = 0; i < 10; i++) {\n    points.push(new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]());\n    pointsSwap.push(new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]());\n  }\n\n  // TODO: same as projectedArea - should this implementation be a derived class? How to do that in javascript?\n  function applyProjection(p, m) {\n\n    var x = p.x,y = p.y,z = p.z;\n    var e = m.elements;\n\n    var w = e[3] * x + e[7] * y + e[11] * z + e[15];\n\n    //This is the difference between this function and\n    //the normal THREE.Vector3.applyProjection. We avoid\n    //inverting the positions of points behind the camera,\n    //otherwise our screen area computation can result in\n    //boxes getting clipped out when they are in fact partially visible.\n    if (w < 0)\n    w = -w;\n\n    var d = 1.0 / w;\n\n    p.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;\n    p.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;\n\n    //We also don't need the Z\n    //p.z = ( e[ 2 ] * x + e[ 6 ] * y + e[ 10 ] * z + e[ 14 ] ) * d;\n  }\n\n  // Optimized to clip against -1 to 1 NDC in X and Y.\n  // NOTE: this modifies the clipPolygon being passed in, as the\n  // code takes four passes (for each edge of the screen) and ping-pongs\n  // the data between clipPolygon (really, the \"points\" array) and pointsSwap, a temporary buffer.\n  // Doing so saves us from having to copy data or duplicate code.\n  function clip(clipPolygon, sizePolygon) {\n    var polygonSource = clipPolygon;\n    var polygonDest = pointsSwap;\n    var polygonSwap;\n    var prevPt, thisPt, prevIn, thisIn;\n    var numPt, numClip;\n    var newSizePolygon;\n\n    var testInside = function testInside(pt) {\n      switch (numClip) {\n        case 0:\n          return pt.x >= -1;\n        case 1:\n          return pt.x <= 1;\n        case 2:\n          return pt.y >= -1;\n        case 3:\n          return pt.y <= 1;}\n\n    };\n    var savePoint = function savePoint(pt) {\n      polygonDest[newSizePolygon].x = pt.x;\n      polygonDest[newSizePolygon++].y = pt.y;\n    };\n    var saveIntersect = function saveIntersect() {\n      var ptx, pty;\n      switch (numClip) {\n        case 0:\n          ptx = -1;\n          pty = prevPt.y + (thisPt.y - prevPt.y) * (ptx - prevPt.x) / (thisPt.x - prevPt.x);\n          break;\n        case 1:\n          ptx = 1;\n          pty = prevPt.y + (thisPt.y - prevPt.y) * (ptx - prevPt.x) / (thisPt.x - prevPt.x);\n          break;\n        case 2:\n          pty = -1;\n          ptx = prevPt.x + (thisPt.x - prevPt.x) * (pty - prevPt.y) / (thisPt.y - prevPt.y);\n          break;\n        case 3:\n          pty = 1;\n          ptx = prevPt.x + (thisPt.x - prevPt.x) * (pty - prevPt.y) / (thisPt.y - prevPt.y);\n          break;}\n\n      polygonDest[newSizePolygon].x = ptx;\n      polygonDest[newSizePolygon++].y = pty;\n    };\n\n    // If polygon size <= 2, it will have no area, so don't care. We need this test to avoid\n    // access polygonSource[-1] when size === 0.\n    for (numClip = 0; numClip < 4 && sizePolygon > 2; numClip++) {\n      newSizePolygon = 0;\n      prevPt = polygonSource[sizePolygon - 1];\n      prevIn = testInside(prevPt);\n      for (numPt = 0; numPt < sizePolygon; numPt++) {\n        thisPt = polygonSource[numPt];\n        thisIn = testInside(thisPt);\n        if (prevIn) {\n          if (thisIn) {\n            // edge is entirely in - save point\n            savePoint(thisPt);\n          } else {\n            // edge is exiting - save intersection\n            saveIntersect();\n          }\n        } else {\n          // edge starts out\n          if (thisIn) {\n            // edge is entering - save intersection and point\n            saveIntersect();\n            savePoint(thisPt);\n          }\n          //else {\n          // edge is still out - save nothing\n          //}\n        }\n        prevPt = thisPt;\n        prevIn = thisIn;\n      }\n\n      // swap for next round\n      sizePolygon = newSizePolygon;\n      polygonSwap = polygonSource;\n      polygonSource = polygonDest;\n      polygonDest = polygonSwap;\n    }\n    sizeClippedPolygon = sizePolygon;\n    return polygonSource;\n  }\n\n  // if not specified, perform clip\n  return function (box, doNotClip) {\n\n    if (box.empty())\n    return 0;\n\n    var matrix = this.viewProj;\n\n    //compute the array index to classify eye with respect to the 6 defining planes\n    //of the bbox, 0-26\n    var pos;\n    if (this.perspective) {\n      if (this.eye.x >= box.min.x) {\n        pos = this.eye.x > box.max.x ? 2 : 1;\n      } else {\n        pos = 0;\n      }\n      if (this.eye.y >= box.min.y) {\n        pos += this.eye.y > box.max.y ? 6 : 3;\n      }\n      if (this.eye.z >= box.min.z) {\n        pos += this.eye.z > box.max.z ? 18 : 9;\n      }\n    } else {\n      if (this.viewDir[0] <= 0) {\n        pos = this.viewDir[0] < 0 ? 2 : 1;\n      } else {\n        pos = 0;\n      }\n      if (this.viewDir[1] <= 0) {\n        pos += this.viewDir[1] < 0 ? 6 : 3;\n      }\n      if (this.viewDir[2] <= 0) {\n        pos += this.viewDir[2] < 0 ? 18 : 9;\n      }\n    }\n\n    // 13 indicates eye location is inside box, index 1+3+9, so return full screen area\n    if (pos === 13) {\n      return 4;\n    }\n    var num = _boxIndexList[pos][6]; //look up number of vertices in outline\n\n    //generate 8 corners of the bbox, as needed\n    // run through \"num\" points and create and transform just those\n    var i;\n    for (i = 0; i < num; i++) {\n      var idx = _boxIndexList[pos][i];\n      // tricksiness here: order is (though this is left-handed; we use right-handed)\n      // (min[0],min[1],min[2]); //     7+------+6\n      // (max[0],min[1],min[2]); //     /|     /|\n      // (max[0],max[1],min[2]); //    / |    / |\n      // (min[0],max[1],min[2]); //   / 4+---/--+5\n      // (min[0],min[1],max[2]); // 3+------+2 /    y   z\n      // (max[0],min[1],max[2]); //  | /    | /     |  /\n      // (max[0],max[1],max[2]); //  |/     |/      |/\n      // (min[0],max[1],max[2]); // 0+------+1      *---x\n\n      points[i].set(\n      (idx + 1) % 4 < 2 ? box.min.x : box.max.x,\n      idx % 4 < 2 ? box.min.y : box.max.y,\n      idx < 4 ? box.min.z : box.max.z);\n\n      applyProjection(points[i], matrix);\n    }\n\n    var sum = 0;\n    // always clip if needed; TODO: make more efficient, i.e., don't alloc each time.\n    if (doNotClip) {\n      sum = (points[num - 1].x - points[0].x) * (points[num - 1].y + points[0].y);\n      for (i = 0; i < num - 1; i++) {\n        sum += (points[i].x - points[i + 1].x) * (points[i].y + points[i + 1].y);}\n    } else {\n      var clippedPolygon = clip(points, num);\n      // see if clipped polygon has anything returned at all; if not, area is 0\n      if (sizeClippedPolygon >= 3) {\n        sum = (clippedPolygon[sizeClippedPolygon - 1].x - clippedPolygon[0].x) * (clippedPolygon[sizeClippedPolygon - 1].y + clippedPolygon[0].y);\n        for (i = 0; i < sizeClippedPolygon - 1; i++) {\n          sum += (clippedPolygon[i].x - clippedPolygon[i + 1].x) * (clippedPolygon[i].y + clippedPolygon[i + 1].y);}\n      }\n    }\n\n    // avoid winding order left-handed/right-handed headaches by taking abs(); fixes clockwise loops\n    return Math.abs(sum * 0.5); //return computed value corrected by 0.5\n  };\n\n}();\n\nFrustumIntersector.prototype.estimateDepth = function (bbox) {\n\n  var e = this.viewProj.elements;\n\n  // Take center of box and find its distance from the eye.\n  var x = (bbox.min.x + bbox.max.x) / 2.0;\n  var y = (bbox.min.y + bbox.max.y) / 2.0;\n  var z = (bbox.min.z + bbox.max.z) / 2.0;\n\n  // not used: var w = e[3] * x + e[7] * y + e[11] * z + e[15];\n\n  var d = 1.0 / (e[3] * x + e[7] * y + e[11] * z + e[15]);\n\n  return (e[2] * x + e[6] * y + e[10] * z + e[14]) * d;\n\n};\n\nFrustumIntersector.prototype.intersectsBox = function () {\n\n  //Copied from three.js and modified to return separate\n  //value for full containment versus intersection.\n  //Return values: 0 -> outside, 1 -> intersects, 2 -> contains\n  var p1 = new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]();\n  var p2 = new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]();\n\n  return function (box) {\n\n    var planes = this.frustum.planes;\n    var contained = 0;\n\n    for (var i = 0; i < 6; i++) {\n\n      var plane = planes[i];\n\n      p1.x = plane.normal.x > 0 ? box.min.x : box.max.x;\n      p2.x = plane.normal.x > 0 ? box.max.x : box.min.x;\n      p1.y = plane.normal.y > 0 ? box.min.y : box.max.y;\n      p2.y = plane.normal.y > 0 ? box.max.y : box.min.y;\n      p1.z = plane.normal.z > 0 ? box.min.z : box.max.z;\n      p2.z = plane.normal.z > 0 ? box.max.z : box.min.z;\n\n      var d1 = plane.distanceToPoint(p1);\n      var d2 = plane.distanceToPoint(p2);\n\n      // if both outside plane, no intersection\n\n      if (d1 < 0 && d2 < 0) {\n\n        return FrustumIntersector.OUTSIDE;\n\n      }\n\n      if (d1 > 0 && d2 > 0) {\n\n        contained++;\n\n      }\n    }\n\n    return contained == 6 ? FrustumIntersector.CONTAINS : FrustumIntersector.INTERSECTS;\n  };\n\n\n}();\n\nfunction getCorner(box, i, target) {\n  target.x = i & 1 ? box.max.x : box.min.x;\n  target.y = i & 2 ? box.max.y : box.min.y;\n  target.z = i & 4 ? box.max.z : box.min.z;\n  return target;\n}\n\nfunction pointOutsideCutPlane(point, cutPlane) {\n  var dp = point.x * cutPlane.x + point.y * cutPlane.y + point.z * cutPlane.z + cutPlane.w;\n  return dp > 1e-6;\n}\n\nvar boxOutsideCutPlane = function () {\n\n  var _tmp;\n  return function (box, plane) {\n\n    if (!_tmp) _tmp = new three__WEBPACK_IMPORTED_MODULE_0__[\"Vector3\"]();\n\n    // for each corner...\n    for (var i = 0; i < 8; i++) {\n      // stop if corner i is outside\n      var corner = getCorner(box, i, _tmp);\n      if (!pointOutsideCutPlane(corner, plane)) {\n        return false;\n      }\n    }\n    // all corners are in the outer half-space\n    return true;\n  };\n}();\n\n// Returns true if the given box is fully in the outer half-space of an active cut plane\nFrustumIntersector.prototype.boxOutsideCutPlanes = function (box) {\n  if (!this.cutPlanes) {\n    return false;\n  }\n\n  for (var i = 0; i < this.cutPlanes.length; i++) {\n    var plane = this.cutPlanes[i];\n    if (boxOutsideCutPlane(box, plane)) {\n      return true;\n    }\n  }\n  return false;\n};\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/LmvBox3.js\":\n/*!**********************************!*\\\n  !*** ./src/wgs/scene/LmvBox3.js ***!\n  \\**********************************/\n/*! exports provided: LmvBox3 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LmvBox3\", function() { return LmvBox3; });\n/* harmony import */ var _LmvVector3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n/**\n * @author bhouston / http://exocortex.com\n * @author WestLangley / http://github.com/WestLangley\n */\n/* Pruned version of THREE.Box3, for use in the LMV web worker */\n\n\n\nvar LmvBox3 = function LmvBox3(min, max) {\n\n  this.min = min !== undefined ? min : new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](Infinity, Infinity, Infinity);\n  this.max = max !== undefined ? max : new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](-Infinity, -Infinity, -Infinity);\n\n};\n\nLmvBox3.prototype = {\n\n  constructor: LmvBox3,\n\n  set: function set(min, max) {\n\n    this.min.copy(min);\n    this.max.copy(max);\n\n    return this;\n\n  },\n\n  setFromPoints: function setFromPoints(points) {\n\n    this.makeEmpty();\n\n    for (var i = 0, il = points.length; i < il; i++) {\n\n      this.expandByPoint(points[i]);\n\n    }\n\n    return this;\n\n  },\n\n  setFromArray: function setFromArray(array, offset) {\n\n    this.min.x = array[offset];\n    this.min.y = array[offset + 1];\n    this.min.z = array[offset + 2];\n\n    this.max.x = array[offset + 3];\n    this.max.y = array[offset + 4];\n    this.max.z = array[offset + 5];\n\n    return this;\n\n  },\n\n  copyToArray: function copyToArray(array, offset) {\n\n    array[offset] = this.min.x;\n    array[offset + 1] = this.min.y;\n    array[offset + 2] = this.min.z;\n\n    array[offset + 3] = this.max.x;\n    array[offset + 4] = this.max.y;\n    array[offset + 5] = this.max.z;\n\n  },\n\n  setFromCenterAndSize: function () {\n\n    var v1 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n\n    return function (center, size) {\n\n      var halfSize = v1.copy(size).multiplyScalar(0.5);\n\n      this.min.copy(center).sub(halfSize);\n      this.max.copy(center).add(halfSize);\n\n      return this;\n\n    };\n\n  }(),\n\n  clone: function clone() {\n\n    return new this.constructor().copy(this);\n\n  },\n\n  copy: function copy(box) {\n\n    this.min.copy(box.min);\n    this.max.copy(box.max);\n\n    return this;\n\n  },\n\n  makeEmpty: function makeEmpty() {\n\n    this.min.x = this.min.y = this.min.z = Infinity;\n    this.max.x = this.max.y = this.max.z = -Infinity;\n\n    return this;\n\n  },\n\n  empty: function empty() {\n\n    // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n    return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;\n\n  },\n\n  center: function center(optionalTarget) {\n\n    var result = optionalTarget || new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    return result.addVectors(this.min, this.max).multiplyScalar(0.5);\n\n  },\n\n  size: function size(optionalTarget) {\n\n    var result = optionalTarget || new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    return result.subVectors(this.max, this.min);\n\n  },\n\n  expandByPoint: function expandByPoint(point) {\n\n    this.min.min(point);\n    this.max.max(point);\n\n    return this;\n\n  },\n\n  expandByVector: function expandByVector(vector) {\n\n    this.min.sub(vector);\n    this.max.add(vector);\n\n    return this;\n\n  },\n\n  expandByScalar: function expandByScalar(scalar) {\n\n    this.min.addScalar(-scalar);\n    this.max.addScalar(scalar);\n\n    return this;\n\n  },\n\n  containsPoint: function containsPoint(point) {\n\n    if (point.x < this.min.x || point.x > this.max.x ||\n    point.y < this.min.y || point.y > this.max.y ||\n    point.z < this.min.z || point.z > this.max.z) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  containsBox: function containsBox(box) {\n\n    if (this.min.x <= box.min.x && box.max.x <= this.max.x &&\n    this.min.y <= box.min.y && box.max.y <= this.max.y &&\n    this.min.z <= box.min.z && box.max.z <= this.max.z) {\n\n      return true;\n\n    }\n\n    return false;\n\n  },\n\n  getParameter: function getParameter(point, optionalTarget) {\n\n    // This can potentially have a divide by zero if the box\n    // has a size dimension of 0.\n\n    var result = optionalTarget || new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n\n    return result.set(\n    (point.x - this.min.x) / (this.max.x - this.min.x),\n    (point.y - this.min.y) / (this.max.y - this.min.y),\n    (point.z - this.min.z) / (this.max.z - this.min.z));\n\n\n  },\n\n  isIntersectionBox: function isIntersectionBox(box) {\n\n    // using 6 splitting planes to rule out intersections.\n\n    if (box.max.x < this.min.x || box.min.x > this.max.x ||\n    box.max.y < this.min.y || box.min.y > this.max.y ||\n    box.max.z < this.min.z || box.min.z > this.max.z) {\n\n      return false;\n\n    }\n\n    return true;\n\n  },\n\n  clampPoint: function clampPoint(point, optionalTarget) {\n\n    var result = optionalTarget || new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    return result.copy(point).clamp(this.min, this.max);\n\n  },\n\n  distanceToPoint: function () {\n\n    var v1 = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n\n    return function (point) {\n\n      var clampedPoint = v1.copy(point).clamp(this.min, this.max);\n      return clampedPoint.sub(point).length();\n\n    };\n\n  }(),\n\n  intersect: function intersect(box) {\n\n    this.min.max(box.min);\n    this.max.min(box.max);\n\n    return this;\n\n  },\n\n  union: function union(box) {\n\n    this.min.min(box.min);\n    this.max.max(box.max);\n\n    return this;\n\n  },\n\n  applyMatrix4: function () {\n\n    var points = [\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"](),\n    new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]()];\n\n\n    return function (matrix) {\n\n      // NOTE: I am using a binary pattern to specify all 2^3 combinations below\n      points[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(matrix); // 000\n      points[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(matrix); // 001\n      points[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(matrix); // 010\n      points[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(matrix); // 011\n      points[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(matrix); // 100\n      points[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(matrix); // 101\n      points[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(matrix); // 110\n      points[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(matrix); // 111\n\n      this.makeEmpty();\n      this.setFromPoints(points);\n\n      return this;\n\n    };\n\n  }(),\n\n  translate: function translate(offset) {\n\n    this.min.add(offset);\n    this.max.add(offset);\n\n    return this;\n\n  },\n\n  equals: function equals(box) {\n\n    return box.min.equals(this.min) && box.max.equals(this.max);\n\n  } };\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/LmvMatrix4.js\":\n/*!*************************************!*\\\n  !*** ./src/wgs/scene/LmvMatrix4.js ***!\n  \\*************************************/\n/*! exports provided: LmvMatrix4 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LmvMatrix4\", function() { return LmvMatrix4; });\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author supereggbert / http://www.paulbrunt.co.uk/\n * @author philogb / http://blog.thejit.org/\n * @author jordi_ros / http://plattsoft.com\n * @author D1plo1d / http://github.com/D1plo1d\n * @author alteredq / http://alteredqualia.com/\n * @author mikael emtinger / http://gomo.se/\n * @author timknip / http://www.floorplanner.com/\n * @author bhouston / http://exocortex.com\n * @author WestLangley / http://github.com/WestLangley\n */\n/* Pruned version of THREE.Matrix4, for use in the LMV web worker */\n\nvar LmvMatrix4 = function LmvMatrix4(useDoublePrecision) {\n\n  if (useDoublePrecision) {\n\n    this.elements = new Float64Array([\n\n    1, 0, 0, 0,\n    0, 1, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1]);\n\n\n\n  } else {\n\n    this.elements = new Float32Array([\n\n    1, 0, 0, 0,\n    0, 1, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1]);\n\n\n\n  }\n\n};\n\nLmvMatrix4.prototype = {\n\n  constructor: LmvMatrix4,\n\n  set: function set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {\n\n    var te = this.elements;\n\n    te[0] = n11;te[4] = n12;te[8] = n13;te[12] = n14;\n    te[1] = n21;te[5] = n22;te[9] = n23;te[13] = n24;\n    te[2] = n31;te[6] = n32;te[10] = n33;te[14] = n34;\n    te[3] = n41;te[7] = n42;te[11] = n43;te[15] = n44;\n\n    return this;\n\n  },\n\n  identity: function identity() {\n\n    this.set(\n\n    1, 0, 0, 0,\n    0, 1, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  copy: function copy(m) {\n\n    this.elements.set(m.elements);\n\n    return this;\n\n  },\n\n  makeRotationFromQuaternion: function makeRotationFromQuaternion(q) {\n\n    var te = this.elements;\n\n    var x = q.x,y = q.y,z = q.z,w = q.w;\n    var x2 = x + x,y2 = y + y,z2 = z + z;\n    var xx = x * x2,xy = x * y2,xz = x * z2;\n    var yy = y * y2,yz = y * z2,zz = z * z2;\n    var wx = w * x2,wy = w * y2,wz = w * z2;\n\n    te[0] = 1 - (yy + zz);\n    te[4] = xy - wz;\n    te[8] = xz + wy;\n\n    te[1] = xy + wz;\n    te[5] = 1 - (xx + zz);\n    te[9] = yz - wx;\n\n    te[2] = xz - wy;\n    te[6] = yz + wx;\n    te[10] = 1 - (xx + yy);\n\n    // last column\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = 0;\n\n    // bottom row\n    te[12] = 0;\n    te[13] = 0;\n    te[14] = 0;\n    te[15] = 1;\n\n    return this;\n\n  },\n\n  multiply: function multiply(n) {\n\n    return this.multiplyMatrices(this, n);\n\n  },\n\n  multiplyMatrices: function multiplyMatrices(a, b) {\n\n    var ae = a.elements;\n    var be = b.elements;\n    var te = this.elements;\n\n    var a11 = ae[0],a12 = ae[4],a13 = ae[8],a14 = ae[12];\n    var a21 = ae[1],a22 = ae[5],a23 = ae[9],a24 = ae[13];\n    var a31 = ae[2],a32 = ae[6],a33 = ae[10],a34 = ae[14];\n    var a41 = ae[3],a42 = ae[7],a43 = ae[11],a44 = ae[15];\n\n    var b11 = be[0],b12 = be[4],b13 = be[8],b14 = be[12];\n    var b21 = be[1],b22 = be[5],b23 = be[9],b24 = be[13];\n    var b31 = be[2],b32 = be[6],b33 = be[10],b34 = be[14];\n    var b41 = be[3],b42 = be[7],b43 = be[11],b44 = be[15];\n\n    te[0] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;\n    te[4] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;\n    te[8] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;\n    te[12] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;\n\n    te[1] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;\n    te[5] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;\n    te[9] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;\n    te[13] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;\n\n    te[2] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;\n    te[6] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;\n    te[10] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;\n    te[14] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;\n\n    te[3] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;\n    te[7] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;\n    te[11] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;\n    te[15] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;\n\n    return this;\n\n  },\n\n  multiplyToArray: function multiplyToArray(a, b, r) {\n\n    var te = this.elements;\n\n    this.multiplyMatrices(a, b);\n\n    r[0] = te[0];r[1] = te[1];r[2] = te[2];r[3] = te[3];\n    r[4] = te[4];r[5] = te[5];r[6] = te[6];r[7] = te[7];\n    r[8] = te[8];r[9] = te[9];r[10] = te[10];r[11] = te[11];\n    r[12] = te[12];r[13] = te[13];r[14] = te[14];r[15] = te[15];\n\n    return this;\n\n  },\n\n  multiplyScalar: function multiplyScalar(s) {\n\n    var te = this.elements;\n\n    te[0] *= s;te[4] *= s;te[8] *= s;te[12] *= s;\n    te[1] *= s;te[5] *= s;te[9] *= s;te[13] *= s;\n    te[2] *= s;te[6] *= s;te[10] *= s;te[14] *= s;\n    te[3] *= s;te[7] *= s;te[11] *= s;te[15] *= s;\n\n    return this;\n\n  },\n\n  determinant: function determinant() {\n\n    var te = this.elements;\n\n    var n11 = te[0],n12 = te[4],n13 = te[8],n14 = te[12];\n    var n21 = te[1],n22 = te[5],n23 = te[9],n24 = te[13];\n    var n31 = te[2],n32 = te[6],n33 = te[10],n34 = te[14];\n    var n41 = te[3],n42 = te[7],n43 = te[11],n44 = te[15];\n\n    //TODO: make this more efficient\n    //( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )\n\n    return (\n      n41 * (\n      +n14 * n23 * n32 -\n      n13 * n24 * n32 -\n      n14 * n22 * n33 +\n      n12 * n24 * n33 +\n      n13 * n22 * n34 -\n      n12 * n23 * n34) +\n\n      n42 * (\n      +n11 * n23 * n34 -\n      n11 * n24 * n33 +\n      n14 * n21 * n33 -\n      n13 * n21 * n34 +\n      n13 * n24 * n31 -\n      n14 * n23 * n31) +\n\n      n43 * (\n      +n11 * n24 * n32 -\n      n11 * n22 * n34 -\n      n14 * n21 * n32 +\n      n12 * n21 * n34 +\n      n14 * n22 * n31 -\n      n12 * n24 * n31) +\n\n      n44 * (\n      -n13 * n22 * n31 -\n      n11 * n23 * n32 +\n      n11 * n22 * n33 +\n      n13 * n21 * n32 -\n      n12 * n21 * n33 +\n      n12 * n23 * n31));\n\n\n\n\n  },\n\n  transpose: function transpose() {\n\n    var te = this.elements;\n    var tmp;\n\n    tmp = te[1];te[1] = te[4];te[4] = tmp;\n    tmp = te[2];te[2] = te[8];te[8] = tmp;\n    tmp = te[6];te[6] = te[9];te[9] = tmp;\n\n    tmp = te[3];te[3] = te[12];te[12] = tmp;\n    tmp = te[7];te[7] = te[13];te[13] = tmp;\n    tmp = te[11];te[11] = te[14];te[14] = tmp;\n\n    return this;\n\n  },\n\n  flattenToArrayOffset: function flattenToArrayOffset(array, offset) {\n\n    var te = this.elements;\n\n    array[offset] = te[0];\n    array[offset + 1] = te[1];\n    array[offset + 2] = te[2];\n    array[offset + 3] = te[3];\n\n    array[offset + 4] = te[4];\n    array[offset + 5] = te[5];\n    array[offset + 6] = te[6];\n    array[offset + 7] = te[7];\n\n    array[offset + 8] = te[8];\n    array[offset + 9] = te[9];\n    array[offset + 10] = te[10];\n    array[offset + 11] = te[11];\n\n    array[offset + 12] = te[12];\n    array[offset + 13] = te[13];\n    array[offset + 14] = te[14];\n    array[offset + 15] = te[15];\n\n    return array;\n\n  },\n\n  setPosition: function setPosition(v) {\n\n    var te = this.elements;\n\n    te[12] = v.x;\n    te[13] = v.y;\n    te[14] = v.z;\n\n    return this;\n\n  },\n\n  getInverse: function getInverse(m, throwOnInvertible) {\n\n    // based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm\n    var te = this.elements;\n    var me = m.elements;\n\n    var n11 = me[0],n12 = me[4],n13 = me[8],n14 = me[12];\n    var n21 = me[1],n22 = me[5],n23 = me[9],n24 = me[13];\n    var n31 = me[2],n32 = me[6],n33 = me[10],n34 = me[14];\n    var n41 = me[3],n42 = me[7],n43 = me[11],n44 = me[15];\n\n    te[0] = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44;\n    te[4] = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44;\n    te[8] = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44;\n    te[12] = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;\n    te[1] = n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44;\n    te[5] = n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44;\n    te[9] = n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44;\n    te[13] = n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34;\n    te[2] = n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44;\n    te[6] = n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44;\n    te[10] = n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44;\n    te[14] = n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34;\n    te[3] = n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43;\n    te[7] = n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43;\n    te[11] = n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43;\n    te[15] = n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33;\n\n    var det = n11 * te[0] + n21 * te[4] + n31 * te[8] + n41 * te[12];\n\n    if (det == 0) {\n\n      var msg = \"Matrix4.getInverse(): can't invert matrix, determinant is 0\";\n\n      if (throwOnInvertible || false) {\n\n        throw new Error(msg);\n\n      } else {\n\n        console.warn(msg);\n\n      }\n\n      this.identity();\n\n      return this;\n    }\n\n    this.multiplyScalar(1 / det);\n\n    return this;\n\n  },\n\n  scale: function scale(v) {\n\n    var te = this.elements;\n    var x = v.x,y = v.y,z = v.z;\n\n    te[0] *= x;te[4] *= y;te[8] *= z;\n    te[1] *= x;te[5] *= y;te[9] *= z;\n    te[2] *= x;te[6] *= y;te[10] *= z;\n    te[3] *= x;te[7] *= y;te[11] *= z;\n\n    return this;\n\n  },\n\n  makeTranslation: function makeTranslation(x, y, z) {\n\n    this.set(\n\n    1, 0, 0, x,\n    0, 1, 0, y,\n    0, 0, 1, z,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationX: function makeRotationX(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    1, 0, 0, 0,\n    0, c, -s, 0,\n    0, s, c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationY: function makeRotationY(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    c, 0, s, 0,\n    0, 1, 0, 0,\n    -s, 0, c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationZ: function makeRotationZ(theta) {\n\n    var c = Math.cos(theta),s = Math.sin(theta);\n\n    this.set(\n\n    c, -s, 0, 0,\n    s, c, 0, 0,\n    0, 0, 1, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeRotationAxis: function makeRotationAxis(axis, angle) {\n\n    // Based on http://www.gamedev.net/reference/articles/article1199.asp\n\n    var c = Math.cos(angle);\n    var s = Math.sin(angle);\n    var t = 1 - c;\n    var x = axis.x,y = axis.y,z = axis.z;\n    var tx = t * x,ty = t * y;\n\n    this.set(\n\n    tx * x + c, tx * y - s * z, tx * z + s * y, 0,\n    tx * y + s * z, ty * y + c, ty * z - s * x, 0,\n    tx * z - s * y, ty * z + s * x, t * z * z + c, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  makeScale: function makeScale(x, y, z) {\n\n    this.set(\n\n    x, 0, 0, 0,\n    0, y, 0, 0,\n    0, 0, z, 0,\n    0, 0, 0, 1);\n\n\n\n    return this;\n\n  },\n\n  compose: function compose(position, quaternion, scale) {\n\n    this.makeRotationFromQuaternion(quaternion);\n    this.scale(scale);\n    this.setPosition(position);\n\n    return this;\n\n  },\n\n  //Added for LMV\n  transformPoint: function transformPoint(pt) {\n\n    // input: THREE.Matrix4 affine matrix\n\n    var x = pt.x,y = pt.y,z = pt.z;\n\n    var e = this.elements;\n\n    pt.x = e[0] * x + e[4] * y + e[8] * z + e[12];\n    pt.y = e[1] * x + e[5] * y + e[9] * z + e[13];\n    pt.z = e[2] * x + e[6] * y + e[10] * z + e[14];\n\n    return pt;\n  },\n\n  //Added for LMV\n  transformDirection: function transformDirection(v) {\n\n    // input: THREE.Matrix4 affine matrix\n    // vector interpreted as a direction\n\n    var x = v.x,y = v.y,z = v.z;\n\n    var e = this.elements;\n\n    v.x = e[0] * x + e[4] * y + e[8] * z;\n    v.y = e[1] * x + e[5] * y + e[9] * z;\n    v.z = e[2] * x + e[6] * y + e[10] * z;\n\n    var len = Math.sqrt(v.x * v.x + v.y * v.y + v.z * v.z);\n    if (len > 0) {\n      var ilen = 1.0 / len;\n      v.x *= ilen;\n      v.y *= ilen;\n      v.z *= ilen;\n    }\n\n    return v;\n  },\n\n\n  fromArray: function fromArray(array) {\n\n    this.elements.set(array);\n\n    return this;\n\n  },\n\n  toArray: function toArray() {\n\n    var te = this.elements;\n\n    return [\n    te[0], te[1], te[2], te[3],\n    te[4], te[5], te[6], te[7],\n    te[8], te[9], te[10], te[11],\n    te[12], te[13], te[14], te[15]];\n\n\n  },\n\n  clone: function clone() {\n\n    return new LmvMatrix4(this.elements instanceof Float64Array).fromArray(this.elements);\n\n  } };\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/LmvVector3.js\":\n/*!*************************************!*\\\n  !*** ./src/wgs/scene/LmvVector3.js ***!\n  \\*************************************/\n/*! exports provided: LmvVector3 */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"LmvVector3\", function() { return LmvVector3; });\n/**\n * @author mrdoob / http://mrdoob.com/\n * @author *kile / http://kile.stravaganza.org/\n * @author philogb / http://blog.thejit.org/\n * @author mikael emtinger / http://gomo.se/\n * @author egraether / http://egraether.com/\n * @author WestLangley / http://github.com/WestLangley\n */\n/* Pruned version of THREE.Vector3, for use in the LMV web worker */\n\nvar LmvVector3 = function LmvVector3(x, y, z) {\n\n  this.x = x || 0;\n  this.y = y || 0;\n  this.z = z || 0;\n\n};\n\nLmvVector3.prototype = {\n\n  constructor: LmvVector3,\n\n  set: function set(x, y, z) {\n\n    this.x = x;\n    this.y = y;\n    this.z = z;\n\n    return this;\n\n  },\n\n  setX: function setX(x) {\n\n    this.x = x;\n\n    return this;\n\n  },\n\n  setY: function setY(y) {\n\n    this.y = y;\n\n    return this;\n\n  },\n\n  setZ: function setZ(z) {\n\n    this.z = z;\n\n    return this;\n\n  },\n\n  setComponent: function setComponent(index, value) {\n\n    switch (index) {\n\n      case 0:this.x = value;break;\n      case 1:this.y = value;break;\n      case 2:this.z = value;break;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  getComponent: function getComponent(index) {\n\n    switch (index) {\n\n      case 0:return this.x;\n      case 1:return this.y;\n      case 2:return this.z;\n      default:throw new Error('index is out of range: ' + index);}\n\n\n\n  },\n\n  clone: function clone() {\n\n    return new this.constructor(this.x, this.y, this.z);\n\n  },\n\n  copy: function copy(v) {\n\n    this.x = v.x;\n    this.y = v.y;\n    this.z = v.z;\n\n    return this;\n\n  },\n\n  add: function add(v, w) {\n\n    if (w !== undefined) {\n\n      console.warn('THREE.Vector3: .add() now only accepts one argument. Use .addVectors( a, b ) instead.');\n      return this.addVectors(v, w);\n\n    }\n\n    this.x += v.x;\n    this.y += v.y;\n    this.z += v.z;\n\n    return this;\n\n  },\n\n  addScalar: function addScalar(s) {\n\n    this.x += s;\n    this.y += s;\n    this.z += s;\n\n    return this;\n\n  },\n\n  addVectors: function addVectors(a, b) {\n\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n    this.z = a.z + b.z;\n\n    return this;\n\n  },\n\n  addScaledVector: function addScaledVector(v, s) {\n\n    this.x += v.x * s;\n    this.y += v.y * s;\n    this.z += v.z * s;\n\n    return this;\n\n  },\n\n  sub: function sub(v, w) {\n\n    if (w !== undefined) {\n\n      console.warn('THREE.Vector3: .sub() now only accepts one argument. Use .subVectors( a, b ) instead.');\n      return this.subVectors(v, w);\n\n    }\n\n    this.x -= v.x;\n    this.y -= v.y;\n    this.z -= v.z;\n\n    return this;\n\n  },\n\n  subScalar: function subScalar(s) {\n\n    this.x -= s;\n    this.y -= s;\n    this.z -= s;\n\n    return this;\n\n  },\n\n  subVectors: function subVectors(a, b) {\n\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n    this.z = a.z - b.z;\n\n    return this;\n\n  },\n\n  multiply: function multiply(v, w) {\n\n    if (w !== undefined) {\n\n      console.warn('THREE.Vector3: .multiply() now only accepts one argument. Use .multiplyVectors( a, b ) instead.');\n      return this.multiplyVectors(v, w);\n\n    }\n\n    this.x *= v.x;\n    this.y *= v.y;\n    this.z *= v.z;\n\n    return this;\n\n  },\n\n  multiplyScalar: function multiplyScalar(scalar) {\n\n    this.x *= scalar;\n    this.y *= scalar;\n    this.z *= scalar;\n\n    return this;\n\n  },\n\n  multiplyVectors: function multiplyVectors(a, b) {\n\n    this.x = a.x * b.x;\n    this.y = a.y * b.y;\n    this.z = a.z * b.z;\n\n    return this;\n\n  },\n\n  applyMatrix3: function applyMatrix3(m) {\n\n    var x = this.x;\n    var y = this.y;\n    var z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[3] * y + e[6] * z;\n    this.y = e[1] * x + e[4] * y + e[7] * z;\n    this.z = e[2] * x + e[5] * y + e[8] * z;\n\n    return this;\n\n  },\n\n  applyMatrix4: function applyMatrix4(m) {\n\n    // input: THREE.Matrix4 affine matrix\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[4] * y + e[8] * z + e[12];\n    this.y = e[1] * x + e[5] * y + e[9] * z + e[13];\n    this.z = e[2] * x + e[6] * y + e[10] * z + e[14];\n\n    return this;\n\n  },\n\n  applyProjection: function applyProjection(m) {\n\n    // input: THREE.Matrix4 projection matrix\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n    var d = 1 / (e[3] * x + e[7] * y + e[11] * z + e[15]); // perspective divide\n\n    this.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * d;\n    this.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * d;\n    this.z = (e[2] * x + e[6] * y + e[10] * z + e[14]) * d;\n\n    return this;\n\n  },\n\n  applyQuaternion: function applyQuaternion(q) {\n\n    var x = this.x;\n    var y = this.y;\n    var z = this.z;\n\n    var qx = q.x;\n    var qy = q.y;\n    var qz = q.z;\n    var qw = q.w;\n\n    // calculate quat * vector\n\n    var ix = qw * x + qy * z - qz * y;\n    var iy = qw * y + qz * x - qx * z;\n    var iz = qw * z + qx * y - qy * x;\n    var iw = -qx * x - qy * y - qz * z;\n\n    // calculate result * inverse quat\n\n    this.x = ix * qw + iw * -qx + iy * -qz - iz * -qy;\n    this.y = iy * qw + iw * -qy + iz * -qx - ix * -qz;\n    this.z = iz * qw + iw * -qz + ix * -qy - iy * -qx;\n\n    return this;\n\n  },\n\n  transformDirection: function transformDirection(m) {\n\n    // input: THREE.Matrix4 affine matrix\n    // vector interpreted as a direction\n\n    var x = this.x,y = this.y,z = this.z;\n\n    var e = m.elements;\n\n    this.x = e[0] * x + e[4] * y + e[8] * z;\n    this.y = e[1] * x + e[5] * y + e[9] * z;\n    this.z = e[2] * x + e[6] * y + e[10] * z;\n\n    this.normalize();\n\n    return this;\n\n  },\n\n  divide: function divide(v) {\n\n    this.x /= v.x;\n    this.y /= v.y;\n    this.z /= v.z;\n\n    return this;\n\n  },\n\n  divideScalar: function divideScalar(scalar) {\n\n    if (scalar !== 0) {\n\n      var invScalar = 1 / scalar;\n\n      this.x *= invScalar;\n      this.y *= invScalar;\n      this.z *= invScalar;\n\n    } else {\n\n      this.x = 0;\n      this.y = 0;\n      this.z = 0;\n\n    }\n\n    return this;\n\n  },\n\n  min: function min(v) {\n\n    if (this.x > v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y > v.y) {\n\n      this.y = v.y;\n\n    }\n\n    if (this.z > v.z) {\n\n      this.z = v.z;\n\n    }\n\n    return this;\n\n  },\n\n  max: function max(v) {\n\n    if (this.x < v.x) {\n\n      this.x = v.x;\n\n    }\n\n    if (this.y < v.y) {\n\n      this.y = v.y;\n\n    }\n\n    if (this.z < v.z) {\n\n      this.z = v.z;\n\n    }\n\n    return this;\n\n  },\n\n  clamp: function clamp(min, max) {\n\n    // This function assumes min < max, if this assumption isn't true it will not operate correctly\n\n    if (this.x < min.x) {\n\n      this.x = min.x;\n\n    } else if (this.x > max.x) {\n\n      this.x = max.x;\n\n    }\n\n    if (this.y < min.y) {\n\n      this.y = min.y;\n\n    } else if (this.y > max.y) {\n\n      this.y = max.y;\n\n    }\n\n    if (this.z < min.z) {\n\n      this.z = min.z;\n\n    } else if (this.z > max.z) {\n\n      this.z = max.z;\n\n    }\n\n    return this;\n\n  },\n\n  clampScalar: function () {\n\n    var min, max;\n\n    return function clampScalar(minVal, maxVal) {\n\n      if (min === undefined) {\n\n        min = new LmvVector3();\n        max = new LmvVector3();\n\n      }\n\n      min.set(minVal, minVal, minVal);\n      max.set(maxVal, maxVal, maxVal);\n\n      return this.clamp(min, max);\n\n    };\n\n  }(),\n\n  floor: function floor() {\n\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n    this.z = Math.floor(this.z);\n\n    return this;\n\n  },\n\n  ceil: function ceil() {\n\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n    this.z = Math.ceil(this.z);\n\n    return this;\n\n  },\n\n  round: function round() {\n\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n    this.z = Math.round(this.z);\n\n    return this;\n\n  },\n\n  roundToZero: function roundToZero() {\n\n    this.x = this.x < 0 ? Math.ceil(this.x) : Math.floor(this.x);\n    this.y = this.y < 0 ? Math.ceil(this.y) : Math.floor(this.y);\n    this.z = this.z < 0 ? Math.ceil(this.z) : Math.floor(this.z);\n\n    return this;\n\n  },\n\n  negate: function negate() {\n\n    this.x = -this.x;\n    this.y = -this.y;\n    this.z = -this.z;\n\n    return this;\n\n  },\n\n  dot: function dot(v) {\n\n    return this.x * v.x + this.y * v.y + this.z * v.z;\n\n  },\n\n  lengthSq: function lengthSq() {\n\n    return this.x * this.x + this.y * this.y + this.z * this.z;\n\n  },\n\n  length: function length() {\n\n    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);\n\n  },\n\n  lengthManhattan: function lengthManhattan() {\n\n    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);\n\n  },\n\n  normalize: function normalize() {\n\n    return this.divideScalar(this.length());\n\n  },\n\n  setLength: function setLength(l) {\n\n    var oldLength = this.length();\n\n    if (oldLength !== 0 && l !== oldLength) {\n\n      this.multiplyScalar(l / oldLength);\n\n    }\n\n    return this;\n\n  },\n\n  lerp: function lerp(v, alpha) {\n\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n    this.z += (v.z - this.z) * alpha;\n\n    return this;\n\n  },\n\n  lerpVectors: function lerpVectors(v1, v2, alpha) {\n\n    this.subVectors(v2, v1).multiplyScalar(alpha).add(v1);\n\n    return this;\n\n  },\n\n  cross: function cross(v, w) {\n\n    if (w !== undefined) {\n\n      console.warn('THREE.Vector3: .cross() now only accepts one argument. Use .crossVectors( a, b ) instead.');\n      return this.crossVectors(v, w);\n\n    }\n\n    var x = this.x,y = this.y,z = this.z;\n\n    this.x = y * v.z - z * v.y;\n    this.y = z * v.x - x * v.z;\n    this.z = x * v.y - y * v.x;\n\n    return this;\n\n  },\n\n  crossVectors: function crossVectors(a, b) {\n\n    var ax = a.x,ay = a.y,az = a.z;\n    var bx = b.x,by = b.y,bz = b.z;\n\n    this.x = ay * bz - az * by;\n    this.y = az * bx - ax * bz;\n    this.z = ax * by - ay * bx;\n\n    return this;\n\n  },\n\n  projectOnVector: function () {\n\n    var v1, dot;\n\n    return function projectOnVector(vector) {\n\n      if (v1 === undefined) v1 = new LmvVector3();\n\n      v1.copy(vector).normalize();\n\n      dot = this.dot(v1);\n\n      return this.copy(v1).multiplyScalar(dot);\n\n    };\n\n  }(),\n\n  projectOnPlane: function () {\n\n    var v1;\n\n    return function projectOnPlane(planeNormal) {\n\n      if (v1 === undefined) v1 = new LmvVector3();\n\n      v1.copy(this).projectOnVector(planeNormal);\n\n      return this.sub(v1);\n\n    };\n\n  }(),\n\n  reflect: function () {\n\n    // reflect incident vector off plane orthogonal to normal\n    // normal is assumed to have unit length\n\n    var v1;\n\n    return function reflect(normal) {\n\n      if (v1 === undefined) v1 = new LmvVector3();\n\n      return this.sub(v1.copy(normal).multiplyScalar(2 * this.dot(normal)));\n\n    };\n\n  }(),\n\n  distanceTo: function distanceTo(v) {\n\n    return Math.sqrt(this.distanceToSquared(v));\n\n  },\n\n  distanceToSquared: function distanceToSquared(v) {\n\n    var dx = this.x - v.x;\n    var dy = this.y - v.y;\n    var dz = this.z - v.z;\n\n    return dx * dx + dy * dy + dz * dz;\n\n  },\n\n  setEulerFromRotationMatrix: function setEulerFromRotationMatrix(m, order) {\n\n    console.error('THREE.Vector3: .setEulerFromRotationMatrix() has been removed. Use Euler.setFromRotationMatrix() instead.');\n\n  },\n\n  setEulerFromQuaternion: function setEulerFromQuaternion(q, order) {\n\n    console.error('THREE.Vector3: .setEulerFromQuaternion() has been removed. Use Euler.setFromQuaternion() instead.');\n\n  },\n\n  getPositionFromMatrix: function getPositionFromMatrix(m) {\n\n    console.warn('THREE.Vector3: .getPositionFromMatrix() has been renamed to .setFromMatrixPosition().');\n\n    return this.setFromMatrixPosition(m);\n\n  },\n\n  getScaleFromMatrix: function getScaleFromMatrix(m) {\n\n    console.warn('THREE.Vector3: .getScaleFromMatrix() has been renamed to .setFromMatrixScale().');\n\n    return this.setFromMatrixScale(m);\n\n  },\n\n  getColumnFromMatrix: function getColumnFromMatrix(index, matrix) {\n\n    console.warn('THREE.Vector3: .getColumnFromMatrix() has been renamed to .setFromMatrixColumn().');\n\n    return this.setFromMatrixColumn(index, matrix);\n\n  },\n\n  setFromMatrixPosition: function setFromMatrixPosition(m) {\n\n    this.x = m.elements[12];\n    this.y = m.elements[13];\n    this.z = m.elements[14];\n\n    return this;\n\n  },\n\n  setFromMatrixScale: function setFromMatrixScale(m) {\n\n    var sx = this.set(m.elements[0], m.elements[1], m.elements[2]).length();\n    var sy = this.set(m.elements[4], m.elements[5], m.elements[6]).length();\n    var sz = this.set(m.elements[8], m.elements[9], m.elements[10]).length();\n\n    this.x = sx;\n    this.y = sy;\n    this.z = sz;\n\n    return this;\n\n  },\n\n  setFromMatrixColumn: function setFromMatrixColumn(index, matrix) {\n\n    var offset = index * 4;\n\n    var me = matrix.elements;\n\n    this.x = me[offset];\n    this.y = me[offset + 1];\n    this.z = me[offset + 2];\n\n    return this;\n\n  },\n\n  equals: function equals(v) {\n\n    return v.x === this.x && v.y === this.y && v.z === this.z;\n\n  },\n\n  fromArray: function fromArray(array, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    this.x = array[offset];\n    this.y = array[offset + 1];\n    this.z = array[offset + 2];\n\n    return this;\n\n  },\n\n  toArray: function toArray(array, offset) {\n\n    if (array === undefined) array = [];\n    if (offset === undefined) offset = 0;\n\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n    array[offset + 2] = this.z;\n\n    return array;\n\n  },\n\n  fromAttribute: function fromAttribute(attribute, index, offset) {\n\n    if (offset === undefined) offset = 0;\n\n    index = index * attribute.itemSize + offset;\n\n    this.x = attribute.array[index];\n    this.y = attribute.array[index + 1];\n    this.z = attribute.array[index + 2];\n\n    return this;\n\n  } };\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/MeshFlags.js\":\n/*!************************************!*\\\n  !*** ./src/wgs/scene/MeshFlags.js ***!\n  \\************************************/\n/*! exports provided: MeshFlags */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"MeshFlags\", function() { return MeshFlags; });\nvar MeshFlags = {\n  // FragmentList flags\n  //visibility/highlight bitmask flags\n\n  //Byte 0\n\n  //NOTE: This is confusing and it should be fixed, but when the MESH_VISIBLE bit is off, the mesh\n  //will draw in ghosted mode. To completely skip drawing a mesh, set the HIDE flag.\n  MESH_VISIBLE: 1,\n  MESH_HIGHLIGHTED: 2,\n  MESH_HIDE: 4,\n  MESH_ISLINE: 8,\n  MESH_MOVED: 0x10, // indicates if an animation matrix is set\n  MESH_RENDERFLAG: 0x20,\n  MESH_NOTLOADED: 0x40, // the mesh has not yet loaded or has been unloaded\n  MESH_ISPOINT: 0x80, // indicates that the mesh is vertex-only\n\n  //Byte 1\n  //TODO: Two bits are enough to hold ISLINE, ISWIDELINE and ISPOINT, we don't need to waste three,\n  //but there is no point to optimizing this as long as the required flags go over one byte.\n  MESH_ISWIDELINE: 0x100, // indicates that the mesh is wide line\n  MESH_TRAVERSED: 0x200, // only used for paging: drawn fragments are tagged and then skipped by forEach() until the flag is being reset (e.g. on scene/camera changes)\n  MESH_DRAWN: 0x400 // only used for paging: drawn fragments are tagged. At the end of all render passes flag is copied to MESH_TRAVERSED.\n  // The Memory Limited Extension uses the high order three bits of this byte\n};\n\n/***/ }),\n\n/***/ \"./src/wgs/scene/VertexEnumerator.js\":\n/*!*******************************************!*\\\n  !*** ./src/wgs/scene/VertexEnumerator.js ***!\n  \\*******************************************/\n/*! exports provided: getVertexCount, enumMeshVertices, enumMeshIndices, enumMeshTriangles, enumMeshLines, enumMeshEdges, VertexEnumerator */\n/***/ (function(module, __webpack_exports__, __webpack_require__) {\n\n\"use strict\";\n__webpack_require__.r(__webpack_exports__);\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"getVertexCount\", function() { return getVertexCount; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enumMeshVertices\", function() { return enumMeshVertices; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enumMeshIndices\", function() { return enumMeshIndices; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enumMeshTriangles\", function() { return enumMeshTriangles; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enumMeshLines\", function() { return enumMeshLines; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"enumMeshEdges\", function() { return enumMeshEdges; });\n/* harmony export (binding) */ __webpack_require__.d(__webpack_exports__, \"VertexEnumerator\", function() { return VertexEnumerator; });\n/* harmony import */ var _LmvVector3__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./LmvVector3 */ \"./src/wgs/scene/LmvVector3.js\");\n\n\n//Utility logic for listing vertex data from LmvBufferGeometry interleaved buffers\n\n\n\n//These functions work for both workers side interleaved buffer structures\n//and main thread side LmvBufferGeometry instances. The difference in naming\n//if the index attribute on both sides is super annoying and should be cleaned up.\n\n\n/** Works for BufferGeometry as well as THREE.BufferGeometry. Supports interleaved and non-interleaved buffers.\n *   @param {BufferGeometry|THREE.BufferGeometry} geom\n *   @returns {number}\n */\nfunction getVertexCount(geom) {\n  if (geom.vb) {\n    // interleaved\n    return geom.vb.length / geom.vbstride;\n  }\n  // no interleaved buffer. Return count from position attribute or 0\n  return geom.attributes.positions ? geom.attributes.positions.count : 0;\n}\n\n\nvar _p, _n, _uv;\nvar _normalsMatrix;\n\nfunction enumMeshVertices(geometry, callback, matrix) {\n\n  var attributes = geometry.attributes;\n\n  if (!_p) {\n    _p = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    _n = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    _uv = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n  }\n\n  if (matrix) {\n    if (!_normalsMatrix)\n    _normalsMatrix = new THREE.Matrix3();\n\n    _normalsMatrix.getNormalMatrix(matrix);\n  }\n\n  var positions = geometry.vb || attributes.position.array;\n  var normals = geometry.vb || attributes.normal && attributes.normal.array;\n  var stride = geometry.vb ? geometry.vbstride : 3;\n  // Get the offset to positions in the buffer. Be careful, 2D buffers\n  // don't use the 'position' attribute for positions. Reject those.\n  var poffset;\n  if (geometry.vblayout) {\n    if (!geometry.vblayout.position)\n    return; // No positions, what to do??\n    poffset = geometry.vblayout.position.offset;\n  } else if (!attributes.position)\n  return; // No positions, what to do??\n  else\n    poffset = attributes.position.itemOffset || 0;\n\n  var noffset = 0;\n  var nattr = geometry.vblayout ? geometry.vblayout.normal : attributes.normal || null;\n  if (nattr) {\n    noffset = nattr.offset || nattr.itemOffset || 0;\n  } else {\n    normals = null;\n  }\n\n  //TODO: UV channel\n\n  if (nattr && (nattr.itemSize !== 3 || nattr.bytesPerItem !== 4)) {\n    //console.log(\"Normals are packed, will be skipped from enumMeshTriangles. Use packNormals=false load option.\");\n    normals = null;\n  }\n\n  var vcount = geometry.vb ? geometry.vb.length / geometry.vbstride : positions.length;\n\n  var pi = poffset;\n  var ni = noffset;\n  for (var i = 0; i < vcount; i++, pi += stride, ni += stride) {\n\n    _p.set(positions[pi], positions[pi + 1], positions[pi + 2]);\n\n    if (matrix)\n    _p.applyMatrix4(matrix);\n\n    if (normals) {\n      _n.set(normals[ni], normals[ni + 1], normals[ni + 2]);\n\n      if (matrix) {\n        _n.applyMatrix3(_normalsMatrix);\n      }\n    }\n\n    //TODO: UV channel\n\n    callback(_p, normals ? _n : null, null /*, _uv*/, i);\n  }\n}\n\nfunction enumMeshIndices(geometry, callback) {\n\n  var indices = geometry.ib || geometry.indices || (attributes.index ? attributes.index.array : null);\n\n  if (indices) {\n\n    var offsets = geometry.offsets;\n\n    if (!offsets || offsets.length === 0) {\n      offsets = [{ start: 0, count: indices.length, index: 0 }];\n    }\n\n    for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {\n\n      var start = offsets[oi].start;\n      var count = offsets[oi].count;\n      var index = offsets[oi].index;\n\n      for (var i = start, il = start + count; i < il; i += 3) {\n\n        var a = index + indices[i];\n        var b = index + indices[i + 1];\n        var c = index + indices[i + 2];\n\n        callback(a, b, c);\n      }\n    }\n  } else {\n\n    var positions = geometry.vb || attributes.position.array;\n    var vcount = geometry.vb ? geometry.vb.length / geometry.vbstride : positions.length / 3;\n\n    for (var _i = 0; _i < vcount; _i++) {\n\n      var _a = 3 * _i;\n      var _b = 3 * _i + 1;\n      var _c = 3 * _i + 2;\n\n      callback(_a, _b, _c);\n    }\n  }\n}\n\n\nvar vA, vB, vC, nA, nB, nC;\n\nfunction enumMeshTriangles(geometry, callback) {\n\n  var attributes = geometry.attributes;\n\n  var a, b, c;\n\n  if (!vA) {\n    vA = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    vB = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    vC = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n\n    nA = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    nB = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    nC = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n  }\n\n  var positions = geometry.vb || attributes.position.array;\n  var normals = geometry.vb || attributes.normal && attributes.normal.array;\n  var stride = geometry.vb ? geometry.vbstride : 3;\n  // Get the offset to positions in the buffer. Be careful, 2D buffers\n  // don't use the 'position' attribute for positions. Reject those.\n  var poffset;\n  if (geometry.vblayout) {\n    if (!geometry.vblayout.position)\n    return; // No positions, what to do??\n    poffset = geometry.vblayout.position.offset;\n  } else if (!attributes.position)\n  return; // No positions, what to do??\n  else\n    poffset = attributes.position.itemOffset || 0;\n\n  var noffset = 0;\n  var nattr = geometry.vblayout ? geometry.vblayout.normal : attributes.normal || null;\n  if (nattr) {\n    noffset = nattr.offset || nattr.itemOffset || 0;\n  } else {\n    normals = null;\n  }\n\n  if (nattr && (nattr.itemSize !== 3 || nattr.bytesPerItem !== 4)) {\n    //console.log(\"Normals are packed, will be skipped from enumMeshTriangles. Use packNormals=false load option.\");\n    normals = null;\n  }\n\n  var indices = geometry.ib || geometry.indices || (attributes.index ? attributes.index.array : null);\n\n  if (indices) {\n\n    var offsets = geometry.offsets;\n\n    if (!offsets || offsets.length === 0) {\n      offsets = [{ start: 0, count: indices.length, index: 0 }];\n    }\n\n    for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {\n\n      var start = offsets[oi].start;\n      var count = offsets[oi].count;\n      var index = offsets[oi].index;\n\n      for (var i = start, il = start + count; i < il; i += 3) {\n\n        a = index + indices[i];\n        b = index + indices[i + 1];\n        c = index + indices[i + 2];\n\n        var pa = a * stride + poffset;\n        var pb = b * stride + poffset;\n        var pc = c * stride + poffset;\n\n        vA.x = positions[pa];vA.y = positions[pa + 1];vA.z = positions[pa + 2];\n        vB.x = positions[pb];vB.y = positions[pb + 1];vB.z = positions[pb + 2];\n        vC.x = positions[pc];vC.y = positions[pc + 1];vC.z = positions[pc + 2];\n\n        if (normals) {\n          var na = a * stride + noffset;\n          var nb = b * stride + noffset;\n          var nc = c * stride + noffset;\n\n          nA.x = normals[na];nA.y = normals[na + 1];nA.z = normals[na + 2];\n          nB.x = normals[nb];nB.y = normals[nb + 1];nB.z = normals[nb + 2];\n          nC.x = normals[nc];nC.y = normals[nc + 1];nC.z = normals[nc + 2];\n\n          callback(vA, vB, vC, a, b, c, nA, nB, nC, i / 3);\n        } else {\n          callback(vA, vB, vC, a, b, c, null, null, null, i / 3);\n        }\n\n\n      }\n\n    }\n\n  } else {\n\n    var vcount = geometry.vb ? geometry.vb.length / geometry.vbstride : positions.length / 3;\n\n    for (var i = 0; i < vcount; i++) {\n\n      a = 3 * i;\n      b = 3 * i + 1;\n      c = 3 * i + 2;\n\n      var pa = a * stride + poffset;\n      var pb = b * stride + poffset;\n      var pc = c * stride + poffset;\n\n      vA.x = positions[pa];vA.y = positions[pa + 1];vA.z = positions[pa + 2];\n      vB.x = positions[pb];vB.y = positions[pb + 1];vB.z = positions[pb + 2];\n      vC.x = positions[pc];vC.y = positions[pc + 1];vC.z = positions[pc + 2];\n\n      if (normals) {\n        var na = a * stride + noffset;\n        var nb = b * stride + noffset;\n        var nc = c * stride + noffset;\n\n        nA.x = normals[na];nA.y = normals[na + 1];nA.z = normals[na + 2];\n        nB.x = normals[nb];nB.y = normals[nb + 1];nB.z = normals[nb + 2];\n        nC.x = normals[nc];nC.y = normals[nc + 1];nC.z = normals[nc + 2];\n\n        callback(vA, vB, vC, a, b, c, nA, nB, nC, i);\n      } else {\n        callback(vA, vB, vC, a, b, c, null, null, null, i);\n      }\n    }\n\n  }\n}\n\n\nvar vP, vQ;\n\nfunction enumMeshLines(geometry, callback) {\n\n  var attributes = geometry.attributes;\n\n  var a, b;\n\n  if (!vP) {\n    vP = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    vQ = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n  }\n\n  var istep = 2;\n  if (geometry.lineWidth) {\n    istep = 6;\n  }\n\n\n  var indices = geometry.ib || geometry.indices || (attributes.index ? attributes.index.array : null);\n\n  if (indices) {\n\n    var positions = geometry.vb ? geometry.vb : attributes.position.array;\n    var stride = geometry.vb ? geometry.vbstride : 3;\n    var offsets = geometry.offsets;\n\n    if (!offsets || offsets.length === 0) {\n\n      offsets = [{ start: 0, count: indices.length, index: 0 }];\n\n    }\n\n    for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {\n\n      var start = offsets[oi].start;\n      var count = offsets[oi].count;\n      var index = offsets[oi].index;\n\n      for (var i = start, il = start + count, lineIdx = start / istep; i < il; i += istep, lineIdx++) {\n\n        a = index + indices[i];\n        b = index + indices[i + 1];\n\n        vP.x = positions[a * stride];vP.y = positions[a * stride + 1];vP.z = positions[a * stride + 2];\n        vQ.x = positions[b * stride];vQ.y = positions[b * stride + 1];vQ.z = positions[b * stride + 2];\n\n        callback(vP, vQ, a, b, lineIdx);\n      }\n\n    }\n\n  } else {\n\n    var positions = geometry.vb ? geometry.vb : attributes.position.array;\n    var stride = geometry.vb ? geometry.vbstride : 3;\n\n    for (var i = 0, il = positions.length / stride, lineIdx = 0; i < il; i += istep, lineIdx++) {\n\n      a = i;\n      b = i + 1;\n\n      vP.x = positions[a * stride];vP.y = positions[a * stride + 1];vP.z = positions[a * stride + 2];\n      vQ.x = positions[b * stride];vQ.y = positions[b * stride + 1];vQ.z = positions[b * stride + 2];\n\n      callback(vP, vQ, a, b, lineIdx);\n    }\n\n  }\n}\n\n\nfunction enumMeshEdges(geometry, callback) {\n  var attributes = geometry.attributes;\n\n  var a, b;\n\n  if (!vP) {\n    vP = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n    vQ = new _LmvVector3__WEBPACK_IMPORTED_MODULE_0__[\"LmvVector3\"]();\n  }\n\n  var istep = 2;\n\n  var indices = geometry.iblines;\n\n  if (!indices) {\n    return;\n  }\n\n  var positions = geometry.vb ? geometry.vb : attributes.position.array;\n  var stride = geometry.vb ? geometry.vbstride : 3;\n  var offsets = geometry.offsets;\n\n  if (!offsets || offsets.length === 0) {\n\n    offsets = [{ start: 0, count: indices.length, index: 0 }];\n\n  }\n\n  for (var oi = 0, ol = offsets.length; oi < ol; ++oi) {\n\n    var start = offsets[oi].start;\n    var count = offsets[oi].count;\n    var index = offsets[oi].index;\n\n    for (var i = start, il = start + count; i < il; i += istep) {\n\n      a = index + indices[i];\n      b = index + indices[i + 1];\n\n      vP.x = positions[a * stride];vP.y = positions[a * stride + 1];vP.z = positions[a * stride + 2];\n      vQ.x = positions[b * stride];vQ.y = positions[b * stride + 1];vQ.z = positions[b * stride + 2];\n\n      callback(vP, vQ, a, b);\n    }\n\n  }\n}\n\nvar VertexEnumerator = {\n  getVertexCount: getVertexCount,\n  enumMeshVertices: enumMeshVertices,\n  enumMeshIndices: enumMeshIndices,\n  enumMeshTriangles: enumMeshTriangles,\n  enumMeshLines: enumMeshLines,\n  enumMeshEdges: enumMeshEdges };\n\n/***/ }),\n\n/***/ \"./thirdparty/zlib/unzip.min.js\":\n/*!**************************************!*\\\n  !*** ./thirdparty/zlib/unzip.min.js ***!\n  \\**************************************/\n/*! no static exports found */\n/***/ (function(module, exports) {\n\n/** @license zlib.js 2012 - imaya [ https://github.com/imaya/zlib.js ] The MIT License */(function() {'use strict';function m(a){throw a;}var p=void 0,t,aa=this;function v(a,b){var c=a.split(\".\"),d=aa;!(c[0]in d)&&d.execScript&&d.execScript(\"var \"+c[0]);for(var g;c.length&&(g=c.shift());)!c.length&&b!==p?d[g]=b:d=d[g]?d[g]:d[g]={}};var w=\"undefined\"!==typeof Uint8Array&&\"undefined\"!==typeof Uint16Array&&\"undefined\"!==typeof Uint32Array;new (w?Uint8Array:Array)(256);var x;for(x=0;256>x;++x)for(var y=x,ba=7,y=y>>>1;y;y>>>=1)--ba;var z=[0,1996959894,3993919788,2567524794,124634137,1886057615,3915621685,2657392035,249268274,2044508324,3772115230,2547177864,162941995,2125561021,3887607047,2428444049,498536548,1789927666,4089016648,2227061214,450548861,1843258603,4107580753,2211677639,325883990,1684777152,4251122042,2321926636,335633487,1661365465,4195302755,2366115317,997073096,1281953886,3579855332,2724688242,1006888145,1258607687,3524101629,2768942443,901097722,1119000684,3686517206,2898065728,853044451,1172266101,3705015759,\n2882616665,651767980,1373503546,3369554304,3218104598,565507253,1454621731,3485111705,3099436303,671266974,1594198024,3322730930,2970347812,795835527,1483230225,3244367275,3060149565,1994146192,31158534,2563907772,4023717930,1907459465,112637215,2680153253,3904427059,2013776290,251722036,2517215374,3775830040,2137656763,141376813,2439277719,3865271297,1802195444,476864866,2238001368,4066508878,1812370925,453092731,2181625025,4111451223,1706088902,314042704,2344532202,4240017532,1658658271,366619977,\n2362670323,4224994405,1303535960,984961486,2747007092,3569037538,1256170817,1037604311,2765210733,3554079995,1131014506,879679996,2909243462,3663771856,1141124467,855842277,2852801631,3708648649,1342533948,654459306,3188396048,3373015174,1466479909,544179635,3110523913,3462522015,1591671054,702138776,2966460450,3352799412,1504918807,783551873,3082640443,3233442989,3988292384,2596254646,62317068,1957810842,3939845945,2647816111,81470997,1943803523,3814918930,2489596804,225274430,2053790376,3826175755,\n2466906013,167816743,2097651377,4027552580,2265490386,503444072,1762050814,4150417245,2154129355,426522225,1852507879,4275313526,2312317920,282753626,1742555852,4189708143,2394877945,397917763,1622183637,3604390888,2714866558,953729732,1340076626,3518719985,2797360999,1068828381,1219638859,3624741850,2936675148,906185462,1090812512,3747672003,2825379669,829329135,1181335161,3412177804,3160834842,628085408,1382605366,3423369109,3138078467,570562233,1426400815,3317316542,2998733608,733239954,1555261956,\n3268935591,3050360625,752459403,1541320221,2607071920,3965973030,1969922972,40735498,2617837225,3943577151,1913087877,83908371,2512341634,3803740692,2075208622,213261112,2463272603,3855990285,2094854071,198958881,2262029012,4057260610,1759359992,534414190,2176718541,4139329115,1873836001,414664567,2282248934,4279200368,1711684554,285281116,2405801727,4167216745,1634467795,376229701,2685067896,3608007406,1308918612,956543938,2808555105,3495958263,1231636301,1047427035,2932959818,3654703836,1088359270,\n936918E3,2847714899,3736837829,1202900863,817233897,3183342108,3401237130,1404277552,615818150,3134207493,3453421203,1423857449,601450431,3009837614,3294710456,1567103746,711928724,3020668471,3272380065,1510334235,755167117],A=w?new Uint32Array(z):z;function B(a){var b=a.length,c=0,d=Number.POSITIVE_INFINITY,g,f,h,e,k,l,q,s,r;for(s=0;s<b;++s)a[s]>c&&(c=a[s]),a[s]<d&&(d=a[s]);g=1<<c;f=new (w?Uint32Array:Array)(g);h=1;e=0;for(k=2;h<=c;){for(s=0;s<b;++s)if(a[s]===h){l=0;q=e;for(r=0;r<h;++r)l=l<<1|q&1,q>>=1;for(r=l;r<g;r+=k)f[r]=h<<16|s;++e}++h;e<<=1;k<<=1}return[f,c,d]};var C=[],D;for(D=0;288>D;D++)switch(!0){case 143>=D:C.push([D+48,8]);break;case 255>=D:C.push([D-144+400,9]);break;case 279>=D:C.push([D-256+0,7]);break;case 287>=D:C.push([D-280+192,8]);break;default:m(\"invalid literal: \"+D)}\nvar ca=function(){function a(a){switch(!0){case 3===a:return[257,a-3,0];case 4===a:return[258,a-4,0];case 5===a:return[259,a-5,0];case 6===a:return[260,a-6,0];case 7===a:return[261,a-7,0];case 8===a:return[262,a-8,0];case 9===a:return[263,a-9,0];case 10===a:return[264,a-10,0];case 12>=a:return[265,a-11,1];case 14>=a:return[266,a-13,1];case 16>=a:return[267,a-15,1];case 18>=a:return[268,a-17,1];case 22>=a:return[269,a-19,2];case 26>=a:return[270,a-23,2];case 30>=a:return[271,a-27,2];case 34>=a:return[272,\na-31,2];case 42>=a:return[273,a-35,3];case 50>=a:return[274,a-43,3];case 58>=a:return[275,a-51,3];case 66>=a:return[276,a-59,3];case 82>=a:return[277,a-67,4];case 98>=a:return[278,a-83,4];case 114>=a:return[279,a-99,4];case 130>=a:return[280,a-115,4];case 162>=a:return[281,a-131,5];case 194>=a:return[282,a-163,5];case 226>=a:return[283,a-195,5];case 257>=a:return[284,a-227,5];case 258===a:return[285,a-258,0];default:m(\"invalid length: \"+a)}}var b=[],c,d;for(c=3;258>=c;c++)d=a(c),b[c]=d[2]<<24|d[1]<<\n16|d[0];return b}();w&&new Uint32Array(ca);function E(a,b){this.l=[];this.m=32768;this.d=this.f=this.c=this.t=0;this.input=w?new Uint8Array(a):a;this.u=!1;this.n=F;this.K=!1;if(b||!(b={}))b.index&&(this.c=b.index),b.bufferSize&&(this.m=b.bufferSize),b.bufferType&&(this.n=b.bufferType),b.resize&&(this.K=b.resize);switch(this.n){case G:this.a=32768;this.b=new (w?Uint8Array:Array)(32768+this.m+258);break;case F:this.a=0;this.b=new (w?Uint8Array:Array)(this.m);this.e=this.W;this.B=this.R;this.q=this.V;break;default:m(Error(\"invalid inflate mode\"))}}\nvar G=0,F=1;\nE.prototype.r=function(){for(;!this.u;){var a=H(this,3);a&1&&(this.u=!0);a>>>=1;switch(a){case 0:var b=this.input,c=this.c,d=this.b,g=this.a,f=p,h=p,e=p,k=d.length,l=p;this.d=this.f=0;f=b[c++];f===p&&m(Error(\"invalid uncompressed block header: LEN (first byte)\"));h=f;f=b[c++];f===p&&m(Error(\"invalid uncompressed block header: LEN (second byte)\"));h|=f<<8;f=b[c++];f===p&&m(Error(\"invalid uncompressed block header: NLEN (first byte)\"));e=f;f=b[c++];f===p&&m(Error(\"invalid uncompressed block header: NLEN (second byte)\"));e|=\nf<<8;h===~e&&m(Error(\"invalid uncompressed block header: length verify\"));c+h>b.length&&m(Error(\"input buffer is broken\"));switch(this.n){case G:for(;g+h>d.length;){l=k-g;h-=l;if(w)d.set(b.subarray(c,c+l),g),g+=l,c+=l;else for(;l--;)d[g++]=b[c++];this.a=g;d=this.e();g=this.a}break;case F:for(;g+h>d.length;)d=this.e({H:2});break;default:m(Error(\"invalid inflate mode\"))}if(w)d.set(b.subarray(c,c+h),g),g+=h,c+=h;else for(;h--;)d[g++]=b[c++];this.c=c;this.a=g;this.b=d;break;case 1:this.q(da,ea);break;\ncase 2:fa(this);break;default:m(Error(\"unknown BTYPE: \"+a))}}return this.B()};\nvar I=[16,17,18,0,8,7,9,6,10,5,11,4,12,3,13,2,14,1,15],J=w?new Uint16Array(I):I,K=[3,4,5,6,7,8,9,10,11,13,15,17,19,23,27,31,35,43,51,59,67,83,99,115,131,163,195,227,258,258,258],L=w?new Uint16Array(K):K,ga=[0,0,0,0,0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,5,5,5,5,0,0,0],O=w?new Uint8Array(ga):ga,ha=[1,2,3,4,5,7,9,13,17,25,33,49,65,97,129,193,257,385,513,769,1025,1537,2049,3073,4097,6145,8193,12289,16385,24577],ia=w?new Uint16Array(ha):ha,ja=[0,0,0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,\n12,12,13,13],P=w?new Uint8Array(ja):ja,Q=new (w?Uint8Array:Array)(288),R,la;R=0;for(la=Q.length;R<la;++R)Q[R]=143>=R?8:255>=R?9:279>=R?7:8;var da=B(Q),S=new (w?Uint8Array:Array)(30),T,ma;T=0;for(ma=S.length;T<ma;++T)S[T]=5;var ea=B(S);function H(a,b){for(var c=a.f,d=a.d,g=a.input,f=a.c,h;d<b;)h=g[f++],h===p&&m(Error(\"input buffer is broken\")),c|=h<<d,d+=8;h=c&(1<<b)-1;a.f=c>>>b;a.d=d-b;a.c=f;return h}\nfunction U(a,b){for(var c=a.f,d=a.d,g=a.input,f=a.c,h=b[0],e=b[1],k,l,q;d<e;){k=g[f++];if(k===p)break;c|=k<<d;d+=8}l=h[c&(1<<e)-1];q=l>>>16;a.f=c>>q;a.d=d-q;a.c=f;return l&65535}\nfunction fa(a){function b(a,b,c){var d,e,f,g;for(g=0;g<a;)switch(d=U(this,b),d){case 16:for(f=3+H(this,2);f--;)c[g++]=e;break;case 17:for(f=3+H(this,3);f--;)c[g++]=0;e=0;break;case 18:for(f=11+H(this,7);f--;)c[g++]=0;e=0;break;default:e=c[g++]=d}return c}var c=H(a,5)+257,d=H(a,5)+1,g=H(a,4)+4,f=new (w?Uint8Array:Array)(J.length),h,e,k,l;for(l=0;l<g;++l)f[J[l]]=H(a,3);h=B(f);e=new (w?Uint8Array:Array)(c);k=new (w?Uint8Array:Array)(d);a.q(B(b.call(a,c,h,e)),B(b.call(a,d,h,k)))}t=E.prototype;\nt.q=function(a,b){var c=this.b,d=this.a;this.C=a;for(var g=c.length-258,f,h,e,k;256!==(f=U(this,a));)if(256>f)d>=g&&(this.a=d,c=this.e(),d=this.a),c[d++]=f;else{h=f-257;k=L[h];0<O[h]&&(k+=H(this,O[h]));f=U(this,b);e=ia[f];0<P[f]&&(e+=H(this,P[f]));d>=g&&(this.a=d,c=this.e(),d=this.a);for(;k--;)c[d]=c[d++-e]}for(;8<=this.d;)this.d-=8,this.c--;this.a=d};\nt.V=function(a,b){var c=this.b,d=this.a;this.C=a;for(var g=c.length,f,h,e,k;256!==(f=U(this,a));)if(256>f)d>=g&&(c=this.e(),g=c.length),c[d++]=f;else{h=f-257;k=L[h];0<O[h]&&(k+=H(this,O[h]));f=U(this,b);e=ia[f];0<P[f]&&(e+=H(this,P[f]));d+k>g&&(c=this.e(),g=c.length);for(;k--;)c[d]=c[d++-e]}for(;8<=this.d;)this.d-=8,this.c--;this.a=d};\nt.e=function(){var a=new (w?Uint8Array:Array)(this.a-32768),b=this.a-32768,c,d,g=this.b;if(w)a.set(g.subarray(32768,a.length));else{c=0;for(d=a.length;c<d;++c)a[c]=g[c+32768]}this.l.push(a);this.t+=a.length;if(w)g.set(g.subarray(b,b+32768));else for(c=0;32768>c;++c)g[c]=g[b+c];this.a=32768;return g};\nt.W=function(a){var b,c=this.input.length/this.c+1|0,d,g,f,h=this.input,e=this.b;a&&(\"number\"===typeof a.H&&(c=a.H),\"number\"===typeof a.P&&(c+=a.P));2>c?(d=(h.length-this.c)/this.C[2],f=258*(d/2)|0,g=f<e.length?e.length+f:e.length<<1):g=e.length*c;w?(b=new Uint8Array(g),b.set(e)):b=e;return this.b=b};\nt.B=function(){var a=0,b=this.b,c=this.l,d,g=new (w?Uint8Array:Array)(this.t+(this.a-32768)),f,h,e,k;if(0===c.length)return w?this.b.subarray(32768,this.a):this.b.slice(32768,this.a);f=0;for(h=c.length;f<h;++f){d=c[f];e=0;for(k=d.length;e<k;++e)g[a++]=d[e]}f=32768;for(h=this.a;f<h;++f)g[a++]=b[f];this.l=[];return this.buffer=g};\nt.R=function(){var a,b=this.a;w?this.K?(a=new Uint8Array(b),a.set(this.b.subarray(0,b))):a=this.b.subarray(0,b):(this.b.length>b&&(this.b.length=b),a=this.b);return this.buffer=a};function V(a){a=a||{};this.files=[];this.v=a.comment}V.prototype.L=function(a){this.j=a};V.prototype.s=function(a){var b=a[2]&65535|2;return b*(b^1)>>8&255};V.prototype.k=function(a,b){a[0]=(A[(a[0]^b)&255]^a[0]>>>8)>>>0;a[1]=(6681*(20173*(a[1]+(a[0]&255))>>>0)>>>0)+1>>>0;a[2]=(A[(a[2]^a[1]>>>24)&255]^a[2]>>>8)>>>0};V.prototype.T=function(a){var b=[305419896,591751049,878082192],c,d;w&&(b=new Uint32Array(b));c=0;for(d=a.length;c<d;++c)this.k(b,a[c]&255);return b};function W(a,b){b=b||{};this.input=w&&a instanceof Array?new Uint8Array(a):a;this.c=0;this.ba=b.verify||!1;this.j=b.password}var na={O:0,M:8},X=[80,75,1,2],Y=[80,75,3,4],Z=[80,75,5,6];function oa(a,b){this.input=a;this.offset=b}\noa.prototype.parse=function(){var a=this.input,b=this.offset;(a[b++]!==X[0]||a[b++]!==X[1]||a[b++]!==X[2]||a[b++]!==X[3])&&m(Error(\"invalid file header signature\"));this.version=a[b++];this.ia=a[b++];this.Z=a[b++]|a[b++]<<8;this.I=a[b++]|a[b++]<<8;this.A=a[b++]|a[b++]<<8;this.time=a[b++]|a[b++]<<8;this.U=a[b++]|a[b++]<<8;this.p=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.z=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.J=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.h=a[b++]|a[b++]<<\n8;this.g=a[b++]|a[b++]<<8;this.F=a[b++]|a[b++]<<8;this.ea=a[b++]|a[b++]<<8;this.ga=a[b++]|a[b++]<<8;this.fa=a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24;this.$=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.filename=String.fromCharCode.apply(null,w?a.subarray(b,b+=this.h):a.slice(b,b+=this.h));this.X=w?a.subarray(b,b+=this.g):a.slice(b,b+=this.g);this.v=w?a.subarray(b,b+this.F):a.slice(b,b+this.F);this.length=b-this.offset};function pa(a,b){this.input=a;this.offset=b}var qa={N:1,ca:8,da:2048};\npa.prototype.parse=function(){var a=this.input,b=this.offset;(a[b++]!==Y[0]||a[b++]!==Y[1]||a[b++]!==Y[2]||a[b++]!==Y[3])&&m(Error(\"invalid local file header signature\"));this.Z=a[b++]|a[b++]<<8;this.I=a[b++]|a[b++]<<8;this.A=a[b++]|a[b++]<<8;this.time=a[b++]|a[b++]<<8;this.U=a[b++]|a[b++]<<8;this.p=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.z=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.J=(a[b++]|a[b++]<<8|a[b++]<<16|a[b++]<<24)>>>0;this.h=a[b++]|a[b++]<<8;this.g=a[b++]|a[b++]<<8;this.filename=\nString.fromCharCode.apply(null,w?a.subarray(b,b+=this.h):a.slice(b,b+=this.h));this.X=w?a.subarray(b,b+=this.g):a.slice(b,b+=this.g);this.length=b-this.offset};\nfunction $(a){var b=[],c={},d,g,f,h;if(!a.i){if(a.o===p){var e=a.input,k;if(!a.D)a:{var l=a.input,q;for(q=l.length-12;0<q;--q)if(l[q]===Z[0]&&l[q+1]===Z[1]&&l[q+2]===Z[2]&&l[q+3]===Z[3]){a.D=q;break a}m(Error(\"End of Central Directory Record not found\"))}k=a.D;(e[k++]!==Z[0]||e[k++]!==Z[1]||e[k++]!==Z[2]||e[k++]!==Z[3])&&m(Error(\"invalid signature\"));a.ha=e[k++]|e[k++]<<8;a.ja=e[k++]|e[k++]<<8;a.ka=e[k++]|e[k++]<<8;a.aa=e[k++]|e[k++]<<8;a.Q=(e[k++]|e[k++]<<8|e[k++]<<16|e[k++]<<24)>>>0;a.o=(e[k++]|\ne[k++]<<8|e[k++]<<16|e[k++]<<24)>>>0;a.w=e[k++]|e[k++]<<8;a.v=w?e.subarray(k,k+a.w):e.slice(k,k+a.w)}d=a.o;f=0;for(h=a.aa;f<h;++f)g=new oa(a.input,d),g.parse(),d+=g.length,b[f]=g,c[g.filename]=f;a.Q<d-a.o&&m(Error(\"invalid file header size\"));a.i=b;a.G=c}}t=W.prototype;t.Y=function(){var a=[],b,c,d;this.i||$(this);d=this.i;b=0;for(c=d.length;b<c;++b)a[b]=d[b].filename;return a};\nt.r=function(a,b){var c;this.G||$(this);c=this.G[a];c===p&&m(Error(a+\" not found\"));var d;d=b||{};var g=this.input,f=this.i,h,e,k,l,q,s,r,M;f||$(this);f[c]===p&&m(Error(\"wrong index\"));e=f[c].$;h=new pa(this.input,e);h.parse();e+=h.length;k=h.z;if(0!==(h.I&qa.N)){!d.password&&!this.j&&m(Error(\"please set password\"));s=this.S(d.password||this.j);r=e;for(M=e+12;r<M;++r)ra(this,s,g[r]);e+=12;k-=12;r=e;for(M=e+k;r<M;++r)g[r]=ra(this,s,g[r])}switch(h.A){case na.O:l=w?this.input.subarray(e,e+k):this.input.slice(e,\ne+k);break;case na.M:l=(new E(this.input,{index:e,bufferSize:h.J})).r();break;default:m(Error(\"unknown compression type\"))}if(this.ba){var u=p,n,N=\"number\"===typeof u?u:u=0,ka=l.length;n=-1;for(N=ka&7;N--;++u)n=n>>>8^A[(n^l[u])&255];for(N=ka>>3;N--;u+=8)n=n>>>8^A[(n^l[u])&255],n=n>>>8^A[(n^l[u+1])&255],n=n>>>8^A[(n^l[u+2])&255],n=n>>>8^A[(n^l[u+3])&255],n=n>>>8^A[(n^l[u+4])&255],n=n>>>8^A[(n^l[u+5])&255],n=n>>>8^A[(n^l[u+6])&255],n=n>>>8^A[(n^l[u+7])&255];q=(n^4294967295)>>>0;h.p!==q&&m(Error(\"wrong crc: file=0x\"+\nh.p.toString(16)+\", data=0x\"+q.toString(16)))}return l};t.L=function(a){this.j=a};function ra(a,b,c){c^=a.s(b);a.k(b,c);return c}t.k=V.prototype.k;t.S=V.prototype.T;t.s=V.prototype.s;v(\"Zlib.Unzip\",W);v(\"Zlib.Unzip.prototype.decompress\",W.prototype.r);v(\"Zlib.Unzip.prototype.getFilenames\",W.prototype.Y);v(\"Zlib.Unzip.prototype.setPassword\",W.prototype.L);}).call(this);\n\n\n/***/ })\n\n/******/ });\n//# sourceMappingURL=3eef7c88799c68fd9fc3.worker.js.map", __webpack_require__.p + "3eef7c88799c68fd9fc3.worker.js");
};

/***/ }),

/***/ "./node_modules/worker-loader/dist/workers/InlineWorker.js":
/*!*****************************************************************!*\
  !*** ./node_modules/worker-loader/dist/workers/InlineWorker.js ***!
  \*****************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";


// http://stackoverflow.com/questions/10343913/how-to-create-a-web-worker-from-a-string

var URL = window.URL || window.webkitURL;

module.exports = function (content, url) {
  try {
    try {
      var blob;

      try {
        // BlobBuilder = Deprecated, but widely implemented
        var BlobBuilder = window.BlobBuilder || window.WebKitBlobBuilder || window.MozBlobBuilder || window.MSBlobBuilder;

        blob = new BlobBuilder();

        blob.append(content);

        blob = blob.getBlob();
      } catch (e) {
        // The proposed API
        blob = new Blob([content]);
      }

      return new Worker(URL.createObjectURL(blob));
    } catch (e) {
      return new Worker('data:application/javascript,' + encodeURIComponent(content));
    }
  } catch (e) {
    if (!url) {
      throw Error('Inline worker is not supported');
    }

    return new Worker(url);
  }
};

/***/ })

/******/ });
//# sourceMappingURL=MemoryLimited.js.map